#!/usr/bin/env python3

import json
import os
import re
import numpy as np
import faiss
import pickle
from typing import Dict, List, Any, Optional
import tiktoken
import time
import pickle

class TennisChatAgentEmbeddingQALocal:
    """
    Tennis Chat Agent using LOCAL embedding model (sentence-transformers) and LLM for answering.
    Uses FREE local embeddings with sophisticated retrieval logic.
    Supports Claude, Gemini, and OpenAI for answering questions.
    """
    
    # ══════════════════════════════════════════════════════════════════════════════
    # VAGUE TERM → METRIC MAPPING SYSTEM
    # Converts "vague" analytical terms into computable metric bundles
    # ══════════════════════════════════════════════════════════════════════════════
    
    # Step 1: Normalize synonyms to canonical tokens
    TERM_NORMALIZATION = {
        # Performance variants
        "perform": "performance", "performed": "performance", "performing": "performance",
        # Effectiveness variants
        "effective": "effectiveness", "ineffective": "effectiveness",
        # Efficiency variants
        "efficient": "efficiency", "inefficient": "efficiency",
        # Aggression variants
        "aggressive": "aggression", "aggressively": "aggression", "aggressor": "aggression",
        # Control variants
        "control": "control", "controlled": "control", "controlling": "control", "dictate": "control", "dictated": "control",
        # Consistency variants
        "consistent": "consistency", "consistently": "consistency", "inconsistent": "consistency",
        # Pressure variants
        "pressure": "pressure", "clutch": "pressure", "tight": "pressure",
        # Risk variants
        "risky": "risk", "risk-taking": "risk", "risks": "risk",
        # Momentum variants
        "momentum": "momentum", "shift": "momentum", "shifted": "momentum", "turning point": "momentum",
        # Dominance variants
        "dominant": "dominance", "dominated": "dominance", "dominate": "dominance", "dominating": "dominance",
    }
    
    # Step 2: Map canonical terms to metric bundles
    # Each term maps to context-specific metric bundles
    VAGUE_TERM_MAP = {
        "performance": {
            "description": "How well did outcomes align with opportunity?",
            "default": ["win_percentage", "winners", "unforced_errors"],
            "serve": ["first_serve_pct", "first_serve_win_pct", "second_serve_win_pct", "aces", "double_faults"],
            "return": ["return_points_won_pct", "return_winners", "break_point_conversion"],
            "rally": ["win_percentage", "winners", "forced_errors"],
        },
        "effectiveness": {
            "description": "Did an action produce the intended advantage?",
            "default": ["win_percentage", "forced_errors", "winners"],
            "serve": ["first_serve_win_pct", "second_serve_win_pct", "service_winners"],
            "return": ["return_points_won_pct", "return_winners"],
            "net": ["net_points_won_pct", "volley_winners"],
        },
        "efficiency": {
            "description": "How much value per unit effort?",
            "default": ["win_percentage", "avg_rally_length", "winners"],
            "serve": ["first_serve_pct", "aces", "service_winners"],
            "rally": ["win_percentage", "avg_rally_length", "short_rally_win_pct"],
        },
        "aggression": {
            "description": "Intent to shorten points and take risk.",
            "default": ["winners", "unforced_errors", "avg_rally_length"],
            "serve": ["aces", "first_serve_pct", "service_winners"],
            "rally": ["winners", "avg_rally_length", "net_approaches"],
            "net": ["net_points_won", "volley_winners"],
        },
        "control": {
            "description": "Who imposed structure on rallies?",
            "default": ["win_percentage", "long_rally_win_pct", "forced_errors"],
            "rally": ["win_percentage", "avg_rally_length", "forced_errors"],
            "serve": ["first_serve_pct", "first_serve_win_pct"],
        },
        "consistency": {
            "description": "Stability of execution over time.",
            "default": ["unforced_errors", "first_serve_pct", "win_percentage"],
            "serve": ["first_serve_pct", "double_faults", "first_serve_win_pct"],
            "rally": ["unforced_errors", "avg_rally_length"],
        },
        "pressure": {
            "description": "Performance under elevated leverage.",
            "default": ["win_percentage", "unforced_errors"],  # Applied to break_point filter
            "break_point": ["break_point_conversion", "break_point_saves", "win_percentage"],
            "serve": ["break_point_saves", "win_percentage"],
            "return": ["break_point_conversion", "win_percentage"],
        },
        "risk": {
            "description": "Volatility vs payoff.",
            "default": ["winners", "unforced_errors"],
            "rally": ["winners", "unforced_errors", "avg_rally_length"],
        },
        "momentum": {
            "description": "Short-term outcome correlation.",
            "default": ["win_percentage"],  # Applied across sets/games
            "group_by": "sets",  # Force grouping by sets to show progression
        },
        "dominance": {
            "description": "Sustained advantage across contexts.",
            "default": ["win_percentage", "winners", "unforced_errors"],
            "serve": ["serve_points_won_pct", "aces"],
            "return": ["return_points_won_pct", "break_point_conversion"],
        },
    }
    
    # ══════════════════════════════════════════════════════════════════════════════
    # GLOBAL CONSTANTS - Used throughout the codebase
    # ══════════════════════════════════════════════════════════════════════════════
    
    # All winner outcome types (referenced in multiple places)
    WINNER_TYPES = {
        'winner',           # Generic winner (groundstroke)
        'volley_winner',    # Winner at net via volley
        'specialty_winner', # Drop shot, lob, etc.
        'net_winner',       # Generic net winner
        'overhead_winner',  # Smash/overhead winner
        'drop_shot_winner', # Drop shot winner
    }
    
    # Metrics where "win rate" doesn't make sense (self-evident outcomes)
    SELF_EVIDENT_OUTCOME_METRICS = {
        'winners', 'groundstroke_winners', 'baseline_winners', 'rally_winners',
        'aces', 'service_winners',
        'unforced_errors', 'forced_errors', 'induced_forced_errors',
        'double_faults',
    }
    
    # Terms indicating "both players" (not a specific player filter)
    BOTH_PLAYER_INDICATORS = {
        'both', 'each', 'both players', 'each player', 'either player',
        'both player', 'which player', 'who', 'compare players', 
        'player comparison', 'players compared', 'each of the players',
        'all players', 'every player', 'per player', 'by player',
        'the players', 'comparison', 'compare',
    }
    
    # When grouping by X, exclude these filters (they're dimensions, not filters)
    GROUP_TO_FILTER_EXCLUSIONS = {
        'rally_length_category': ['rally_length'],
        'player': ['player'],
        'sets': ['set'],
        'set_groups': ['set'],
        'court_side': ['court_side'],
        'serve_number': ['serve_number'],
        'shot_type': ['shot_type', 'shot_base'],
        'serve_direction': ['serve_target'],
        'situation': ['situation'],
    }
    
    # ══════════════════════════════════════════════════════════════════════════════
    # OUTCOME CONFIGURATION - Maps outcome strings to their properties
    # ══════════════════════════════════════════════════════════════════════════════
    OUTCOME_CONFIG = {
        'WINNER': {
            'winning_shot_type': 'winner',
            'point_ends_match': True,
            'player_attribution': 'winner',  # Who hit the shot
            'is_positive': True,  # Good for the player who hit it
        },
        'ACE': {
            'winning_shot_type': 'ace',
            'point_ends_match': True,
            'player_attribution': 'server',
            'is_positive': True,
        },
        'SERVICE_WINNER': {
            'winning_shot_type': 'service_winner',
            'point_ends_match': True,
            'player_attribution': 'server',
            'is_positive': True,
        },
        'DOUBLE_FAULT': {
            'winning_shot_type': 'double_fault',
            'point_ends_match': True,
            'player_attribution': 'server',
            'is_positive': False,  # Bad for server
        },
        'UNFORCED ERROR': {
            'winning_shot_type': 'unforced_error',
            'point_ends_match': True,
            'player_attribution': 'error',
            'is_positive': False,
        },
        'FORCED ERROR': {
            'winning_shot_type': 'forced_error',
            'point_ends_match': True,
            'player_attribution': 'error',
            'is_positive': False,
        },
    }
    
    # ══════════════════════════════════════════════════════════════════════════════
    # SITUATION CONFIGURATION - Maps situations to their detection logic
    # ══════════════════════════════════════════════════════════════════════════════
    SITUATION_CONFIG = {
        'break_point': {
            'detection_method': '_is_break_point_score',
            'score_patterns': ['0-40', '15-40', '30-40', 'AD-OUT'],
            'role_context': 'returner_advantage',
        },
        'game_point': {
            'detection_method': '_is_game_point_score',
            'score_patterns': ['40-0', '40-15', '40-30', 'AD-IN'],
            'role_context': 'server_advantage',
        },
        'set_point': {
            'detection_method': '_is_set_point_score',
            'score_patterns': [],  # Complex logic
            'role_context': 'varies',
        },
        'match_point': {
            'detection_method': '_is_match_point_score',
            'score_patterns': [],  # Complex logic
            'role_context': 'varies',
        },
        'deuce': {
            'detection_method': '_is_deuce_score',
            'score_patterns': ['40-40', 'DEUCE'],
            'role_context': 'neutral',
        },
        'tiebreak': {
            'detection_method': '_is_tiebreak',
            'score_patterns': [],
            'role_context': 'neutral',
        },
    }
    
    # ══════════════════════════════════════════════════════════════════════════════
    # ROLE CONFIGURATION - Maps roles to player resolution
    # ══════════════════════════════════════════════════════════════════════════════
    ROLE_CONFIG = {
        'server': {
            'player_field': 'server',
            'opposite_role': 'returner',
            'domain': 'serve',
        },
        'returner': {
            'player_field': 'returner',
            'opposite_role': 'server',
            'domain': 'return',
        },
        'winner': {
            'player_field': 'point_winner',
            'opposite_role': 'loser',
            'domain': None,
        },
        'error': {
            'player_field': 'error_player',
            'opposite_role': 'winner',
            'domain': None,
        },
    }
    
    # ══════════════════════════════════════════════════════════════════════════════
    # DOMAIN CONFIGURATION - Maps domains to their properties
    # ══════════════════════════════════════════════════════════════════════════════
    DOMAIN_CONFIG = {
        'serve': {
            'role': 'server',
            'default_metrics': ['first_serve_pct', 'first_serve_win_pct', 'aces', 'double_faults'],
            'player_field': 'server',
        },
        'return': {
            'role': 'returner',
            'default_metrics': ['return_points_won_pct', 'return_winners'],
            'player_field': 'returner',
        },
        'rally': {
            'role': None,
            'default_metrics': ['win_percentage', 'winners', 'unforced_errors'],
            'player_field': None,
        },
        'net': {
            'role': None,
            'default_metrics': ['net_points_won', 'volley_winners'],
            'player_field': None,
        },
    }
    
    # ══════════════════════════════════════════════════════════════════════════════
    # COURT SIDE CONFIGURATION - Maps court sides to their properties
    # ══════════════════════════════════════════════════════════════════════════════
    COURT_SIDE_CONFIG = {
        'deuce': {
            'game_score_patterns': ['0-', '30-', 'deuce'],
            'aliases': ['deuce', 'right'],
        },
        'ad': {
            'game_score_patterns': ['15-', '40-', 'AD'],
            'aliases': ['ad', 'advantage', 'left'],
        },
    }
    
    # ══════════════════════════════════════════════════════════════════════════════
    # COURT ZONE CONFIGURATION - Maps court zones to their properties
    # ══════════════════════════════════════════════════════════════════════════════
    COURT_ZONE_CONFIG = {
        'net': {
            'detection_fields': ['at_net', 'court_position'],
            'detection_value': True,
            'shot_modifiers': ['volley', 'half_volley', 'overhead', 'swinging_volley', 'drop_volley'],
        },
        'baseline': {
            'detection_fields': ['at_net'],
            'detection_value': False,
            'shot_modifiers': [],
        },
    }
    
    # ══════════════════════════════════════════════════════════════════════════════
    # GROUP BY CONFIGURATION - Maps group_by values to their grouping logic
    # FULLY VARIABLE-DRIVEN: Add new groupings here, no code changes needed!
    # ══════════════════════════════════════════════════════════════════════════════
    GROUP_CONFIG = {
        'player': {
            'extraction_method': 'metric_aware',  # Uses METRIC_CONFIG to determine player_field
            'metadata_path': None,  # Determined dynamically
            'normalize': None,
            'display_source': 'custom',  # Special: uses player1/player2 names
            'custom_display': 'get_player_display',  # String identifier
            'display_type': 'player',  # Each group IS a player
        },
        'serve_number': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['serve_info', 'serve_number'],
            'normalize': lambda v: '2nd' if v == 2 else '1st',
            'fallback': lambda point_lower: '2nd' if '2nd serve' in point_lower or 'fault' in point_lower[:50] else '1st',
            'display_source': 'inventory',
            'inventory_key': 'serve_numbers',
            'default_branches': ['1st', '2nd'],
            'display_labels': {'1st': '1st Serve', '2nd': '2nd Serve', '1': '1st Serve', '2': '2nd Serve'},
        },
        'serve_direction': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['serve_info', 'target'],
            'normalize': None,
            'display_source': 'inventory',
            'inventory_key': 'serve_targets',
            'default_branches': ['wide', 'body', 't'],
            'display_labels': {'wide': 'Wide', 'body': 'Body', 't': 'T (Down the Middle)'},
            'display_type': 'role_based',  # Shows returner perspective
        },
        'shot_type': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['winning_shot', 'shot_type'],
            'normalize': None,
            'display_source': 'inventory',
            'inventory_key': 'shot_types',
            'default_branches': ['forehand', 'backhand'],
            'display_labels': {'forehand': 'Forehand', 'backhand': 'Backhand', 'volley': 'Volley', 'overhead': 'Overhead/Smash', 'drop_shot': 'Drop Shot', 'serve': 'Serve'},
            'include_modifiers': True,  # Also include shot_modifiers from inventory
        },
        'shot_direction': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['winning_shot', 'direction'],
            'normalize': None,
            'display_source': 'inventory',
            'inventory_key': 'directions',
            'default_branches': ['crosscourt', 'down_the_line', 'inside_out', 'inside_in', 'down_the_middle'],
            'display_labels': {'crosscourt': 'Crosscourt', 'down_the_line': 'Down the Line', 'inside_out': 'Inside-Out', 'inside_in': 'Inside-In', 'down_the_middle': 'Down the Middle'},
        },
        'shot_modifier': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['winning_shot', 'shot_modifier'],
            'normalize': None,
            'display_source': 'inventory',
            'inventory_key': 'shot_modifiers',
            'default_branches': ['slice', 'volley', 'drop_shot', 'approach'],
        },
        'depth': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['winning_shot', 'depth'],
            'normalize': None,
            'display_source': 'inventory',
            'inventory_key': 'depths',
            'default_branches': ['shallow', 'deep', 'very_deep'],
            'display_labels': {'shallow': 'Shallow', 'deep': 'Deep', 'very_deep': 'Very Deep'},
        },
        'court_zone': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['winning_shot', 'court_position'],
            'normalize': None,
            'display_source': 'inventory',
            'inventory_key': 'court_positions',
            'default_branches': ['baseline', 'net', 'approach'],
        },
        'court_position': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['winning_shot', 'court_position'],
            'normalize': None,
            'display_source': 'inventory',
            'inventory_key': 'court_positions',
            'default_branches': ['baseline', 'net', 'approach'],
            'display_labels': {'baseline': 'Baseline', 'net': 'Net', 'approach': 'Approach'},
        },
        'spin': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['winning_shot', 'spin'],
            'normalize': None,
            'display_source': 'inventory',
            'inventory_key': 'spin_types',
            'default_branches': ['topspin', 'slice', 'flat'],
            'display_labels': {'topspin': 'Topspin', 'slice': 'Slice', 'flat': 'Flat'},
        },
        'return_depth': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['return_info', 'return_depth'],
            'normalize': lambda v: v or 'unspecified',
            'display_source': 'inventory',
            'inventory_key': 'depths',
            'default_branches': ['shallow', 'deep', 'very_deep'],
            'display_labels': {'shallow': 'Shallow', 'deep': 'Deep', 'very_deep': 'Very Deep', 'unspecified': 'Unspecified'},
            'always_include': ['unspecified'],  # Always include this branch
        },
        'sets': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['set_number'],
            'normalize': lambda v: str(v) if v else None,
            'fallback': 'extract_current_set',  # Special fallback identifier
            'display_source': 'inventory',
            'inventory_key': 'sets_played',
            'default_branches': [1, 2, 3, 4, 5],
            'display_labels': lambda v: f'Set {v}',  # Function to format
        },
        'set': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['set_number'],
            'normalize': lambda v: f"Set {v}" if v else None,
            'display_source': 'inventory',
            'inventory_key': 'sets_played',
            'default_branches': [1, 2, 3, 4, 5],
            'display_labels': lambda v: f'Set {v}',
        },
        'set_groups': {
            'extraction_method': 'custom',
            'custom_func': 'get_set_group',  # String identifier - handled in _extract_group_key
            'display_source': 'custom',
            'custom_display': 'get_set_groups_display',  # String identifier
        },
        'situation': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['situation', 'type'],
            'normalize': None,
            'display_source': 'inventory',
            'inventory_key': 'situations',
            'default_branches': ['break_point', 'game_point', 'deuce', 'set_point', 'match_point', 'tiebreak'],
        },
        'outcome': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['winning_shot', 'outcome'],
            'normalize': 'normalize_outcome',  # String identifier - handled in _extract_group_key
            'display_source': 'inventory',
            'inventory_key': 'outcomes',
            'default_branches': ['winner', 'ace', 'forced_error', 'unforced_error', 'double_fault'],
            'display_labels': {'winner': 'Winner', 'ace': 'Ace', 'forced_error': 'Forced Error (Induced)', 'unforced_error': 'Unforced Error', 'double_fault': 'Double Fault'},
        },
        'shot_number': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['rally_length'],
            'normalize': lambda v: '1' if v == 1 else '2' if v == 2 else '3' if v == 3 else '4+' if v >= 4 else None,
            'display_source': 'predefined',
            'default_branches': ['1', '2', '3', '4+'],
            'display_labels': {'1': 'Serve (1st shot)', '2': 'Return (2nd shot)', '3': 'Serve+1 (3rd shot)', '4+': 'Rally (4+ shots)'},
        },
        'rally_length_category': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['rally_category'],
            'normalize': None,
            'fallback': lambda rally_length: '1-3' if 1 <= rally_length <= 3 else '4-6' if 4 <= rally_length <= 6 else '7-9' if 7 <= rally_length <= 9 else '10+' if rally_length >= 10 else None,
            'display_source': 'inventory',
            'inventory_key': 'rally_categories',
            'default_branches': ['1-3', '4-6', '7-9', '10+'],
            'display_labels': {'1-3': 'Short (1-3 shots)', '4-6': 'Medium (4-6 shots)', '7-9': 'Extended (7-9 shots)', '10+': 'Long (10+ shots)'},
        },
        'rally_length': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['rally_length'],
            'normalize': None,
            'display_source': 'dynamic',  # Values discovered during traversal
        },
        'court_side': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['situation', 'court_side'],
            'normalize': None,
            'fallback': lambda score: 'deuce',  # Default
            'display_source': 'inventory',
            'inventory_key': 'court_sides',
            'default_branches': ['deuce', 'ad'],
            'display_labels': {'deuce': 'Deuce Court', 'ad': 'Ad Court'},
        },
        'pressure_level': {
            'extraction_method': 'filter',
            'filter_key': '_pressure_tightness',
            'normalize': lambda v: 'low' if 0 <= v <= 3 else 'medium' if 4 <= v <= 6 else 'high' if 7 <= v <= 10 else None,
            'display_source': 'inventory',
            'inventory_key': 'pressure_levels',
            'default_branches': ['low', 'medium', 'high'],
            'display_labels': {'low': 'Low Pressure (0-3)', 'medium': 'Medium Pressure (4-6)', 'high': 'High Pressure (7-10)'},
        },
        'serve_plus_one_type': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['serve_plus_one', 'shot_type'],
            'normalize': lambda v: v or 'none',
            'display_source': 'inventory',
            'inventory_key': 'serve_plus_one_shot_types',
            'default_branches': ['forehand', 'backhand', 'volley'],
            'display_labels': {'forehand': 'Serve+1 Forehand', 'backhand': 'Serve+1 Backhand', 'volley': 'Serve+1 Volley', 'none': 'No Serve+1 (ended on serve/return)'},
            'always_include': ['none'],  # Always include this branch
        },
        'after_rally_length': {
            'extraction_method': 'filter',
            'filter_key': '_prev_rally_length',
            'normalize': lambda v: 'first_point' if v == 0 else 'after_short' if 1 <= v <= 4 else 'after_medium' if 5 <= v <= 9 else 'after_long' if v >= 10 else None,
            'display_source': 'predefined',
            'default_branches': ['after_short', 'after_medium', 'after_long', 'first_point'],
            'display_labels': {'after_short': 'After Short Rally (1-4 shots)', 'after_medium': 'After Medium Rally (5-9 shots)', 'after_long': 'After Long Rally (10+ shots)', 'first_point': 'First Point (no previous rally)'},
        },
        'net_play_type': {
            'extraction_method': 'custom',
            'custom_func': 'get_net_play_type',  # String identifier - handled in _extract_group_key
            'display_source': 'inventory',
            'inventory_key': 'net_play_types',
            'default_branches': [],
        },
        'game': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['game_number_in_set'],
            'normalize': lambda v: f"Game {v}" if v else None,
            'display_source': 'dynamic',  # Values discovered during traversal
        },
        'game_overall': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['game_number_overall'],
            'normalize': lambda v: f"Game {v}" if v else None,
            'display_source': 'dynamic',  # Values discovered during traversal
        },
    }
    
    # ══════════════════════════════════════════════════════════════════════════════
    # METRIC CONFIGURATION - SINGLE SOURCE OF TRUTH
    # Defines how each metric behaves: whose metric, what counts toward denominator/numerator
    # ══════════════════════════════════════════════════════════════════════════════
    METRIC_CONFIG = {
        # Serve percentage metrics
        'first_serve_pct': {
            'player_role': 'server',
            'total_filter': 'always',
            'count_filter': 'first_serve_in'
        },
        'first_serve_win_pct': {
            'player_role': 'server',
            'total_filter': 'first_serve',
            'count_filter': 'won'
        },
        'second_serve_pct': {
            'player_role': 'server',
            'total_filter': 'second_serve',
            'count_filter': 'second_serve_in'
        },
        'second_serve_win_pct': {
            'player_role': 'server',
            'total_filter': 'second_serve',
            'count_filter': 'won'
        },
        
        # Point outcome metrics
        'points_won': {
            'player_role': 'both',
            'total_filter': 'always',
            'count_filter': 'won'
        },
        'win_percentage': {
            'player_role': 'both',
            'total_filter': 'always',
            'count_filter': 'won'
        },
        'winners': {
            'player_role': 'winner',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['winner']
        },
        'aces': {
            'player_role': 'server',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['ace']
        },
        'double_faults': {
            'player_role': 'server',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['double fault']
        },
        'forced_errors': {
            'player_role': 'winner',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['forced error']
        },
        'unforced_errors': {
            'player_role': 'error',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['unforced error']
        },
        
        # Net play metrics
        'net_points_won': {
            'player_role': 'performer',
            'total_filter': 'on_match',
            'count_filter': 'won',
            'keywords': ['volley', 'at net', 'approach']
        },
        'net_approaches': {
            'player_role': 'performer',
            'total_filter': 'on_match',
            'count_filter': 'always',
            'keywords': ['approach', 'net approach']
        },
        
        # Return metrics
        'return_winners': {
            'player_role': 'returner',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['return', 'winner']
        },
        'return_errors': {
            'player_role': 'returner',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['return', 'error']
        },
        'returns_in_play': {
            'player_role': 'returner',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['return']
        },
        
        # Shot-based outcome metrics
        'forehand_winners': {
            'player_role': 'winner',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['forehand', 'winner']
        },
        'backhand_winners': {
            'player_role': 'winner',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['backhand', 'winner']
        },
        'forehand_errors': {
            'player_role': 'error',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['forehand', 'error']
        },
        'backhand_errors': {
            'player_role': 'error',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['backhand', 'error']
        },
        
        # Rally-based metrics
        'rally_winners': {
            'player_role': 'winner',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['winner'],
            'min_rally_length': 2  # Must be a rally, not serve
        },
        'groundstroke_winners': {
            'player_role': 'winner',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['winner'],
            'min_rally_length': 2
        },
        'baseline_winners': {
            'player_role': 'winner',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['winner'],
            'exclude_modifiers': ['volley', 'overhead']
        },
        
        # Service-based metrics
        'service_winners': {
            'player_role': 'server',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['winner'],
            'max_rally_length': 1  # Must be service point
        },
        'first_serve_in': {
            'player_role': 'server',
            'total_filter': 'always',
            'count_filter': 'first_serve_in'
        },
        
        # Generic outcome metrics
        'errors': {
            'player_role': 'error',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['error']  # Matches both forced and unforced
        },
        'points_lost': {
            'player_role': 'loser',
            'total_filter': 'always',
            'count_filter': 'lost'
        },
        'induced_forced_errors': {
            'player_role': 'winner',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['forced error'],  # Must match 'forced error' specifically, not 'unforced error'
            'exclude_keywords': ['unforced']  # Exclude unforced errors
        },
        
        # Game-level metrics (aggregated from points)
        'games_won': {
            'player_role': 'game_winner',
            'total_filter': 'games',
            'count_filter': 'game_won',
            'aggregate_level': 'game'
        },
        'games_lost': {
            'player_role': 'game_loser',
            'total_filter': 'games',
            'count_filter': 'game_lost',
            'aggregate_level': 'game'
        },
        'service_games_held': {
            'player_role': 'server',
            'total_filter': 'service_games',
            'count_filter': 'game_won',
            'aggregate_level': 'game'
        },
        'breaks': {
            'player_role': 'returner',
            'total_filter': 'return_games',
            'count_filter': 'game_won',
            'aggregate_level': 'game'
        },
        'sets_won': {
            'player_role': 'set_winner',
            'total_filter': 'sets',
            'count_filter': 'set_won',
            'aggregate_level': 'set'
        },
    }
    
    def __init__(self, llm_provider: str = "gemini", api_key: str = None, model: str = None):
        """
        Initialize with specified LLM provider and LOCAL embeddings.
        
        Args:
            llm_provider: "openai", "claude", or "gemini" (for answering questions, default: gemini)
            api_key: API key for the provider (optional, will use env vars)
        """
        self.llm_provider = llm_provider.lower()
        self.api_key = api_key
        self.custom_model = model  # Allow custom model override
        self.chunks = []
        self.index = None
        self.metadata_store = []
        self.match_id = "match_data"  # Generic default, overwritten when loading match
        self.player1 = None
        self.player2 = None
        self.point_by_point = []  # Structured point-by-point data for analysis
        
        # === MATCH FILTER INVENTORY ===
        # Built once at load time - contains ALL available filter values from this match
        # LLM uses this to map queries to KNOWN filters (no guessing)
        self.match_filter_inventory = {}
        self.match_stats_summary = {}
        
        # Store last analysis result for external access
        self.last_analysis = None
        self.last_answer = None
        
        # Rate limiting
        self.last_api_call = 0
        self.min_delay = 2.0  # Minimum 2 seconds between API calls
        
        # Initialize local embedding model (FREE!)
        print("Loading LOCAL embedding model (sentence-transformers)...")
        try:
            from sentence_transformers import SentenceTransformer
            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
            self.embedding_dim = 384
            print("Local embedding model loaded (FREE)!")
        except ImportError:
            raise ImportError("Please install sentence-transformers: pip install sentence-transformers")
        
        # Initialize the appropriate LLM client
        self._init_llm_client()
    
    # ══════════════════════════════════════════════════════════════════════════════
    # GENERIC CONFIG-DRIVEN HELPER METHODS
    # These replace ALL hardcoded if/elif chains with config lookups
    # ══════════════════════════════════════════════════════════════════════════════
    
    def _get_outcome_config(self, outcome: str) -> Dict:
        """Get config for an outcome - NEVER hardcode outcome checks!"""
        return self.OUTCOME_CONFIG.get(outcome.upper() if outcome else '', {})
    
    def _get_winning_shot_type(self, outcome: str) -> str:
        """Get winning shot type from outcome - GENERIC lookup."""
        config = self._get_outcome_config(outcome)
        return config.get('winning_shot_type', '')
    
    def _get_player_for_outcome(self, outcome: str, server: str, returner: str, 
                                 point_winner: str, error_player: str) -> str:
        """Get which player is attributed to an outcome - GENERIC lookup."""
        config = self._get_outcome_config(outcome)
        attribution = config.get('player_attribution', '')
        
        # Use ROLE_CONFIG to resolve the actual player
        if attribution in self.ROLE_CONFIG:
            field = self.ROLE_CONFIG[attribution].get('player_field', '')
            players = {'server': server, 'returner': returner, 
                      'point_winner': point_winner, 'error_player': error_player}
            return players.get(field, '')
        return ''
    
    def _get_situation_config(self, situation: str) -> Dict:
        """Get config for a situation - NEVER hardcode situation checks!"""
        return self.SITUATION_CONFIG.get(situation.lower() if situation else '', {})
    
    def _check_situation(self, situation: str, score: str, game_score: str = None) -> bool:
        """Check if a score matches a situation - GENERIC lookup."""
        config = self._get_situation_config(situation)
        if not config:
            return False
        
        method_name = config.get('detection_method')
        if method_name and hasattr(self, method_name):
            return getattr(self, method_name)(score)
        
        # Fallback to pattern matching
        patterns = config.get('score_patterns', [])
        return score in patterns if patterns else False
    
    def _get_role_config(self, role: str) -> Dict:
        """Get config for a role - NEVER hardcode role checks!"""
        return self.ROLE_CONFIG.get(role.lower() if role else '', {})
    
    def _get_player_for_role(self, role: str, server: str, returner: str,
                              point_winner: str = '', error_player: str = '') -> str:
        """Get the player for a given role - GENERIC lookup."""
        config = self._get_role_config(role)
        field = config.get('player_field', '')
        players = {'server': server, 'returner': returner,
                  'point_winner': point_winner, 'error_player': error_player}
        return players.get(field, '')
    
    def _get_domain_config(self, domain: str) -> Dict:
        """Get config for a domain - NEVER hardcode domain checks!"""
        return self.DOMAIN_CONFIG.get(domain.lower() if domain else '', {})
    
    def _get_role_for_domain(self, domain: str) -> str:
        """Get the role associated with a domain - GENERIC lookup."""
        config = self._get_domain_config(domain)
        return config.get('role', '')
    
    def _get_player_for_domain(self, domain: str, server: str, returner: str) -> str:
        """Get the player field for a domain - GENERIC lookup."""
        config = self._get_domain_config(domain)
        field = config.get('player_field', '')
        if field == 'server':
            return server
        elif field == 'returner':
            return returner
        return ''
    
    def _get_court_zone_config(self, zone: str) -> Dict:
        """Get config for a court zone - NEVER hardcode zone checks!"""
        return self.COURT_ZONE_CONFIG.get(zone.lower() if zone else '', {})
    
    def _check_court_zone(self, zone: str, point_metadata: Dict) -> bool:
        """Check if a point matches a court zone - GENERIC lookup."""
        config = self._get_court_zone_config(zone)
        if not config:
            return True  # No filter
        
        # Check detection fields
        for field in config.get('detection_fields', []):
            if point_metadata.get(field) == config.get('detection_value'):
                return True
        
        # Check shot modifiers
        shot_modifier = point_metadata.get('winning_shot', {}).get('shot_modifier', '')
        shot_modifiers = point_metadata.get('winning_shot', {}).get('shot_modifiers', [])
        zone_modifiers = config.get('shot_modifiers', [])
        
        if shot_modifier in zone_modifiers or any(m in zone_modifiers for m in shot_modifiers):
            return zone == 'net'  # These modifiers indicate net play
        
        return zone == 'baseline'  # Default to baseline if no net indicators
    
    def _get_group_config(self, group_by: str) -> Dict:
        """Get config for a group_by value - NEVER hardcode group_by checks!"""
        return self.GROUP_CONFIG.get(group_by.lower() if group_by else '', {})
    
    def _extract_group_key(self, group_by: str, point_data: Dict, metadata: Dict, 
                           filters: Dict, score: str, point_lower: str, 
                           rally_length: int = 0) -> str:
        """
        GENERIC group key extraction using GROUP_CONFIG.
        This replaces ALL hardcoded if/elif chains for group_by routing.
        """
        config = self._get_group_config(group_by)
        if not config:
            return None
        
        extraction_method = config.get('extraction_method', 'metadata_path')
        normalize = config.get('normalize')
        fallback = config.get('fallback')
        
        value = None
        
        if extraction_method == 'metadata_path':
            path = config.get('metadata_path', [])
            if path:
                # SPECIAL CASE: For shot_type grouping with error metrics, use error_shot_type instead of winning_shot.shot_type
                if group_by == 'shot_type' and path == ['winning_shot', 'shot_type']:
                    current_metric = filters.get('_current_metric', '')
                    error_metrics = ['unforced_errors', 'forced_errors', 'errors']
                    if current_metric in error_metrics:
                        # Use error_shot_type for error metrics (stored in error_info)
                        error_info = metadata.get('error_info', {})
                        error_shot_type = error_info.get('error_shot_type')
                        if error_shot_type:
                            value = error_shot_type
                            # DEBUG: Show that we're using error_shot_type
                            if not hasattr(self, '_error_shot_debug_count'):
                                self._error_shot_debug_count = 0
                            if self._error_shot_debug_count < 3:
                                self._error_shot_debug_count += 1
                                print(f"[GROUP-DEBUG] Using error_shot_type='{error_shot_type}' for error metric '{current_metric}' (not winning_shot)")
                        else:
                            # Fallback to winning_shot path if error_shot_type not available
                            value = metadata
                            for key in path:
                                value = value.get(key, {}) if isinstance(value, dict) else None
                                if value is None:
                                    break
                    else:
                        # Normal path for non-error metrics
                        value = metadata
                        for key in path:
                            value = value.get(key, {}) if isinstance(value, dict) else None
                            if value is None:
                                break
                else:
                    # Normal metadata_path extraction
                    value = metadata
                    for key in path:
                        value = value.get(key, {}) if isinstance(value, dict) else None
                        if value is None:
                            break
                if value and isinstance(value, dict):
                    value = None  # Don't return dicts
        
        elif extraction_method == 'filter':
            filter_key = config.get('filter_key', '')
            value = filters.get(filter_key)
        
        elif extraction_method == 'custom':
            custom_func = config.get('custom_func')
            if custom_func:
                # Handle string identifiers for custom functions that need self
                if isinstance(custom_func, str):
                    if custom_func == 'get_set_group':
                        value = self._get_set_group(filters, score)
                    elif custom_func == 'get_net_play_type':
                        value = self._get_net_play_type(metadata)
                    # Add more custom function handlers here as needed
                else:
                    # Callable - pass parameters directly
                    value = custom_func(filters, metadata, score)
        
        elif extraction_method == 'metric_aware':
            # Special handling for player grouping - uses metric context
            value = self._get_player_group_key(filters, metadata)
        
        # Apply normalization if provided
        if value is not None and normalize:
            try:
                # Handle string identifiers for normalizers that need self
                if isinstance(normalize, str):
                    if normalize == 'normalize_outcome':
                        value = self._normalize_outcome_for_grouping(value)
                    # Add more normalizer handlers here as needed
                else:
                    # Callable
                    value = normalize(value)
            except:
                pass
        
        # Use fallback if value is None
        if value is None and fallback:
            try:
                # Handle string identifiers for special fallbacks
                if isinstance(fallback, str):
                    if fallback == 'extract_current_set':
                        value = str(self._extract_current_set(score)) if score else None
                    # Add more special fallback handlers here as needed
                # Handle callable fallbacks
                elif callable(fallback):
                    if 'point_lower' in fallback.__code__.co_varnames:
                        value = fallback(point_lower)
                    elif 'score' in fallback.__code__.co_varnames:
                        value = fallback(score)
                    elif 'rally_length' in fallback.__code__.co_varnames:
                        value = fallback(rally_length)
                    else:
                        value = fallback()
            except:
                pass
        
        return str(value) if value is not None else None
    
    def _get_player_group_key(self, filters: Dict, metadata: Dict) -> str:
        """Get player group key based on metric context - uses METRIC_CONFIG."""
        current_metric = filters.get('_current_metric')
        
        # Use METRIC_CONFIG to determine player_role
        metric_config = self.METRIC_CONFIG.get(current_metric, {}) if current_metric else {}
        player_role = metric_config.get('player_role', 'server')  # Default to server
        
        # Get player field from ROLE_CONFIG
        role_config = self.ROLE_CONFIG.get(player_role, {})
        player_field = role_config.get('player_field', 'server')
        
        # Map to filter/metadata keys
        field_to_key = {
            'server': '_server',
            'returner': '_returner',
            'point_winner': '_point_winner',
            'error_player': '_error_player'
        }
        filter_key = field_to_key.get(player_field, '_server')
        target_player = filters.get(filter_key, '') or metadata.get(player_field, '')
        
        # Match to player1 or player2
        if target_player and self._names_match_robust(self.player1, target_player):
            return 'player1'
        elif target_player and self._names_match_robust(self.player2, target_player):
            return 'player2'
        else:
            # Fallback to server
            server = filters.get('_server', '') or metadata.get('server', '')
            if self._names_match_robust(self.player1, server):
                return 'player1'
            else:
                return 'player2'
    
    def _normalize_outcome_for_grouping(self, outcome: str) -> str:
        """Normalize outcome string for grouping - uses OUTCOME_CONFIG."""
        outcome_config = self._get_outcome_config(outcome)
        winning_shot_type = outcome_config.get('winning_shot_type', '')
        if winning_shot_type:
            return winning_shot_type
        
        # Fallback normalization
        outcome_lower = outcome.lower().replace(' ', '_')
        if 'unforced' in outcome_lower:
            return 'unforced_error'
        elif 'forced' in outcome_lower:
            return 'forced_error'
        return outcome_lower
    
    def _get_set_group(self, filters: Dict, score: str) -> str:
        """Get set group (group_a/group_b) for a point."""
        current_set = self._extract_current_set(score)
        set_group_a = filters.get('set_group_a', [])
        set_group_b = filters.get('set_group_b', [])
        if current_set in set_group_a:
            return 'group_a'
        elif current_set in set_group_b:
            return 'group_b'
        return None
    
    def _get_net_play_type(self, metadata: Dict) -> str:
        """Get net play type from metadata."""
        winning_shot = metadata.get('winning_shot', {})
        shot_type = winning_shot.get('shot_type')
        at_net = winning_shot.get('at_net', False)
        shot_modifiers = winning_shot.get('shot_modifiers', [])
        shot_modifier = winning_shot.get('shot_modifier')
        
        if 'volley' in shot_modifiers or shot_modifier == 'volley':
            return f"{shot_type}_volley" if shot_type else "volley"
        elif at_net or winning_shot.get('court_position') == 'net':
            return f"{shot_type}_at_net" if shot_type else "net_play"
        return None
    
    def _get_player_display(self, classification: Dict) -> Dict:
        """Get player display groups - GENERIC."""
        return {
            'player1': {'label': self.player1, 'total': 0, 'player1_wins': 0, 'player2_wins': 0, 'player1_metric': 0, 'player2_metric': 0},
            'player2': {'label': self.player2, 'total': 0, 'player1_wins': 0, 'player2_wins': 0, 'player1_metric': 0, 'player2_metric': 0}
        }
    
    def _get_set_groups_display(self, classification: Dict) -> Dict:
        """Get set groups display - GENERIC."""
        filters = classification.get('filters', {})
        set_a = filters.get('set_group_a', [])
        set_b = filters.get('set_group_b', [])
        set_a_label = f"Set{'s' if len(set_a) > 1 else ''} {', '.join(map(str, set_a))}" if set_a else "Group A"
        set_b_label = f"Set{'s' if len(set_b) > 1 else ''} {', '.join(map(str, set_b))}" if set_b else "Group B"
        
        def make_group(label):
            return {'label': label, 'total': 0, 'player1_wins': 0, 'player2_wins': 0, 'player1_metric': 0, 'player2_metric': 0}
        
        return {
            'group_a': {'label': set_a_label, 'sets': set_a, **make_group(set_a_label)},
            'group_b': {'label': set_b_label, 'sets': set_b, **make_group(set_b_label)}
        }
    
    def _get_display_label(self, group_by: str, value: Any, classification: Dict = None) -> str:
        """
        GENERIC display label getter using GROUP_CONFIG.
        Returns the display label for a given group_by value.
        """
        config = self._get_group_config(group_by)
        if not config:
            # Fallback: format value as title case
            if isinstance(value, str):
                return value.replace('_', ' ').title()
            return str(value)
        
        display_source = config.get('display_source', 'default')
        display_labels = config.get('display_labels', {})
        
        # Handle custom display functions
        if display_source == 'custom':
            custom_display = config.get('custom_display')
            if custom_display == 'get_player_display':
                # Special case: player grouping uses player names
                if value == 'player1':
                    return self.player1 or 'Player 1'
                elif value == 'player2':
                    return self.player2 or 'Player 2'
                return str(value)
            elif custom_display == 'get_set_groups_display':
                # Special case: set groups handled separately
                if value == 'group_a':
                    if classification:
                        filters = classification.get('filters', {})
                        set_a = filters.get('set_group_a', [])
                        if set_a:
                            return f"Set{'s' if len(set_a) > 1 else ''} {', '.join(map(str, set_a))}"
                    return "Group A"
                elif value == 'group_b':
                    if classification:
                        filters = classification.get('filters', {})
                        set_b = filters.get('set_group_b', [])
                        if set_b:
                            return f"Set{'s' if len(set_b) > 1 else ''} {', '.join(map(str, set_b))}"
                    return "Group B"
                return str(value)
        
        # Handle function-based display_labels (e.g., sets)
        if callable(display_labels):
            try:
                return display_labels(value)
            except:
                pass
        
        # Handle dictionary-based display_labels
        if isinstance(display_labels, dict):
            # Try exact match first
            if value in display_labels:
                return display_labels[value]
            # Try string conversion
            str_value = str(value)
            if str_value in display_labels:
                return display_labels[str_value]
        
        # Handle inventory-based display (with labels)
        if display_source == 'inventory':
            inventory = getattr(self, 'match_filter_inventory', {})
            inventory_key = config.get('inventory_key')
            if inventory_key and isinstance(display_labels, dict):
                # Use display_labels if available
                if value in display_labels:
                    return display_labels[value]
                str_value = str(value)
                if str_value in display_labels:
                    return display_labels[str_value]
        
        # Fallback: format value nicely
        if isinstance(value, str):
            return value.replace('_', ' ').title()
        return str(value)
    
    def _get_all_group_values(self, group_by: str, classification: Dict = None) -> Dict[str, str]:
        """
        GENERIC method to get all possible group values and their display labels.
        Uses GROUP_CONFIG as single source of truth.
        """
        config = self._get_group_config(group_by)
        if not config:
            return {}
        
        display_source = config.get('display_source', 'default')
        display_labels = config.get('display_labels', {})
        inventory = getattr(self, 'match_filter_inventory', {})
        
        result = {}
        
        # Handle custom display
        if display_source == 'custom':
            custom_display = config.get('custom_display')
            if custom_display == 'get_player_display':
                result['player1'] = self.player1 or 'Player 1'
                result['player2'] = self.player2 or 'Player 2'
                return result
            elif custom_display == 'get_set_groups_display':
                if classification:
                    filters = classification.get('filters', {})
                    set_a = filters.get('set_group_a', [])
                    set_b = filters.get('set_group_b', [])
                    set_a_label = f"Set{'s' if len(set_a) > 1 else ''} {', '.join(map(str, set_a))}" if set_a else "Group A"
                    set_b_label = f"Set{'s' if len(set_b) > 1 else ''} {', '.join(map(str, set_b))}" if set_b else "Group B"
                    result['group_a'] = set_a_label
                    result['group_b'] = set_b_label
                else:
                    result['group_a'] = 'Group A'
                    result['group_b'] = 'Group B'
                return result
        
        # Handle inventory-based (most common)
        if display_source == 'inventory':
            inventory_key = config.get('inventory_key')
            if inventory_key:
                values = inventory.get(inventory_key, config.get('default_branches', []))
                for val in values:
                    label = self._get_display_label(group_by, val, classification)
                    result[str(val)] = label
                # Add always_include values
                always_include = config.get('always_include', [])
                for val in always_include:
                    label = self._get_display_label(group_by, val, classification)
                    result[str(val)] = label
            else:
                # No inventory key, use default_branches
                default_branches = config.get('default_branches', [])
                for val in default_branches:
                    label = self._get_display_label(group_by, val, classification)
                    result[str(val)] = label
        
        # Handle predefined
        elif display_source == 'predefined':
            default_branches = config.get('default_branches', [])
            for val in default_branches:
                label = self._get_display_label(group_by, val, classification)
                result[str(val)] = label
        
        # Handle dynamic (values discovered during traversal)
        elif display_source == 'dynamic':
            # For dynamic, we can't pre-populate - return empty
            # Caller will discover values during traversal
            pass
        
        # Default: use display_labels if available
        else:
            if isinstance(display_labels, dict):
                result = {k: v for k, v in display_labels.items()}
            elif config.get('default_branches'):
                for val in config.get('default_branches', []):
                    label = self._get_display_label(group_by, val, classification)
                    result[str(val)] = label
        
        return result
    
    def _metric_matches_outcome(self, metric: str, outcome: str) -> bool:
        """Check if a metric matches an outcome - GENERIC using METRIC_CONFIG."""
        metric_config = self.METRIC_CONFIG.get(metric, {})
        keywords = metric_config.get('keywords', [])
        
        if not keywords:
            # No keywords means this metric doesn't filter by outcome
            return True
        
        outcome_lower = outcome.lower() if outcome else ''
        # Check if ANY keyword matches the outcome
        return any(kw.lower() in outcome_lower for kw in keywords)
    
    def _outcome_matches_metric(self, outcome: str, metric: str) -> bool:
        """Check if an outcome matches a metric - GENERIC using configs."""
        outcome_config = self._get_outcome_config(outcome)
        winning_shot_type = outcome_config.get('winning_shot_type', '')
        
        metric_config = self.METRIC_CONFIG.get(metric, {})
        keywords = metric_config.get('keywords', [])
        
        if not keywords:
            return True  # No keywords = matches all
        
        # Check if winning shot type matches any keyword
        return any(kw.lower() in winning_shot_type for kw in keywords)
        
    def _get_model_config(self, complexity: int) -> Dict:
        """
        Get model name and generation config based on complexity tier.
        
        Returns dict with:
            - model_name: str
            - temperature: float
        """
        if self.llm_provider != "gemini":
            # For non-Gemini, just return default model
            return {
                "model_name": self.model,
                "temperature": 0.1
            }
        
        if complexity == 1:
            # Tier 1: Simple - Fast & cheap (2.5 Flash)
            return {
                "model_name": self.model_25_flash,
                "temperature": 0.1
            }
        elif complexity == 2:
            # Tier 2: Moderate - 3 Flash with medium temperature
            # Note: 3 Flash has built-in reasoning capabilities
            return {
                "model_name": self.model_30_flash,
                "temperature": 0.7
            }
        else:  # complexity == 3
            # Tier 3: Complex - 3 Flash with lower temperature for precision
            # Note: 3 Flash has built-in deep reasoning capabilities
            return {
                "model_name": self.model_30_flash,
                "temperature": 0.3
            }
    
    def _fix_player_role_detection(self, question: str, classification: Dict) -> Dict:
        """
        Fix player detection for "[Player]'s return/service games" patterns.
        
        When a query says "Sinner's return games", the player should be Sinner,
        not "both". This overrides incorrect LLM parsing.
        """
        import re
        # Normalize ALL apostrophe variants to ASCII apostrophe
        # U+2019 = ' (right single quote - most common smart quote)
        # U+2018 = ' (left single quote)
        # U+0060 = ` (grave accent/backtick)
        # U+00B4 = ´ (acute accent)
        # U+2032 = ′ (prime)
        question_normalized = question
        for char in ['\u2019', '\u2018', '\u0060', '\u00b4', '\u2032', ''', ''', '`', '´']:
            question_normalized = question_normalized.replace(char, "'")
        question_lower = question_normalized.lower()
        filters = classification.get('filters', {})
        
        # Debug: print bytes of apostrophe area to see exactly what character is there
        if "sinner" in question_lower:
            idx = question_lower.find("sinner")
            snippet = question_lower[idx:idx+15]
            print(f"[FIX-PLAYER-ROLE] Apostrophe debug: '{snippet}' | bytes: {[hex(ord(c)) for c in snippet]}")
        print(f"[FIX-PLAYER-ROLE] Normalized: '{question_lower[:60]}...' | Current player: {filters.get('player')}")
        
        # Pattern: "[Player]'s return/service games"
        # This indicates the player is the RETURNER/SERVER, not just a filter
        # NOTE: Patterns are ordered from most specific to least specific
        # After normalization, all apostrophes are converted to straight quote '
        patterns = [
            # "On Sinner's return games" → player=Sinner, role=returner (most specific)
            (r"(?:on\s+)?(\w+)'s\s+return\s+(?:games?|points?)", 'returner'),
            # "On Sinner's service/serve games" → player=Sinner, role=server
            (r"(?:on\s+)?(\w+)'s\s+(?:service|serve)\s+(?:games?|points?)", 'server'),
            # "On Sinner's return" (without games/points) → player=Sinner, role=returner
            (r"on\s+(\w+)'s\s+return(?:\s|$|,)", 'returner'),
            # "On Sinner's serve" (without games/points) → player=Sinner, role=server
            (r"on\s+(\w+)'s\s+(?:service|serve)(?:\s|$|,)", 'server'),
            # "When Sinner returns" → player=Sinner, role=returner
            (r"when\s+(\w+)\s+returns?", 'returner'),
            # "When Sinner serves" → player=Sinner, role=server
            (r"when\s+(\w+)\s+serves?", 'server'),
            # "Sinner returning" or "Sinner on return" → player=Sinner, role=returner
            (r"(\w+)\s+(?:returning|on\s+return)", 'returner'),
            # "Sinner serving" or "Sinner on serve" → player=Sinner, role=server
            (r"(\w+)\s+(?:serving|on\s+serve)", 'server'),
        ]
        
        # Debug: Test first pattern explicitly
        test_pattern = r"(?:on\s+)?(\w+)'s\s+return\s+(?:games?|points?)"
        test_match = re.search(test_pattern, question_lower)
        print(f"[FIX-PLAYER-ROLE] Test match for return pattern: {test_match}")
        if test_match:
            print(f"[FIX-PLAYER-ROLE] Test match groups: {test_match.groups()}")
        
        print(f"[FIX-PLAYER-ROLE] Testing {len(patterns)} patterns...")
        for i, (pattern, role) in enumerate(patterns):
            match = re.search(pattern, question_lower)
            print(f"[FIX-PLAYER-ROLE] Pattern {i+1} ({role}): match={match is not None}")
            if match:
                player_name_raw = match.group(1).strip()
                print(f"[FIX-PLAYER-ROLE] Pattern matched! Found '{player_name_raw}' with role '{role}'")
                
                # Try to match against known player names
                player1 = self.player1 if hasattr(self, 'player1') else None
                player2 = self.player2 if hasattr(self, 'player2') else None
                
                matched_player = None
                if player1 and player_name_raw.lower() in player1.lower():
                    matched_player = player1
                elif player2 and player_name_raw.lower() in player2.lower():
                    matched_player = player2
                elif player1 and player1.lower().split()[-1] == player_name_raw.lower():
                    # Last name match
                    matched_player = player1
                elif player2 and player2.lower().split()[-1] == player_name_raw.lower():
                    matched_player = player2
                
                if matched_player:
                    # Only override if current player is 'both' or unset
                    current_player = filters.get('player', '')
                    if not current_player or (current_player and current_player.lower() == 'both'):
                        filters['player'] = matched_player
                        filters['role'] = role
                        print(f"[FIX-PLAYER-ROLE] Detected '{player_name_raw}'s {role} games' -> player={matched_player}, role={role}")
                    else:
                        print(f"[FIX-PLAYER-ROLE] Skipping - player already set to '{current_player}'")
                else:
                    print(f"[FIX-PLAYER-ROLE] Pattern matched but couldn't resolve '{player_name_raw}' to known player (p1={player1}, p2={player2})")
                break
        
        classification['filters'] = filters
        return classification
    
    def _resolve_vague_terms(self, question: str, classification: Dict) -> Dict:
        """
        Detect vague analytical terms and resolve them to concrete metric bundles.
        
        This converts questions like "How effective was Sinner's serve?" into
        computable metrics like [first_serve_win_pct, second_serve_win_pct, service_winners].
        
        Returns:
            Updated classification with:
            - _vague_term: The detected term (if any)
            - _vague_interpretation: Description of what we're measuring
            - metrics: Updated with resolved metric bundle
            - query_category: Changed to 'analytical' if we can compute
        """
        question_lower = question.lower()
        
        # Step A: Detect vague terms using keyword match
        detected_term = None
        for raw_term, canonical in self.TERM_NORMALIZATION.items():
            # Word boundary check to avoid partial matches
            if f' {raw_term}' in f' {question_lower} ' or question_lower.startswith(raw_term):
                detected_term = canonical
                break
        
        # Also check canonical terms directly
        if not detected_term:
            for canonical in self.VAGUE_TERM_MAP.keys():
                if f' {canonical}' in f' {question_lower} ' or question_lower.startswith(canonical):
                    detected_term = canonical
                    break
        
        if not detected_term:
            return classification  # No vague term detected, return as-is
        
        # Step B: Infer context from query
        context = "default"
        filters = classification.get('filters', {})
        domain = classification.get('domain', 'all')
        
        # Check for context based on domain or role - GENERIC using configs
        role = filters.get('role')
        if domain in self.DOMAIN_CONFIG:
            context = domain
        elif role in self.ROLE_CONFIG:
            # Map role to context using DOMAIN_CONFIG
            for d, cfg in self.DOMAIN_CONFIG.items():
                if cfg.get('role') == role:
                    context = d
                    break
        elif 'serve' in question_lower:
            context = 'serve'
        elif 'return' in question_lower:
            context = 'return'
        # Check for rally context
        elif 'rally' in question_lower or 'baseline' in question_lower:
            context = "rally"
        # Check for net context
        elif 'net' in question_lower and 'internet' not in question_lower:
            context = "net"
        # Check for break point context
        elif 'break point' in question_lower or filters.get('situation') == 'break_point':
            context = "break_point"
        
        # Step C: Bind to metric bundle
        term_config = self.VAGUE_TERM_MAP.get(detected_term, {})
        metric_bundle = term_config.get(context, term_config.get("default", ["win_percentage"]))
        interpretation = term_config.get("description", f"Analyzing {detected_term}")
        
        # Step D: Update classification
        print(f"[VAGUE-RESOLVE] Detected '{detected_term}' in context '{context}'")
        print(f"[VAGUE-RESOLVE] Interpretation: {interpretation}")
        print(f"[VAGUE-RESOLVE] Metric bundle: {metric_bundle}")
        
        # Store vague term info for disclosure
        classification['_vague_term'] = detected_term
        classification['_vague_context'] = context
        classification['_vague_interpretation'] = interpretation
        classification['_vague_metrics'] = metric_bundle
        
        # Update metrics (add to existing, don't replace)
        existing_metrics = classification.get('metrics', [])
        for m in metric_bundle:
            if m not in existing_metrics:
                existing_metrics.append(m)
        classification['metrics'] = existing_metrics
        
        # Force group_by if term has special grouping (e.g., momentum → by sets)
        if 'group_by' in term_config and not classification.get('group_by'):
            classification['group_by'] = term_config['group_by']
            print(f"[VAGUE-RESOLVE] Forcing group_by: {term_config['group_by']}")
        
        # CRITICAL: If we can compute metrics, change to analytical (not narrative)
        if metric_bundle:
            classification['query_category'] = 'analytical'
            print(f"[VAGUE-RESOLVE] Converting to ANALYTICAL route (computable metrics found)")
        
        return classification
    
    def _classify_query_complexity(self, question: str, classification: Dict) -> int:
        """
        Classify query complexity for model selection.
        
        Returns:
            1 = Simple (2.5 Flash, no thinking) - Retrieval, counts, basic stats
            2 = Moderate (3.0 Flash, medium thinking) - Comparisons, multi-step, cross-tab
            3 = Complex (3.0 Flash, high thinking) - Deep tactical, causation, strategy analysis
        """
        question_lower = question.lower()
        query_category = classification.get('query_category', 'analytical')
        analysis_type = classification.get('analysis_type', 'count')
        metrics = classification.get('metrics', [])
        filters = classification.get('filters', {})
        group_by = classification.get('group_by')
        secondary_group_by = classification.get('secondary_group_by')
        
        # === TIER 3: COMPLEX (3.0 Flash, High Thinking) ===
        # Deep tactical analysis, causation, multi-layered strategic questions
        if query_category == 'narrative':
            # Narrative questions need strategic thinking
            if any(kw in question_lower for kw in ['why', 'how did', 'what caused', 'momentum', 'tactical', 'strategy', 'aggressive', 'pattern']):
                return 3  # Deep tactical analysis
            return 2  # Simple narrative lookup
        
        # Multi-dimensional or chained analysis
        if analysis_type in ['chain', 'momentum', '2d_cross_tab']:
            return 3
        
        # Questions about causation or correlation
        if any(kw in question_lower for kw in ['why', 'because', 'lead to', 'caused', 'result in', 'due to']):
            return 3
        
        # === TIER 2: MODERATE (3.0 Flash, Medium Thinking) ===
        # Comparisons, grouping, cross-sectional analysis
        if secondary_group_by or analysis_type in ['comparison', 'ratio', 'trend']:
            return 2
        
        # Comparing across sets, situations, or players
        if group_by in ['sets', 'set_groups', 'player', 'situation', 'rally_length_category']:
            return 2
        
        # Multiple filters (needs coordination)
        active_filters = sum(1 for v in filters.values() if v is not None and v != '')
        if active_filters >= 3:
            return 2
        
        # Comparison keywords
        if any(kw in question_lower for kw in ['vs', 'versus', 'compared to', 'difference', 'change', 'across sets']):
            return 2
        
        # === TIER 1: SIMPLE (2.5 Flash, No Thinking) ===
        # Direct retrieval, simple counts, basic aggregation
        if analysis_type == 'count' and not group_by and active_filters <= 1:
            return 1  # "How many aces?" - simple count
        
        # Simple lookup questions
        if any(question_lower.startswith(kw) for kw in ['how many', 'what was', 'who won', 'show me', 'list']):
            if not group_by and active_filters <= 1:
                return 1
        
        # Default to moderate for anything not clearly simple or complex
        return 2
    
    def _init_llm_client(self):
        """Initialize the LLM client based on provider."""
        if self.llm_provider == "claude":
            try:
                import anthropic
                api_key = self.api_key or os.getenv("ANTHROPIC_API_KEY")
                if not api_key:
                    raise ValueError("ANTHROPIC_API_KEY environment variable required for Claude")
                self.client = anthropic.Anthropic(api_key=api_key)
                self.model = "claude-3-5-sonnet-20241022"
            except ImportError:
                raise ImportError("Please install anthropic: pip install anthropic")
                
        elif self.llm_provider == "gemini":
            try:
                import google.generativeai as genai
                api_key = self.api_key or os.getenv("GOOGLE_API_KEY")
                if not api_key:
                    raise ValueError("GOOGLE_API_KEY environment variable required for Gemini")
                genai.configure(api_key=api_key)
                self.client = genai
                # Default to 2.5 Flash (fast & cheap) - will be overridden dynamically based on query complexity
                self.model = self.custom_model or "gemini-2.5-flash"
                self.model_25_flash = "gemini-2.5-flash"  # For simple queries
                self.model_30_flash = "gemini-3-flash-preview"  # For complex queries
            except ImportError:
                raise ImportError("Please install google-generativeai: pip install google-generativeai")
                
        elif self.llm_provider == "openai":
            try:
                from openai import OpenAI
                api_key = self.api_key or os.getenv("OPENAI_API_KEY")
                if not api_key:
                    raise ValueError("OPENAI_API_KEY environment variable required for OpenAI")
                self.client = OpenAI(api_key=api_key)
                self.model = self.custom_model or "gpt-4o-mini"  # Allow custom model
            except ImportError:
                raise ImportError("Please install openai: pip install openai")
        else:
            raise ValueError("llm_provider must be 'claude', 'gemini', or 'openai'")
        
    def _parse_match_score(self, content: str) -> None:
        """
        Parse the match score from the markdown content and build set mapping.
        Example: "Carlos Alcaraz d. Jannik Sinner 4-6 6-7(4) 6-4 7-6(3)"
        Format: "Winner d. Loser winner_score-loser_score ..."
        """
        import re
        
        # Initialize
        self.match_score = None
        self.set_mapping = {}  # Maps set number to set score (e.g., {1: "0-0", 2: "0-1", 3: "0-2", 4: "1-2"})
        self.total_sets = 0
        self.set_winners = {}  # Maps set number to winner (player1 or player2)
        self.match_winner = None
        self.match_loser = None
        self.game_winners = {}  # Maps (set_num, game_num) -> winner (player1 or player2)
        
        # Find the Final Score line
        score_match = re.search(r'Final Score:\s*(.+?)(?:\n|$)', content)
        if not score_match:
            print("[WARN] Could not find Final Score in markdown")
            return
        
        score_line = score_match.group(1).strip()
        self.match_score = score_line
        
        # Parse the format: "Winner d. Loser score score score"
        match_result = re.match(r'(.+?)\s+d\.\s+(.+?)\s+([\d\-\(\)\s]+)$', score_line)
        if not match_result:
            print("[WARN] Could not parse match result format:", score_line)
            return
        
        winner_name = match_result.group(1).strip()
        loser_name = match_result.group(2).strip()
        scores_str = match_result.group(3).strip()
        
        self.match_winner = winner_name
        self.match_loser = loser_name
        
        # Extract the set scores
        set_scores = re.findall(r'(\d+)-(\d+)(?:\(\d+\))?', scores_str)
        
        if not set_scores:
            print("[WARN] Could not parse set scores from:", score_line)
            return
        
        self.total_sets = len(set_scores)
        
        # Determine which player is player1 and which is player2
        # (based on who is mentioned first in self.player1/player2)
        winner_is_player1 = (hasattr(self, 'player1') and 
                            self.player1 and 
                            winner_name.lower().replace(' ', '') == self.player1.lower().replace(' ', ''))
        
        # Build cumulative set score and track set winners
        # Scores in the format are: winner_score-loser_score for each set
        player1_sets = 0
        player2_sets = 0
        
        for i, (score1, score2) in enumerate(set_scores, 1):
            # Record the set score BEFORE this set starts
            self.set_mapping[i] = f"{player1_sets}-{player2_sets}"
            
            # Determine who won this set
            # score1 is winner's score, score2 is loser's score
            if int(score1) > int(score2):
                # Winner won this set
                if winner_is_player1:
                    self.set_winners[i] = 'player1'
                    player1_sets += 1
                else:
                    self.set_winners[i] = 'player2'
                    player2_sets += 1
            else:
                # Loser won this set
                if winner_is_player1:
                    self.set_winners[i] = 'player2'
                    player2_sets += 1
                else:
                    self.set_winners[i] = 'player1'
                    player1_sets += 1
        
        print(f"[MATCH] Final Score: {self.match_score}")
        print(f"[MATCH] Winner: {winner_name} | Loser: {loser_name}")
        print(f"[MATCH] Winner is Player1: {winner_is_player1}")
        print(f"[MATCH] Set Mapping: {self.set_mapping}")
        print(f"[MATCH] Set Winners: {self.set_winners}")
    
    def _get_sets_won_by_player(self, player_name: str) -> list:
        """
        Get the list of set numbers won by a specific player.
        Returns empty list if player not found or no sets tracked.
        """
        if not hasattr(self, 'set_winners') or not self.set_winners:
            return []
        
        if not player_name:
            return []
        
        # Normalize player name for comparison
        player_normalized = player_name.lower().replace(' ', '')
        player1_normalized = (self.player1 or '').lower().replace(' ', '')
        player2_normalized = (self.player2 or '').lower().replace(' ', '')
        
        # Determine if this is player1 or player2
        is_player1 = player_normalized == player1_normalized
        is_player2 = player_normalized == player2_normalized
        
        if not is_player1 and not is_player2:
            return []
        
        # Get sets won by this player
        sets_won = []
        for set_num, winner in self.set_winners.items():
            if (is_player1 and winner == 'player1') or (is_player2 and winner == 'player2'):
                sets_won.append(set_num)
        
        return sets_won
    
    def _get_sets_lost_by_player(self, player_name: str) -> list:
        """
        Get the list of set numbers lost by a specific player.
        Returns empty list if player not found or no sets tracked.
        """
        if not hasattr(self, 'set_winners') or not self.set_winners:
            return []
        
        if not player_name:
            return []
        
        # Normalize player name for comparison
        player_normalized = player_name.lower().replace(' ', '')
        player1_normalized = (self.player1 or '').lower().replace(' ', '')
        player2_normalized = (self.player2 or '').lower().replace(' ', '')
        
        # Determine if this is player1 or player2
        is_player1 = player_normalized == player1_normalized
        is_player2 = player_normalized == player2_normalized
        
        if not is_player1 and not is_player2:
            return []
        
        # Get sets lost by this player (won by opponent)
        sets_lost = []
        for set_num, winner in self.set_winners.items():
            if (is_player1 and winner == 'player2') or (is_player2 and winner == 'player1'):
                sets_lost.append(set_num)
        
        return sets_lost
    
    def _detect_set_reference(self, query: str) -> int:
        """
        Detect if the query references a specific set.
        Returns the set number (1, 2, 3, 4, 5) or None.
        Returns None if MULTIPLE sets are mentioned (e.g., "set 3 and set 4").
        """
        import re
        
        query_lower = query.lower()
        
        # Check for multiple set references (e.g., "set 3 and set 4")
        # If found, return None to avoid filtering
        set_count = len(re.findall(r'set\s+\d+', query_lower))
        if set_count > 1:
            return None
        
        # Direct number references
        # Match "set 3", "in set 3", "3rd set", "the 3rd set", etc.
        set_match = re.search(r'set\s+(\d+)', query_lower)  # "set 3"
        if not set_match:
            set_match = re.search(r'(\d+)(?:st|nd|rd|th)?\s+set', query_lower)  # "3rd set"
        if set_match:
            return int(set_match.group(1))
        
        # Word-based references
        set_words = {
            'first': 1, 'second': 2, 'third': 3, 'fourth': 4, 'fifth': 5,
            '1st': 1, '2nd': 2, '3rd': 3, '4th': 4, '5th': 5
        }
        
        for word, num in set_words.items():
            if f"{word} set" in query_lower:
                return num
        
        # Special references
        if any(word in query_lower for word in ['final set', 'deciding set', 'last set']):
            return self.total_sets if self.total_sets else None
        
        return None
    
    def _detect_multiple_set_references(self, query: str) -> List[int]:
        """
        Detect if the query references MULTIPLE specific sets (for comparison questions).
        Returns a list of set numbers [1, 5] or empty list if not a multi-set comparison.
        Examples: "Set 1 vs Set 5", "Set 1 versus Set 5", "compare Set 1 and Set 5"
        """
        import re
        
        query_lower = query.lower()
        
        # Find all set number references
        set_numbers = []
        
        # Match "set 1", "set 5", etc.
        for match in re.finditer(r'set\s+(\d+)', query_lower):
            set_num = int(match.group(1))
            if 1 <= set_num <= 5 and set_num not in set_numbers:
                set_numbers.append(set_num)
        
        # Also check for word-based references
        set_words = {
            'first': 1, 'second': 2, 'third': 3, 'fourth': 4, 'fifth': 5,
            '1st': 1, '2nd': 2, '3rd': 3, '4th': 4, '5th': 5
        }
        
        for word, num in set_words.items():
            if f"{word} set" in query_lower and num not in set_numbers:
                set_numbers.append(num)
        
        # Only return if we found multiple sets AND it's a comparison question
        if len(set_numbers) >= 2:
            comparison_indicators = ['vs', 'versus', 'compared to', 'compare', 'vs.', 'v.']
            if any(indicator in query_lower for indicator in comparison_indicators):
                set_numbers.sort()  # Return in order [1, 5]
                return set_numbers
        
        return []
    
    def _detect_game_reference(self, query: str) -> str:
        """
        Detect if the query references a specific game or game score.
        Returns a game score pattern like "3-2" or None.
        """
        import re
        
        query_lower = query.lower()
        
        # Game score patterns (e.g., "at 4-3", "when it was 5-5", "3-2")
        game_score_match = re.search(r'(?:at\s+|when\s+it\s+was\s+|score\s+was\s+)?(\d+)-(\d+)', query_lower)
        if game_score_match:
            return f"{game_score_match.group(1)}-{game_score_match.group(2)}"
        
        # Game number references (e.g., "game 5", "5th game")
        game_num_match = re.search(r'(?:game\s+|the\s+)?(\d+)(?:st|nd|rd|th)?\s+game', query_lower)
        if game_num_match:
            # This would need more complex logic to determine the exact game score
            # For now, just return a marker that we need game-specific data
            return f"game_{game_num_match.group(1)}"
        
        return None
        
    def load_exact_full_format(self, file_path: str = "EXACT_FULL_FORMAT.md") -> None:
        """
        Load and process the specified natural language file into chunks with embeddings.
        """
        print(f"Loading {file_path}...")
        
        # Extract player names from filename (e.g., "Jannik_Sinner_Carlos_Alcaraz_20250608_NL.md")
        import os
        filename = os.path.basename(file_path)
        parts = filename.replace('_NL.md', '').split('_')
        if len(parts) >= 4:
            # Reconstruct player names (handle names with spaces)
            # Find the date (8 digits) to split the names
            date_idx = next((i for i, part in enumerate(parts) if part.isdigit() and len(part) == 8), None)
            if date_idx and date_idx >= 2:
                player1_parts = parts[:date_idx//2] 
                player2_parts = parts[date_idx//2:date_idx]
                self.player1 = ' '.join(player1_parts)
                self.player2 = ' '.join(player2_parts)
                print(f"Extracted player names: {self.player1} vs {self.player2}")
        
        # Read the file
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Extract match score for set mapping (needed for transformation)
        self._parse_match_score(content)
        
        # Transform point-by-point data to add shot attribution (NEW!)
        content = self._transform_point_by_point_in_content(content)
        
        # Extract structured point-by-point data for analysis
        self._extract_point_by_point_data(content)
        
        # Split content into sections (tables vs point-by-point)
        sections = self._split_into_sections(content)
        
        # Process each section
        all_chunks = []
        for section_name, section_text in sections.items():
            print(f"Processing section: {section_name}")
            
            # Determine chunk type based on section content
            chunk_type = self._determine_chunk_type(section_name, section_text)
            
            chunks = self._create_chunks_with_metadata(
                section_text, 
                chunk_type=chunk_type,
                section=section_name,
                match_id=self.match_id
            )
            all_chunks.extend(chunks)
        
        # Generate embeddings for all chunks
        print("Generating embeddings...")
        self.chunks = self._embed_chunks(all_chunks)
        
        # Create FAISS index
        print("Creating vector index...")
        self._create_vector_index()
        
        print(f"Loaded {len(self.chunks)} chunks with embeddings")
        
    def _split_into_sections(self, content: str) -> Dict[str, str]:
        """
        Split the natural language content using improved semantic + size-aware chunking.
        Creates optimal chunks based on content type and size for better searchability.
        """
        sections = {}
        lines = content.split('\n')
        
        # Define section patterns and chunking strategies
        section_config = {
            'MATCH OVERVIEW:': 'small',
            'RALLY OUTCOMES STATISTICS:': 'medium', 
            'OVERVIEW STATISTICS:': 'small',
            'SERVE1 STATISTICS (SUMMARY):': 'medium',
            'SERVE1 STATISTICS (DETAILED):': 'large',
            'SERVE2 STATISTICS (SUMMARY):': 'medium',
            'SERVE2 STATISTICS (DETAILED):': 'large',
            'RETURN1 STATISTICS (DETAILED):': 'large',
            'RETURN2 STATISTICS (DETAILED):': 'large',
            'KEY POINTS STATISTICS (SERVES):': 'medium',
            'KEY POINTS STATISTICS (RETURNS):': 'medium',
            'SHOTS1 STATISTICS:': 'large',
            'SHOTS2 STATISTICS:': 'large',
            'SHOTDIR1 STATISTICS:': 'large',
            'SHOTDIR2 STATISTICS:': 'large',
            'EXPLICIT TOTALS FOR SHOT DIRECTION + OUTCOME COMBINATIONS:': 'small',
            'NETPTS1 STATISTICS:': 'small',
            'NETPTS2 STATISTICS:': 'small',
            'POINT-BY-POINT NARRATIVE:': 'narrative'
        }
        
        current_section = None
        current_text = []
        current_strategy = None
        
        
        for line in lines:
            line_stripped = line.strip()
            
            # Check if this line starts a new section
            section_found = None
            strategy_found = None
            
            for pattern, strategy in section_config.items():
                if line_stripped.startswith(pattern):
                    section_found = pattern.rstrip(':').lower().replace(' ', '_').replace('(', '').replace(')', '')
                    strategy_found = strategy
                    break
            
            if section_found:
                # Process previous section with its strategy
                if current_section and current_text:
                    self._process_section_with_strategy(sections, current_section, current_text, current_strategy)
                
                # Start new section
                current_section = section_found
                current_strategy = strategy_found
                current_text = [line]
            else:
                current_text.append(line)
        
        # Process the last section
        if current_section and current_text:
            self._process_section_with_strategy(sections, current_section, current_text, current_strategy)
        
        print(f"Created {len(sections)} optimized chunks using semantic boundaries")
        return sections
    
    def _process_section_with_strategy(self, sections: Dict[str, str], section_name: str, 
                                     lines: List[str], strategy: str):
        """Process a section according to its chunking strategy."""
        content = '\n'.join(lines)
        
        if strategy == 'small':
            # Keep small sections intact (MATCH OVERVIEW, NETPTS, etc.)
            sections[section_name] = content
            
        elif strategy == 'medium':
            # Split medium sections by player if beneficial
            player_chunks = self._split_by_player_if_beneficial(content, section_name)
            if len(player_chunks) > 1:
                for i, chunk in enumerate(player_chunks):
                    sections[f"{section_name}_player_{i+1}"] = chunk
            else:
                sections[section_name] = content
                
        elif strategy == 'large':
            # Split large detailed sections by logical subsections
            subsection_chunks = self._split_large_section_intelligently(content, section_name)
            if len(subsection_chunks) > 1:
                for i, chunk in enumerate(subsection_chunks):
                    sections[f"{section_name}_part_{i+1}"] = chunk
            else:
                sections[section_name] = content
                
        elif strategy == 'narrative':
            # Split point-by-point by game groups (every 12-15 points)
            point_chunks = self._split_narrative_by_games(content)
            for i, chunk in enumerate(point_chunks):
                sections[f"{section_name}_games_{i+1}"] = chunk
            
        elif strategy == 'return_split':
            # Custom strategy for return statistics: split by outcomes and depth
            return_chunks = self._split_return_statistics_by_outcomes_and_depth(content, section_name)
            if len(return_chunks) > 1:
                for i, chunk in enumerate(return_chunks):
                    if i == 0:
                        sections[f"{section_name}_outcomes"] = chunk
                    else:
                        sections[f"{section_name}_depth"] = chunk
            else:
                sections[section_name] = content
    
    def _split_return_statistics_by_outcomes_and_depth(self, content: str, section_name: str) -> List[str]:
        """Split return statistics into outcomes and depth sections."""
        lines = content.split('\n')
        outcomes_section = []
        depth_section = []
        current_section = None
        
        for line in lines:
            # Check for depth section indicators
            if any(phrase in line.lower() for phrase in [
                'shallow returns', 'deep returns', 'very deep returns', 
                'unforced errors when returning', 'net approaches when returning'
            ]):
                current_section = 'depth'
            
            # Add line to appropriate section
            if current_section == 'depth':
                depth_section.append(line)
            else:
                outcomes_section.append(line)
        
        chunks = []
        if outcomes_section:
            chunks.append('\n'.join(outcomes_section))
        if depth_section:
            chunks.append('\n'.join(depth_section))
        
        return chunks if len(chunks) > 1 else [content]
    
    def _split_by_player_if_beneficial(self, content: str, section_name: str, player1: str = None, player2: str = None) -> List[str]:
        """Split content by player if it creates meaningful chunks."""
        lines = content.split('\n')
        player1_lines = []
        player2_lines = []
        header_lines = []
        
        # For key points sections, we need to include the authoritative totals
        authoritative_totals = []
        if 'key_points_statistics' in section_name:
            # Look for authoritative totals in the content
            content_lines = content.split('\n')
            in_authoritative_section = False
            for line in content_lines:
                if 'AUTHORITATIVE TOTALS FOR KEY POINTS:' in line:
                    in_authoritative_section = True
                    authoritative_totals.append(line)
                elif in_authoritative_section and line.strip() == '':
                    # End of authoritative section
                    break
                elif in_authoritative_section:
                    authoritative_totals.append(line)
        
        for line in lines:
            if player1 and player1 in line and not line.strip().endswith(':'):
                player1_lines.append(line)
            elif player2 and player2 in line and not line.strip().endswith(':'):
                player2_lines.append(line)
            elif line.strip().endswith(':') or line.startswith('---') or line.startswith('='):
                header_lines.append(line)
            else:
                # Neutral lines go to both if we're splitting, otherwise to header
                if player1_lines or player2_lines:
                    continue
                header_lines.append(line)
        
        # Only split if both players have significant content
        if len(player1_lines) >= 3 and len(player2_lines) >= 3:
            chunks = []
            if player1_lines:
                # Include authoritative totals at the beginning for key points sections
                if authoritative_totals:
                    chunks.append('\n'.join(authoritative_totals + [''] + header_lines + player1_lines))
                else:
                    chunks.append('\n'.join(header_lines + player1_lines))
            if player2_lines:
                # Include authoritative totals at the beginning for key points sections
                if authoritative_totals:
                    chunks.append('\n'.join(authoritative_totals + [''] + header_lines + player2_lines))
                else:
                    chunks.append('\n'.join(header_lines + player2_lines))
            return chunks
            
        return [content]  # Don't split if not beneficial
    
    def _split_large_section_intelligently(self, content: str, section_name: str) -> List[str]:
        """Split large sections by natural semantic boundaries."""
        lines = content.split('\n')
        chunks = []
        current_chunk = []
        
        # Identify natural break points
        for i, line in enumerate(lines):
            current_chunk.append(line)
            
            # Look for natural breaks in detailed statistics
            is_break_point = (
                len(current_chunk) > 40 and  # Minimum chunk size
                (line.strip().endswith('court.') or 
                 line.strip().endswith('serves.') or
                 line.strip().endswith('returns.') or
                 (i < len(lines) - 1 and lines[i+1].strip() == '') or  # Empty line follows
                 ('served to the' in line and 'court' in line and 
                  i > 0 and 'served to the' not in lines[i-1]))
            )
            
            if is_break_point:
                chunks.append('\n'.join(current_chunk))
                current_chunk = []
        
        # Handle remaining content
        if current_chunk:
            if chunks and len(current_chunk) < 20:
                # Append small remainder to last chunk
                chunks[-1] += '\n' + '\n'.join(current_chunk)
            else:
                chunks.append('\n'.join(current_chunk))
        
        return chunks if len(chunks) > 1 else [content]
    
    def _split_narrative_by_games(self, content: str) -> List[str]:
        """Split point-by-point narrative by game groups for optimal chunk size."""
        lines = content.split('\n')
        chunks = []
        current_chunk = []
        point_count = 0
        
        for line in lines:
            current_chunk.append(line)
            
            # Count actual points
            if line.startswith('Point '):
                point_count += 1
                
                # Create new chunk every 20 points (more comprehensive coverage)
                # This ensures longer rallies don't get split across chunks
                if point_count % 20 == 0 and len(current_chunk) > 10:
                    chunks.append('\n'.join(current_chunk))
                    current_chunk = []
        
        # Handle remaining points
        if current_chunk:
            if chunks and len(current_chunk) < 8:
                # Append small remainder to last chunk
                chunks[-1] += '\n' + '\n'.join(current_chunk)
            else:
                chunks.append('\n'.join(current_chunk))
        
        return chunks if chunks else [content]
    
    def _extract_set_numbers_from_chunk(self, chunk_text: str) -> List[int]:
        """
        Extract which set(s) this chunk contains based on score patterns.
        Returns list of set numbers (e.g., [2, 3] for a mixed chunk).
        """
        import re
        
        if not hasattr(self, 'set_mapping') or not self.set_mapping:
            return []
        
        set_numbers = set()
        
        # Find all "Score: X-Y" patterns in chunk
        score_matches = re.findall(r'Score: (\d+)-(\d+)', chunk_text)
        
        for server_sets, returner_sets in score_matches:
            set_score = f"{server_sets}-{returner_sets}"
            
            # Reverse lookup: which set has this score pattern?
            for set_num, expected_score in self.set_mapping.items():
                # Check both the expected score and its reverse (server perspective flip)
                score_parts = expected_score.split('-')
                reversed_score = f"{score_parts[1]}-{score_parts[0]}" if len(score_parts) == 2 else expected_score
                
                if set_score == expected_score or set_score == reversed_score:
                    set_numbers.add(set_num)
        
        return sorted(list(set_numbers))
    
    def _extract_game_scores_from_chunk(self, chunk_text: str) -> List[str]:
        """
        Extract which game scores appear in this chunk.
        Returns list of game scores (e.g., ['0-0', '1-0', '2-1']).
        """
        import re
        
        game_scores = set()
        
        # Find all "Score: X-Y G1-G2" patterns in chunk
        # Format: "Score: 2-0 4-5 0-15" where 4-5 is the game score
        score_matches = re.findall(r'Score: \d+-\d+ (\d+-\d+)', chunk_text)
        
        for game_score in score_matches:
            game_scores.add(game_score)
        
        return sorted(list(game_scores))
    
    def _transform_point_by_point_in_content(self, content: str) -> str:
        """
        Find and transform the point-by-point section in the full content.
        Adds player attribution to each shot in rallies.
        """
        import re
        
        # Find the point-by-point section
        pbp_start = content.find('POINT-BY-POINT NARRATIVE:')
        if pbp_start == -1:
            return content  # No PBP section found
        
        # Find where it ends (look for next major section or end of file)
        # PBP is typically the last section, but check anyway
        pbp_end = len(content)
        for next_section in ['RALLY OUTCOMES STATISTICS:', 'OTHER DATA:']:
            section_pos = content.find(next_section, pbp_start + 1)
            if section_pos != -1 and section_pos < pbp_end:
                pbp_end = section_pos
        
        # Extract, transform, and replace
        raw_pbp = content[pbp_start:pbp_end]
        print("[TRANSFORM] Adding shot attribution to point-by-point data...")
        transformed_pbp = self._transform_point_by_point_data(raw_pbp)
        
        return content[:pbp_start] + transformed_pbp + content[pbp_end:]
    
    def _transform_point_by_point_data(self, raw_pbp_text: str) -> str:
        """
        Transform raw PBP notation into explicit, LLM-friendly format with shot attribution.
        """
        import re
        
        # Keep the header
        result = "POINT-BY-POINT NARRATIVE:\n"
        result += "-" * 30 + "\n\n"
        
        # Find all points
        points = re.findall(r'(Point \d+.*?)(?=Point \d+|$)', raw_pbp_text, re.DOTALL)
        
        transformed_count = 0
        for point_text in points:
            if not point_text.strip():
                continue
            transformed = self._transform_single_point(point_text.strip())
            result += transformed + "\n\n"
            transformed_count += 1
        
        return result
    
    def _transform_single_point(self, point_text: str) -> str:
        """Transform a single point into explicit format with shot attribution."""
        import re
        
        # Parse point header
        header_match = re.search(
            r'Point (\d+) \[Server: (.*?) \| Returner: (.*?) \| Score: ([\d-]+) ([\d-]+) ([\d-]+)\]:',
            point_text
        )
        
        if not header_match:
            return point_text  # Fallback to original
        
        point_num = header_match.group(1)
        server = header_match.group(2).strip()
        returner = header_match.group(3).strip()
        set_score = header_match.group(4)
        game_score = header_match.group(5)
        point_score = header_match.group(6)
        
        # CRITICAL: Validate and fix server == returner bug using rally structure
        # SEMICOLONS INDICATE A CHANGE IN HITTER
        rally_text = point_text[header_match.end():].strip()
        
        # Check if server == returner (this is the bug!)
        if server.strip().lower() == returner.strip().lower() and self.player1 and self.player2:
            # Use rally structure (semicolons = hitter alternation) to determine correct returner
            shots = [s.strip() for s in rally_text.split(';') if s.strip()]
            
            if len(shots) >= 2:
                # Rally structure: Shot 0 = server, Shot 1 = returner, Shot 2 = server, etc.
                # First shot should be serve (by server), second shot is return (by returner)
                first_shot = shots[0].lower()
                is_serve = '1st serve' in first_shot or '2nd serve' in first_shot or 'serve' in first_shot
                
                if is_serve:
                    # Determine which player the server is by matching server name
                    server_lower = server.lower().strip()
                    p1_lower = self.player1.lower().strip()
                    p2_lower = self.player2.lower().strip()
                    
                    # Use fuzzy matching to determine server
                    if server_lower == p1_lower or (p1_lower in server_lower or server_lower in p1_lower):
                        # Server is player1, returner is player2
                        returner = self.player2
                    elif server_lower == p2_lower or (p2_lower in server_lower or server_lower in p2_lower):
                        # Server is player2, returner is player1
                        returner = self.player1
                    else:
                        # Can't match - use context from player names
                        # If server name is closer to player1, returner is player2
                        sim1 = 1.0 if server_lower == p1_lower else (0.9 if p1_lower in server_lower or server_lower in p1_lower else 0.0)
                        sim2 = 1.0 if server_lower == p2_lower else (0.9 if p2_lower in server_lower or server_lower in p2_lower else 0.0)
                        returner = self.player2 if sim1 > sim2 else self.player1
                    
                else:
                    # First shot is not a serve - can't infer from structure, use best guess
                    server_lower = server.lower().strip()
                    p1_lower = self.player1.lower().strip()
                    p2_lower = self.player2.lower().strip()
                    sim1 = 1.0 if server_lower == p1_lower else (0.9 if p1_lower in server_lower or server_lower in p1_lower else 0.0)
                    sim2 = 1.0 if server_lower == p2_lower else (0.9 if p2_lower in server_lower or server_lower in p2_lower else 0.0)
                    returner = self.player2 if sim1 > sim2 else self.player1
            else:
                # Single shot (ace/service winner) - CRITICAL: Server ALWAYS hits the shot
                # Since server is correct, returner MUST be the other player
                server_lower = server.lower().strip()
                p1_lower = self.player1.lower().strip()
                p2_lower = self.player2.lower().strip()
                
                # Match server to determine which player it is, then returner is the other
                if server_lower == p1_lower or (p1_lower in server_lower or server_lower in p1_lower):
                    # Server is player1, returner is player2
                    returner = self.player2
                elif server_lower == p2_lower or (p2_lower in server_lower or server_lower in p2_lower):
                    # Server is player2, returner is player1
                    returner = self.player1
                else:
                    # Can't match - use similarity as fallback
                    sim1 = 1.0 if server_lower == p1_lower else (0.9 if p1_lower in server_lower or server_lower in p1_lower else 0.0)
                    sim2 = 1.0 if server_lower == p2_lower else (0.9 if p2_lower in server_lower or server_lower in p2_lower else 0.0)
                    returner = self.player2 if sim1 > sim2 else self.player1
                
        
        # Parse rally with corrected returner
        rally_shots = self._parse_rally_sequence(rally_text, server, returner)
        
        # UNIFIED: Use _determine_point_winner
        point_winner = self._determine_point_winner(rally_shots, server, returner)
        
        # Build the transformed point text
        result = f"Point {point_num} [Server: {server} | Returner: {returner} | Score: {set_score} {game_score} {point_score}]:\n"
        
        # Add rally with attribution
        rally_description = []
        for shot in rally_shots:
            shot_desc = f"{shot['description']} [{shot['player']}]"
            rally_description.append(shot_desc)
        
        result += "; ".join(rally_description) + "."
        
        # Add point winner
        if point_winner:
            result += f" [Point won by: {point_winner}]"
        
        return result
    
    def _extract_point_by_point_data(self, content: str) -> None:
        """
        Extract point-by-point data into structured format for analysis.
        Populates self.point_by_point with list of point dictionaries.
        """
        import re
        
        self.point_by_point = []
        
        # Find the point-by-point section
        pbp_start = content.find('POINT-BY-POINT NARRATIVE:')
        if pbp_start == -1:
            print("[WARN] No POINT-BY-POINT NARRATIVE section found")
            return
        
        # Find where it ends
        pbp_end = len(content)
        for next_section in ['RALLY OUTCOMES STATISTICS:', 'OTHER DATA:', 'KEY POINTS']:
            section_pos = content.find(next_section, pbp_start + 1)
            if section_pos != -1 and section_pos < pbp_end:
                pbp_end = section_pos
        
        pbp_text = content[pbp_start:pbp_end]
        
        # Parse each point - look for transformed format with [Server: ...] headers
        # Format: Point N [Server: X | Returner: Y | Score: A-B C-D E-F]:
        point_pattern = r'Point\s+(\d+)\s+\[Server:\s*([^\|]+)\s*\|\s*Returner:\s*([^\|]+)\s*\|\s*Score:\s*([^\]]+)\]:\s*(.+?)(?=Point\s+\d+\s+\[|$)'
        
        points = re.findall(point_pattern, pbp_text, re.DOTALL)
        
        for point_num, server, returner, score, point_text in points:
            server = server.strip()
            returner = returner.strip()
            score = score.strip()
            point_text = point_text.strip()
            
            # Clean up the point text (remove trailing newlines, etc.)
            point_text = re.sub(r'\s+', ' ', point_text).strip()
            
            self.point_by_point.append({
                'point_number': int(point_num),
                'server': server,
                'returner': returner,
                'score': score,
                'point_text': point_text,
                'description': point_text  # Alias for compatibility
            })
        
        print(f"[PBP] Extracted {len(self.point_by_point)} points for analysis")
        
        # Enrich point data with context, pressure, and tactics
        self._enrich_point_data()
        
        # Extract game winners after loading point data
        self._extract_game_winners()
    
    def _extract_point_by_point_from_nl_file(self, nl_filename: str) -> None:
        """
        Load and extract point-by-point data from NL file.
        This is used when embeddings are cached but PBP data needs to be loaded.
        The NL file has [Point won by:] tags which are essential for analysis.
        """
        print(f"[EXTRACT] Reading NL file for point-by-point data: {nl_filename}")
        with open(nl_filename, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Extract player names from content if not already set
        if not self.player1 or not self.player2:
            import re
            players_match = re.search(r'players were (.+?)\s+and\s+(.+?)\.', content, re.IGNORECASE)
            if players_match:
                self.player1 = players_match.group(1).strip()
                self.player2 = players_match.group(2).strip()
                print(f"[EXTRACT] Found players: {self.player1} vs {self.player2}")
        
        # Parse match score for set mapping
        self._parse_match_score(content)
        
        # Extract structured point-by-point data (includes [Point won by:] tags)
        self._extract_point_by_point_data(content)
    
    def _load_point_by_point_from_json(self, pointlog_rows: list) -> None:
        """
        Load point-by-point data from structured JSON (pointlog_rows).
        This is more reliable than parsing text.
        """
        if not pointlog_rows:
            print("[WARN] No pointlog_rows provided")
            return
        
        self.point_by_point = []
        
        for row in pointlog_rows:
            # Extract the key fields from JSON structure
            point_number = row.get('point_number', 0)
            server = row.get('server', '')
            returner = row.get('returner', '')
            
            # Build score string from sets, games, points
            sets = row.get('sets', '')
            games = row.get('games', '')
            points = row.get('points', '')
            score = f"{sets} {games} {points}".strip()
            
            # Get the point description/rally text
            point_text = row.get('description', '')
            
            # Some JSON formats have 'formatted' field
            if not point_text and 'formatted' in row:
                # Extract from formatted: "Point N: description"
                formatted = row['formatted']
                if ':' in formatted:
                    point_text = formatted.split(':', 1)[1].strip()
            
            if point_text:
                self.point_by_point.append({
                    'point_number': point_number,
                    'server': server,
                    'returner': returner,
                    'score': score,
                    'point_text': point_text,
                    'description': point_text  # Alias for compatibility
                })
        
        print(f"[JSON-PBP] Loaded {len(self.point_by_point)} points from JSON")
        
        # Enrich point data with context, pressure, and tactics
        self._enrich_point_data()
        
        # Extract game winners after loading point data
        self._extract_game_winners()
    
    def _extract_game_winners(self) -> None:
        """
        Parse point-by-point data to determine which player won each game.
        Populates self.game_winners with mapping of (set_num, game_num) -> winner.
        """
        if not self.point_by_point:
            return
        
        self.game_winners = {}
        prev_games = None
        current_set = 1
        current_game = 0  # Current game number (0 = not started, 1 = first game, etc.)
        prev_set = 1
        
        for point_data in self.point_by_point:
            score = point_data.get('score', '')
            server = point_data.get('server', '')
            returner = point_data.get('returner', '')
            
            # Parse score: "0-0 0-0 0-0" -> sets, games, points
            parts = score.strip().split()
            if len(parts) < 2:
                continue
            
            try:
                sets_score = parts[0]  # e.g., "0-0"
                games_score = parts[1]  # e.g., "3-2"
                
                # Detect set change
                if '-' in sets_score:
                    set_parts = sets_score.split('-')
                    p1_sets = int(set_parts[0])
                    p2_sets = int(set_parts[1])
                    new_set = p1_sets + p2_sets + 1
                    
                    if new_set != current_set:
                        # Record final game of previous set if needed
                        if prev_games is not None and current_game > 0:
                            if '-' in prev_games:
                                prev_parts = prev_games.split('-')
                                prev_p1 = int(prev_parts[0])
                                prev_p2 = int(prev_parts[1])
                                # Determine winner of last game
                                if prev_p1 > prev_p2:
                                    self.game_winners[(prev_set, current_game)] = 'player1'
                                elif prev_p2 > prev_p1:
                                    self.game_winners[(prev_set, current_game)] = 'player2'
                        
                        prev_set = current_set
                        current_set = new_set
                        prev_games = None  # Reset for new set
                        current_game = 0  # Reset for new set
                
                # Detect game change (when games_score changes, a game just completed)
                if games_score != prev_games:
                    if prev_games is None:
                        # First point of set - initialize current_game
                        if '-' in games_score:
                            game_parts = games_score.split('-')
                            p1_games = int(game_parts[0])
                            p2_games = int(game_parts[1])
                            
                            # If first point already shows a completed game (not 0-0)
                            if p1_games > 0 or p2_games > 0:
                                # Game 1 is already complete
                                current_game = 1
                                if p1_games > p2_games:
                                    self.game_winners[(current_set, 1)] = 'player1'
                                elif p2_games > p1_games:
                                    self.game_winners[(current_set, 1)] = 'player2'
                                # Move to next game since game 1 is complete
                                current_game = 2
                            else:
                                # Starting at 0-0, we're in game 1 (not completed yet)
                                current_game = 1
                    else:
                        # A game was just completed - determine who won the game that just ended
                        if '-' in games_score and '-' in prev_games:
                            game_parts = games_score.split('-')
                            p1_games = int(game_parts[0])
                            p2_games = int(game_parts[1])
                            
                            prev_parts = prev_games.split('-')
                            prev_p1 = int(prev_parts[0])
                            prev_p2 = int(prev_parts[1])
                            
                            # Determine who won by checking which player's score increased
                            # Record for the game that just completed (prev_games represents the completed game)
                            # current_game is the game we were in, which just completed
                            if current_game > 0:
                                if p1_games > prev_p1:
                                    # Player 1's game count increased - they won
                                    self.game_winners[(current_set, current_game)] = 'player1'
                                elif p2_games > prev_p2:
                                    # Player 2's game count increased - they won
                                    self.game_winners[(current_set, current_game)] = 'player2'
                            
                            # Move to next game AFTER recording the winner
                            current_game += 1
                        else:
                            # Games score changed but not in expected format, increment anyway
                            if current_game == 0:
                                current_game = 1
                            else:
                                current_game += 1
                
                prev_games = games_score
                
            except (ValueError, IndexError):
                continue
        
        # Record final game if match ended mid-game (though this is rare)
        # Actually, if we're at the end, the last game should already be recorded
        # But let's handle the case where the last point is the final point of the last game
        if prev_games is not None and current_game > 0:
            game_key = (current_set, current_game)
            if game_key not in self.game_winners:
                # Last game might not have been recorded yet
                if '-' in prev_games:
                    prev_parts = prev_games.split('-')
                    prev_p1 = int(prev_parts[0])
                    prev_p2 = int(prev_parts[1])
                    # Determine winner of last game
                    if prev_p1 > prev_p2:
                        self.game_winners[game_key] = 'player1'
                    elif prev_p2 > prev_p1:
                        self.game_winners[game_key] = 'player2'
        
        if self.game_winners:
            print(f"[GAMES] Tracked {len(self.game_winners)} games across {current_set} sets")
    
    def _is_game_query(self, question: str) -> bool:
        """
        Detect if query is about games (not points).
        
        Examples of game queries:
        - "How many games did each player win?"
        - "How many service games did Sinner hold?"
        - "What was the total number of games won?"
        """
        question_lower = question.lower()
        
        # Game indicators
        game_keywords = [
            'games won', 'games did', 'service games', 'service game',
            'games held', 'games hold', 'hold',
            'total number of games', 'how many games', 'game count',
            'break serve', 'breaks', 'broke serve', 'broken serve'
        ]
        
        # Check for game keywords
        has_game_keyword = any(kw in question_lower for kw in game_keywords)
        
        # Exclude if clearly asking about points
        point_keywords = ['points', 'point won', 'point by point']
        has_point_keyword = any(kw in question_lower for kw in point_keywords)
        
        # CRITICAL: "service game" + "percentage" queries MUST use game-level tracking
        # They count GAMES held/won, not POINTS won
        is_service_game_percentage = ('service game' in question_lower or 'service games' in question_lower) and \
                                     any(kw in question_lower for kw in ['percentage', 'percent', '%', 'win rate'])
        
        # Break queries are game-level queries (count games won on opponent's serve)
        is_break_query = 'break' in question_lower and 'break point' not in question_lower
        
        # Return True for:
        # 1. Regular game count queries (has_game_keyword without points)
        # 2. Service game percentage queries (must use game-level tracking)
        # 3. Break queries (game-level, not point-level)
        return (has_game_keyword and not has_point_keyword) or is_service_game_percentage or is_break_query
    
    def _handle_game_query(self, question: str, classification: Dict) -> str:
        """
        Handle queries about games (not points).
        
        Uses game tracking from self.game_winners.
        Supports both count and percentage queries.
        """
        question_lower = question.lower()
        player_filter = classification.get('filters', {}).get('player', '')
        
        # Ensure game_winners is populated
        if not hasattr(self, 'game_winners') or not self.game_winners:
            self._extract_game_winners()
        
        # Check if asking for percentage
        is_percentage_query = any(kw in question_lower for kw in ['percentage', 'percent', '%', 'win rate'])
        
        # Check if asking about service games
        is_service_games = 'service' in question_lower
        
        # Determine which player(s) to show
        show_both = not player_filter or player_filter.lower() == 'both' or 'each player' in question_lower
        
        if is_percentage_query and is_service_games:
            # Service game win percentage: (service games held) / (total service games)
            # USE TREE STRUCTURE: Build game aggregation from point metadata (uses set_number, game_number_in_set)
            # This ensures we're using the proper point->game->set->match hierarchy
            if not hasattr(self, '_game_aggregation') or not self._game_aggregation:
                self._build_game_aggregation()
            
            p1_service_games_held = 0
            p1_total_service_games = 0
            p2_service_games_held = 0
            p2_total_service_games = 0
            
            # Use _game_aggregation which is built from point metadata tree structure
            # Each game has: winner, server, is_break, set_number, game_number_in_set
            for game_key, game_data in self._game_aggregation.items():
                winner = game_data.get('winner', '')
                server = game_data.get('server', '')
                
                # Skip games without server or winner
                if not server or not winner:
                    continue
                
                # Normalize player names using same pattern as _get_games_won_by_player for consistency
                server_normalized = (server or '').lower().replace(' ', '')
                winner_normalized = (winner or '').lower().replace(' ', '')
                player1_normalized = (self.player1 or '').lower().replace(' ', '')
                player2_normalized = (self.player2 or '').lower().replace(' ', '')
                
                is_player1_server = server_normalized == player1_normalized
                is_player2_server = server_normalized == player2_normalized
                is_player1_winner = winner_normalized == player1_normalized
                is_player2_winner = winner_normalized == player2_normalized
                
                if is_player1_server:
                    p1_total_service_games += 1
                    if is_player1_winner:
                        p1_service_games_held += 1
                elif is_player2_server:
                    p2_total_service_games += 1
                    if is_player2_winner:
                        p2_service_games_held += 1
                else:
                    # Debug: why didn't match?
                    print(f"[GAME-QUERY] WARNING: Server '{server}' didn't match '{self.player1}' or '{self.player2}' for game {game_key}")
            
            print(f"[GAME-QUERY] Using _game_aggregation (tree structure) - {len(self._game_aggregation)} games")
            print(f"[GAME-QUERY] {self.player1}: {p1_service_games_held}/{p1_total_service_games} service games held")
            print(f"[GAME-QUERY] {self.player2}: {p2_service_games_held}/{p2_total_service_games} service games held")
            
            # Calculate percentages
            p1_pct = (p1_service_games_held / p1_total_service_games * 100) if p1_total_service_games > 0 else 0
            p2_pct = (p2_service_games_held / p2_total_service_games * 100) if p2_total_service_games > 0 else 0
            
            if show_both:
                response = f"Based on the calculated match data:\n\n"\
                      f"- **{self.player1}**: {p1_pct:.1f}% ({p1_service_games_held} of {p1_total_service_games} service games held)\n"\
                      f"- **{self.player2}**: {p2_pct:.1f}% ({p2_service_games_held} of {p2_total_service_games} service games held)"
                return response
            else:
                # Use same normalization pattern as _get_games_won_by_player for consistency
                player_filter_normalized = (player_filter or '').lower().replace(' ', '')
                player1_normalized = (self.player1 or '').lower().replace(' ', '')
                player2_normalized = (self.player2 or '').lower().replace(' ', '')
                is_player1 = player_filter_normalized == player1_normalized
                pct = p1_pct if is_player1 else p2_pct
                held = p1_service_games_held if is_player1 else p2_service_games_held
                total = p1_total_service_games if is_player1 else p2_total_service_games
                return f"Based on the calculated match data, {player_filter} had a **{pct:.1f}% service game win percentage** ({held} of {total} service games held)."
        
        else:
            # Count query (not percentage)
            # UNIFIED: ALWAYS calculate both players - filter at display time
            p1_games = len(self._get_games_won_by_player(self.player1))
            p2_games = len(self._get_games_won_by_player(self.player2))
            
            metric_label = "service games held" if is_service_games and ('held' in question_lower or 'hold' in question_lower) else "games won"
            
            if show_both:
                response = f"Based on the calculated match data:\n\n"\
                      f"- **{self.player1}**: {p1_games} {metric_label}\n"\
                      f"- **{self.player2}**: {p2_games} {metric_label}\n\n"\
                      f"**Total:** {p1_games + p2_games} games"
                
                # Note: Narrative synthesis removed - game queries are simple counts
                # If narrative context is needed, it should be handled at a higher level
                
                return response
            else:
                # Single player - extract from already-calculated data
                # Use same normalization pattern as _get_games_won_by_player for consistency
                player_filter_normalized = (player_filter or '').lower().replace(' ', '')
                player1_normalized = (self.player1 or '').lower().replace(' ', '')
                player2_normalized = (self.player2 or '').lower().replace(' ', '')
                is_player1 = player_filter_normalized == player1_normalized
                games = p1_games if is_player1 else p2_games
                return f"Based on the calculated match data, {player_filter} had **{games} {metric_label}**."
    
    def _get_games_won_by_player(self, player_name: str, set_filter: int = None, role: str = None) -> list:
        """
        Get the list of (set, game) tuples won by a specific player.
        
        Args:
            player_name: Name of player
            set_filter: Optional set number to filter by
            role: Optional 'server' or 'returner' to filter by service games
        
        Returns:
            List of (set_num, game_num) tuples
        """
        if not hasattr(self, 'game_winners') or not self.game_winners:
            return []
        
        if not player_name:
            return []
        
        # Normalize player name
        player_normalized = player_name.lower().replace(' ', '')
        player1_normalized = (self.player1 or '').lower().replace(' ', '')
        player2_normalized = (self.player2 or '').lower().replace(' ', '')
        
        is_player1 = player_normalized == player1_normalized
        is_player2 = player_normalized == player2_normalized
        
        if not is_player1 and not is_player2:
            return []
        
        # Get games won
        games_won = []
        for (set_num, game_num), winner in self.game_winners.items():
            if set_filter and set_num != set_filter:
                continue
            
            if (is_player1 and winner == 'player1') or (is_player2 and winner == 'player2'):
                # TODO: Add role filtering if needed (requires tracking server per game)
                games_won.append((set_num, game_num))
        
        return games_won
    
    def _get_games_lost_by_player(self, player_name: str, set_filter: int = None, role: str = None) -> list:
        """
        Get the list of (set, game) tuples lost by a specific player.
        
        If role='returner', this counts games where the player was the returner and WON (broke serve).
        Otherwise, it counts games where the player LOST (their serve was broken or they lost as returner).
        """
        if not hasattr(self, 'game_winners') or not self.game_winners:
            return []
        
        if not player_name:
            return []
        
        # Normalize player name
        player_normalized = player_name.lower().replace(' ', '')
        player1_normalized = (self.player1 or '').lower().replace(' ', '')
        player2_normalized = (self.player2 or '').lower().replace(' ', '')
        
        is_player1 = player_normalized == player1_normalized
        is_player2 = player_normalized == player2_normalized
        
        if not is_player1 and not is_player2:
            return []
        
        # Get game servers to determine who was serving
        if not hasattr(self, 'game_servers') or not self.game_servers:
            return []
        
        games_result = []
        for (set_num, game_num), winner in self.game_winners.items():
            if set_filter and set_num != set_filter:
                continue
            
            server = self.game_servers.get((set_num, game_num), '')
            server_is_player1 = server and player1_normalized in server.lower()
            server_is_player2 = server and player2_normalized in server.lower()
            
            if role == 'returner':
                # For "break serve": count games where player was returner AND won
                if is_player1:
                    # Player1 was returner if server was player2, and player1 won
                    if server_is_player2 and winner == 'player1':
                        games_result.append((set_num, game_num))
                elif is_player2:
                    # Player2 was returner if server was player1, and player2 won
                    if server_is_player1 and winner == 'player2':
                        games_result.append((set_num, game_num))
            else:
                # Regular games_lost: count games where player lost
                if (is_player1 and winner == 'player2') or (is_player2 and winner == 'player1'):
                    games_result.append((set_num, game_num))
        
        return games_result
    
    def _get_overall_game_number(self, set_num: int, game_num: int) -> int:
        """
        Convert (set_num, game_num) to overall game number across the match.
        
        Examples:
        - (1, 4) -> 4 (if set 1 has 4+ games)
        - (2, 5) -> 15 (if set 1 had 10 games, then 10 + 5 = 15)
        - (3, 4) -> 25 (if set 1 had 10 games, set 2 had 11 games, then 10 + 11 + 4 = 25)
        
        Args:
            set_num: Set number (1-indexed)
            game_num: Game number within that set (1-indexed)
        
        Returns:
            Overall game number (1-indexed), or None if (set_num, game_num) not found
        """
        if not hasattr(self, 'game_winners') or not self.game_winners:
            return None
        
        # Verify that (set_num, game_num) exists
        if (set_num, game_num) not in self.game_winners:
            return None
        
        # Count all games in sets before this set
        games_in_previous_sets = 0
        for (s, g), _ in self.game_winners.items():
            if s < set_num:
                games_in_previous_sets += 1
        
        # Add the game number in this set
        overall_game = games_in_previous_sets + game_num
        
        return overall_game
    
    def _parse_rally_sequence(self, rally_text: str, server: str, returner: str) -> List[Dict]:
        """
        Parse rally into sequence of shots with player attribution.
        EXTRACTS player from [Player Name] tags in NL file (authoritative).
        Falls back to alternation logic if tags are missing.
        Returns list of {player, description, outcome} dicts.
        """
        import re
        
        shots = []
        current_player = server  # Server always starts (fallback for alternation)
        in_rally = False  # Track if we're in rally (after successful serve)
        shot_number = 0  # Track shot number (excludes faults)
        
        # CRITICAL: Handle "fault. 2nd serve" patterns - ensure 2nd serve is a separate segment
        # Pattern 1: "fault (reason). 2nd serve" - with reason in parentheses
        rally_text = re.sub(r'fault \([^)]+\)\.\s+(2nd serve)', r'fault. SERVE_SEPARATOR \1', rally_text)
        # Pattern 2: "fault. 2nd serve" - without reason
        rally_text = re.sub(r'fault\.\s+(2nd serve)', r'fault. SERVE_SEPARATOR \1', rally_text, flags=re.IGNORECASE)
        # Pattern 3: ", fault. 2nd serve" - comma before fault
        rally_text = re.sub(r',\s*fault\.\s+(2nd serve)', r', fault. SERVE_SEPARATOR \1', rally_text, flags=re.IGNORECASE)
        # Pattern 4: Handle let serves - "let. 1st serve" or "let. 2nd serve"
        rally_text = re.sub(r'let\.\s+(\d(?:st|nd)\s+serve)', r'let. SERVE_SEPARATOR \1', rally_text, flags=re.IGNORECASE)
        
        # Split by semicolons (each shot)
        shot_parts = rally_text.split(';')
        
        # Also split by SERVE_SEPARATOR marker
        expanded_parts = []
        for part in shot_parts:
            if 'SERVE_SEPARATOR' in part:
                sub_parts = part.split('SERVE_SEPARATOR')
                expanded_parts.extend(sub_parts)
            else:
                expanded_parts.append(part)
        shot_parts = expanded_parts
        
        for shot_part in shot_parts:
            shot_part = shot_part.strip()
            if not shot_part:
                continue
            
            # EXTRACT player from [Player Name] tag (authoritative from NL file)
            player_from_tag = None
            player_tag_match = re.search(r'\[([A-Z][^\]]+)\]', shot_part)
            if player_tag_match:
                player_from_tag = player_tag_match.group(1).strip()
                # Skip [Point won by:] tags
                if 'point won by' in player_from_tag.lower():
                    player_from_tag = None
            
            # Clean up shot description (remove tags)
            shot_clean = shot_part.strip()
            shot_clean = re.sub(r'\s*\[point won by:.*?\]', '', shot_clean, flags=re.IGNORECASE)
            shot_clean = re.sub(r'\s*\[[A-Z][^\]]*\]\s*\.?$', '', shot_clean)  # Remove trailing [Player Name] tags
            shot_clean = shot_clean.strip()
            
            # Check for outcomes - ORDER MATTERS! Check specific outcomes before generic ones
            outcome = None
            shot_lower = shot_clean.lower()
            if 'double fault' in shot_lower or ('2nd serve' in shot_lower and 'fault' in shot_lower):
                outcome = 'DOUBLE_FAULT'
            elif 'ace' in shot_lower:
                outcome = 'ACE'
            elif 'service winner' in shot_lower:
                outcome = 'SERVICE_WINNER'
            elif 'winner' in shot_lower:
                outcome = 'WINNER'
            elif 'unforced error' in shot_lower:
                outcome = 'UNFORCED ERROR'
            elif 'forced error' in shot_lower:
                outcome = 'FORCED ERROR'
            elif 'fault' in shot_lower and ('1st serve' in shot_lower or '2nd serve' in shot_lower):
                # Only mark as FAULT if it's a serve fault, not other uses of "fault"
                outcome = 'FAULT'
            elif 'let' in shot_lower and ('1st serve' in shot_lower or '2nd serve' in shot_lower):
                outcome = 'LET'
            
            # Determine player: use tag if available, otherwise use alternation logic
            shot_player = player_from_tag if player_from_tag else current_player
            
            # Handle serves - ALWAYS assigned to server
            if '1st serve' in shot_clean.lower() or '2nd serve' in shot_clean.lower():
                # Serve is always by the server (override tag if needed)
                shot_player = server
                
                # Increment shot number only for non-faults
                if outcome not in ('FAULT', 'LET'):
                    shot_number += 1
                
                # Extract full shot metadata
                shot_meta = self._extract_shot_metadata(shot_clean)
                shots.append({
                    'player': shot_player,
                    'description': shot_clean,
                    'outcome': outcome or shot_meta.get('outcome'),
                    'shot_number': shot_number if outcome not in ('FAULT', 'LET') else None,
                    # === NEW TAXONOMY ===
                    'shot_phase': shot_meta.get('shot_phase'),
                    'contact_type': shot_meta.get('contact_type'),
                    'spin': shot_meta.get('spin'),
                    'intent': shot_meta.get('intent'),
                    'location': shot_meta.get('location'),
                    # === CORE DIMENSIONS ===
                    'shot_type': shot_meta.get('shot_type'),
                    'direction': shot_meta.get('direction'),
                    'depth': shot_meta.get('depth'),
                    'serve_target': shot_meta.get('serve_target'),
                    # === LEGACY (backward compatibility) ===
                    'shot_modifier': shot_meta.get('shot_modifier'),
                    'shot_modifiers': shot_meta.get('shot_modifiers'),
                    'at_net': shot_meta.get('at_net'),
                    'court_position': shot_meta.get('court_position'),
                    'is_return': shot_meta.get('is_return')
                })
                # If successful serve, next shot is returner's
                # CRITICAL: Faults and Lets do NOT start the rally - server serves again
                if outcome not in ('FAULT', 'LET', None) or (outcome is None and 'fault' not in shot_clean.lower() and 'let' not in shot_clean.lower()):
                    current_player = returner
                    in_rally = True
                else:
                    # Fault or Let - next serve attempt, stay on server
                    current_player = server
                    in_rally = False
            else:
                # Regular rally shot
                shot_number += 1
                # Extract full shot metadata
                shot_meta = self._extract_shot_metadata(shot_clean)
                shots.append({
                    'player': shot_player,
                    'description': shot_clean,
                    'outcome': outcome or shot_meta.get('outcome'),
                    'shot_number': shot_number,
                    # === NEW TAXONOMY ===
                    'shot_phase': shot_meta.get('shot_phase'),
                    'contact_type': shot_meta.get('contact_type'),
                    'spin': shot_meta.get('spin'),
                    'intent': shot_meta.get('intent'),
                    'location': shot_meta.get('location'),
                    # === CORE DIMENSIONS ===
                    'shot_type': shot_meta.get('shot_type'),
                    'direction': shot_meta.get('direction'),
                    'depth': shot_meta.get('depth'),
                    'serve_target': shot_meta.get('serve_target'),
                    # === LEGACY (backward compatibility) ===
                    'shot_modifier': shot_meta.get('shot_modifier'),
                    'shot_modifiers': shot_meta.get('shot_modifiers'),
                    'at_net': shot_meta.get('at_net'),
                    'court_position': shot_meta.get('court_position'),
                    'is_return': shot_meta.get('is_return')
                })
                # Alternate for next shot (fallback logic)
                current_player = returner if current_player == server else server
        
        return shots
    
    def _extract_shot_metadata(self, shot_description: str) -> Dict:
        """
        ROBUST SHOT METADATA EXTRACTOR - NEW TAXONOMY
        
        Extracts ALL components from complex shot descriptions using a cleaner taxonomy:
        "forehand at the net volley down the line,winner"
        "backhand slice approach shot crosscourt (deep)"
        
        NEW STRUCTURE:
        - shot_type: forehand, backhand, serve (base stroke) - NOTE: overhead is NOT a shot_type
        - shot_phase: serve, return, rally, net (tactical phase)
        - contact_type: groundstroke, volley, half_volley, swinging_volley, overhead (how ball is struck)
        - spin: slice, flat, topspin
        - intent: approach, drop_shot, lob, passing_shot, winner_attempt
        - location: baseline, mid_court, net, service_line
        - direction: crosscourt, down_the_line, inside_out, inside_in, down_the_middle
        - depth: deep, shallow, very_deep
        - serve_target: wide, body, t (for serves only)
        - outcome: winner, unforced_error, forced_error, ace, etc.
        - is_return: True if this is a return shot
        
        LEGACY FIELDS (for backward compatibility):
        - shot_modifier: primary modifier (deprecated, use contact_type/spin/intent)
        - shot_modifiers: LIST of ALL modifiers (deprecated)
        - at_net: True/False (deprecated, use location=='net')
        - court_position: (deprecated, use location)
        """
        desc = shot_description.lower()
        
        # === SHOT TYPE (primary stroke) ===
        # NOTE: overhead/smash is NOT a shot_type, it's a contact_type
        # shot_type indicates forehand/backhand stroke used for overhead
        shot_type = None
        if 'forehand' in desc:
            shot_type = 'forehand'
        elif 'backhand' in desc:
            shot_type = 'backhand'
        elif 'serve' in desc:
            shot_type = 'serve'
        # Note: 'overhead' and 'smash' are handled in contact_type, not shot_type
        
        # === CONTACT TYPE (how ball is struck) ===
        contact_type = 'groundstroke'  # Default
        if 'overhead' in desc or 'smash' in desc:
            contact_type = 'overhead'
            # For overheads, try to determine shot_type from context if not already set
            if shot_type is None:
                # Default to forehand if not specified (most overheads are forehand)
                shot_type = 'forehand'
        elif 'swinging volley' in desc:
            contact_type = 'swinging_volley'
        elif 'half volley' in desc or 'half-volley' in desc:
            contact_type = 'half_volley'
        elif 'drop volley' in desc:
            contact_type = 'drop_volley'
        elif 'volley' in desc:
            contact_type = 'volley'
        
        # === SPIN (ball rotation) ===
        spin = None
        if 'topspin' in desc:
            spin = 'topspin'
        elif 'slice' in desc or 'chip' in desc:
            spin = 'slice'
        elif 'flat' in desc:
            spin = 'flat'
        # If not specified, infer from contact type
        elif contact_type in ['volley', 'swinging_volley', 'half_volley']:
            spin = 'flat'  # Volleys are typically flat
        # Note: We don't infer spin from shot_type as shot_type values don't contain spin info
        
        # === INTENT (tactical purpose) ===
        intent = None
        if 'approach shot' in desc or 'approach' in desc:
            intent = 'approach'
        elif 'drop shot' in desc:
            intent = 'drop_shot'
        elif 'lob' in desc:
            intent = 'lob'
        elif 'passing shot' in desc or 'pass' in desc:
            intent = 'passing_shot'
        elif 'winner' in desc or 'ace' in desc or 'service winner' in desc:
            intent = 'winner_attempt'
        
        # === LEGACY: SHOT MODIFIERS (for backward compatibility) ===
        shot_modifiers = []
        if contact_type != 'groundstroke':
            shot_modifiers.append(contact_type)
        if spin:
            shot_modifiers.append(spin)
        if intent:
            shot_modifiers.append(intent)
        
        # Primary modifier (first one found, most specific)
        shot_modifier = shot_modifiers[0] if shot_modifiers else None
        
        # === DIRECTION ===
        direction = None
        if 'inside-out' in desc or 'inside out' in desc:
            direction = 'inside_out'
        elif 'inside-in' in desc or 'inside in' in desc:
            direction = 'inside_in'
        elif 'crosscourt' in desc or 'cross court' in desc or 'cross-court' in desc:
            direction = 'crosscourt'
        elif 'down the line' in desc or 'down-the-line' in desc or 'dtl' in desc:
            direction = 'down_the_line'
        elif 'down the middle' in desc or 'middle' in desc:
            direction = 'down_the_middle'
        
        # === LOCATION (court position) ===
        location = 'baseline'  # Default
        if 'at net' in desc or 'at the net' in desc:
            location = 'net'
        elif contact_type in ['volley', 'half_volley', 'swinging_volley', 'drop_volley', 'overhead']:
            location = 'net'
        elif intent == 'approach' or 'approach' in desc:
            location = 'mid_court'
        elif 'service line' in desc:
            location = 'service_line'
        
        # === SHOT PHASE (tactical context) ===
        is_return = 'return' in desc
        is_serve = shot_type and 'serve' in shot_type.lower() or '1st serve' in desc or '2nd serve' in desc
        shot_phase = 'rally'  # Default
        if is_serve:
            shot_phase = 'serve'
        elif is_return:
            shot_phase = 'return'
        elif location == 'net':
            shot_phase = 'net'
        # else: rally (default)
        
        # === LEGACY: AT NET (for backward compatibility) ===
        at_net = (location == 'net')
        
        # === LEGACY: COURT POSITION (for backward compatibility) ===
        court_position = location
        if location == 'mid_court':
            court_position = 'approach'
        
        # === DEPTH ===
        depth = None
        if 'very deep' in desc or '(very deep)' in desc:
            depth = 'very_deep'
        elif '(deep)' in desc or 'deep)' in desc:
            depth = 'deep'
        elif '(shallow)' in desc or 'shallow)' in desc:
            depth = 'shallow'
        
        # === SERVE TARGET (for serves) ===
        serve_target = None
        if is_serve:  # Use is_serve from above
            if 'wide' in desc:
                serve_target = 'wide'
            elif 'to body' in desc or 'body' in desc:
                serve_target = 'body'
            elif 'down the t' in desc:
                serve_target = 't'
        
        # === OUTCOME ===
        outcome = None
        if 'ace' in desc:
            outcome = 'ace'
        elif 'double fault' in desc:
            outcome = 'double_fault'
        elif 'service winner' in desc:
            outcome = 'service_winner'
        elif 'unforced error' in desc:
            outcome = 'unforced_error'
        elif 'forced error' in desc:
            outcome = 'forced_error'
        elif 'winner' in desc:
            outcome = 'winner'
        elif 'fault' in desc:
            outcome = 'fault'
        
        return {
            # === NEW TAXONOMY (primary) ===
            'shot_type': shot_type,           # forehand, backhand, serve (overhead is contact_type, not shot_type)
            'shot_phase': shot_phase,         # serve, return, rally, net
            'contact_type': contact_type,     # groundstroke, volley, half_volley, swinging_volley, overhead
            'spin': spin,                     # slice, flat, topspin
            'intent': intent,                 # approach, drop_shot, lob, passing_shot, winner_attempt
            'location': location,             # baseline, mid_court, net, service_line
            'direction': direction,           # crosscourt, down_the_line, inside_out, inside_in, down_the_middle
            'depth': depth,                   # shallow, deep, very_deep
            'serve_target': serve_target,     # wide, body, t (serves only)
            'outcome': outcome,               # winner, unforced_error, forced_error, ace, etc.
            'is_return': is_return,           # Boolean
            
            # === LEGACY FIELDS (backward compatibility) ===
            'shot_modifier': shot_modifier,   # Deprecated: use contact_type/spin/intent
            'shot_modifiers': shot_modifiers, # Deprecated: ALL modifiers as list
            'at_net': at_net,                 # Deprecated: use location=='net'
            'court_position': court_position, # Deprecated: use location
            
            # === RAW ===
            'raw': shot_description
        }
    
    # =========================================================================
    # SHOT NORMALIZATION SYSTEM
    # =========================================================================
    # Maps variations/aliases to canonical forms and defines hierarchies
    # =========================================================================
    
    # ALIASES: Map variations to canonical form
    SHOT_ALIASES = {
        # Direction aliases
        'cc': 'crosscourt',
        'xc': 'crosscourt',
        'x-court': 'crosscourt',
        'cross-court': 'crosscourt',
        'cross court': 'crosscourt',
        'dtl': 'down_the_line',
        'down the line': 'down_the_line',
        'down-the-line': 'down_the_line',
        'line': 'down_the_line',
        'dtm': 'down_the_middle',
        'down the middle': 'down_the_middle',
        'middle': 'down_the_middle',
        'center': 'down_the_middle',
        'io': 'inside_out',
        'inside out': 'inside_out',
        'inside-out': 'inside_out',
        'ii': 'inside_in',
        'inside in': 'inside_in',
        'inside-in': 'inside_in',
        
        # Shot type aliases
        'fh': 'forehand',
        'bh': 'backhand',
        'sv': 'serve',
        'ret': 'return',
        'oh': 'overhead',
        
        # Modifier aliases
        'slice': 'slice',
        'chip': 'slice',
        'underspin': 'slice',
        'topspin': 'topspin',
        'flat': 'flat',
        'vb': 'volley',
        'vol': 'volley',
        'sv': 'swinging_volley',
        'hv': 'half_volley',
        'dv': 'drop_volley',
        'ds': 'drop_shot',
        'dropshot': 'drop_shot',
        'drop': 'drop_shot',
        'app': 'approach',
        'approach': 'approach',
        'approach shot': 'approach',
        
        # Serve target aliases (NOTE: These are CONTEXT-SPECIFIC - only for serve detection)
        # NOT included here to avoid conflicts with direction aliases
        # Serve target aliases are handled in serve-specific detection code
        
        # Depth aliases
        'deep': 'deep',
        'very deep': 'very_deep',
        'shallow': 'shallow',
        'short': 'shallow',
        
        # Outcome aliases
        'winner': 'winner',
        'wnr': 'winner',
        'w': 'winner',
        'ue': 'unforced_error',
        'unforced': 'unforced_error',
        'unforced error': 'unforced_error',
        'fe': 'forced_error',
        'forced': 'forced_error',
        'forced error': 'forced_error',
        'ace': 'ace',
        'df': 'double_fault',
        'double fault': 'double_fault',
    }
    
    # HIERARCHY: Supersets contain their subsets
    # When filtering by superset, include all subsets
    SHOT_HIERARCHY = {
        # Shot types: these are independent (forehand is not a superset of backhand)
        
        # Modifiers: volleys hierarchy
        'volley': ['volley', 'swinging_volley', 'half_volley', 'drop_volley'],
        'net_shot': ['volley', 'swinging_volley', 'half_volley', 'drop_volley', 'overhead'],
        
        # Depth hierarchy
        'any_deep': ['deep', 'very_deep'],
        
        # Direction groupings
        'wide_shots': ['crosscourt', 'inside_out', 'inside_in'],  # Shots that go wide
        'center_shots': ['down_the_middle', 'down_the_line'],  # Shots that go center/line
        
        # Outcome groupings
        'errors': ['unforced_error', 'forced_error', 'double_fault'],
        'winners_all': ['winner', 'ace', 'service_winner'],
        'point_ending': ['winner', 'ace', 'unforced_error', 'forced_error', 'double_fault'],
        
        # Court position groupings
        'at_net': ['volley', 'half_volley', 'drop_volley', 'overhead', 'swinging_volley'],
        'baseline': ['groundstroke', 'slice', 'topspin'],
    }
    
    def _normalize_value(self, value: str, category: str = None) -> str:
        """
        Normalize a shot/filter value to its canonical form.
        
        Args:
            value: The raw value (e.g., "cc", "dtl", "forehand")
            category: Optional hint about what type of value this is
            
        Returns:
            Canonical form (e.g., "crosscourt", "down_the_line")
        """
        if not value:
            return None
            
        value_lower = value.lower().strip()
        
        # Check aliases first
        if value_lower in self.SHOT_ALIASES:
            return self.SHOT_ALIASES[value_lower]
        
        # Already canonical
        return value_lower.replace(' ', '_').replace('-', '_')
    
    def _expand_to_matching_values(self, value: str, actual_values: set = None) -> list:
        """
        Expand a filter value to all matching values (including subsets).
        
        Args:
            value: Normalized filter value (e.g., "volley")
            actual_values: Set of values that actually exist in the data
            
        Returns:
            List of all values that should match (e.g., ["volley", "swinging_volley", "half_volley"])
        """
        if not value:
            return []
        
        # Normalize first
        normalized = self._normalize_value(value)
        
        # Check if this is a superset
        if normalized in self.SHOT_HIERARCHY:
            expanded = self.SHOT_HIERARCHY[normalized]
        else:
            expanded = [normalized]
        
        # If we have actual values, filter to only those that exist
        if actual_values:
            expanded = [v for v in expanded if v in actual_values]
        
        return expanded if expanded else [normalized]
    
    def _values_match(self, query_value: str, data_value: str, expand_hierarchy: bool = True) -> bool:
        """
        Check if a query value matches a data value, handling aliases and hierarchies.
        
        Args:
            query_value: What the user asked for (e.g., "cc", "volley")
            data_value: What's in the data (e.g., "crosscourt", "swinging_volley")
            expand_hierarchy: Whether to check superset matches
            
        Returns:
            True if they match
        """
        if not query_value or not data_value:
            return False
        
        # Normalize both
        norm_query = self._normalize_value(query_value)
        norm_data = self._normalize_value(data_value)
        
        # Direct match
        if norm_query == norm_data:
            return True
        
        # Hierarchy match (query is superset of data)
        if expand_hierarchy and norm_query in self.SHOT_HIERARCHY:
            return norm_data in self.SHOT_HIERARCHY[norm_query]
        
        return False
    
    def _get_point_metadata(self, point_data: Dict) -> Dict:
        """
        UNIVERSAL POINT METADATA EXTRACTOR
        
        Extracts ALL metadata from a point ONCE, to be used throughout the system.
        This is the SINGLE SOURCE OF TRUTH for all point analysis.
        
        Returns:
            {
                'point_number': int,
                'server': str,
                'returner': str,
                'score': str,
                'set_number': int,
                'rally_length': int,
                'rally_category': str ('1-3', '4-6', '7-9', '10+'),
                'point_winner': str,
                'winning_shot': {
                    'player': str,
                    'shot_type': str ('forehand', 'backhand', 'serve'),
                    'shot_modifier': str ('volley', 'slice', 'drop_shot', etc.),
                    'direction': str ('crosscourt', 'down_the_line', 'inside_out', etc.),
                    'at_net': bool,
                    'depth': str ('deep', 'shallow', 'very_deep'),
                    'outcome': str ('winner', 'ace', 'unforced_error', etc.)
                },
                'serve_info': {
                    'serve_number': int (1 or 2),
                    'serve_target': str ('wide', 'body', 't'),
                    'is_ace': bool,
                    'is_double_fault': bool
                },
                'return_info': {
                    'return_depth': str ('deep', 'shallow', 'very_deep'),
                    'return_direction': str,
                    'return_in_play': bool
                },
                'serve_plus_one': {
                    'shot_type': str,
                    'direction': str
                },
                'situation': {
                    'is_break_point': bool,
                    'is_game_point': bool,
                    'is_deuce': bool,
                    'is_tiebreak': bool,
                    'court_side': str ('deuce', 'ad')
                },
                'error_info': {
                    'error_player': str,
                    'error_type': str ('unforced', 'forced'),
                    'error_shot_type': str
                }
            }
        """
        point_text = point_data.get('point_text', point_data.get('description', ''))
        server = point_data.get('server', '')
        returner = point_data.get('returner', '')
        score = point_data.get('score', '')
        point_number = point_data.get('point_number', 0)
        
        # Parse rally ONCE
        rally_shots = self._parse_rally_sequence(point_text, server, returner)
        actual_shots = [s for s in rally_shots if s.get('outcome') not in ['FAULT', 'LET']]
        
        # PREFER the annotated rally count "(X-shot rally)" if it exists
        # CRITICAL: In tennis terminology, rallies START AT THE RETURN (shot 1), NOT the serve.
        # The annotated count correctly excludes serves, counting from return onwards.
        # Example: Serve → Return → Groundstroke → Groundstroke = 3-shot rally
        # Try multiple patterns to match annotated rally count
        annotated_rally_match = (
            re.search(r'\((\d+)\s*-\s*shot\s*rally\)', point_text, re.IGNORECASE) or
            re.search(r'\((\d+)\s*shot\s*rally\)', point_text, re.IGNORECASE) or
            re.search(r'\((\d+)\s*-\s*shot\)', point_text, re.IGNORECASE)
        )
        if annotated_rally_match:
            rally_length = int(annotated_rally_match.group(1))
        else:
            # Fallback: exclude serve shots from count
            # In tennis, rallies start at the return (shot 2), not the serve (shot 1)
            # Exclude shots where: shot_type starts with 'serve' OR shot_number is 1 (serve is always shot 1)
            rally_length = len([
                s for s in actual_shots 
                if not (s.get('shot_type') or '').lower().startswith('serve') 
                and s.get('shot_number') != 1
            ])
        
        # Rally category
        if rally_length <= 3:
            rally_category = '1-3'
        elif rally_length <= 6:
            rally_category = '4-6'
        elif rally_length <= 9:
            rally_category = '7-9'
        else:
            rally_category = '10+'
        
        # Extract point winner from [Point won by:] tag
        point_winner = None
        winner_match = re.search(r'\[Point won by:\s*([^\]]+)\]', point_text)
        if winner_match:
            point_winner = winner_match.group(1).strip()
        
        # === WINNING SHOT METADATA ===
        winning_shot = {}
        error_info = {}
        if actual_shots:
            last_shot = actual_shots[-1]
            last_desc = last_shot.get('description', '')
            
            winning_shot = {
                'player': last_shot.get('player', ''),
                'shot_type': last_shot.get('shot_type'),
                'shot_modifier': last_shot.get('shot_modifier'),
                'shot_modifiers': last_shot.get('shot_modifiers', []),  # ALL modifiers
                'direction': last_shot.get('direction'),
                'at_net': last_shot.get('at_net', False),
                'court_position': last_shot.get('court_position'),
                'depth': last_shot.get('depth'),
                'spin': last_shot.get('spin'),
                'outcome': last_shot.get('outcome')
            }
            
            # Error info
            outcome = last_shot.get('outcome', '')
            if outcome in ['UNFORCED ERROR', 'FORCED ERROR']:
                # Extract error shot type from description - find the FIRST (leftmost) occurrence
                # This is more accurate than checking in a fixed order
                last_description = last_shot.get('description', '').lower()
                error_shot_type = None
                earliest_pos = len(last_description)
                for shot in ['backhand', 'forehand', 'serve']:
                    pos = last_description.find(shot)
                    if pos != -1 and pos < earliest_pos:
                        earliest_pos = pos
                        error_shot_type = shot
                # Fallback to shot_type from parsed metadata if description parsing fails
                if not error_shot_type:
                    error_shot_type = last_shot.get('shot_type')
                
                error_info = {
                    'error_player': last_shot.get('player', ''),
                    'error_type': 'unforced' if 'UNFORCED' in outcome else 'forced',
                    'error_shot_type': error_shot_type
                }
        
        # === SERVE INFO ===
        point_lower = point_text.lower()
        has_1st_fault = bool(re.search(r'1st serve[^;]*fault', point_lower))
        has_2nd_serve = '2nd serve' in point_lower
        is_2nd_serve_point = has_1st_fault or has_2nd_serve
        
        serve_target = None
        if is_2nd_serve_point:
            match = re.search(r'2nd serve\s+([^;,]+)', point_lower)
            serve_desc = match.group(1) if match else ''
        else:
            match = re.search(r'1st serve\s+([^;,]+)', point_lower)
            serve_desc = match.group(1) if match else ''
        
        if 'wide' in serve_desc:
            serve_target = 'wide'
        elif 'body' in serve_desc:
            serve_target = 'body'
        elif 'down the t' in serve_desc or 't' in serve_desc.split()[-2:] if serve_desc else False:
            serve_target = 't'
        
        serve_info = {
            'serve_number': 2 if is_2nd_serve_point else 1,
            'serve_target': serve_target,
            'is_ace': winning_shot.get('outcome') == 'ACE',
            'is_double_fault': winning_shot.get('outcome') == 'DOUBLE_FAULT'
        }
        
        # === RETURN INFO ===
        return_info = {'return_depth': None, 'return_direction': None, 'return_in_play': rally_length >= 2}
        if len(actual_shots) >= 2:
            return_shot = actual_shots[1]  # Shot index 1 is the return
            return_info['return_depth'] = return_shot.get('depth')
            return_info['return_direction'] = return_shot.get('direction')
        
        # === SERVE+1 INFO ===
        serve_plus_one = {'shot_type': None, 'direction': None}
        if len(actual_shots) >= 3:
            third_shot = actual_shots[2]  # Server's 2nd shot (serve+1)
            serve_plus_one['shot_type'] = third_shot.get('shot_type')
            serve_plus_one['direction'] = third_shot.get('direction')
        
        # === SITUATION INFO ===
        situation = {
            'is_break_point': self._is_break_point_score(score),
            'is_game_point': self._is_game_point_score(score),
            'is_set_point': self._is_set_point_score(score),
            'is_match_point': self._is_match_point_score(score),
            'is_deuce': self._is_deuce_score(score),
            'is_tiebreak': self._is_tiebreak_point(score),
            'court_side': self._determine_court_side(score)
        }
        
        # === SET AND GAME INFO ===
        set_number = self._extract_current_set(score)
        game_info = self._extract_game_info(score, point_number)
        
        # === SHOT COUNTS (for all shots in the point, not just outcomes) ===
        # This enables questions like "percentage of shots that were winners"
        shot_counts = {
            'total': 0,
            'by_player': {},  # {player_name: count}
            'by_type': {},    # {forehand: count, backhand: count, ...}
            'by_player_type': {},  # {player_name: {forehand: count, backhand: count}}
            'winners': 0,
            'errors': 0,
        }
        
        for shot in actual_shots:
            shot_counts['total'] += 1
            shot_player = shot.get('player', '')
            shot_type = shot.get('shot_type', 'unknown')
            outcome = shot.get('outcome', '')
            
            # Count by player
            if shot_player:
                shot_counts['by_player'][shot_player] = shot_counts['by_player'].get(shot_player, 0) + 1
                
                # Count by player + type
                if shot_player not in shot_counts['by_player_type']:
                    shot_counts['by_player_type'][shot_player] = {}
                shot_counts['by_player_type'][shot_player][shot_type] = \
                    shot_counts['by_player_type'][shot_player].get(shot_type, 0) + 1
            
            # Count by shot type
            if shot_type:
                shot_counts['by_type'][shot_type] = shot_counts['by_type'].get(shot_type, 0) + 1
            
            # Count outcomes - GENERIC using OUTCOME_CONFIG
            outcome_config = self._get_outcome_config(outcome)
            winning_shot_type = outcome_config.get('winning_shot_type', '')
            is_positive = outcome_config.get('is_positive', True)
            
            if winning_shot_type in ['winner', 'ace', 'service_winner']:
                shot_counts['winners'] += 1
            elif 'error' in winning_shot_type:
                shot_counts['errors'] += 1
        
        return {
            'point_number': point_number,
            'server': server,
            'returner': returner,
            'score': score,
            # === SET/GAME HIERARCHY ===
            'set_number': set_number,
            'game_number_in_set': game_info.get('game_number_in_set'),
            'game_number_overall': game_info.get('game_number_overall'),
            'set_score': game_info.get('set_score'),
            'game_score': game_info.get('game_score'),
            'point_score': game_info.get('point_score'),
            # === POINT DATA ===
            'rally_length': rally_length,
            'rally_category': rally_category,
            'point_winner': point_winner,
            'winning_shot': winning_shot,
            'serve_info': serve_info,
            'return_info': return_info,
            'serve_plus_one': serve_plus_one,
            'situation': situation,
            'error_info': error_info,
            'all_shots': actual_shots,  # ALL shots with full metadata
            'shot_counts': shot_counts,  # Aggregated shot counts for this point
            'raw_text': point_text
        }
    
    def _determine_court_side(self, score: str) -> str:
        """Determine if point is on deuce or ad side based on score."""
        if not score:
            return None
        
        # Parse game score (last part of score)
        parts = score.split()
        if not parts:
            return None
        
        game_score = parts[-1] if parts else ''
        
        # Points mapping
        point_values = {'0': 0, '15': 1, '30': 2, '40': 3, 'AD': 4, 'A': 4}
        
        try:
            if '-' in game_score:
                server_pts, returner_pts = game_score.split('-')
                server_val = point_values.get(server_pts, 0)
                returner_val = point_values.get(returner_pts, 0)
                total_points = server_val + returner_val
                # Even total = deuce side, odd = ad side
                return 'deuce' if total_points % 2 == 0 else 'ad'
        except:
            pass
        
        return None
    
    def _extract_game_info(self, score: str, point_number: int = 0) -> Dict:
        """
        Extract comprehensive game/set information from score string.
        
        Handles scores like:
        - "0-0 1-2 15-30" → set 1, game 4 in set (1+2+1), game 4 overall
        - "1-1 3-4 40-30" → set 3, game 8 in set (3+4+1), game 8 + prev sets overall
        
        Returns:
            {
                'set_number': int,                  # Current set (1-indexed)
                'game_number_in_set': int,          # Game within this set (1-indexed)
                'game_number_overall': int,         # Game across whole match (1-indexed)
                'set_score': str,                   # e.g., "1-1"
                'game_score': str,                  # e.g., "3-4"
                'point_score': str,                 # e.g., "40-30"
                'games_in_set_server': int,         # Server's games in this set
                'games_in_set_returner': int,       # Returner's games in this set
                'total_sets_server': int,           # Server's sets won
                'total_sets_returner': int,         # Returner's sets won
            }
        """
        import re
        
        result = {
            'set_number': 1,
            'game_number_in_set': 1,
            'game_number_overall': 1,
            'set_score': '0-0',
            'game_score': '0-0',
            'point_score': '0-0',
            'games_in_set_server': 0,
            'games_in_set_returner': 0,
            'total_sets_server': 0,
            'total_sets_returner': 0,
        }
        
        if not score:
            return result
        
        # Parse all X-X patterns from score
        patterns = re.findall(r'(\d+)-(\d+)', score)
        
        if len(patterns) < 2:
            return result
        
        # First pattern is usually set score, second is game score
        try:
            # Set score (e.g., "1-1" means 1 set each)
            set_server = int(patterns[0][0])
            set_returner = int(patterns[0][1])
            result['set_score'] = f"{set_server}-{set_returner}"
            result['total_sets_server'] = set_server
            result['total_sets_returner'] = set_returner
            result['set_number'] = set_server + set_returner + 1  # Current set (1-indexed)
            
            # Game score (e.g., "3-4" means 7 games played in this set)
            games_server = int(patterns[1][0])
            games_returner = int(patterns[1][1])
            result['game_score'] = f"{games_server}-{games_returner}"
            result['games_in_set_server'] = games_server
            result['games_in_set_returner'] = games_returner
            
            # Game number in set (1-indexed, current game being played)
            result['game_number_in_set'] = games_server + games_returner + 1
            
            # Estimate total games in previous sets (assume ~10 games per set avg)
            # This is approximate - for accurate tracking, need to parse full match history
            games_in_previous_sets = (set_server + set_returner) * 10  # Rough estimate
            result['game_number_overall'] = games_in_previous_sets + games_server + games_returner + 1
            
            # Point score (if available)
            if len(patterns) >= 3:
                result['point_score'] = f"{patterns[2][0]}-{patterns[2][1]}"
            else:
                # Check for tennis point patterns like "15-30", "40-AD"
                point_match = re.search(r'(0|15|30|40|AD)-(0|15|30|40|AD)', score, re.IGNORECASE)
                if point_match:
                    result['point_score'] = point_match.group(0)
        except (ValueError, IndexError):
            pass
        
        return result
    
    def _build_game_aggregation(self) -> Dict:
        """
        Build game-level aggregation from point-by-point data.
        
        Creates a mapping of (set_num, game_num) -> {
            'winner': player_name,
            'server': player_name,
            'points_won_server': int,
            'points_won_returner': int,
            'total_points': int,
            'is_break': bool,
        }
        
        This enables queries like:
        - "How many games did Sinner win?"
        - "Games won in set 2"
        - "How many service games did Medvedev hold?"
        - "Break percentage"
        """
        if not hasattr(self, 'point_by_point') or not self.point_by_point:
            return {}
        
        games = {}  # (set_num, game_num_in_set) -> game data
        set_winners = {}  # set_num -> winner (player name)
        current_set = 1
        current_game = 1
        current_server = None
        prev_server = None  # Track previous server for set score normalization
        points_in_game = {'server': 0, 'returner': 0}
        games_in_set = {'player1': 0, 'player2': 0}  # Track games won per set
        
        prev_set_score = None
        prev_game_score = None
        
        for point in self.point_by_point:
            # Get metadata
            if '_metadata' in point:
                meta = point['_metadata']
            else:
                meta = self._get_point_metadata(point)
            
            server = meta.get('server', '')
            returner = meta.get('returner', '')
            point_winner = meta.get('point_winner', '')
            set_score = meta.get('set_score', '0-0')
            game_score = meta.get('game_score', '0-0')
            
            # IMPORTANT: Check game change BEFORE set change, because when a set ends,
            # the last game of that set completes AND the set changes at the same time.
            # We need to record the game completion first, then handle the set change.
            
            # Detect game change (game score changed)
            # Check if game ended - this can happen within same set OR when set changes
            game_ended = False
            if prev_game_score and game_score != prev_game_score:
                game_ended = True
            
            # If game ended, record it BEFORE handling set change
            if game_ended:
                # Game ended - record the game winner
                game_key = (current_set, current_game)
                
                # Determine game winner by comparing the NEW score (game_score) to games_in_set
                # IMPORTANT: Score format is "server_games-returner_games" (server's score first)
                # game_score is from the CURRENT point (new server), showing state AFTER the game ended
                # games_in_set shows what we've recorded so far (before this game)
                game_winner = None
                try:
                    # Use the NEW score (game_score) with the NEW server (server)
                    new_parts = game_score.split('-')
                    if len(new_parts) == 2:
                        # Parse game score - format is "Server's games - Returner's games"
                        new_server_games = int(new_parts[0])
                        new_returner_games = int(new_parts[1])
                        
                        # Map to player1/player2 based on who is NOW serving (the new server)
                        def normalize_name(n):
                            return (n or '').lower().replace(' ', '').replace('.', '')
                        
                        new_server_norm = normalize_name(server)  # Use 'server' (new server), not 'current_server' (old)
                        p1_norm = normalize_name(self.player1)
                        p2_norm = normalize_name(self.player2)
                        
                        if new_server_norm == p1_norm:
                            # Player 1 is now serving: first num = P1's games, second = P2's games
                            score_p1 = new_server_games
                            score_p2 = new_returner_games
                        elif new_server_norm == p2_norm:
                            # Player 2 is now serving: first num = P2's games, second = P1's games
                            score_p1 = new_returner_games
                            score_p2 = new_server_games
                        else:
                            # Unknown server - skip score-based detection
                            score_p1 = score_p2 = -1
                        
                        recorded_p1 = games_in_set.get('player1', 0)
                        recorded_p2 = games_in_set.get('player2', 0)
                        
                        # If the NEW score shows more games for a player than we've recorded,
                        # that player won this game
                        if score_p1 > recorded_p1:
                            game_winner = self.player1
                        elif score_p2 > recorded_p2:
                            game_winner = self.player2
                except (ValueError, AttributeError):
                    pass
                
                # Fallback: use points if score parsing didn't work
                if not game_winner:
                    if points_in_game['server'] > points_in_game['returner']:
                        game_winner = current_server
                    elif points_in_game['returner'] > points_in_game['server']:
                        game_winner = returner if current_server else ''
                    else:
                        # Equal or no points - use server as default
                        game_winner = current_server
                
                # Check if server held or got broken
                is_break = game_winner and current_server and \
                          not self._names_match_robust(game_winner, current_server)
                
                # Only record if we don't already have this game (avoid duplicates)
                if game_key not in games:
                    games[game_key] = {
                        'winner': game_winner,
                        'server': current_server,
                        'points_won_server': points_in_game['server'],
                        'points_won_returner': points_in_game['returner'],
                        'total_points': points_in_game['server'] + points_in_game['returner'],
                        'is_break': is_break,
                        'set_number': current_set,
                        'game_number_in_set': current_game,
                    }
                    
                    # Track games won in this set
                    # Use exact matching to avoid "Player 1" matching "Player 2"
                    if game_winner:
                        winner_norm = (game_winner or '').lower().replace(' ', '').replace('.', '')
                        p1_norm = (self.player1 or '').lower().replace(' ', '').replace('.', '')
                        p2_norm = (self.player2 or '').lower().replace(' ', '').replace('.', '')
                        
                        if winner_norm == p1_norm:
                            games_in_set['player1'] += 1
                        elif winner_norm == p2_norm:
                            games_in_set['player2'] += 1
                    
                    # Check if set is complete:
                    # 1. Player has 6+ games AND 2+ game lead (6-4, 7-5, etc.)
                    # 2. OR player has 7 games and opponent has 6 (7-6 tiebreak win)
                    p1_games = games_in_set['player1']
                    p2_games = games_in_set['player2']
                    
                    # Standard win: 6+ games with 2+ game lead
                    if p1_games >= 6 and (p1_games - p2_games) >= 2:
                        # Player 1 won the set (e.g., 6-4, 7-5)
                        set_winners[current_set] = self.player1
                    elif p2_games >= 6 and (p2_games - p1_games) >= 2:
                        # Player 2 won the set (e.g., 6-4, 7-5)
                        set_winners[current_set] = self.player2
                    # Tiebreak win: 7-6
                    elif p1_games == 7 and p2_games == 6:
                        # Player 1 won the set in a tiebreak (7-6)
                        set_winners[current_set] = self.player1
                    elif p2_games == 7 and p1_games == 6:
                        # Player 2 won the set in a tiebreak (7-6)
                        set_winners[current_set] = self.player2
                
                current_game += 1
                points_in_game = {'server': 0, 'returner': 0}
            
            # Now detect set change (set score changed)
            # IMPORTANT: Set scores are in "Server's sets - Returner's sets" format
            # We need to normalize to P1-P2 format before comparing
            def normalize_set_score(raw_score, server_name, player1_name, player2_name):
                """Convert server-returner set score to P1-P2 format."""
                if not raw_score or '-' not in raw_score:
                    return (0, 0)
                parts = raw_score.split('-')
                if len(parts) != 2:
                    return (0, 0)
                try:
                    first = int(parts[0])
                    second = int(parts[1])
                except ValueError:
                    return (0, 0)
                
                # Normalize names for comparison
                norm = lambda n: (n or '').lower().replace(' ', '').replace('.', '')
                server_norm = norm(server_name)
                p1_norm = norm(player1_name)
                p2_norm = norm(player2_name)
                
                if server_norm == p1_norm:
                    # Server is P1: first = P1's sets, second = P2's sets
                    return (first, second)
                elif server_norm == p2_norm:
                    # Server is P2: first = P2's sets, second = P1's sets
                    return (second, first)
                else:
                    # Unknown server - return as-is
                    return (first, second)
            
            # Normalize current and previous set scores
            curr_normalized = normalize_set_score(set_score, server, self.player1, self.player2)
            prev_normalized = normalize_set_score(prev_set_score, prev_server if prev_server else server, self.player1, self.player2) if prev_set_score else (0, 0)
            
            # Detect actual set change by comparing normalized scores
            actual_set_change = curr_normalized != prev_normalized and (curr_normalized[0] + curr_normalized[1]) > (prev_normalized[0] + prev_normalized[1])
            
            if actual_set_change:
                # Set changed - check if we need to record set winner from games won
                # If set winner not already recorded from game completion rule, determine from final game scores
                if current_set not in set_winners:
                    # Set ended but winner not detected yet - determine from accumulated games
                    p1_games = games_in_set['player1']
                    p2_games = games_in_set['player2']
                    
                    # Standard win: 6+ games with 2+ game lead
                    if p1_games >= 6 and (p1_games - p2_games) >= 2:
                        set_winners[current_set] = self.player1
                    elif p2_games >= 6 and (p2_games - p1_games) >= 2:
                        set_winners[current_set] = self.player2
                    # Tiebreak win: 7-6
                    elif p1_games == 7 and p2_games == 6:
                        set_winners[current_set] = self.player1
                    elif p2_games == 7 and p1_games == 6:
                        set_winners[current_set] = self.player2
                    # Fallback: determine from who has more games (shouldn't happen in normal tennis)
                    elif p1_games > p2_games:
                        set_winners[current_set] = self.player1
                    elif p2_games > p1_games:
                        set_winners[current_set] = self.player2
                
                # Move to new set
                current_set += 1
                current_game = 1  # Reset to game 1 for new set
                games_in_set = {'player1': 0, 'player2': 0}  # Reset games won for new set
                # Don't reset points_in_game here - it was already reset when we recorded the game above
                # But if for some reason it wasn't reset, reset it now
                if points_in_game['server'] > 0 or points_in_game['returner'] > 0:
                    points_in_game = {'server': 0, 'returner': 0}
            
            # Track current server (changes each game)
            # Track previous server before updating current
            prev_server = current_server
            
            if server:
                current_server = server
            
            # Count point for server or returner
            if point_winner:
                if self._names_match_robust(point_winner, server):
                    points_in_game['server'] += 1
                elif self._names_match_robust(point_winner, returner):
                    points_in_game['returner'] += 1
            
            prev_set_score = set_score
            prev_game_score = game_score
        
        # Record final game if match ended
        # This game hasn't been recorded yet because there was no "next point" to trigger detection
        game_key = (current_set, current_game)
        
        # Always try to record the final game if it doesn't exist
        if game_key not in games:
            # Determine game winner - use the final score to infer who won this game
            # IMPORTANT: Score format is "server_games-returner_games" (server's score first)
            game_winner = None
            
            # Try to determine winner from the final game score
            # The final score shows the result AFTER the last game was won
            # Score format is "server_games - returner_games"
            try:
                final_parts = prev_game_score.split('-') if prev_game_score else []
                if len(final_parts) == 2:
                    server_games = int(final_parts[0])
                    returner_games = int(final_parts[1])
                    
                    # Map to player1/player2 based on who was serving
                    def normalize_name(n):
                        return (n or '').lower().replace(' ', '').replace('.', '')
                    
                    server_norm = normalize_name(current_server)
                    p1_norm = normalize_name(self.player1)
                    p2_norm = normalize_name(self.player2)
                    
                    if server_norm == p1_norm:
                        final_p1 = server_games
                        final_p2 = returner_games
                    elif server_norm == p2_norm:
                        final_p1 = returner_games
                        final_p2 = server_games
                    else:
                        final_p1 = final_p2 = -1
                    
                    # Compare with games_in_set to see who won the last game
                    p1_recorded = games_in_set.get('player1', 0)
                    p2_recorded = games_in_set.get('player2', 0)
                    
                    if final_p1 > p1_recorded:
                        game_winner = self.player1
                    elif final_p2 > p2_recorded:
                        game_winner = self.player2
            except (ValueError, AttributeError):
                pass
            
            # Fallback: use accumulated points if available
            if not game_winner:
                if points_in_game['server'] > points_in_game['returner']:
                    game_winner = current_server
                elif points_in_game['returner'] > points_in_game['server']:
                    game_winner = returner if current_server else ''
                else:
                    # No clear winner from points - use server as fallback
                    game_winner = current_server
            
            # Check if server held or got broken
            is_break = game_winner and current_server and \
                      not self._names_match_robust(game_winner, current_server)
            
            games[game_key] = {
                'winner': game_winner,
                'server': current_server,
                'points_won_server': points_in_game['server'],
                'points_won_returner': points_in_game['returner'],
                'total_points': points_in_game['server'] + points_in_game['returner'],
                'is_break': is_break,
                'set_number': current_set,
                'game_number_in_set': current_game,
            }
            
            # Update games_in_set for set winner detection
            if game_winner:
                if self._names_match_robust(game_winner, self.player1):
                    games_in_set['player1'] += 1
                elif self._names_match_robust(game_winner, self.player2):
                    games_in_set['player2'] += 1
            
            # Check if set is complete after recording final game
            p1_games = games_in_set.get('player1', 0)
            p2_games = games_in_set.get('player2', 0)
            
            # Standard win: 6+ games with 2+ game lead
            if p1_games >= 6 and (p1_games - p2_games) >= 2:
                set_winners[current_set] = self.player1
            elif p2_games >= 6 and (p2_games - p1_games) >= 2:
                set_winners[current_set] = self.player2
            # Tiebreak win: 7-6
            elif p1_games == 7 and p2_games == 6:
                set_winners[current_set] = self.player1
            elif p2_games == 7 and p1_games == 6:
                set_winners[current_set] = self.player2
        
        # Check final set completion if match ended (in case winner not detected above)
        # If final set winner not recorded yet, determine from accumulated games
        if current_set not in set_winners:
            p1_games = games_in_set.get('player1', 0)
            p2_games = games_in_set.get('player2', 0)
            
            # Standard win: 6+ games with 2+ game lead
            if p1_games >= 6 and (p1_games - p2_games) >= 2:
                set_winners[current_set] = self.player1
            elif p2_games >= 6 and (p2_games - p1_games) >= 2:
                set_winners[current_set] = self.player2
            # Tiebreak win: 7-6
            elif p1_games == 7 and p2_games == 6:
                set_winners[current_set] = self.player1
            elif p2_games == 7 and p1_games == 6:
                set_winners[current_set] = self.player2
            # Fallback: determine from who has more games
            elif p1_games > p2_games:
                set_winners[current_set] = self.player1
            elif p2_games > p1_games:
                set_winners[current_set] = self.player2
        
        # Store for later use
        self._game_aggregation = games
        self._set_winners_from_tree = set_winners  # Store set winners from tree structure
        return games
    
    def _get_games_count(self, player_filter: str = None, set_filter: int = None, 
                        role_filter: str = None) -> Dict:
        """
        Get games count for player(s), optionally filtered by set or role.
        
        Args:
            player_filter: 'both', player name, or None (all)
            set_filter: Specific set number to filter by
            role_filter: 'server' (held serve) or 'returner' (broke serve)
        
        Returns:
            {
                'player1_games': int,
                'player2_games': int,
                'total_games': int,
                'player1_holds': int,  # Service games won
                'player2_holds': int,
                'player1_breaks': int, # Return games won (broke opponent)
                'player2_breaks': int,
            }
        """
        # Build aggregation if not already done
        if not hasattr(self, '_game_aggregation') or not self._game_aggregation:
            self._build_game_aggregation()
        
        # Fallback to existing game_winners if aggregation failed
        if not hasattr(self, '_game_aggregation') or not self._game_aggregation:
            # Use legacy game_winners dict
            games = getattr(self, 'game_winners', {})
            p1_games = sum(1 for w in games.values() if w == 'player1')
            p2_games = sum(1 for w in games.values() if w == 'player2')
            return {
                'player1_games': p1_games,
                'player2_games': p2_games,
                'total_games': p1_games + p2_games,
                'player1_holds': 0,
                'player2_holds': 0,
                'player1_breaks': 0,
                'player2_breaks': 0,
            }
        
        result = {
            'player1_games': 0,
            'player2_games': 0,
            'total_games': 0,
            'player1_holds': 0,
            'player2_holds': 0,
            'player1_breaks': 0,
            'player2_breaks': 0,
        }
        
        player1 = self.player1
        player2 = self.player2
        
        for game_key, game_data in self._game_aggregation.items():
            set_num, game_num = game_key
            
            # Apply set filter
            if set_filter and set_num != set_filter:
                continue
            
            winner = game_data.get('winner', '')
            server = game_data.get('server', '')
            is_break = game_data.get('is_break', False)
            
            # Determine if player1 or player2 won
            is_p1_win = winner and self._names_match_robust(player1, winner)
            is_p2_win = winner and self._names_match_robust(player2, winner)
            is_p1_serving = server and self._names_match_robust(player1, server)
            
            # Apply role filter - GENERIC using role expectation
            if role_filter:
                # Determine if winner was in the expected role
                winner_was_serving = (is_p1_win and is_p1_serving) or (is_p2_win and not is_p1_serving)
                winner_was_returning = (is_p1_win and not is_p1_serving) or (is_p2_win and is_p1_serving)
                
                role_config = self.ROLE_CONFIG.get(role_filter, {})
                expected_role = role_config.get('player_field', '')  # 'server' or 'returner'
                
                # Skip if winner wasn't in the expected role
                if expected_role == 'server' and not winner_was_serving:
                    continue
                elif expected_role == 'returner' and not winner_was_returning:
                    continue
            
            # Count games
            result['total_games'] += 1
            
            if is_p1_win:
                result['player1_games'] += 1
                if is_p1_serving:
                    result['player1_holds'] += 1
                else:
                    result['player1_breaks'] += 1
            elif is_p2_win:
                result['player2_games'] += 1
                if not is_p1_serving:  # P2 was serving
                    result['player2_holds'] += 1
                else:
                    result['player2_breaks'] += 1
        
        return result
    
    def _aggregate_games_from_points(self, points: list, filters: Dict = None) -> Dict:
        """
        Aggregate games and sets from a collection of points.
        
        Detects game transitions from score changes and counts winners.
        
        Args:
            points: List of point data dictionaries
            filters: Optional filters (set, game_number, game_number_in_set)
        
        Returns:
            {
                'player1_games': int,
                'player2_games': int,
                'total_games': int,
                'player1_holds': int,
                'player2_holds': int,
                'player1_breaks': int,
                'player2_breaks': int,
                'player1_sets': int,
                'player2_sets': int,
                'total_sets': int,
            }
        """
        import re
        
        filters = filters or {}
        set_filter = filters.get('set')
        game_filter = filters.get('game_number')  # Overall game number
        game_in_set_filter = filters.get('game_number_in_set')
        
        player1 = self.player1
        player2 = self.player2
        
        result = {
            'player1_games': 0,
            'player2_games': 0,
            'total_games': 0,
            'player1_holds': 0,
            'player2_holds': 0,
            'player1_breaks': 0,
            'player2_breaks': 0,
            'player1_sets': 0,
            'player2_sets': 0,
            'total_sets': 0,
        }
        
        # Track unique games: (set_number, game_score_at_start) -> {winner, server, is_break}
        games_seen = {}
        sets_completed = {}  # set_number -> winner
        games_per_set = {}  # set_number -> {player1: count, player2: count}
        
        prev_set_score = None
        prev_game_score = None
        prev_server = None
        current_game_points = []
        current_set = 1
        current_game_in_set = 1
        current_server = None
        overall_game_num = 0
        
        # Helper to normalize set scores from server-returner format to P1-P2 format
        def normalize_set_score(raw_score, server_name):
            """Convert server-returner set score to P1-P2 format."""
            if not raw_score or '-' not in raw_score:
                return (0, 0)
            parts = raw_score.split('-')
            if len(parts) != 2:
                return (0, 0)
            try:
                first = int(parts[0])
                second = int(parts[1])
            except ValueError:
                return (0, 0)
            
            # Normalize names for comparison
            norm = lambda n: (n or '').lower().replace(' ', '').replace('.', '')
            server_norm = norm(server_name)
            p1_norm = norm(player1)
            p2_norm = norm(player2)
            
            if server_norm == p1_norm:
                return (first, second)
            elif server_norm == p2_norm:
                return (second, first)
            else:
                return (first, second)
        
        for point_data in points:
            # Get metadata (use cached if available)
            if '_metadata' in point_data:
                meta = point_data['_metadata']
            else:
                meta = self._get_point_metadata(point_data)
            
            server = meta.get('server', '')
            point_winner = meta.get('point_winner', '')
            set_score = meta.get('set_score', '0-0')
            game_score = meta.get('game_score', '0-0')
            point_set_num = meta.get('set_number', 1)
            
            # Apply set filter
            if set_filter and point_set_num != set_filter:
                continue
            
            # Detect set change using normalized scores
            curr_normalized = normalize_set_score(set_score, server)
            prev_normalized = normalize_set_score(prev_set_score, prev_server if prev_server else server) if prev_set_score else (0, 0)
            
            # Actual set change: normalized scores differ AND total sets increased
            actual_set_change = curr_normalized != prev_normalized and (curr_normalized[0] + curr_normalized[1]) > (prev_normalized[0] + prev_normalized[1])
            
            if actual_set_change:
                # Set completed - determine who won the previous set
                # Compare normalized scores to see who gained a set
                if curr_normalized[0] > prev_normalized[0]:
                    sets_completed[current_set] = player1
                elif curr_normalized[1] > prev_normalized[1]:
                    sets_completed[current_set] = player2
                
                current_set += 1
                current_game_in_set = 1
                current_game_points = []
            
            # Detect game change (game score changed within same set)
            # Use normalized set scores for "same set" comparison
            same_set = curr_normalized == prev_normalized
            if prev_game_score and game_score != prev_game_score and same_set:
                # Game completed - determine winner using score comparison
                game_key = (current_set, current_game_in_set)
                
                # Try score-based winner detection first (more reliable)
                is_p1_win = False
                is_p2_win = False
                
                # Initialize games_per_set for this set if not exists
                if current_set not in games_per_set:
                    games_per_set[current_set] = {'player1': 0, 'player2': 0}
                
                # Parse NEW game_score to determine who won (not prev_game_score!)
                # Score format: "server_games - returner_games"
                # game_score is from the NEW server's perspective (after game ended)
                try:
                    new_parts = game_score.split('-')
                    if len(new_parts) == 2:
                        new_server_games = int(new_parts[0])
                        new_returner_games = int(new_parts[1])
                        
                        # Map to P1/P2 based on NEW server (who is serving in the current point)
                        norm = lambda n: (n or '').lower().replace(' ', '').replace('.', '')
                        new_server_norm = norm(server)  # Use 'server' (new), not 'current_server' (old)
                        p1_norm = norm(player1)
                        p2_norm = norm(player2)
                        
                        if new_server_norm == p1_norm:
                            p1_score = new_server_games
                            p2_score = new_returner_games
                        elif new_server_norm == p2_norm:
                            p1_score = new_returner_games
                            p2_score = new_server_games
                        else:
                            p1_score = p2_score = -1
                        
                        # Compare to recorded games to determine winner
                        recorded_p1 = games_per_set[current_set]['player1']
                        recorded_p2 = games_per_set[current_set]['player2']
                        
                        if p1_score > recorded_p1:
                            is_p1_win = True
                        elif p2_score > recorded_p2:
                            is_p2_win = True
                except (ValueError, AttributeError):
                    pass
                
                # Fallback: use last point winner if available
                if not is_p1_win and not is_p2_win and current_game_points:
                    last_point_winner = current_game_points[-1].get('point_winner')
                    is_p1_win = last_point_winner and self._names_match_robust(player1, last_point_winner)
                    is_p2_win = last_point_winner and self._names_match_robust(player2, last_point_winner)
                
                is_p1_serving = current_server and self._names_match_robust(player1, current_server)
                
                # Apply game number filter
                should_count = True
                overall_game_num += 1
                
                if game_filter and overall_game_num != game_filter:
                    should_count = False
                if game_in_set_filter and current_game_in_set != game_in_set_filter:
                    should_count = False
                
                if should_count and game_key not in games_seen:
                    games_seen[game_key] = True
                    result['total_games'] += 1
                    
                    if is_p1_win:
                        result['player1_games'] += 1
                        games_per_set[current_set]['player1'] += 1
                        if is_p1_serving:
                            result['player1_holds'] += 1
                        else:
                            result['player1_breaks'] += 1
                    elif is_p2_win:
                        result['player2_games'] += 1
                        games_per_set[current_set]['player2'] += 1
                        if is_p1_serving:
                            result['player2_breaks'] += 1
                        else:
                            result['player2_holds'] += 1
                
                current_game_in_set += 1
                current_game_points = []
            
            # Track previous server before updating current
            prev_server = current_server
            
            # Track current server
            if server:
                current_server = server
            
            # Add point to current game
            current_game_points.append({
                'point_winner': point_winner,
                'server': server
            })
            
            prev_set_score = set_score
            prev_game_score = game_score
        
        # Count sets from sets_completed (detected via set score changes)
        for set_num, winner in sets_completed.items():
            result['total_sets'] += 1
            if winner and self._names_match_robust(player1, winner):
                result['player1_sets'] += 1
            elif winner and self._names_match_robust(player2, winner):
                result['player2_sets'] += 1
        
        # Check for set completions NOT in sets_completed (e.g., final set of match)
        for set_num, counts in games_per_set.items():
            if set_num in sets_completed:
                continue  # Already counted via set score change
            
            p1_games = counts['player1']
            p2_games = counts['player2']
            
            # Standard win: 6+ games with 2+ game lead
            if p1_games >= 6 and (p1_games - p2_games) >= 2:
                result['total_sets'] += 1
                result['player1_sets'] += 1
            elif p2_games >= 6 and (p2_games - p1_games) >= 2:
                result['total_sets'] += 1
                result['player2_sets'] += 1
            # Tiebreak win: 7-6
            elif p1_games == 7 and p2_games == 6:
                result['total_sets'] += 1
                result['player1_sets'] += 1
            elif p2_games == 7 and p1_games == 6:
                result['total_sets'] += 1
                result['player2_sets'] += 1
        
        # If no games detected via transitions, fall back to existing game_winners
        if result['total_games'] == 0 and hasattr(self, 'game_winners') and self.game_winners:
            for game_key, winner in self.game_winners.items():
                if set_filter:
                    # Filter by set if specified
                    if isinstance(game_key, tuple) and len(game_key) >= 1:
                        if game_key[0] != set_filter:
                            continue
                
                result['total_games'] += 1
                if winner == 'player1' or (winner and self._names_match_robust(player1, winner)):
                    result['player1_games'] += 1
                elif winner == 'player2' or (winner and self._names_match_robust(player2, winner)):
                    result['player2_games'] += 1
        
        return result
    
    def chunk_text(self, text: str, max_tokens: int = 500) -> List[str]:
        """
        Splits a long text into chunks small enough to feed an LLM.
        Uses simple token count approximation (1 token ≈ 4 chars).
        """
        approx_chunk_size = max_tokens * 4  # 4 chars per token
        chunks = []
        start = 0
        while start < len(text):
            end = start + approx_chunk_size
            chunk = text[start:end]
            chunks.append(chunk)
            start = end
        return chunks
    
    def _create_chunks_with_metadata(self, text: str, chunk_type: str, section: str, match_id: str) -> List[Dict]:
        """
        Returns a list of dicts with chunk text and enhanced metadata for better searchability.
        """
        # For tennis data, we want to keep sections intact rather than splitting arbitrarily
        # Only split if the section exceeds embedding model limits (8k tokens)
        estimated_tokens = len(text) // 4  # Rough approximation
        
        if estimated_tokens > 6000:  # More conservative buffer for 8192 token limit
            # Split large sections intelligently
            chunks = self._smart_chunk_large_section(text, section)
        else:
            # Keep section intact
            chunks = [text]
        
        # Determine player focus and statistics type from section
        player_focus = self._determine_player_focus(section)
        stat_category = self._determine_stat_category(section)
        
        result_chunks = []
        for i, chunk in enumerate(chunks):
            # Extract set and game metadata for point-by-point chunks
            set_numbers = []
            game_scores = []
            if 'point-by-point' in section.lower():
                set_numbers = self._extract_set_numbers_from_chunk(chunk)
                game_scores = self._extract_game_scores_from_chunk(chunk)
            
            result_chunks.append({
                "text": chunk,
                "metadata": {
                    "type": chunk_type,
                    "section": section,
                    "match_id": match_id,
                    "player_focus": player_focus,
                    "stat_category": stat_category,
                    "set_numbers": set_numbers,  # NEW: Which sets are in this chunk (e.g., [2, 3])
                    "game_scores": game_scores,  # NEW: Which game scores appear (e.g., ['4-5', '5-5', '6-5'])
                    "contains_percentages": "%" in chunk,
                    "contains_point_details": "Point " in chunk,
                    "contains_long_rallies": any("shot rally" in line or "stroke rally" in line for line in chunk.split('\n') if "rally" in line),
                    "match_info": {
                        "date": "2025-06-28",
                        "tournament": "Bad Homburg F",
                        "players": [self.player1 if self.player1 else "Player 1", self.player2 if self.player2 else "Player 2"],
                        "match_type": "WTA"
                    }
                }
            })
        
        return result_chunks
    
    def _smart_chunk_large_section(self, text: str, section: str) -> List[str]:
        """
        Intelligently chunk large sections while preserving semantic meaning.
        """
        lines = text.split('\n')
        
        if "point-by-point" in section.lower():
            # For point-by-point, group by games (every 6-8 points)
            chunks = []
            current_chunk = []
            point_count = 0
            
            for line in lines:
                current_chunk.append(line)
                if line.startswith("Point "):
                    point_count += 1
                    if point_count >= 6:  # Start new chunk every 6 points
                        chunks.append('\n'.join(current_chunk))
                        current_chunk = []
                        point_count = 0
            
            if current_chunk:
                chunks.append('\n'.join(current_chunk))
            
            return chunks
        
        else:
            # For statistics sections, try to split by player if possible
            player1_lines = []
            player2_lines = []
            header_lines = []
            other_lines = []
            
            for line in lines:
                if self.player1 and self.player1 in line:
                    player1_lines.append(line)
                elif self.player2 and self.player2 in line:
                    player2_lines.append(line)
                elif line.strip().endswith(':') or line.startswith('---'):
                    header_lines.append(line)
                else:
                    other_lines.append(line)
            
            # If we can separate by players, create player-specific chunks
            if player1_lines or player2_lines:
                chunks = []
                if player1_lines:
                    chunks.append('\n'.join(header_lines + player1_lines))
                if player2_lines:
                    chunks.append('\n'.join(header_lines + player2_lines))
                if other_lines and not (player1_lines or player2_lines):
                    chunks.append('\n'.join(header_lines + other_lines))
                return chunks
            
            # Fallback: use precise token-based chunking
            return self._precise_token_chunk(text, max_tokens=6000)
    
    def _precise_token_chunk(self, text: str, max_tokens: int) -> List[str]:
        """Precisely chunk text using actual token counting."""
        try:
            import tiktoken
            encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")
            
            total_tokens = len(encoding.encode(text))
            if total_tokens <= max_tokens:
                return [text]
            
            
            lines = text.split('\n')
            chunks = []
            current_chunk = []
            current_tokens = 0
            
            for line in lines:
                line_tokens = len(encoding.encode(line + '\n'))
                
                if current_tokens + line_tokens > max_tokens and current_chunk:
                    # Start new chunk
                    chunks.append('\n'.join(current_chunk))
                    current_chunk = [line]
                    current_tokens = line_tokens
                else:
                    current_chunk.append(line)
                    current_tokens += line_tokens
            
            if current_chunk:
                chunks.append('\n'.join(current_chunk))
            
            return chunks
            
        except Exception as e:
            # Fallback to character-based chunking
            max_chars = max_tokens * 4  # Rough estimate
            chunks = []
            for i in range(0, len(text), max_chars):
                chunks.append(text[i:i + max_chars])
            return chunks
    
    def _apply_rate_limit(self):
        """Apply rate limiting to avoid hitting API limits."""
        current_time = time.time()
        time_since_last_call = current_time - self.last_api_call
        
        if time_since_last_call < self.min_delay:
            sleep_time = self.min_delay - time_since_last_call
            print(f"[WAIT] Rate limiting: waiting {sleep_time:.1f}s...")
            time.sleep(sleep_time)
        
        self.last_api_call = time.time()
    
    def _determine_player_focus(self, section: str) -> str:
        """Determine which player this section focuses on."""
        if "serve1" in section.lower() or "return1" in section.lower() or "shots1" in section.lower() or "shotdir1" in section.lower() or "netpts1" in section.lower():
            return self.player1 if self.player1 else "Player 1"
        elif "serve2" in section.lower() or "return2" in section.lower() or "shots2" in section.lower() or "shotdir2" in section.lower() or "netpts2" in section.lower():
            return self.player2 if self.player2 else "Player 2"
        else:
            return "Both"
    
    def _determine_stat_category(self, section: str) -> str:
        """Determine the category of statistics."""
        section_lower = section.lower()
        if "serve" in section_lower:
            return "serving"
        elif "return" in section_lower:
            return "returning"
        elif "shot" in section_lower:
            return "shots"
        elif "net" in section_lower:
            return "net_play"
        elif "key_points" in section_lower:
            return "key_points"
        elif "rally" in section_lower:
            return "rally_outcomes"
        elif "point-by-point" in section_lower:
            return "narrative"
        elif "overview" in section_lower:
            return "overview"
        else:
            return "general"
    
    def _determine_chunk_type(self, section_name: str, section_text: str) -> str:
        """Determine the type of chunk based on section name and content."""
        section_lower = section_name.lower()
        
        if "point-by-point" in section_lower or "Point " in section_text:
            return "narrative"
        elif any(keyword in section_lower for keyword in ["statistics", "serve", "return", "shots", "net"]):
            return "statistics"
        elif "overview" in section_lower:
            return "overview"
        else:
            return "general"
    
    def _detect_long_rallies(self, text: str) -> List[str]:
        """Detect and extract information about long rallies in the text."""
        long_rallies = []
        lines = text.split('\n')
        
        for line in lines:
            if "shot rally" in line or "stroke rally" in line:
                # Extract rally length and details
                if "16-shot rally" in line:
                    long_rallies.append(f"LONGEST RALLY: {line}")
                elif "10+ shot rally" in line or "11-shot rally" in line or "12-shot rally" in line or "13-shot rally" in line or "14-shot rally" in line or "15-shot rally" in line:
                    long_rallies.append(f"LONG RALLY: {line}")
        
        return long_rallies
    
    def _is_match_insight_question(self, query: str) -> bool:
        """Determine if a query is asking for match insights vs. statistics."""
        query_lower = query.lower()
        
        # Match insight keywords
        insight_keywords = [
            "key moments", "decided", "outcome", "strategy", "momentum", 
            "critical", "turning point", "what happened", "how did", 
            "why did", "analyze", "explain", "describe the match",
            "tactical", "pattern", "trend", "shift", "flow"
        ]
        
        # Statistical keywords (strong indicators)
        stat_keywords = [
            "how many", "percentage", "total", "count", "statistics",
            "breakdown", "compare", "numbers", "figures", "aces", 
            "double faults", "winners", "errors", "first serve", "second serve"
        ]
        
        insight_score = sum(1 for keyword in insight_keywords if keyword in query_lower)
        stat_score = sum(1 for keyword in stat_keywords if keyword in query_lower)
        
        # If it's clearly asking for numbers, it's stats
        if stat_score > 0:
            return False
        
        return insight_score > 0
    
    def _embed_chunks(self, chunks: List[Dict]) -> List[Dict]:
        """
        Generate embeddings for chunks using LOCAL sentence-transformers (100% FREE).
        No API calls, runs entirely on your computer!
        """
        print("[EMBED] Generating embeddings with LOCAL model (FREE - no API calls!)...")
        
        # Extract text from chunks
        texts = [chunk["text"] for chunk in chunks]
        
        # Generate embeddings locally
        embeddings = self.embedding_model.encode(
            texts, 
            show_progress_bar=True,
            batch_size=32,
            convert_to_numpy=True
        )
        
        # Add embeddings to chunks
        for i, chunk in enumerate(chunks):
            chunk["embedding"] = embeddings[i].tolist()
        
        print(f"Successfully generated {len(chunks)} embeddings locally (384 dimensions)")
        
        return chunks
    
    def _create_vector_index(self) -> None:
        """
        Create FAISS index and store metadata.
        """
        if not self.chunks:
            raise ValueError("No chunks available. Call load_exact_full_format() first.")
        
        # Get embedding dimension
        dim = len(self.chunks[0]["embedding"])
        
        # Create FAISS index
        self.index = faiss.IndexFlatL2(dim)
        
        # Convert embeddings to numpy
        vectors = np.array([c["embedding"] for c in self.chunks]).astype('float32')
        self.index.add(vectors)
        
        # Keep a parallel list of metadata for retrieval
        self.metadata_store = [c["metadata"] for c in self.chunks]
        
        print(f"Created FAISS index with {len(self.chunks)} vectors of dimension {dim}")
    
    def save_embeddings_to_disk(self, filename_prefix: str = "tennis_embeddings") -> None:
        """
        Save embeddings, FAISS index, and metadata to disk for persistence.
        """
        if not self.chunks or not self.index:
            raise ValueError("No embeddings available. Call load_exact_full_format() first.")
        
        # Save FAISS index
        faiss_filename = f"{filename_prefix}_faiss.pkl"
        with open(faiss_filename, 'wb') as f:
            pickle.dump(self.index, f)
        
        # Save metadata store (including match score, set/game winners, and point-by-point data)
        metadata_filename = f"{filename_prefix}_metadata.pkl"
        metadata_bundle = {
            'metadata_store': self.metadata_store,
            'match_score': getattr(self, 'match_score', None),
            'set_mapping': getattr(self, 'set_mapping', {}),
            'total_sets': getattr(self, 'total_sets', 0),
            'set_winners': getattr(self, 'set_winners', {}),
            'game_winners': getattr(self, 'game_winners', {}),
            'match_winner': getattr(self, 'match_winner', None),
            'match_loser': getattr(self, 'match_loser', None),
            'point_by_point': getattr(self, 'point_by_point', [])
        }
        with open(metadata_filename, 'wb') as f:
            pickle.dump(metadata_bundle, f)
        
        # Save chunks (for debugging/inspection)
        chunks_filename = f"{filename_prefix}_chunks.pkl"
        with open(chunks_filename, 'wb') as f:
            pickle.dump(self.chunks, f)
        
        print(f"Saved embeddings to disk:")
        print(f"   FAISS index: {faiss_filename}")
        print(f"   Metadata: {metadata_filename}")
        print(f"   Chunks: {chunks_filename}")
    
    def load_embeddings_from_disk(self, filename_prefix: str = "tennis_embeddings") -> bool:
        """
        Load embeddings, FAISS index, and metadata from disk.
        Returns True if successful, False if files don't exist.
        """
        try:
            # Extract player names from filename_prefix (e.g., "Jannik_Sinner_Carlos_Alcaraz_20250608")
            parts = filename_prefix.split('_')
            if len(parts) >= 4:
                # Find the date (8 digits at the end)
                date_idx = -1
                for i in range(len(parts) - 1, -1, -1):
                    if parts[i].isdigit() and len(parts[i]) == 8:
                        date_idx = i
                        break
                
                if date_idx >= 2:
                    # Everything before the date is player names
                    # Find the split point (usually middle, but handle multi-word names)
                    player_parts = parts[:date_idx]
                    # Simple heuristic: split roughly in middle
                    mid = len(player_parts) // 2
                    self.player1 = ' '.join(player_parts[:mid])
                    self.player2 = ' '.join(player_parts[mid:])
                    print(f"[CACHE] Extracted player names: {self.player1} vs {self.player2}")
            
            # Load FAISS index
            faiss_filename = f"{filename_prefix}_faiss.pkl"
            with open(faiss_filename, 'rb') as f:
                self.index = pickle.load(f)
            
            # Load metadata store and match info
            metadata_filename = f"{filename_prefix}_metadata.pkl"
            with open(metadata_filename, 'rb') as f:
                metadata_bundle = pickle.load(f)
                
                # Handle both old format (just metadata_store) and new format (bundle)
                if isinstance(metadata_bundle, dict) and 'metadata_store' in metadata_bundle:
                    # New format with match score, set mapping, set/game winners, and point-by-point
                    self.metadata_store = metadata_bundle['metadata_store']
                    self.match_score = metadata_bundle.get('match_score', None)
                    self.set_mapping = metadata_bundle.get('set_mapping', {})
                    self.total_sets = metadata_bundle.get('total_sets', 0)
                    self.set_winners = metadata_bundle.get('set_winners', {})
                    self.game_winners = metadata_bundle.get('game_winners', {})
                    self.match_winner = metadata_bundle.get('match_winner', None)
                    self.match_loser = metadata_bundle.get('match_loser', None)
                    self.point_by_point = metadata_bundle.get('point_by_point', [])
                    if self.match_score:
                        print(f"[CACHE] Loaded match score: {self.match_score}")
                    if self.set_mapping:
                        print(f"[CACHE] Loaded set mapping with {len(self.set_mapping)} entries")
                    if self.set_winners:
                        print(f"[CACHE] Loaded set winners: {self.set_winners}")
                    if self.game_winners:
                        print(f"[CACHE] Loaded {len(self.game_winners)} game winners")
                    if self.point_by_point:
                        print(f"[CACHE] Loaded {len(self.point_by_point)} points for analysis")
                        # Enrich point data if it wasn't enriched before (old cache format)
                        # Check if first point has enrichment data
                        if self.point_by_point and 'context' not in self.point_by_point[0]:
                            print(f"[CACHE] Enriching loaded points (old format)...")
                            self._enrich_point_data()
                else:
                    # Old format - just metadata_store
                    self.metadata_store = metadata_bundle
                    self.match_score = None
                    self.set_mapping = {}
                    self.total_sets = 0
                    self.set_winners = {}
                    self.game_winners = {}
                    self.match_winner = None
                    self.match_loser = None
                    self.point_by_point = []
            
            # Load chunks (optional, for debugging)
            chunks_filename = f"{filename_prefix}_chunks.pkl"
            if os.path.exists(chunks_filename):
                with open(chunks_filename, 'rb') as f:
                    self.chunks = pickle.load(f)
            else:
                # Reconstruct chunks from metadata if needed
                self.chunks = [{"metadata": meta} for meta in self.metadata_store]
            
            print(f"Loaded embeddings from disk:")
            print(f"   FAISS index: {faiss_filename}")
            print(f"   Metadata: {metadata_filename}")
            print(f"   Total chunks: {len(self.metadata_store)}")
            
            return True
            
        except FileNotFoundError:
            print(f"[ERROR] Embedding files not found. Run load_exact_full_format() first.")
            return False
        except Exception as e:
            print(f"[ERROR] Error loading embeddings: {e}")
            return False
    
    def _detect_player_mentioned(self, query: str) -> str:
        """
        Detect which player is mentioned in the query.
        Returns the player name, "both" if asking about both players, or None if no specific player is mentioned.
        """
        if not self.player1 or not self.player2:
            return None
            
        query_lower = query.lower()
        player1_lower = self.player1.lower()
        player2_lower = self.player2.lower()
        
        # Check for "both players" indicators FIRST (use class constant)
        if any(indicator in query_lower for indicator in self.BOTH_PLAYER_INDICATORS):
            return 'both'
        
        # Check for player1 (first player)
        if any(word in query_lower for word in player1_lower.split()):
            return self.player1
        
        # Check for player2 (second player)  
        if any(word in query_lower for word in player2_lower.split()):
            return self.player2
        
        return None

    def _get_player_suffix(self, player_mentioned: str) -> str:
        """
        Get the player suffix (_player_1 or _player_2) based on which player is mentioned.
        """
        if not player_mentioned or not self.player1 or not self.player2:
            return "_player_1"  # Default to player 1
            
        if player_mentioned.lower() == self.player1.lower():
            return "_player_1"
        elif player_mentioned.lower() == self.player2.lower():
            return "_player_2"
        else:
            return "_player_1"  # Default fallback

    def _detect_shot_from_query(self, query: str) -> Dict[str, Any]:
        """
        METADATA-DRIVEN shot detection.
        Matches query terms against actual values from match_filter_inventory.
        No hard-coded shot types - discovers from data.
        
        Returns dict with:
        - shot_base: Shot type from inventory (e.g., 'forehand', 'backhand') or None
        - shot_modifier: Modifier from inventory (e.g., 'slice', 'volley') or None
        - shot_type: Combined description or None
        - shot_direction: Direction from inventory or None
        """
        query_lower = query.lower()
        
        # Get inventory (built from actual match data)
        inventory = getattr(self, 'match_filter_inventory', {})
        aliases = inventory.get('common_aliases', {})
        
        # === SHOT TYPE DETECTION (from inventory) ===
        shot_base = None
        known_shot_types = inventory.get('shot_types', [])
        for st in known_shot_types:
            if st:
                st_lower = st.lower()
                # Match exact word boundaries to avoid false positives
                if st_lower in query_lower:
                    shot_base = st
                    break
        # Check aliases (fh -> forehand, bh -> backhand)
        for alias, canonical in aliases.get('shots', {}).items():
            # Match alias as word boundary
            if f" {alias} " in f" {query_lower} " or query_lower.startswith(f"{alias} ") or query_lower.endswith(f" {alias}"):
                shot_base = canonical
                break
        
        # === SHOT MODIFIER DETECTION (from inventory) ===
        shot_modifier = None
        known_modifiers = inventory.get('shot_modifiers', [])
        for mod in known_modifiers:
            if mod:
                mod_lower = mod.lower()
                mod_spaced = mod_lower.replace('_', ' ')
                if mod_lower in query_lower or mod_spaced in query_lower:
                    shot_modifier = mod
                    break
        
        # === DIRECTION DETECTION (from inventory) ===
        shot_direction = None
        known_directions = inventory.get('directions', [])
        for dir_val in known_directions:
            if dir_val:
                # Handle both underscore and space versions
                dir_lower = dir_val.lower()
                dir_spaced = dir_lower.replace('_', ' ')
                if dir_lower in query_lower or dir_spaced in query_lower:
                    shot_direction = dir_val
                    break
        # Check direction aliases (cc -> crosscourt, dtl -> down_the_line)
        for alias, canonical in aliases.get('directions', {}).items():
            if f" {alias} " in f" {query_lower} " or query_lower.startswith(f"{alias} ") or query_lower.endswith(f" {alias}"):
                shot_direction = canonical
                break
        
        # Combine into shot_type for display
        if shot_base and shot_modifier:
            shot_type = f"{shot_base} {shot_modifier}"
        elif shot_base:
            shot_type = shot_base
        elif shot_modifier:
            shot_type = shot_modifier
        else:
            shot_type = None
        
        return {
            'shot_base': shot_base,
            'shot_modifier': shot_modifier,
            'shot_type': shot_type,
            'shot_direction': shot_direction
        }

    def _detect_from_inventory(self, query_lower: str, inventory_key: str, fallback_values: list = None) -> str:
        """
        METADATA-DRIVEN value detection.
        
        Matches query terms against values from match_filter_inventory.
        Falls back to provided values if inventory doesn't have the key.
        
        Args:
            query_lower: Lowercased query string
            inventory_key: Key in match_filter_inventory to look up
            fallback_values: Default values if inventory key doesn't exist
            
        Returns:
            Matched value from inventory, or None if no match
        """
        inventory = getattr(self, 'match_filter_inventory', {})
        known_values = inventory.get(inventory_key, fallback_values or [])
        
        for val in known_values:
            if val:
                val_lower = val.lower()
                val_spaced = val_lower.replace('_', ' ')
                if val_lower in query_lower or val_spaced in query_lower:
                    return val
        return None

    def _determine_optimal_chunk_count(self, query: str) -> int:
        """
        Determine optimal number of chunks based on question complexity.
        Returns the number of chunks needed for comprehensive analysis.
        
        4-tier system:
        - Ultra-high (18): Multi-factor analysis needing ALL point-by-point data
        - High (15): Complex tactical/pattern questions
        - Detailed (8): Specific context questions
        - Simple (5): Direct factual questions
        """
        query_lower = query.lower()
        
        # Ultra-high complexity (need ALL point-by-point chunks - ~18-19 total)
        # These are RARE, genuinely complex multi-factor questions
        ultra_high_indicators = [
            # Multi-factor match analysis
            "match flow", "match progression", "match dynamics",
            "how the match unfolded", "match evolution",
            "throughout the match", "over time", "entire match",
            # Complex shot sequences and patterns
            "shot sequences", "shot sequence", "rally patterns",
            "when hit a", "when they hit", "when he hit", "when she hit",
            "response to", "respond to", "responded to", "in response",
            # Adaptation and change detection (need before/after comparison)
            "adapt", "adapted", "adaptation",
            "adjust", "adjusted", "adjustment",
            "changed over",
            "counter", "countered", "neutralize", "neutralized",
            # Behavioral transitions
            "switched to", "started hitting more", "began favoring",
            "moved away from", "increased reliance on",
            "started doing", "stopped doing",
            "changed shot direction",
            # Sequential momentum analysis (specific patterns, not common words)
            "consecutive", "streak", "run of", "string of",
            # Rally length and patterns
            "long rallies", "short rallies", "rally length",
            "extended rallies", "quick points",
            "8+ shot", "5+ shot", "rallies longer", "rallies shorter",
            # Physical and performance variance
            "fatigue", "tired", "wore down",
            "variance", "highs and lows",
            "defensive to offensive", "pushed back", "stepped in",
            # Counterfactual analysis
            "what if", "if he had", "if she had",
            "could have", "should have", "would have", "prevented"
        ]
        
        # High complexity (need most point-by-point data)
        high_complexity_indicators = [
            # Match narrative and strategy
            "match pattern", "match analysis", "match strategy",
            "what was the pattern", "analyze the match",
            "turning point", "momentum", "match narrative", "match story",
            "match breakdown", "match summary", "match overview", "match recap",
            "progression", "progressed", "developed",
            "early vs late", "first set vs", "as the match", "match went on",
            # Evolution and shifts (moved from ultra_high - common but still complex)
            "evolve", "evolved", "evolution",
            "momentum shift", "momentum swing",
            "shift", "shifted",
            # Situational and conditional
            "after losing", "after winning", "after missing", "after break",
            "after", "following", "then", "led to", "triggered",
            "when rallies got", "as rallies got",
            "on important points", "on key points", "in crucial moments", "in tight moments",
            "when facing break", "when trailing", "when ahead",
            # Shot responses and effectiveness
            "most common response", "typical response", "usual response",
            "how did", "what did", "how would", "what would",
            "drop shot", "most effective", "least effective", "best response", "worst response",
            # Tactical patterns
            "serve placement", "shot selection", "shot placement",
            "approach shot", "net approach", "serve and volley", "chip and charge",
            "rally control", "dictate", "dictating", "control the point",
            "tactical", "tactics", "strategy", "strategic", "game plan",
            # Psychology and momentum
            "clutch", "pressure", "under pressure", "mental", "mentality",
            "champion", "fighting spirit", "resilience", "comeback",
            "statement", "deflate", "demoralize", "confidence",
            # Sequential patterns
            "next", "subsequent", "immediately after",
            "in response to", "as a result",
            # Comparative time periods
            "first half", "second half", "early", "late", "beginning", "end",
            "set 1 vs", "set 2 vs", "first two sets", "last three sets",
            "tiebreak vs", "regular games", "important games vs",
            # Pattern and tendency
            "pattern", "patterns", "tendency", "tendencies", "prefer", "preferred",
            "favor", "favored", "typically", "usually", "commonly", "often",
            "most of the time", "majority", "predominant", "characteristic",
            # Context-specific situations
            "set point", "game point", "match point",
            "deuce", "advantage", "30-30", "40-40",
            "must hold", "must break",
            "tiebreak", "tie-break", "deciding", "crucial game",
            # Outcome and effectiveness
            "effectiveness", "effective", "ineffective",
            "worked", "didn't work", "successful", "unsuccessful",
            "paid off", "backfired",
            # Quality and level
            "quality", "level", "standard", "performance level",
            "raised their game", "elevated", "dropped off", "declined",
            "peak", "best", "worst", "high point", "low point"
        ]
        
        # Specific but detailed questions
        detailed_indicators = [
            "break points", "game points", "key points", "pressure points",
            "shot direction", "shot types", "serve types", "return types",
            "net play", "baseline play", "point construction",
            "serve performance", "return performance", "overall performance"
        ]
        
        # Check complexity in order (most specific first)
        if any(indicator in query_lower for indicator in ultra_high_indicators):
            return 18  # Get ALL point-by-point chunks
        
        if any(indicator in query_lower for indicator in high_complexity_indicators):
            return 15  # Most point-by-point chunks
        
        if any(indicator in query_lower for indicator in detailed_indicators):
            return 8  # More context for detailed analysis
        
        # Simple specific questions
        return 5  # Default for simple questions

    def retrieve_relevant_chunks(self, query: str, top_k: int = None) -> List[Dict]:
        """
        Retrieve the most relevant chunks for a given query with enhanced filtering.
        Uses adaptive chunk count based on question complexity.
        """
        # Determine optimal chunk count based on question complexity
        if top_k is None:
            top_k = self._determine_optimal_chunk_count(query)
        
        # BOOST chunk count for multi-set comparisons (need data from multiple sets)
        multiple_sets = self._detect_multiple_set_references(query)
        if multiple_sets and len(multiple_sets) >= 2:
            original_top_k = top_k
            top_k = 20  # Ensure we get enough chunks from all requested sets
        
        
        if not self.index:
            raise ValueError("Vector index not created. Call load_exact_full_format() first.")
        
        # Generate query embedding with LOCAL model (100% FREE!)
        query_embedding = self.embedding_model.encode([query])[0].tolist()
        
        # Search for similar chunks (get more than needed for filtering)
        search_k = min(top_k * 3, len(self.chunks))  # Get 3x more for filtering
        query_vector = np.array([query_embedding]).astype('float32')
        distances, indices = self.index.search(query_vector, search_k)
        
        # Collect candidates with metadata
        candidates = []
        for i in indices[0]:
            if i < len(self.chunks):
                chunk_info = {
                    "text": self.chunks[i]["text"],
                    "metadata": self.chunks[i]["metadata"],
                    "distance": float(distances[0][list(indices[0]).index(i)])
                }
                candidates.append(chunk_info)
        
        # Apply intelligent filtering based on query content
        filtered_chunks = self._filter_chunks_by_query(query, candidates)
        
        # CRITICAL FIX: For specific point number questions, force include the chunk containing that point
        import re
        point_match = re.search(r'point\s+(\d+)', query.lower())
        if point_match:
            requested_point = int(point_match.group(1))
            # Find the chunk containing this point
            point_chunk = None
            for chunk in self.chunks:
                if 'point-by-point' in chunk['metadata'].get('section', '').lower():
                    chunk_text = chunk['text']
                    if f"Point {requested_point}" in chunk_text or f"Point {requested_point} [" in chunk_text:
                        point_chunk = {
                            "text": chunk['text'],
                            "metadata": chunk['metadata'],
                            "distance": 0.0,  # Perfect match
                            "relevance_score": 10.0  # Maximum score for specific point questions
                        }
                        break
            
            # Force include the point chunk at the top
            if point_chunk:
                # Remove any existing point-by-point chunks and add this one
                filtered_chunks = [c for c in filtered_chunks if 'point-by-point' not in c['metadata'].get('section', '').lower()]
                filtered_chunks.insert(0, point_chunk)
        
        # Initialize fix flags FIRST (must be before any code path that uses them!)
        direction_outcome_fix_applied = False
        bp_gp_fix_applied = False
        universal_fix_applied = False
        net_points_fix_applied = False

        
        # MATCH OVERVIEW PRIORITY: For score/winner questions, always include match_overview
        query_lower = query.lower()
        if any(word in query_lower for word in ["score", "won", "winner", "result", "defeated", "beat", "lost", "final"]):
            match_overview_chunk = None
            for chunk in self.chunks:
                if 'match_overview' in chunk['metadata']['section']:
                    match_overview_chunk = {
                        "text": chunk['text'],
                        "metadata": chunk['metadata'],
                        "distance": 0.0,
                        "relevance_score": 10.0
                    }
                    break
            if match_overview_chunk:
                filtered_chunks = [chunk for chunk in filtered_chunks if 'match_overview' not in chunk['metadata']['section']]
                filtered_chunks.insert(0, match_overview_chunk)
        
        # OVERVIEW PRIORITY: For basic statistical questions, prioritize overview_statistics
        if not self._is_match_insight_question(query) and any(word in query.lower() for word in [
            # Winners
            "winner", "winners", "winner forehand", "winner backhand",
            # Errors
            "unforced error", "unforced errors", "unforced error forehand", "unforced error backhand",
            "forced error", "forced errors",
            # Serve statistics
            "ace", "aces", "ace percent", "ace percentage",
            "double fault", "double faults", "double fault percent", "double fault percentage",
            "first serve", "first serve in", "first serve won", "first serve percentage",
            "second serve", "second serve won", "second serve percentage",
            # Break points
            "break point", "break points", "break points saved", "break points converted",
            # Return points
            "return points", "return points won", "rpw", "rpw%",
            # General
            "total", "how many", "percentage", "percent"
        ]):
            # Find overview_statistics chunk
            overview_chunk = None
            for chunk in self.chunks:
                if 'overview_statistics' in chunk['metadata']['section']:
                    overview_chunk = {
                        "text": chunk['text'],
                        "metadata": chunk['metadata'],
                        "distance": 0.0,
                        "relevance_score": 10.0
                    }
                    break
            
            # Force overview to be the first chunk for basic stats questions
            if overview_chunk:
                # Remove any existing overview chunk
                filtered_chunks = [chunk for chunk in filtered_chunks if 'overview_statistics' not in chunk['metadata']['section']]
                # Add overview at the very top
                filtered_chunks.insert(0, overview_chunk)
        
        # CRITICAL FIX: Always include overview_statistics for statistical questions
        if not self._is_match_insight_question(query):
            # Find overview_statistics chunk
            overview_chunk = None
            for chunk in self.chunks:
                if 'overview_statistics' in chunk['metadata']['section']:
                    overview_chunk = {
                        "text": chunk['text'],
                        "metadata": chunk['metadata'],
                        "distance": 0.0,  # Perfect match
                        "relevance_score": 10.0  # Maximum score
                    }
                    break
            
            # If overview chunk exists and not already in results, add it at the top
            if overview_chunk and not any('overview_statistics' in chunk['metadata']['section'] for chunk in filtered_chunks):
                filtered_chunks.insert(0, overview_chunk)
            
            # DIRECTION + OUTCOME FIX: For questions about shots by direction AND outcome, force include all shot types for that direction/outcome combo
            direction_keywords = {
                "crosscourt": ["crosscourt", "cross court"],
                "down the line": ["down the line", "downline", "dtl"],
                "down the middle": ["down the middle", "middle", "center"],
                "inside-out": ["inside-out", "inside out"],
                "inside-in": ["inside-in", "inside in"]
            }
            
            outcome_keywords = {
                "winner": ["winner", "winners"],
                "forced error": ["forced error", "forced errors", "induced"],
                "unforced error": ["unforced error", "unforced errors"],
                "pt ending": ["pt ending", "point ending", "ended", "end points"],
                "pts won": ["pts won", "points won", "ptswon"],
                "pts lost": ["pts lost", "points lost", "ptslost"]
            }
            
            detected_direction = None
            detected_outcome = None
            
            # Check for direction + outcome combinations
            for direction, dir_keywords in direction_keywords.items():
                if any(keyword in query.lower() for keyword in dir_keywords):
                    detected_direction = direction
                    break
            
            for outcome, outcome_keywords_list in outcome_keywords.items():
                if any(keyword in query.lower() for keyword in outcome_keywords_list):
                    detected_outcome = outcome
                    break
            
            if detected_direction and detected_outcome:
                # Determine which player is being asked about
                player_mentioned = None
                if self.player1 and (self.player1.lower() in query.lower() or any(word.lower() in query.lower() for word in self.player1.lower().split())):
                    player_mentioned = self.player1
                    target_chunk_name = "shotdir1_statistics"
                elif self.player2 and (self.player2.lower() in query.lower() or any(word.lower() in query.lower() for word in self.player2.lower().split())):
                    player_mentioned = self.player2
                    target_chunk_name = "shotdir2_statistics"
                else:
                    # If no specific player mentioned, include both (for "each player" questions)
                    player_mentioned = "both"
                    target_chunk_name = None
                
                if player_mentioned == "both":
                    # Force include both players' shot direction chunks for "each player" questions
                    chunk_names = ["shotdir1_statistics", "shotdir2_statistics"]
                    chunk1_found = None
                    chunk2_found = None
                    explicit_totals_found = None
                    
                    # Find both chunks and explicit totals chunk
                    for chunk in self.chunks:
                        if "shotdir1_statistics" in chunk['metadata']['section']:
                            chunk1_found = {
                                "text": chunk['text'],
                                "metadata": chunk['metadata'],
                                "distance": 0.0,  # Perfect match
                                "relevance_score": 9.5  # Very high score for specific direction/outcome queries
                            }
                        elif "shotdir2_statistics" in chunk['metadata']['section']:
                            chunk2_found = {
                                "text": chunk['text'],
                                "metadata": chunk['metadata'],
                                "distance": 0.0,  # Perfect match
                                "relevance_score": 9.5  # Very high score for specific direction/outcome queries
                            }
                        elif "explicit_totals_for_shot_direction_+_outcome_combinations" in chunk['metadata']['section']:
                            explicit_totals_found = {
                                "text": chunk['text'],
                                "metadata": chunk['metadata'],
                                "distance": 0.0,  # Perfect match
                                "relevance_score": 10.0  # Highest score for explicit totals
                            }
                    
                    # Add explicit totals chunk first (highest priority)
                    if explicit_totals_found:
                        # Remove any existing explicit totals chunk first
                        filtered_chunks = [chunk for chunk in filtered_chunks if "explicit_totals_for_shot_direction_+_outcome_combinations" not in chunk['metadata']['section']]
                        # Insert at the very beginning
                        filtered_chunks.insert(0, explicit_totals_found)
                    
                    # Add chunks if not already in results
                    if chunk1_found and not any("shotdir1_statistics" in chunk['metadata']['section'] for chunk in filtered_chunks):
                        filtered_chunks.insert(0, chunk1_found)
                    
                    if chunk2_found and not any("shotdir2_statistics" in chunk['metadata']['section'] for chunk in filtered_chunks):
                        filtered_chunks.insert(0, chunk2_found)
                else:
                    # Force include only the specific player's shot direction chunk and explicit totals
                    target_chunk = None
                    explicit_totals_found = None
                    
                    for chunk in self.chunks:
                        if target_chunk_name in chunk['metadata']['section']:
                            target_chunk = {
                                "text": chunk['text'],
                                "metadata": chunk['metadata'],
                                "distance": 0.0,  # Perfect match
                                "relevance_score": 9.5  # Very high score for specific direction/outcome queries
                            }
                        elif "explicit_totals_for_shot_direction_+_outcome_combinations" in chunk['metadata']['section']:
                            explicit_totals_found = {
                                "text": chunk['text'],
                                "metadata": chunk['metadata'],
                                "distance": 0.0,  # Perfect match
                                "relevance_score": 10.0  # Highest score for explicit totals
                            }
                    
                    # Add explicit totals chunk first (highest priority)
                    if explicit_totals_found:
                        # Remove any existing explicit totals chunk first
                        filtered_chunks = [chunk for chunk in filtered_chunks if "explicit_totals_for_shot_direction_+_outcome_combinations" not in chunk['metadata']['section']]
                        # Insert at the very beginning
                        filtered_chunks.insert(0, explicit_totals_found)
                    
                    # Add chunk if not already in results
                    if target_chunk and not any(target_chunk_name in chunk['metadata']['section'] for chunk in filtered_chunks):
                        filtered_chunks.insert(0, target_chunk)
                
                direction_outcome_fix_applied = True
            
            # BP/GP ROUTING FIX: For break point and game point questions, route to correct data sources
            if any(phrase in query.lower() for phrase in ["break point", "bp", "game point", "gp", "deuce"]) and "net points" not in query.lower():
                # Determine which player is being asked about
                player_mentioned = self._detect_player_mentioned(query)
                
                if player_mentioned:
                    # Route the question to get the correct section
                    target_section = self._route_bp_gp_question(query, player_mentioned)
                    
                    if target_section != "unknown" and target_section != "both":
                        # First, check if overview statistics has the data we need
                        overview_chunk = None
                        for chunk in self.chunks:
                            if 'overview_statistics' in chunk['metadata']['section']:
                                overview_chunk = {
                                    "text": chunk['text'],
                                    "metadata": chunk['metadata'],
                                    "distance": 0.0,  # Perfect match
                                    "relevance_score": 10.0  # Highest score for overview data
                                }
                                break
                        
                        # Add overview chunk if it has BP/GP data and not already in results
                        if overview_chunk and not any('overview_statistics' in chunk['metadata']['section'] for chunk in filtered_chunks):
                            filtered_chunks.insert(0, overview_chunk)
                            bp_gp_fix_applied = True
                        
                        # Also add the specific section chunk as backup
                        target_chunk = None
                        
                        # For break point, game point, and deuce questions, prioritize key points statistics
                        if "break point" in query.lower() or "bp" in query.lower() or "game point" in query.lower() or "gp" in query.lower() or "deuce" in query.lower():
                            # Look for key points statistics first
                            # Determine which key points section to look for based on question type
                            if "break point" in query.lower() or "bp" in query.lower():
                                # For break points, use returns data for conversions, serves data for faced/saved
                                if "convert" in query.lower() or "win" in query.lower() or "won" in query.lower():
                                    # Look for returning key points statistics
                                    for chunk in self.chunks:
                                        # Get player suffix dynamically
                                        player_suffix = self._get_player_suffix(player_mentioned)
                                        if 'key_points_statistics_returns' in chunk['metadata']['section'] and player_suffix in chunk['metadata']['section']:
                                            target_chunk = {
                                                "text": chunk['text'],
                                                "metadata": chunk['metadata'],
                                                "distance": 0.0,  # Perfect match
                                                "relevance_score": 9.5  # Higher score for key points data
                                            }
                                            break
                                else:
                                    # For other break point questions, look for serving key points statistics
                                    for chunk in self.chunks:
                                        # Get player suffix dynamically
                                        player_suffix = self._get_player_suffix(player_mentioned)
                                        if 'key_points_statistics_serves' in chunk['metadata']['section'] and player_suffix in chunk['metadata']['section']:
                                            target_chunk = {
                                                "text": chunk['text'],
                                                "metadata": chunk['metadata'],
                                                "distance": 0.0,  # Perfect match
                                                "relevance_score": 9.5  # Higher score for key points data
                                            }
                                            break
                            elif "game point" in query.lower() or "gp" in query.lower():
                                # For game points, use returns data for faced, serves data for won
                                if "face" in query.lower():
                                    # Look for returning key points statistics
                                    for chunk in self.chunks:
                                        # Get player suffix dynamically
                                        player_suffix = self._get_player_suffix(player_mentioned)
                                        if 'key_points_statistics_returns' in chunk['metadata']['section'] and player_suffix in chunk['metadata']['section']:
                                            target_chunk = {
                                                "text": chunk['text'],
                                                "metadata": chunk['metadata'],
                                                "distance": 0.0,  # Perfect match
                                                "relevance_score": 9.5  # Higher score for key points data
                                            }
                                            break
                                else:
                                    # For other game point questions, look for serving key points statistics
                                    for chunk in self.chunks:
                                        # Get player suffix dynamically
                                        player_suffix = self._get_player_suffix(player_mentioned)
                                        if 'key_points_statistics_serves' in chunk['metadata']['section'] and player_suffix in chunk['metadata']['section']:
                                            target_chunk = {
                                                "text": chunk['text'],
                                                "metadata": chunk['metadata'],
                                                "distance": 0.0,  # Perfect match
                                                "relevance_score": 9.5  # Higher score for key points data
                                            }
                                            break
                            elif "deuce" in query.lower():
                                # For deuce points, use returns data for return deuce, serves data for serve deuce
                                if "return" in query.lower():
                                    # Look for returning key points statistics
                                    for chunk in self.chunks:
                                        # Get player suffix dynamically
                                        player_suffix = self._get_player_suffix(player_mentioned)
                                        if 'key_points_statistics_returns' in chunk['metadata']['section'] and player_suffix in chunk['metadata']['section']:
                                            target_chunk = {
                                                "text": chunk['text'],
                                                "metadata": chunk['metadata'],
                                                "distance": 0.0,  # Perfect match
                                                "relevance_score": 9.5  # Higher score for key points data
                                            }
                                            break
                                else:
                                    # For other deuce questions, look for serving key points statistics
                                    for chunk in self.chunks:
                                        # Get player suffix dynamically
                                        player_suffix = self._get_player_suffix(player_mentioned)
                                        if 'key_points_statistics_serves' in chunk['metadata']['section'] and player_suffix in chunk['metadata']['section']:
                                            target_chunk = {
                                                "text": chunk['text'],
                                                "metadata": chunk['metadata'],
                                                "distance": 0.0,  # Perfect match
                                                "relevance_score": 9.5  # Higher score for key points data
                                            }
                                            break
                        
                        # If no key points chunk found, fall back to regular statistics
                        if not target_chunk:
                            for chunk in self.chunks:
                                # Handle split return statistics chunks (e.g., return2_statistics_detailed_part_1)
                                if target_section in chunk['metadata']['section'] or (target_section.replace('_statistics', '') in chunk['metadata']['section'] and 'return' in chunk['metadata']['section']):
                                    target_chunk = {
                                        "text": chunk['text'],
                                        "metadata": chunk['metadata'],
                                        "distance": 0.0,  # Perfect match
                                        "relevance_score": 9.0  # High score for BP/GP questions
                                    }
                                    break
                        
                        # Add the chunk if not already in results
                        if target_chunk:
                            # For key points chunks, use the actual chunk section name
                            if 'key_points_statistics' in target_chunk['metadata']['section']:
                                key_points_section = target_chunk['metadata']['section']
                                # Remove any existing instance first
                                filtered_chunks = [chunk for chunk in filtered_chunks if key_points_section not in chunk['metadata']['section']]
                                
                                # Set maximum priority and force to top
                                target_chunk['relevance_score'] = 10.0
                                filtered_chunks.insert(0, target_chunk)
                                bp_gp_fix_applied = True
                            else:
                                # For regular statistics chunks, use target_section
                                if not any(target_section in chunk['metadata']['section'] for chunk in filtered_chunks):
                                    filtered_chunks.insert(0, target_chunk)
                                    bp_gp_fix_applied = True
                    
                    elif target_section == "both":
                        # Need both serve and return sections for BP/GP/deuce totals or ambiguous questions
                        serve_section = "serve1_statistics_summary" if (self.player1 and (self.player1.lower() in query.lower() or any(word.lower() in query.lower() for word in self.player1.lower().split()))) else "serve2_statistics_summary"
                        return_section = "return1_statistics_detailed" if (self.player1 and (self.player1.lower() in query.lower() or any(word.lower() in query.lower() for word in self.player1.lower().split()))) else "return2_statistics_detailed"
                        
                        # Add both chunks
                        for section in [serve_section, return_section]:
                            target_chunk = None
                            for chunk in self.chunks:
                                if section in chunk['metadata']['section']:
                                    target_chunk = {
                                        "text": chunk['text'],
                                        "metadata": chunk['metadata'],
                                        "distance": 0.0,
                                        "relevance_score": 9.0
                                    }
                                    break
                            
                            if target_chunk and not any(section in chunk['metadata']['section'] for chunk in filtered_chunks):
                                filtered_chunks.insert(0, target_chunk)
                                bp_gp_fix_applied = True
            
            # DIRECTION TOTALS FIX: For questions asking about shot direction totals (e.g., "how many crosscourt shots")
            if any(direction in query.lower() for direction in ["crosscourt", "down the line", "down the middle", "inside-out", "inside-in"]) and not any(outcome in query.lower() for outcome in ["winner", "winners", "unforced error", "unforced errors", "forced error", "forced errors", "error", "errors"]):
                # Force include both shotdir chunks for comprehensive direction totals
                shotdir1_chunk = None
                shotdir2_chunk = None
                
                # Find shotdir1_statistics chunk
                for chunk in self.chunks:
                    if 'shotdir1_statistics' in chunk['metadata']['section']:
                        shotdir1_chunk = {
                            "text": chunk['text'],
                            "metadata": chunk['metadata'],
                            "distance": 0.0,  # Perfect match
                            "relevance_score": 8.0  # High score
                        }
                        break
                
                # Find shotdir2_statistics chunk
                for chunk in self.chunks:
                    if 'shotdir2_statistics' in chunk['metadata']['section']:
                        shotdir2_chunk = {
                            "text": chunk['text'],
                            "metadata": chunk['metadata'],
                            "distance": 0.0,  # Perfect match
                            "relevance_score": 8.0  # High score
                        }
                        break
                
                # Add shotdir1 chunk if not already in results
                if shotdir1_chunk and not any('shotdir1_statistics' in chunk['metadata']['section'] for chunk in filtered_chunks):
                    filtered_chunks.insert(0, shotdir1_chunk)
                
                # Add shotdir2 chunk if not already in results
                if shotdir2_chunk and not any('shotdir2_statistics' in chunk['metadata']['section'] for chunk in filtered_chunks):
                    filtered_chunks.insert(0, shotdir2_chunk)
            
            # UNIVERSAL FIX: For "each player" or "both players" questions, force include both players' chunks
            detected_stat_type = None  # Initialize outside the if block
            
            if any(phrase in query.lower() for phrase in ["each player", "both players", "both player"]):
                # Define all the split player statistics sections
                split_sections = {
                    "serve": ["serve1_statistics_summary", "serve2_statistics_summary", "serve1_statistics_detailed", "serve2_statistics_detailed"],
                    "shots": ["shots1_statistics", "shots2_statistics"],
                    "shotdir": ["shotdir1_statistics", "shotdir2_statistics"],
                    "return": ["return1_statistics_detailed", "return2_statistics_detailed"],
                    "netpts": ["netpts1_statistics", "netpts2_statistics"],
                    "keypoints": ["key_points_statistics_serves", "key_points_statistics_returns"]
                }
                
                # Check which statistic type the question is about (in order of specificity)
                
                # Check most specific keywords first to avoid conflicts
                if any(phrase in query.lower() for phrase in ["break point", "break points", "game point", "game points"]):
                    detected_stat_type = "keypoints"
                elif any(phrase in query.lower() for phrase in ["net points", "net approaches"]):
                    detected_stat_type = "netpts"
                elif any(phrase in query.lower() for phrase in ["volley", "volleys"]):
                    detected_stat_type = "shots"  # Volley is a shot type, not just net points
                elif any(phrase in query.lower() for phrase in ["overhead", "smash", "smashes"]):
                    detected_stat_type = "shots"  # Overhead/smash is a shot type
                elif any(phrase in query.lower() for phrase in ["crosscourt", "down the line", "down the middle", "inside-out", "inside-in"]):
                    detected_stat_type = "shotdir"
                elif any(phrase in query.lower() for phrase in ["winner", "winners", "unforced error", "unforced errors", "forehand", "backhand"]):
                    # Only set to shots if we haven't already detected a more specific type
                    if not detected_stat_type:
                        detected_stat_type = "shots"
                elif any(phrase in query.lower() for phrase in ["return", "returns", "returnable"]):
                    detected_stat_type = "return"
                elif any(phrase in query.lower() for phrase in ["ace", "aces", "serve", "serving", "double fault", "double faults", "first serve", "second serve"]):
                    detected_stat_type = "serve"
                
                # Apply the fix for the detected statistic type
                if detected_stat_type and detected_stat_type in split_sections:
                    chunk_names = split_sections[detected_stat_type]
                    
                    # Find all matching chunks (handle variable-length lists)
                    found_chunks = []
                    for chunk_name in chunk_names:
                        for chunk in self.chunks:
                            if chunk_name in chunk['metadata']['section']:
                                found_chunk = {
                                    "text": chunk['text'],
                                    "metadata": chunk['metadata'],
                                    "distance": 0.0,
                                    "relevance_score": 8.0
                                }
                                found_chunks.append(found_chunk)
                                break
                    
                    # Remove existing instances and add with high priority
                    for found_chunk in found_chunks:
                        chunk_section = found_chunk['metadata']['section']
                        # Remove any existing instance
                        filtered_chunks = [chunk for chunk in filtered_chunks if chunk['metadata']['section'] != chunk_section]
                        # Set high priority and add to top
                        found_chunk['relevance_score'] = 9.0
                        filtered_chunks.insert(0, found_chunk)
                    
                    universal_fix_applied = True
                    
                    # If we added netpts chunks, set the flag to prevent FINAL NEGATIVE FILTER from removing them
                    if detected_stat_type == "netpts":
                        net_points_fix_applied = True
            
                        # CRITICAL FIX: For ace/serve questions (only if other fixes didn't apply)
            if not universal_fix_applied and not direction_outcome_fix_applied and not bp_gp_fix_applied and any(word in query.lower() for word in ["serve", "serves", "ace", "aces", "serving", "double fault", "first serve", "second serve"]) and not any(word in query.lower() for word in ["return", "returning"]):
                serve1_summary_chunks = []
                serve2_summary_chunks = []
                serve1_detailed_chunks = []
                serve2_detailed_chunks = []
                
                # Find ALL serve1_statistics_summary chunks
                for chunk in self.chunks:
                    if 'serve1_statistics_summary' in chunk['metadata'].get('section', ''):
                        serve1_summary_chunks.append({
                            "text": chunk['text'],
                            "metadata": chunk['metadata'],
                            "distance": 0.0,
                            "relevance_score": 8.0
                        })
                
                # Find ALL serve2_statistics_summary chunks
                for chunk in self.chunks:
                    if 'serve2_statistics_summary' in chunk['metadata'].get('section', ''):
                        serve2_summary_chunks.append({
                            "text": chunk['text'],
                            "metadata": chunk['metadata'],
                            "distance": 0.0,
                            "relevance_score": 8.0
                        })
                
                # Find ALL serve1_statistics_detailed chunks
                for chunk in self.chunks:
                    if 'serve1_statistics_detailed' in chunk['metadata'].get('section', ''):
                        serve1_detailed_chunks.append({
                            "text": chunk['text'],
                            "metadata": chunk['metadata'],
                            "distance": 0.0,
                            "relevance_score": 7.5  # Slightly lower than summary
                        })
                
                # Find ALL serve2_statistics_detailed chunks
                for chunk in self.chunks:
                    if 'serve2_statistics_detailed' in chunk['metadata'].get('section', ''):
                        serve2_detailed_chunks.append({
                            "text": chunk['text'],
                            "metadata": chunk['metadata'],
                            "distance": 0.0,
                            "relevance_score": 7.5
                        })
                
                # Add serve1 summary chunks to position 0 (remove if exists first)
                for chunk in serve1_summary_chunks:
                    filtered_chunks = [c for c in filtered_chunks if c['metadata']['section'] != chunk['metadata']['section']]
                    filtered_chunks.insert(0, chunk)
                
                # Add serve2 summary chunks to position 0 (remove if exists first)
                for chunk in serve2_summary_chunks:
                    filtered_chunks = [c for c in filtered_chunks if c['metadata']['section'] != chunk['metadata']['section']]
                    filtered_chunks.insert(0, chunk)
                
                # Add serve1 detailed chunks to position 0 (for detailed questions)
                for chunk in serve1_detailed_chunks:
                    filtered_chunks = [c for c in filtered_chunks if c['metadata']['section'] != chunk['metadata']['section']]
                    filtered_chunks.insert(0, chunk)
                
                # Add serve2 detailed chunks to position 0 (for detailed questions)
                for chunk in serve2_detailed_chunks:
                    filtered_chunks = [c for c in filtered_chunks if c['metadata']['section'] != chunk['metadata']['section']]
                    filtered_chunks.insert(0, chunk)
            
            # CRITICAL FIX: For return questions (return depth, return direction, etc.)
            if any(word in query.lower() for word in ["return", "returning", "deep return", "shallow return", "return depth"]):
                
                # Detect which player is mentioned
                player_mentioned = self._detect_player_mentioned(query)
                
                # Check if this is a serve-return question (e.g., "When X served, Y's return rate")
                is_serve_return_question = any(word in query.lower() for word in ["served", "serving", "serve to", "serve wide", "serve down"])
                
                # Only force the relevant player's chunks
                if player_mentioned:
                    # FLIP logic for serve-return questions: if asking about X's serve → need OTHER player's returns
                    if is_serve_return_question:
                        # If server is mentioned, get the OTHER player's return stats
                        if player_mentioned.lower() == self.player1.lower():
                            target_sections = "return2_statistics_detailed"  # FLIPPED: Get player2's returns
                        else:
                            target_sections = "return1_statistics_detailed"  # FLIPPED: Get player1's returns
                    else:
                        # Normal return question: player mentioned is the returner
                        if player_mentioned.lower() == self.player1.lower():
                            target_sections = "return1_statistics_detailed"
                        else:
                            target_sections = "return2_statistics_detailed"
                    
                    # Find and force the relevant player's chunks to position 0
                    chunks_to_add = []
                    for chunk in self.chunks:
                        if target_sections in chunk['metadata'].get('section', ''):
                            chunks_to_add.append({
                                "text": chunk['text'],
                                "metadata": chunk['metadata'],
                                "distance": 0.0,
                                "relevance_score": 8.0
                            })
                    
                    # Remove these chunks if they already exist, then add them at position 0
                    for chunk_to_add in chunks_to_add:
                        filtered_chunks = [c for c in filtered_chunks if c['metadata']['section'] != chunk_to_add['metadata']['section']]
                        filtered_chunks.insert(0, chunk_to_add)
                else:
                    # If no player mentioned, force both players' chunks to position 0
                    chunks_to_add = []
                    for chunk in self.chunks:
                        if 'return1_statistics_detailed' in chunk['metadata'].get('section', '') or 'return2_statistics_detailed' in chunk['metadata'].get('section', ''):
                            chunks_to_add.append({
                                "text": chunk['text'],
                                "metadata": chunk['metadata'],
                                "distance": 0.0,
                                "relevance_score": 8.0
                            })
                    
                    # Remove these chunks if they already exist, then add them at position 0
                    for chunk_to_add in chunks_to_add:
                        filtered_chunks = [c for c in filtered_chunks if c['metadata']['section'] != chunk_to_add['metadata']['section']]
                        filtered_chunks.insert(0, chunk_to_add)
            
            # CRITICAL FIX: For net points questions (always apply for net points questions)
            if any(word in query.lower() for word in ["net points", "net approaches", "approach shot", "approach shots", "net play", "at the net", "net points won", "net points lost", "net percentage", "net points won percentage", "net points percentage", "net"]):
                # Determine which player is being asked about
                player_mentioned = self._detect_player_mentioned(query)
                if player_mentioned:
                    if player_mentioned.lower() == self.player1.lower():
                        target_chunk_name = "netpts1_statistics"
                    else:
                        target_chunk_name = "netpts2_statistics"
                else:
                    # If no specific player mentioned, pull both chunks
                    player_mentioned = "both players"
                    target_chunk_name = None
                
                if target_chunk_name:
                    # Find the specific player's net points chunk
                    target_chunk = None
                    for chunk in self.chunks:
                        if target_chunk_name in chunk['metadata']['section']:
                            target_chunk = {
                                "text": chunk['text'],
                                "metadata": chunk['metadata'],
                                "distance": 0.0,  # Perfect match
                                "relevance_score": 10.0  # Maximum score for net points
                            }
                            break
                    
                    # Add or move the specific player's chunk to position 0
                    if target_chunk:
                        # Remove it if it already exists (we'll re-insert at position 0)
                        filtered_chunks = [c for c in filtered_chunks if target_chunk_name not in c['metadata']['section']]
                        # Insert at position 0
                        filtered_chunks.insert(0, target_chunk)
                        net_points_fix_applied = True
                    
                
                else:
                    # Pull both players' chunks for "each player" questions
                    netpts1_chunk = None
                    netpts2_chunk = None
                    
                    # Find netpts1_statistics chunk
                    for chunk in self.chunks:
                        if 'netpts1_statistics' in chunk['metadata']['section']:
                            netpts1_chunk = {
                                "text": chunk['text'],
                                "metadata": chunk['metadata'],
                                "distance": 0.0,  # Perfect match
                                "relevance_score": 10.0  # Maximum score for net points
                            }
                            break
                    
                    # Find netpts2_statistics chunk
                    for chunk in self.chunks:
                        if 'netpts2_statistics' in chunk['metadata']['section']:
                            netpts2_chunk = {
                                "text": chunk['text'],
                                "metadata": chunk['metadata'],
                                "distance": 0.0,  # Perfect match
                                "relevance_score": 10.0  # Maximum score for net points
                            }
                            break
                    
                    # Add netpts1 chunk if not already in results
                    if netpts1_chunk and not any('netpts1_statistics' in chunk['metadata']['section'] for chunk in filtered_chunks):
                        filtered_chunks.insert(0, netpts1_chunk)
                        net_points_fix_applied = True
                    
                    # Add netpts2 chunk if not already in results
                    if netpts2_chunk and not any('netpts2_statistics' in chunk['metadata']['section'] for chunk in filtered_chunks):
                        filtered_chunks.insert(0, netpts2_chunk)
                        net_points_fix_applied = True
        
        # MATCH RESULT FIX: For questions about match outcome, force include match_overview (FINAL PRIORITY)
        if any(phrase in query.lower() for phrase in ["final score", "who won", "match result", "outcome", "d.", "defeated", "victory", "victor"]):
            # Force include match_overview chunk
            match_overview_chunk = None
            for chunk in self.chunks:
                if 'match_overview' in chunk['metadata']['section']:
                    match_overview_chunk = {
                        "text": chunk['text'],
                        "metadata": chunk['metadata'],
                        "distance": 0.0,
                        "relevance_score": 10.0  # Maximum score for match result questions
                    }
                    break
            
            # Remove any existing match_overview chunks and add at the very top
            filtered_chunks = [chunk for chunk in filtered_chunks if 'match_overview' not in chunk['metadata']['section']]
            if match_overview_chunk:
                filtered_chunks.insert(0, match_overview_chunk)
        
        # CRITICAL FIX: For MULTI-SET comparison questions (must come BEFORE single-set logic)
        multiple_sets = self._detect_multiple_set_references(query)
        if multiple_sets and hasattr(self, 'set_mapping'):
            
            # Collect chunks from ALL requested sets
            multi_set_chunks = []
            for set_num in multiple_sets:
                if set_num in self.set_mapping:
                    target_set_score = self.set_mapping[set_num]
                    
                    # Generate score patterns for this set
                    score_parts = target_set_score.split('-')
                    if len(score_parts) == 2:
                        set_score_patterns = [
                            target_set_score,
                            f"{score_parts[1]}-{score_parts[0]}",
                        ]
                        total = int(score_parts[0]) + int(score_parts[1])
                        if total == 2 and score_parts[0] != score_parts[1]:
                            set_score_patterns.append("1-1")
                    else:
                        set_score_patterns = [target_set_score]
                    
                    # Find chunks for this set
                    for chunk in self.chunks:
                        if 'point-by-point_narrative' in chunk['metadata'].get('section', ''):
                            chunk_metadata = chunk.get('metadata', {})
                            chunk_set_numbers = chunk_metadata.get('set_numbers', [])
                            
                            # Use metadata or text fallback
                            if set_num in chunk_set_numbers:
                                multi_set_chunks.append({
                                    "text": chunk['text'],
                                    "metadata": chunk['metadata'],
                                    "distance": 0.0,
                                    "relevance_score": 10.0,
                                    "set_number": set_num  # Track which set this is from
                                })
                            elif not chunk_set_numbers:
                                chunk_text = chunk['text']
                                for pattern in set_score_patterns:
                                    if f"Score: {pattern}" in chunk_text:
                                        multi_set_chunks.append({
                                            "text": chunk['text'],
                                            "metadata": chunk['metadata'],
                                            "distance": 0.0,
                                            "relevance_score": 10.0,
                                            "set_number": set_num
                                        })
                                        break
            
            # Remove ALL point-by-point chunks and add the multi-set chunks
            if multi_set_chunks:
                filtered_chunks = [c for c in filtered_chunks if 'point-by-point_narrative' not in c['metadata'].get('section', '')]
                
                # Add chunks in set order (Set 1 first, then Set 5, etc.)
                for chunk_to_add in multi_set_chunks:
                    filtered_chunks.insert(0, chunk_to_add)
                
        
        # CRITICAL FIX: For set-specific questions (single set only)
        elif not multiple_sets:  # Only run single-set logic if NOT a multi-set comparison
            set_number = self._detect_set_reference(query)
            if set_number and hasattr(self, 'set_mapping') and set_number in self.set_mapping:
                target_set_score = self.set_mapping[set_number]
                
                # Generate ALL possible score patterns for this set
                # For Set 3 with mapping "2-0", we need to match BOTH "2-0" AND "0-2" (server perspective)
                # Also handle "1-1" if it's a tied situation
                score_parts = target_set_score.split('-')
                if len(score_parts) == 2:
                    set_score_patterns = [
                        target_set_score,  # e.g., "2-0"
                        f"{score_parts[1]}-{score_parts[0]}",  # e.g., "0-2" (reversed)
                    ]
                    # Add "1-1" pattern if the total is 2 (for set 3)
                    total = int(score_parts[0]) + int(score_parts[1])
                    if total == 2 and score_parts[0] != score_parts[1]:
                        set_score_patterns.append("1-1")
                    
                else:
                    set_score_patterns = [target_set_score]
                
                # Find all point-by-point chunks containing ANY points from this set
                # Use metadata filtering (fast) with text fallback (backward compatibility)
                set_specific_chunks = []
                for chunk in self.chunks:
                    if 'point-by-point_narrative' in chunk['metadata'].get('section', ''):
                        chunk_metadata = chunk.get('metadata', {})
                        chunk_set_numbers = chunk_metadata.get('set_numbers', [])
                        
                        # Method 1: Use metadata (preferred - fast and accurate)
                        if set_number in chunk_set_numbers:
                            set_specific_chunks.append({
                                "text": chunk['text'],
                                "metadata": chunk['metadata'],
                                "distance": 0.0,
                                "relevance_score": 10.0  # Maximum score for set-specific
                            })
                        # Method 2: Text search fallback (for old chunks without metadata)
                        elif not chunk_set_numbers:  # Only if metadata is missing
                            chunk_text = chunk['text']
                            for pattern in set_score_patterns:
                                if f"Score: {pattern}" in chunk_text:
                                    set_specific_chunks.append({
                                        "text": chunk['text'],
                                        "metadata": chunk['metadata'],
                                        "distance": 0.0,
                                        "relevance_score": 10.0
                                    })
                                    break  # Don't add the same chunk twice
                
                # CRITICAL: Remove ALL point-by-point chunks from OTHER sets
                # Only keep chunks that match the target set score
                if set_specific_chunks:
                    filtered_chunks = [c for c in filtered_chunks if 'point-by-point_narrative' not in c['metadata'].get('section', '')]
                    
                    # Now add ONLY the Set 3 chunks at the top
                    for chunk_to_add in set_specific_chunks:
                        filtered_chunks.insert(0, chunk_to_add)
                        
        
        # CRITICAL FIX: For game-specific questions
        game_reference = self._detect_game_reference(query)
        if game_reference and not game_reference.startswith('game_'):  # Game score pattern like "3-2"
            
            # IMPORTANT: Search within already-filtered chunks (which may already be set-specific)
            # This prevents adding back games from other sets
            game_specific_chunks = []
            search_source = filtered_chunks if set_number else self.chunks
            
            for chunk in search_source:
                if 'point-by-point_narrative' in chunk.get('metadata', {}).get('section', ''):
                    chunk_metadata = chunk.get('metadata', {})
                    chunk_game_scores = chunk_metadata.get('game_scores', [])
                    
                    # Method 1: Use metadata (preferred)
                    if game_reference in chunk_game_scores:
                        game_specific_chunks.append({
                            "text": chunk.get('text', ''),
                            "metadata": chunk.get('metadata', {}),
                            "distance": chunk.get('distance', 0.0),
                            "relevance_score": 9.5
                        })
                    # Method 2: Text search fallback
                    elif not chunk_game_scores:  # Only if metadata missing
                        if f" {game_reference} " in chunk.get('text', ''):
                            game_specific_chunks.append({
                                "text": chunk.get('text', ''),
                                "metadata": chunk.get('metadata', {}),
                                "distance": chunk.get('distance', 0.0),
                                "relevance_score": 9.5
                            })
            
            # Remove existing PBP chunks and add only the game-specific ones
            if game_specific_chunks:
                filtered_chunks = [c for c in filtered_chunks if 'point-by-point_narrative' not in c['metadata'].get('section', '')]
                for chunk_to_add in game_specific_chunks:
                    filtered_chunks.insert(0, chunk_to_add)
        
        # POINT-BY-POINT PRIORITY: For conditional/temporal/shot-sequence questions, prioritize narrative chunks
        # ONLY include indicators that ALWAYS need PBP (not words that could be stats OR PBP)
        conditional_indicators = [
            # Conditional/situational (always need PBP context)
            "after losing", "after winning", "after missing", "after break",
            "when rallies got", "as rallies got",
            "on important points", "on key points", "in crucial moments", "in tight moments",
            "when facing break", "when trailing", "when ahead",
            # Temporal/evolution (always need PBP analysis over time)
            "evolve", "evolved", "evolution", "over time", "throughout the match",
            "progression", "progressed", "changed over", "developed",
            "early vs late", "first set vs", "as the match", "match went on",
            # Per-set/per-game breakdowns (always need PBP counting)
            "each set", "per set", "in each set", "every set", "set by set",
            "across sets", "across the sets", "across all sets", "across the five sets",
            "in set 1", "in set 2", "in set 3", "in set 4", "in set 5",
            "per game", "each game", "game by game",
            # Shot sequence/response indicators (ALWAYS need rally-level data)
            "when hit a", "when he hit", "when she hit", "when they hit",
            "response to", "respond to", "responded to", "in response",
            "shot sequence", "shot sequences", "rally patterns",
            "most common response", "typical response",
            # Sequential/consequential (always need PBP flow)
            "next shot", "following shot", "then hit",
            # Specific rally questions (need PBP not stats)
            "rallies with", "rallies where", "points where", "points when",
            "long rallies", "short rallies", "extended rallies",
            "8+ shot", "5+ shot", "10+ shot",
            # Adaptation/tactical evolution (need PBP temporal analysis)
            "adapt", "adapted", "adaptation",
            "counter", "countered", "countering",
            "switched to", "started hitting", "began favoring", "began using"
        ]
        if any(indicator in query.lower() for indicator in conditional_indicators):
            # Collect all point-by-point narrative chunks
            pbp_chunks = []
            non_pbp_chunks = []
            
            for chunk in filtered_chunks:
                if 'narrative' in chunk['metadata']['section'].lower() or 'point-by-point' in chunk['metadata']['section'].lower():
                    # Boost relevance score for PBP chunks
                    chunk['relevance_score'] = chunk.get('relevance_score', 1.0) + 5.0
                    pbp_chunks.append(chunk)
                else:
                    non_pbp_chunks.append(chunk)
            
            # Reorder: PBP chunks first, then statistical chunks
            if pbp_chunks:
                filtered_chunks = pbp_chunks + non_pbp_chunks
        
        # FINAL NEGATIVE FILTER: Remove net points chunks unless question is about net play
        if not net_points_fix_applied and not any(word in query.lower() for word in ["net points", "net approaches", "overhead", "approach shot", "approach shots", "net play", "at the net", "net points won", "net points lost", "net percentage", "net points won percentage", "net points percentage", "net"]):
            original_count = len(filtered_chunks)
            filtered_chunks = [chunk for chunk in filtered_chunks if 'netpts' not in chunk['metadata']['section']]
            if len(filtered_chunks) < original_count:
                pass
        
        # For complex analytical questions, ensure we have diverse chunk types
        if top_k > 8:
            # Ensure we have a mix of different section types for comprehensive analysis
            section_types = set()
            for chunk in filtered_chunks[:top_k]:
                section = chunk['metadata']['section']
                if 'overview' in section:
                    section_types.add('overview')
                elif 'serve' in section:
                    section_types.add('serve')
                elif 'return' in section:
                    section_types.add('return')
                elif 'shot' in section:
                    section_types.add('shot')
                elif 'key_points' in section:
                    section_types.add('key_points')
                elif 'netpts' in section:
                    section_types.add('netpts')
                elif 'rally' in section:
                    section_types.add('rally')
                elif 'match_overview' in section:
                    section_types.add('match_overview')
            
        
        # Return top_k results
        return filtered_chunks[:top_k]
    
    def _route_bp_gp_question(self, question: str, player: str) -> str:
        """
        Route break point and game point questions to correct data sources.
        Returns the appropriate section and data field to look for.
        """
        q = question.lower()
        player_lower = player.lower()
        
        # Determine which player is being asked about
        if not self.player1 or not self.player2:
            return "unknown"
            
        if player_lower == self.player1.lower():
            player_prefix = "serve1" if "serve" in q else "serve2" if "return" in q else "serve1"  # Default to serve1 for player1
        elif player_lower == self.player2.lower():
            player_prefix = "serve2" if "serve" in q else "serve1" if "return" in q else "serve2"  # Default to serve2 for player2
        else:
            # Fallback - check if any part of the player name matches
            if any(word in q for word in self.player1.lower().split()):
                player_prefix = "serve1"
            elif any(word in q for word in self.player2.lower().split()):
                player_prefix = "serve2"
            else:
                return "unknown"
        
        # --- BREAK POINTS (BP) ---
        if "break point" in q or "bp" in q:
            if "face" in q:  
                return f"{player_prefix}_statistics"  # Serving side (opponent had chance to break) - BP Faced
            elif "save" in q or "saved" in q:
                return f"{player_prefix}_statistics"  # Serving side (player defended successfully) - BP Faced, col = PtsW
            elif "opp" in q or "opportunit" in q:
                return f"{player_prefix.replace('serve', 'return')}_statistics"  # Returning side (player created break chances) - BP Opps
            elif "convert" in q or "win" in q or "won" in q:
                return f"{player_prefix.replace('serve', 'return')}_statistics"  # Returning side (player actually broke serve) - BP Opps, col = PtsW
            elif "total" in q or "overall" in q:
                return "both"  # Need both serve and return for complete totals
            else:
                # No keyword → Default = Return side (converted), because that's most common in questions
                return f"{player_prefix.replace('serve', 'return')}_statistics"
        
        # --- GAME POINTS (GP) ---
        if "game point" in q or "gp" in q:
            if "face" in q:
                return f"{player_prefix.replace('serve', 'return')}_statistics"  # Returning side (opponent had game points on serve) - GP Faced
            elif "save" in q or "saved" in q:
                return f"{player_prefix.replace('serve', 'return')}_statistics"  # Returning side (player denied opponent's game point while returning) - GP Faced, col = PtsW
            elif "win" in q or "won" in q:
                if "serve" in q:
                    return f"{player_prefix}_statistics"  # Serving side (player won their own service game points) - Game Pts, col = PtsW
                elif "return" in q:
                    return f"{player_prefix.replace('serve', 'return')}_statistics"  # Returning side (rare phrasing, but = broke opponent on GP) - GP Faced, col = PtsW
                elif "each player" in q or "both player" in q:
                    return "both"  # Need both serve and return for "each player" questions
                else:
                    # Default: GP won on serve (most common case)
                    return f"{player_prefix}_statistics"  # Serving side (Game Pts won) - Game Pts, col = PtsW
            elif "convert" in q:
                return f"{player_prefix.replace('serve', 'return')}_statistics"  # Returning side (converted while returning) - GP Faced, col = PtsW
            elif "total" in q or "overall" in q or "each player" in q or "both player" in q:
                return "both"  # Need both serve and return for complete totals
            else:
                # No keyword → Default = Serve side (Game Pts won), because that's the most natural reading
                return f"{player_prefix}_statistics"
        
        # --- DEUCE POINTS ---
        if "deuce" in q:
            if "serve" in q or "served" in q:
                return f"{player_prefix}_statistics"  # Serving side (deuce points on own serve) - Svg Deuce
            elif "return" in q or "returned" in q:
                return f"{player_prefix.replace('serve', 'return')}_statistics"  # Returning side (deuce points when opponent served) - Ret Deuce
            elif "each player" in q or "both player" in q:
                return "both"  # Need both serve and return for "each player" questions
            else:
                # No keyword → Need both, since "deuce points" could mean either. Safest = "both"
                return "both"
        
        return "unknown"

    def _get_stat_keywords(self, stat_type: str) -> List[str]:
        """Get keywords that indicate a question is about a specific statistic type."""
        keywords = {
            "serve": ["ace", "aces", "serve", "serving", "double fault", "double faults", "first serve", "second serve"],
            "shots": ["winner", "winners", "unforced error", "unforced errors", "forehand", "backhand", "shot"],
            "shotdir": ["crosscourt", "down the line", "down the middle", "inside-out", "inside-in", "direction"],
            "return": ["return", "returns", "returnable", "returning"],
            "netpts": ["net points", "net approaches", "volley", "volleys", "overhead", "approach"],
            "keypoints": ["break point", "break points", "game point", "game points", "deuce", "key point"]
        }
        return keywords.get(stat_type, [])
    
    def _filter_chunks_by_query(self, query: str, candidates: List[Dict]) -> List[Dict]:
        """
        Filter and re-rank chunks based on query content and metadata.
        """
        query_lower = query.lower()
        
        # Determine query intent
        player_mentioned = self._detect_player_mentioned(query)
        
        stat_category = None
        if any(word in query_lower for word in ["return", "returning"]):
            stat_category = "returning"
        elif any(word in query_lower for word in ["serve", "serving", "aces", "double fault"]):
            stat_category = "serving"
        elif any(word in query_lower for word in ["shot", "winner", "error", "forehand", "backhand"]):
            stat_category = "shots"
        elif any(word in query_lower for word in ["net", "volley", "approach"]):
            stat_category = "net_play"
        elif any(word in query_lower for word in ["key point", "break point", "game point", "set point", "match point", "deuce", "advantage", "bp", "gp", "converted", "faced", "saved"]):
            stat_category = "key_points"
        elif any(word in query_lower for word in ["point", "rally", "narrative", "longest", "shot", "stroke", "key moments", "decided", "outcome", "strategy", "momentum", "critical", "turning point"]):
            stat_category = "narrative"
        elif any(word in query_lower for word in ["overview", "summary", "total"]):
            stat_category = "overview"
        
        # Score and filter chunks
        scored_chunks = []
        for chunk in candidates:
            score = 1.0 - chunk["distance"]  # Convert distance to similarity score
            metadata = chunk["metadata"]
            
            # CRITICAL FIX: Prioritize overview statistics for statistical questions
            if not self._is_match_insight_question(query):
                # For statistical questions, heavily prioritize overview and authoritative totals
                if "overview_statistics" in metadata.get("section", "").lower():
                    score += 5.0  # Extremely high boost for overview statistics
                elif "authoritative totals" in chunk["text"].lower():
                    score += 3.0  # Very high boost for authoritative totals
                elif "serve1_statistics_summary" in metadata.get("section", "").lower():
                    score += 2.0  # High boost for serve summary with authoritative totals
                elif "serve2_statistics_summary" in metadata.get("section", "").lower():
                    score += 2.0  # High boost for serve summary with authoritative totals
                # KEY POINTS HIERARCHY: Prioritize key points section for break points and game points
                elif "key_points" in metadata.get("section", "").lower():
                    if any(word in query_lower for word in ["break point", "break points", "bp", "converted", "faced", "saved"]):
                        score += 3.0  # Very high boost for break point questions
                    elif any(word in query_lower for word in ["game point", "game points", "gp", "set point", "set points", "match point", "match points"]):
                        score += 3.0  # Very high boost for game/set/match point questions
                    elif any(word in query_lower for word in ["key point", "key points", "critical point", "deuce", "advantage"]):
                        score += 2.5  # High boost for general key point questions
                
                # SHOT HIERARCHY: Establish clear priority for shot-related questions
                # 1. SHOT STATISTICS: For forehand/backhand SIDE (all shots from that side - volleys, dropshots, etc.)
                if any(word in query_lower for word in ["forehand side", "backhand side", "volley", "dropshot", "lob", "net play", "swinging volley"]) and "shots" in metadata.get("section", "").lower():
                    if "shots1_statistics" in metadata.get("section", "").lower() or "shots2_statistics" in metadata.get("section", "").lower():
                        score += 2.5  # High boost for shot statistics (side-based shots)
                
                # Also use SHOT STATISTICS for general shot performance questions
                if any(word in query_lower for word in ["shot", "winner", "error", "unforced", "forced", "total shots"]) and "shots" in metadata.get("section", "").lower():
                    if "shots1_statistics" in metadata.get("section", "").lower() or "shots2_statistics" in metadata.get("section", "").lower():
                        score += 2.0  # High boost for general shot statistics
                
                # 2. SHOT DIRECTION: For forehand/backhand GROUNDSTROKES and placement patterns
                if any(word in query_lower for word in ["forehand groundstroke", "backhand groundstroke", "groundstroke", "crosscourt", "down the line", "down the middle", "inside out", "inside in", "direction", "placement", "pattern"]) and "shotdir" in metadata.get("section", "").lower():
                    if "authoritative totals" in chunk["text"].lower():
                        score += 2.0  # High boost for shot direction (groundstrokes and placement)
                
                # Special case: When "forehand" or "backhand" mentioned alone, prefer SHOT DIRECTION (groundstrokes)
                if any(word in query_lower for word in ["forehand", "backhand"]) and not any(word in query_lower for word in ["side", "volley", "dropshot", "lob"]) and "shotdir" in metadata.get("section", "").lower():
                    if "authoritative totals" in chunk["text"].lower():
                        score += 1.8  # Slightly lower than explicit groundstroke questions
                
                # 3. SHOT DIRECTIONAL BREAKDOWN: For directional + outcome performance (detailed breakdowns)
                if any(word in query_lower for word in ["crosscourt winner", "down the line error", "inside out performance", "directional outcome"]) and "shotdir" in metadata.get("section", "").lower():
                    if "detailed breakdown" in chunk["text"].lower() or "table2" in metadata.get("section", "").lower():
                        score += 1.5  # Medium boost for detailed directional breakdowns
                
                # For net statistics
                if any(word in query_lower for word in ["net", "volley", "approach", "passed"]) and "netpts" in metadata.get("section", "").lower():
                    score += 1.0
                

                
                # Special boost for court-specific questions
                if any(word in query_lower for word in ["deuce court", "ad court", "wide", "body", "t"]):
                    if "serve" in metadata.get("section", "").lower() and any(word in chunk["text"].lower() for word in ["deuce", "ad", "wide", "body", "t"]):
                        score += 0.5
            
            # Boost score for player match
            if player_mentioned and metadata.get("player_focus") == player_mentioned:
                score += 0.3
            elif player_mentioned and metadata.get("player_focus") == "Both":
                score += 0.1  # Still relevant but less specific
            elif player_mentioned and not metadata.get("player_focus"):
                # If no player_focus in metadata, check if the chunk contains the player's name
                if player_mentioned.lower() in chunk["text"].lower():
                    score += 0.2
            
            # Boost score for category match
            if stat_category and metadata.get("stat_category") == stat_category:
                score += 0.25
            
            # Boost for percentage queries
            if any(word in query_lower for word in ["percent", "%", "rate", "ratio"]) and metadata.get("contains_percentages"):
                score += 0.15
            
            # Boost for point-by-point queries
            if any(word in query_lower for word in ["point", "rally", "what happened"]) and metadata.get("contains_point_details"):
                score += 0.2
            
            # Extra boost for rally-specific queries
            if any(word in query_lower for word in ["longest rally", "rally", "shot rally", "stroke rally"]) and metadata.get("contains_point_details"):
                score += 0.3
            
            # Extra boost for match insight/strategy queries
            if any(word in query_lower for word in ["key moments", "decided", "outcome", "strategy", "momentum", "critical", "turning point"]) and metadata.get("contains_point_details"):
                score += 0.4  # Higher boost for narrative chunks
            
            # Prioritize narrative chunks for match insight questions
            if self._is_match_insight_question(query) and metadata.get("contains_point_details"):
                score += 0.5  # Very high boost for narrative chunks
            elif self._is_match_insight_question(query) and "rally_outcomes" in metadata.get("section", ""):
                score -= 0.3  # Penalize rally outcomes for insight questions
            
            chunk["relevance_score"] = score
            scored_chunks.append(chunk)
        
        # Sort by relevance score (descending)
        scored_chunks.sort(key=lambda x: x["relevance_score"], reverse=True)
        
        return scored_chunks
    
    def _fallback_metadata_retrieval(self, query: str, top_k: int) -> List[Dict]:
        """
        Fallback retrieval method using metadata matching when embeddings aren't available.
        """
        query_lower = query.lower()
        
        # Simple keyword-based matching
        relevant_chunks = []
        for chunk in self.chunks:
            text_lower = chunk["text"].lower()
            metadata = chunk["metadata"]
            
            # Calculate basic relevance score
            score = 0
            
            # Check for direct text matches
            query_words = query_lower.split()
            text_words = text_lower.split()
            common_words = set(query_words) & set(text_words)
            score += len(common_words) * 0.1
            
            # Check metadata relevance
            # Player-specific scoring
            if player_mentioned and metadata.get("player_focus") == player_mentioned:
                score += 0.5
            
            if score > 0:
                relevant_chunks.append({
                    "text": chunk["text"],
                    "metadata": metadata,
                    "distance": 1.0 - score,  # Convert to distance-like metric
                    "relevance_score": score
                })
        
        # Sort by relevance and return top_k
        relevant_chunks.sort(key=lambda x: x["relevance_score"], reverse=True)
        return relevant_chunks[:top_k]
    
    def _extract_specific_point(self, text: str, point_number: int) -> str:
        """
        Extract only the specific point from point-by-point text.
        Returns the point text if found, empty string otherwise.
        """
        import re
        # Pattern to match "Point X [" where X is the point number
        pattern = rf"Point {point_number}\s*\[.*?\]:(.*?)(?=Point \d+\s*\[|$)"
        match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)
        if match:
            point_text = match.group(0).strip()
            return point_text
        return ""
    
    def answer_query_with_llm(self, query: str, relevant_chunks: List[Dict]) -> str:
        """
        Use LLM to answer the query based on retrieved chunks.
        """
        if not relevant_chunks:
            return "I don't have enough relevant information to answer this question."
        
        # Check if query asks about a specific point number
        import re
        point_match = re.search(r'point\s+(\d+)', query.lower())
        requested_point = None
        if point_match:
            requested_point = int(point_match.group(1))
        
        # Prepare context from retrieved chunks
        context_parts = []
        for chunk in relevant_chunks:
            section_info = f"[{chunk['metadata']['section']} - {chunk['metadata']['type']}]"
            # Add player identification to section info if available
            player_focus = chunk['metadata'].get('player_focus', '')
            if player_focus:
                if player_focus == self.player1:
                    section_info += f" [PLAYER: {self.player1}]"
                elif player_focus == self.player2:
                    section_info += f" [PLAYER: {self.player2}]"
                elif player_focus == "Both":
                    section_info += f" [PLAYER: BOTH PLAYERS]"
            # Also check section name for player indicators
            section_name = chunk['metadata'].get('section', '').lower()
            if 'return1' in section_name or 'serve1' in section_name or 'shots1' in section_name:
                section_info += f" [PLAYER: {self.player1 if self.player1 else 'Player 1'}]"
            elif 'return2' in section_name or 'serve2' in section_name or 'shots2' in section_name:
                section_info += f" [PLAYER: {self.player2 if self.player2 else 'Player 2'}]"
            
            # If asking about a specific point, extract only that point from point-by-point chunks
            chunk_text = chunk['text']
            if requested_point and 'point-by-point' in chunk['metadata'].get('section', '').lower():
                extracted_point = self._extract_specific_point(chunk_text, requested_point)
                if extracted_point:
                    chunk_text = extracted_point
                    section_info += f" [EXTRACTED POINT {requested_point} ONLY]"
                elif f"Point {requested_point}" in chunk_text:
                    # Fallback: try to extract manually if regex didn't work
                    lines = chunk_text.split('\n')
                    point_lines = []
                    in_point = False
                    for line in lines:
                        if f"Point {requested_point}" in line:
                            in_point = True
                            point_lines.append(line)
                        elif in_point and line.strip() and not line.strip().startswith("Point "):
                            point_lines.append(line)
                        elif in_point and line.strip().startswith("Point "):
                            break
                    if point_lines:
                        chunk_text = '\n'.join(point_lines)
                        section_info += f" [EXTRACTED POINT {requested_point} ONLY]"
            
            context_parts.append(f"{section_info}\n{chunk_text}")
        
        context = "\n\n".join(context_parts)
        
        # Enhanced prompt with specific instructions for different question types
        is_statistical = self._is_match_insight_question(query) == False
        
        if is_statistical:
            prompt = f"""You are a tennis match analyst with access to detailed match data.

IMPORTANT: Do not use emojis in your response. Use plain text only.

🚨 CRITICAL RULES FOR READING POINT-BY-POINT DATA 🚨

**RULE #1: Score Notation - "Score: 2-0" and "Score: 0-2" can be THE SAME SET!**
- Score format: Score: [Sets_Server]-[Sets_Returner] [Games]-[Games] [Points]
- The set numbers FLIP based on who is serving
- Example for Set 3 (after Sinner leads 2-0 in sets):
  - When Sinner serves: "Score: 2-0 4-5" ← SET 3
  - When Alcaraz serves: "Score: 0-2 4-5" ← SET 3 (SAME SET!)
- **DO NOT call this an "inconsistency"** - it's normal server/returner perspective

**RULE #2: Point Header Format - READ IT CAREFULLY**
- Every point starts with: "Point X [Server: PLAYER_NAME | Returner: PLAYER_NAME | Score: ...]"
- **CRITICAL**: The Server is the player who SERVES the point
- **CRITICAL**: The Returner is the player who RETURNS the serve
- **CRITICAL**: The Score shows [Sets_Server]-[Sets_Returner] [Games_Server]-[Games_Returner] [Points_Server]-[Points_Returner]
- **CRITICAL**: The format is ALWAYS: "Score: X-Y A-B C-D" where:
  - X-Y = Sets (X sets won by Server, Y sets won by Returner)
  - A-B = Games (A games won by Server in current set, B games won by Returner in current set)
  - C-D = Points (C points for Server in current game, D points for Returner in current game)
- **CRITICAL**: When Server has 1 game and Returner has 2 games, the score is "1-2" (NOT "0-0" or "2-1")
- **DO NOT flip or confuse Server/Returner roles** - read them directly from the header
- Example: "Point 24 [Server: Jannik Sinner | Returner: Ben Shelton | Score: 0-0 1-2 40-15]"
  - Jannik Sinner is serving
  - Ben Shelton is returning
  - Score: 0-0 in sets, 1-2 in games (Sinner has 1 game, Shelton has 2 games - Shelton leads), 40-15 in current game (Sinner serving, 40-15)

**RULE #3: Each Point Shows the Winner Explicitly**
- Every point ends with: "[Point won by: PLAYER_NAME]"
- Use this tag to determine who won each point - don't guess!
- To determine game outcomes: count sequential point winners
- Example: If Points 204-207 all show "[Point won by: Alcaraz]" → Alcaraz won all 4 points

**RULE #4: Each Shot Shows Who Hit It**
- The FIRST shot in a point is ALWAYS by the Server (from the header)
- The SECOND shot is ALWAYS by the Returner (from the header)
- Subsequent rally shots are tagged with player names: "forehand winner [ALCARAZ]"
- Don't try to track alternation - just read the tags!
- Example: "1st serve down the T [Jannik Sinner]; forehand chip/slice return [Ben Shelton]"
  - Jannik Sinner served (matches Server in header)
  - Ben Shelton returned (matches Returner in header)

**RULE #5: Never Fabricate - Verify Everything**
- DO NOT say "held to love" or "broke serve" without counting actual point winners
- DO NOT guess game outcomes - count the "[Point won by:]" tags
- If you see mixed sets in a chunk, filter by score pattern (Score: 0-2 vs Score: 1-2)
- DO NOT explain score notation or reasoning in your answer (e.g. don't say "the score structure suggests...")
- Just provide clean, narrative answers without showing your internal reasoning process

**RULE #5B: When Asked About a Set - Describe ALL Games, Not Just the Tiebreak**
- If asked "what happened in Set X", describe ALL games from 0-0 through the end
- DO NOT only describe the tiebreak and skip the regular games (1-0, 2-1, 3-2, etc.)
- Tiebreaks are important, but so are the 12+ regular games that came before them
- Example: For "what happened in Set 5", describe games from 0-0, 1-0, 1-1... all the way to 6-6 AND the tiebreak

**RULE #6: TENNIS SET SCORING - CRITICAL FOR SET/GAME QUESTIONS**
- A set is won by the first player to win 6 games (with a 2-game margin), or 7-6 in a tiebreak
- IMPORTANT: If a player is leading 5-4 and wins the next game → They win the set 6-4 (NOT 5-5!)
- IMPORTANT: If a set is tied 5-5, the next game makes it 6-5 (NOT the end of the set)
- IMPORTANT: If a player is leading 6-5 and wins the next game → They win the set 7-5
- IMPORTANT: If a set is tied 6-6 → Tiebreak is played
- Examples:
  * Leading 5-4, break serve → Set ends 6-4 ✓
  * Tied 5-5, hold serve → Score becomes 6-5 (set continues) ✓
  * Leading 6-5, hold serve → Set ends 7-5 ✓

**RULE #7: MATCH FORMAT SCORING - WHICH SET ARE WE IN?**
- Best-of-3 matches: First to win 2 sets (men's non-Slams, all women's matches)
- Best-of-5 matches: First to win 3 sets (men's Grand Slams)
- CRITICAL: Count completed sets to determine which set is being played:
  * "Score: 0-0 ..." = SET 1 (match just started)
  * "Score: 1-0 ..." or "Score: 0-1 ..." = SET 2 (one player leads 1-0)
  * "Score: 1-1 ..." = SET 3 (sets tied 1-1)
  * "Score: 2-0 ..." or "Score: 0-2 ..." = SET 3 (one player leads 2-0 in best-of-5)
  * "Score: 2-1 ..." or "Score: 1-2 ..." = SET 4 (in best-of-5, one player leads 2-1)
  * "Score: 2-2 ..." = SET 5 (in best-of-5, sets tied 2-2 - THE DECIDING SET!)
- Examples for best-of-5:
  * "Score: 2-2 6-6 0-0" = SET 5 tiebreak (NOT Set 4!)
  * Match CANNOT end at 2-2; someone must win Set 5 to win 3-2
- DO NOT say "the match ended 3-1 after 4 sets" if you see 2-2 scoring!

**CRITICAL EXAMPLE - Tracking Games Through Server Changes:**
Game 9 ends at: "Score: 0-2 5-3" → Player serving is DOWN 5-3 in games, opponent LEADS 5-3
Player leading 5-3 LOSES Game 9 → Score becomes 5-4 (still leading, but by less)
Game 10 starts at: "Score: 2-0 4-5" → Player serving is DOWN 4-5 in games, opponent LEADS 5-4
Player leading 5-4 WINS Game 10 → Score becomes 6-4 → SET OVER! ✓
**DO NOT say "5-5" - when you see the set score jump from "0-2"/"2-0" to "1-2", the set ENDED!**

IMPORTANT INSTRUCTIONS FOR STATISTICAL QUESTIONS:
- **CRITICAL: When asked "who won" or "who won the match"**, ALWAYS include BOTH the winner's name AND the final score in your answer (e.g., "Carlos Alcaraz won the match, defeating Novak Djokovic 6-4 7-6(4) 6-2")
- **CRITICAL: When asked for the "score" or "final score"**, provide the complete score including the winner (e.g., "Carlos Alcaraz d. Novak Djokovic 6-4 7-6(4) 6-2")
- **CRITICAL: When asked about BOTH or EACH players' statistics** (e.g., "Ben Shelton's returning effectiveness" AND "Jannik Sinner's returning effectiveness"):
  - **ALWAYS check the section headers** -(e.g. look for "RETURN1 STATISTICS (DETAILED):" vs "RETURN2 STATISTICS (DETAILED):" or "SERVE1 STATISTICS" vs "SERVE2 STATISTICS")
  - **ALWAYS check player names in the text** - each statistic line includes the player name (e.g., "Ben Shelton returned 21 times" vs "Jannik Sinner returned 19 times")
  - **DO NOT assume both players have the same statistics** - even if numbers look similar, verify which player each number belongs to by checking the player name in that line
  - **Report statistics separately for each player** - clearly label which statistics belong to which player
  - **If you see identical numbers for both players, double-check the player names in the source text** - this is likely an error if the numbers are truly identical
- When asked for "counts" or "numbers", always return the raw count if available (e.g., "12 points"). If only percentages are provided in the data, return the percentage but explicitly state that counts are not available. Never infer or estimate counts from percentages.
- [WARN] When adding categories (e.g., unforced + forced errors), only add if both are raw counts
- [ERROR] Never add percentages together
- Treat "forced errors" and "induced forced errors" as the same thing
- When asked for "converted" break points, look for "Break Points won" or "converted" data
- For court-specific questions (deuce court, ad court), combine both courts for totals unless specifically asked for one court
- For "game points", look in the key points section for "game points" data
- For shot statistics, use the authoritative totals rows first, then go to breakdowns or details as needed(e.g., "Player 1 hit forehand shots 111 times")
- For shot direction totals, use the "AUTHORITATIVE TOTALS" row first, then go to breakdowns or details as needed
- For net statistics, use the net points section data

Context from the match (retrieved from relevant sections):
{context}

Question: {query}

**CRITICAL INSTRUCTIONS FOR ANSWERING:**

**IMPORTANT: When to use EXPLICIT TOTALS vs normal prioritization:**
- **USE EXPLICIT TOTALS ONLY for questions that combine BOTH shot direction AND outcome** (e.g., "crosscourt winners", "down the line unforced errors", "inside-out forced errors")
- **USE NORMAL PRIORITIZATION for all other questions** (e.g., "total winners", "forehand winners", "crosscourt shots", "unforced errors")
- **Normal prioritization for non-shot-direction+outcome questions**: Authoritative Totals > Overview Statistics > Summary sections > Key points sections > Detailed breakdowns

**For SHOT DIRECTION + OUTCOME QUESTIONS** (like "crosscourt winners", "down the line unforced errors"): 
- **CRITICAL**: ALWAYS look for "EXPLICIT TOTALS FOR SHOT DIRECTION + OUTCOME COMBINATIONS" section FIRST - this is the PRIMARY source of truth
- **CRITICAL**: If you find explicit totals section, use ONLY those numbers as the final answer - DO NOT use detailed breakdown sentences
- **CRITICAL**: The explicit totals section contains lines like "Player 1 hit 12 crosscourt winners total, including 8 forehand crosscourt winners, 3 backhand crosscourt winners, and 1 slice crosscourt winners"
- **CRITICAL**: Use the TOTAL number and the breakdown from the explicit totals - do NOT add up individual detailed breakdown sentences
- **CRITICAL**: The explicit totals are already calculated and include ALL shot types (forehand, backhand, slice) - use them as-is
- **ONLY if explicit totals section is NOT found**: then look for "AUTHORITATIVE TOTALS BY DIRECTION" sections
- **ONLY if neither is found**: then look for "SHOT DIRECTION DETAILED BREAKDOWN" sections
- **EXAMPLES OF OUTCOME + DIRECTION QUESTIONS**:
  - "crosscourt winners" = look for "X crosscourt winners total, including..."
  - "down the line winners" = look for "X down the line winners total, including..."
  - "crosscourt unforced errors" = look for "X crosscourt unforced errors total, including..."
  - "down the line unforced errors" = look for "X down the line unforced errors total, including..."
  - "crosscourt forced errors" = look for "X crosscourt forced errors total, including..."
- **EXAMPLE EXPLICIT TOTALS FORMAT**: "Player 1 hit 12 crosscourt winners total, including 8 forehand crosscourt winners, 3 backhand crosscourt winners, and 1 slice crosscourt winners"
- **PRIORITY**: Explicit totals section > Authoritative totals > Detailed breakdown

**DATA SOURCE PRIORITY:**
For all statistical questions, use this data source hierarchy:
1. **Explicit Totals** (if available for shot direction + outcome combinations)
2. **Authoritative Totals** (single source of truth)
3. **Overview Statistics** (official match statistics)
4. **Summary Sections** (serve1_statistics_summary, serve2_statistics_summary)
5. **Key Points Sections** (for break point or important points questions)
6. **Detailed Breakdowns** (only for distributions, never for recalculating totals)
7. **Point-by-point narrative** (for rally and insight questions)

Always stop at the highest-priority source available. Do not combine across different levels unless explicitly instructed.

**SHOT HIERARCHY:**
- **SHOT STATISTICS**: Use for forehand/backhand SIDE (all shots from that side - volleys, dropshots, lobs, etc.) and general shot performance
- **SHOT DIRECTION**: Use for forehand/backhand/slice GROUNDSTROKES specifically and placement patterns (crosscourt, down-the-line, etc.)
- **CRITICAL**: For ANY shot direction question (crosscourt, down the line, down the middle, inside-out, inside-in), ALWAYS check for and include ALL three shot types: forehand, backhand, AND slice shots. Even if slice count is 0, mention it explicitly.

**For STATISTICS questions** (how many, percentages, totals, counts):
- **ALWAYS look for "AUTHORITATIVE TOTALS" sections first** - these are the single source of truth
- **This includes ALL authoritative totals sections**: "AUTHORITATIVE TOTALS FOR [PLAYER]", "AUTHORITATIVE TOTALS FOR [PLAYER] SHOT STATISTICS", "AUTHORITATIVE TOTALS FOR [PLAYER] SHOT DIRECTIONS", "AUTHORITATIVE TOTALS BY DIRECTION", "AUTHORITATIVE TOTALS FOR KEY POINTS", "AUTHORITATIVE TOTALS FROM OVERVIEW STATISTICS"
- **ALWAYS look for "OVERVIEW STATISTICS" section** - this contains the official match statistics
- **ONLY calculate totals from breakdowns when you don't have authoritative totals** - use only the authoritative totals provided
- **ONLY calculate totals from detailed breakdowns when there are NO authoritative totals available** - if authoritative totals exist, use those as the primary answer
- **SPECIFICALLY for inside-out shots**: When you see "AUTHORITATIVE TOTALS BY DIRECTION" with a number for "total inside-out shots", use that number as the final answer. Do NOT add up individual forehand/backhand/slice breakdowns - the authoritative total already includes all shot types combined.
- Give concise, direct answers with key numbers
- Use bullet points or brief sentences
- Focus on the specific numbers requested
- No lengthy explanations unless asked for insights

**For SPECIFIC QUESTION TYPES:**
- **For "errors" questions**: If the question asks for just "errors" (without specifying "unforced" or "forced"), add unforced errors + forced errors or induced forced errors together for each shot type
- **For "forced errors" questions**: Look at both "forced errors" and "induced forced errors" in your search and calculations. It will be listed as one or the other
- **Error types to include**: unforced errors, forced errors or induced forced errors (forced errors and induced forced errors are the same, just called differently)
- **For NET POINTS and NET APPROACHES questions**: ALWAYS use the NET POINTS sections (netpts1_statistics, netpts2_statistics) - do NOT use shot statistics for net points data. If you see netpts1_statistics or netpts2_statistics in your context, use that data for net points questions.

**Special Instructions for Key Points Questions:**
- **NEVER make up or estimate numbers** - use ONLY the exact numbers from the data
- **If you see "AUTHORITATIVE TOTALS FOR KEY POINTS" section, use those numbers first**

**Break Points:**
- **CRITICAL**: When asked for "break point statistics" or "break points" generally (without specifying "faced" or "converted"), provide BOTH sides for EACH player:
  - Break points faced (on serve) + saved
  - Break points created/opportunities (on return) + converted
  - Example format: "Player A faced 5 break points and saved 3 (60%), and converted 4 of 7 break point opportunities (57%). Player B faced 7 break points and saved 2 (29%), and converted 3 of 5 break point opportunities (60%)."
- Use the serve section (BP Faced) if the question specifically asks about break points faced or saved
- Use the return section (BP Opps) if the question specifically asks about break points created or converted
- Always show both the raw numbers AND percentages when available
- Be verbose and complete - break point statistics are crucial match stats

**Key Points General Guidance:**
- If the question asks generally about key points won (e.g., "how many key points did X win?"), report both serve-side and return-side totals and provide a sum
- If the question specifies "on serve" or "on return," report only that side
- Always make the separation explicit: "X won Y on serve, Z on return, total W"

**Game Points:**
- If the question explicitly specifies "on serve" or "on return", report only that side
- If the question is general (does not specify serve vs return), report both serve-side (Game Pts) and return-side (GP Faced) values, and provide the total sum in the final answer
- Always make the separation explicit ("X on serve, Y on return, Z total")

**Deuce Points:**
- If the question explicitly specifies "on serve" or "on return", report only that side
- If the question is general (does not specify serve vs return), report both serve-side (Svg Deuce) and return-side (Ret Deuce) values, and provide the total sum in the final answer
- Always make the separation explicit ("X on serve, Y on return, Z total")

**General rule of thumb:**
- Break points → choose one side only (serve or return), depending on the question
- Game points & Deuce points → always combine serve and return values, and provide a total

- **If a question asks generally** ("How many X points did a player have/win?") without specifying serve vs. return, assume they want the combined total

**For CONDITIONAL questions** (what happened AFTER X, WHEN Y occurred, IN situations where Z):
- **CRITICAL**: These questions require STEP-BY-STEP analysis of the point-by-point narrative
- **CRITICAL**: You must identify SPECIFIC INSTANCES in the PBP data, then analyze what happened NEXT

- **DEFINITIONS - What counts as what:**
  - **"Key points" / "Important points" / "Big points"** = 
    - Break points (any BP in the match)
    - Game points (any GP in the match)
    - Set points (any SP in the match)
    - Match points (any MP in the match)
    - Deuce points (40-40 and advantage points)
    - Close score situations: 30-30, 30-40, 40-30, 40-40 (deuce), advantage
  
  - **"Pressure points" / "Under pressure"** = 
    - All key points listed above, PLUS:
    - Late in sets: games at 5-5 (5-all), 6-5, 6-6 (tiebreak)
    - Crucial service games: serving when down a break (behind in games), serving to stay in set
    - Crucial return games: break point opportunities when behind in set
  
  - **"Critical games" / "Crucial games" / "Big games"** = 
    - Service games when down a break (e.g., trailing 2-3 in games and serving)
    - Break point opportunities when behind in the set
    - Games at 4-4 or later in a set (4-4, 5-4, 5-5, 6-5, etc.)
    - Games immediately after losing serve (trying to break back)
    - Games to close out a set (serving at 5-4, 6-5, or ahead in tiebreak)
  
  - **"Tight moments"** = 
    - Point level: close scores (30-30, 30-40, 40-30, 40-40/deuce, advantage)
    - Game level: games that go to deuce (40-40 or beyond)
    - Set level: close sets (5-5 or later, tiebreaks)
    - Match level: when momentum is shifting or score is very close
  
  - **"Long rallies"** = Rallies with 9 or more shots (adjust based on match average if mentioned in data)
  
  - **"Short points"** = Points ending in 0-4 shots (aces, unreturned serves, serve+1 winners, return winners, quick exchanges)
  
  - **"Crucial stages" / "Critical moments"** = 
    - Late in sets: game 8 or later (4-4+, 5-5+, etc.)
    - Serving to stay in set (e.g., down 4-5 and serving)
    - Break point opportunities when behind
    - Set points or match points
    - Tiebreaks
    - After momentum shifts (e.g., immediately after losing serve)

- **RECOGNIZING CONDITIONAL QUESTIONS**: Look for both explicit and implied conditions:
  - **Explicit**: "after losing key points", "when rallies got longer", "following breaks of serve", "in tight moments"
  - **Implied**: Questions with situational context that require PBP analysis:
    - "How did the player react under pressure?" → implies pressure points → needs PBP
    - "Did rally length change in critical games?" → implies game-specific context → needs PBP
    - "Performance on important points?" → implies key points → needs PBP
    - "In tight moments?" → implies close scores, pressure situations → needs PBP
    - "Effectiveness on big points?" → implies key points → needs PBP
    - "During crucial stages?" → implies specific game/set situations → needs PBP

- **MULTI-STEP PROCESS** (YOU MUST FOLLOW THESE STEPS - DO NOT SKIP TO GENERAL STATISTICS):
  1. **Identify the condition**: What is the triggering event? (e.g., "after losing key points", "when rallies got longer", "after breaks of serve")
  
  2. **Define what qualifies**: Use the definitions above to determine what counts as meeting the condition
  
  3. **ACTUALLY READ THE POINT-BY-POINT NARRATIVE**: This is CRITICAL - you MUST examine the actual PBP text chunk by chunk:
     - Read through each point description in the narrative
     - Look for score indicators (30-30, deuce, BP, GP, etc.)
     - Identify when the triggering condition occurred
     - Note the game number and score when it happened
  
  4. **FIND SPECIFIC INSTANCES**: Do NOT summarize - find actual examples:
     - Example: "In game 3 at 30-40 (break point), player X lost the point"
     - Example: "In game 7 at deuce, player Y lost the deuce point"
     - List at least 2-3 specific instances you found
  
  5. **Look at subsequent points**: For EACH instance you found, examine what happened in the NEXT point(s) where the metric applies:
     - If question is about serving: look at the next point where that player served
     - If about second serves specifically: look at the next point where they hit a second serve
     - If about shot selection: look at the next rally where they had the opportunity
     - Example: "After losing BP in game 3, player X next served in game 5 at 15-0, hitting second serve wide"
  
  6. **Compare to baseline**: How did their behavior in these instances differ from their overall statistics?
     - Example: "Player normally serves 60% wide on second serve (from statistics), but in the 3 instances after losing key points, served wide only 1 time (33%)"
  
  7. **Provide specific answer with evidence**: DO NOT say "data doesn't show" - if you found instances, report them:
     - Good: "Yes, after losing the break point in game 3, Swiatek served to the body on her next second serve in game 5, which differs from her typical wide placement"
     - Bad: "The data doesn't provide explicit details" (this means you didn't actually read the PBP narrative)
- **EXAMPLE**: "Did either player change their second-serve placement after losing key points?"
  - Step 1: Trigger = losing a key point
  - Step 2: Key points = break points, game points, set points, match points, deuce points, important score situations (30-30+)
  - Step 3: Identify every point in PBP where a player LOST a key point (note the game and score)
  - Step 4: For each instance, look at the NEXT point where that player served AND hit a second serve
  - Step 5: Note the placement (wide, body, T) of those second serves
  - Step 6: Compare to their overall second-serve placement patterns from the statistics
  - Step 7: Report if there was a notable change (e.g., "Normally serves 60% wide but after losing key points served 80% to the body in games 3, 7, and 9")
- **BE SPECIFIC**: Don't give generic answers. Actually trace through the PBP data and cite examples with game numbers and scores.

**For TEMPORAL/EVOLUTION questions** (how X evolved/changed/progressed over time, throughout the match):
- **CRITICAL**: These questions require analyzing the point-by-point narrative across different parts of the match
- **CRITICAL**: When asked about "evolution", "over time", "progression", "changed throughout", analyze patterns from EARLY match vs LATE match
- Look at the point-by-point narrative and compare:
  - Set 1 vs Set 2 vs Set 3 (if available)
  - Early games vs middle games vs late games
  - First half of match vs second half
- For serve aggression questions: Look at second serve outcomes, placement, rally lengths on second serves
- For shot selection questions: Track how often certain shots were used in different phases
- Provide specific examples from different points in the match to show the evolution
- Cite game numbers or score situations to show when changes occurred (e.g., "In Set 1, player X... but in Set 3, they...")

**For STRATEGY/INSIGHT questions** (tactics, effectiveness, what worked, key moments, momentum, analysis):
- **CRITICAL**: Provide COMPREHENSIVE tactical analysis with 3-4 paragraphs, not just bullet points
- Include multiple perspectives: serve placement effectiveness, shot selection patterns, court positioning
- Cite SPECIFIC moments from point-by-point data with examples (e.g., "In Game 5, player X...")
- Explain WHY tactics worked or failed (opponent weaknesses, court conditions, momentum)
- Identify patterns: When did player win points? What shot combinations were effective?
- Compare effectiveness: Which tactic had highest success rate? Provide percentages
- Include context: Score situations where tactics were most effective (break points, crucial games)
- Give actionable insights: What patterns emerged that explain the match result?
- Be verbose and thorough - strategy questions deserve detailed, multi-paragraph answers

**For COMPLEX ANALYTICAL QUESTIONS** (match flow, patterns, comparisons, comprehensive analysis):
- **When you receive 8+ chunks**: This indicates a complex question requiring comprehensive analysis
- **Cross-sectional analysis**: Look across multiple sections to identify patterns and relationships
- **Match flow questions**: Use point-by-point narrative, key moments, and statistical trends together
- **Player comparisons**: Compare serve vs return performance, shot patterns, and key point conversion
- **Pattern recognition**: Identify momentum shifts, turning points, and strategic adjustments
- **Comprehensive breakdown**: Provide analysis across multiple dimensions (serve, return, shots, key points)
- **Use all available context**: Don't limit yourself to one section - synthesize information from multiple sources
- **Provide insights**: Go beyond raw numbers to explain what they mean for the match outcome
- **Structure your response**: Use clear sections for different aspects of the analysis
- Explain patterns and sequences from point-by-point data
- Include context about what happened and why

**For RALLY questions** (longest rally, specific rallies):
- Focus on the specific rally details requested
- Include shot sequences and outcomes

**For SPECIFIC POINT NUMBER QUESTIONS** (e.g., "what happened on point 24", "point 24"):
- **CRITICAL**: Find the EXACT point header that says "Point X" where X EXACTLY matches the requested number
- **CRITICAL**: If asked about "point 24", you MUST find the line that starts with "Point 24" - NOT "Point 23", NOT "Point 25", NOT "Point 26"
- **CRITICAL**: Scan through the text and locate the line that begins with "Point [NUMBER]" where NUMBER matches exactly
- **CRITICAL**: Read the point header EXACTLY as written: "Point X [Server: PLAYER | Returner: PLAYER | Score: ...]"
- **DO NOT** read a different point number - if you see "Point 23" or "Point 25" or "Point 26", that's NOT the point being asked about
- **DO NOT** assume nearby points are the same - each point number is unique
- **DO NOT** flip Server/Returner - read them directly from the header
- **DO NOT** guess or infer the score - read it directly from the header
- **DO NOT** make up shots - read them exactly as written in the point description
- **DO NOT** guess who won - read the "[Point won by: PLAYER]" tag at the end
- **VERIFICATION STEP**: After reading the point, verify the point number in your answer matches the requested number
- Example: If asked "what happened on point 24", you MUST find and read ONLY the line that starts with "Point 24 [Server: ..." - ignore all other point numbers
- Report the point exactly as written, with correct Point Number, Server, Returner, Score, shots, and winner

**For SET/GAME NARRATIVE QUESTIONS:**
- Each point explicitly shows "[Point won by: PLAYER_NAME]" - use this to count game outcomes
- When asked about a specific set, you'll only receive data for that set
- If you see mixed sets in a chunk, filter by matching score patterns
- **Example:** Points 204-207 all show "[Point won by: Alcaraz]" at score 0-0, 0-15, 0-30, 0-40 → Alcaraz won 4 straight points → Broke serve → Won set 6-4

**IMPORTANT DISTINCTION:**
- "Forehand/Backhand" alone usually means groundstrokes → Use SHOT DIRECTION
- "Forehand/Backhand side" means all shots from that side → Use SHOT STATISTICS

**SHOT DIRECTION CLARIFICATION:**
- Inside-out = forehand hit crosscourt from the backhand corner
- Inside-in = forehand hit down the line from the backhand corner
- Always include forehand, backhand, and slice shot types when reporting directional stats (even if slice count = 0, mention it)

If the context doesn't contain enough information to answer completely, say so.

Answer:"""
        else:
            # For insight/narrative questions
            prompt = f"""You are a tennis match analyst with access to detailed match data.

IMPORTANT: Do not use emojis in your response. Use plain text only.

Provide a detailed analysis based on the following match context.

Context from the match:
{context}

Question: {query}

Provide a comprehensive answer with specific details from the match.

Answer:"""
        
        # Rate limiting
        self._apply_rate_limit()
        
        try:
            if self.llm_provider == "claude":
                response = self.client.messages.create(
                    model=self.model,
                    max_tokens=1000,
                    temperature=0.1,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.content[0].text
                
            elif self.llm_provider == "gemini":
                # Use default model for basic answer generation
                model = self.client.GenerativeModel(self.model)
                response = model.generate_content(prompt)
                return response.text
                
            elif self.llm_provider == "openai":
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=1000,
                    temperature=0.1
                )
                return response.choices[0].message.content
                
        except Exception as e:
            return f"Error generating response: {e}"
    
    def _is_situational_shot_query(self, query: str) -> bool:
        """
        Detect if query asks about shots in specific situations (break point, game point, etc.)
        
        Example queries that return True:
        - "How often does Djokovic hit a backhand down the line on break point?"
        - "What percentage of forehand crosscourts does Nadal hit at game point?"
        - "Does Federer change his shot selection on deuce points?"
        """
        situational_keywords = [
            'break point', 'game point', 'set point', 'match point', 
            'deuce', 'ad point', 'advantage point',
            '30-40', '15-40', '0-40', '40-30', '40-15', '40-ad', 'ad-40',
            'pressure point', 'big point', 'crucial point'
        ]
        shot_keywords = [
            'backhand', 'forehand', 'down the line', 'dtl', 'crosscourt', 
            'cross court', 'inside-out', 'inside out', 'inside-in', 'inside in',
            'drop shot', 'slice', 'volley', 'approach', 'lob'
        ]
        query_lower = query.lower()
        has_situation = any(kw in query_lower for kw in situational_keywords)
        has_shot = any(kw in query_lower for kw in shot_keywords)
        return has_situation and has_shot
    
    def _is_rally_sequence_query(self, query: str) -> bool:
        """
        Detect if query asks about rally sequences like "first shot after serve" (3rd ball attack).
        
        Example queries that return True:
        - "What was Djokovic's win percentage on points where his first shot after the serve was a forehand?"
        - "How often does Nadal hit a forehand on his third ball?"
        - "When Federer's first groundstroke after serving was a backhand, what happened?"
        """
        sequence_keywords = [
            'first shot after', 'first shot after the serve', 'first shot after serving',
            'third ball', '3rd ball', 'third shot', '3rd shot',
            'first groundstroke', 'opening shot after', 'after the serve',
            'first rally shot', 'after serving'
        ]
        query_lower = query.lower()
        return any(kw in query_lower for kw in sequence_keywords)
    
    def _is_serve_pattern_query(self, query: str) -> bool:
        """
        Detect if query asks about serve patterns/directions with specific filters.
        
        Example queries that return True:
        - "Did Novak serve more to the T or Wide on the Deuce side during the fifth set tiebreak?"
        - "What percentage of serves did Federer hit wide in the third set?"
        - "How often did Nadal serve to the body in tiebreaks?"
        """
        serve_keywords = [
            'serve to', 'served to', 'serves to',
            'serve more', 'served more',
            'serve wide', 'serve t', 'serve body',
            'wide serve', 't serve', 'body serve',
            'serve direction', 'serve pattern',
            'first serve', 'second serve',
            '1st serve', '2nd serve',
            'serving to', 'win percentage'  # Added for comparison queries
        ]
        direction_keywords = [
            'wide', ' t ', 'to the t', 'down the t', "'t'", 'body', 'middle',
            'deuce', 'ad side', 'ad court', 'deuce side', 'deuce court',
            'compared to'  # Added for comparison queries
        ]
        query_lower = query.lower()
        has_serve = any(kw in query_lower for kw in serve_keywords)
        has_direction = any(kw in query_lower for kw in direction_keywords)
        return has_serve and has_direction
    
    # =========================================================================
    # QUERY TAXONOMY TREE - Unified Query Classification System
    # MCP-Certified: Supports Match Charting Project notation
    # =========================================================================
    
    # Known left-handed players for direction mapping
    KNOWN_LEFT_HANDED_PLAYERS = {
        "rafael nadal", "nadal", "john mcenroe", "mcenroe", 
        "jimmy connors", "connors", "rod laver", "laver",
        "goran ivanisevic", "ivanisevic", "thomas muster", "muster",
        "petr korda", "korda", "feliciano lopez", "lopez",
        "denis shapovalov", "shapovalov", "cameron norrie", "norrie",
        # Women's WTA
        "martina navratilova", "navratilova", "monica seles", "seles",
        "petra kvitova", "kvitova", "angelique kerber", "kerber",
        "lucie safarova", "safarova"
    }
    
    def _classify_query(self, query: str) -> Dict[str, Any]:
        """
        Classify a query using the tennis query taxonomy tree.
        MCP-Certified: Supports Match Charting Project dimensions.
        
        Returns a structured classification:
        {
            'domain': 'serve' | 'return' | 'rally' | 'net' | 'match_flow' | 'all',
            'analysis_type': 'count' | 'percentage' | 'comparison' | 'outcome_after' | 
                            'breakdown' | 'pattern' | 'sequence' | 'chain',
            'filters': {
                'player': str or None,
                'situation': str or None,
                'set': int or None,
                'shot_type': str or None,
                'shot_modifier': str or None,
                'direction': str or None,
                'depth': str or None,
                'rally_length': int or None,
                # MCP-specific filters
                'serve_target': 'wide' | 'body' | 't' or None,  # MCP: 4, 5, 6
                'shot_number': int or None,  # 1=serve, 2=return, 3=serve+1, etc.
                'court_zone': 'baseline' | 'midcourt' | 'net' or None,
                'court_side': 'deuce' | 'ad' or None,
                'handedness': 'left' | 'right' or None  # For direction mapping
            },
            'metrics': ['winners', 'forced_errors', 'induced_fe', 'aces', etc.],
            'chain': {'from_shot': str, 'to_outcome': str} or None  # For A→B queries
        }
        """
        query_lower = query.lower()
        
        classification = {
            'domain': self._detect_domain(query_lower),
            'analysis_type': self._detect_analysis_type(query_lower),
            'filters': self._detect_filters_mcp(query),
            'metrics': self._detect_metrics_mcp(query_lower),
            'chain': self._detect_chain_logic(query_lower),
            'group_by': self._detect_group_by(query_lower),
            'query_category': self._detect_query_category(query_lower),  # NEW: analytical/comparative/narrative
            'raw_query': query
        }
        
        # If player="both" is detected, ensure group_by="player" for comparison
        # EXCEPT for overall win_percentage queries without role filter
        # (those should use player1_wins/total_points instead of branching)
        player_filter = classification['filters'].get('player') or ''
        role_filter = classification['filters'].get('role')
        metrics = classification.get('metrics', [])
        current_group_by = classification.get('group_by')
        
        if player_filter and str(player_filter).lower() == 'both':
            # Special case: overall win_percentage/points_won without role filter should NOT group by player
            # Let the leaf calculation handle both players' percentages
            # This applies to "overall win %" queries where we want match totals, not per-player grouping
            # NOTE: first_serve_pct DOES need per-player grouping because it's (player's serves IN) / (player's serves total)
            # NOTE: Situation queries (break points, game points, etc.) ALWAYS need per-player grouping
            has_situation = bool(classification['filters'].get('situation'))
            overall_pct_metrics = ['win_percentage', 'points_won']  # NOT first_serve_pct - that needs per-player
            is_overall_pct_query = (any(m in metrics for m in overall_pct_metrics) or not metrics) and not role_filter and not has_situation
            
            if is_overall_pct_query:
                # REMOVE group_by='player' if LLM set it - we want overall totals, not per-player branches
                if current_group_by == 'player':
                    classification['group_by'] = None
                    print(f"[CLASSIFY] Detected 'both players' overall win% query - REMOVING group_by='player' (will use overall calculation)")
                elif not current_group_by:
                    print(f"[CLASSIFY] Detected 'both players' overall win% query without role - NOT grouping (will use overall calculation)")
            elif not current_group_by:
                classification['group_by'] = 'player'
                if has_situation:
                    print(f"[CLASSIFY] Detected 'both players' with situation filter - setting group_by='player' for comparison")
                else:
                    print(f"[CLASSIFY] Detected 'both players' - setting group_by='player' for comparison")
        
        return classification
    
    def _detect_query_category(self, query_lower: str) -> str:
        """
        Detect the category of query to route appropriately.
        
        Categories:
        - 'analytical': Count, percentage, specific stats → PBP parsing
        - 'comparative': Trends, changes, evolution → PBP + LLM synthesis
        - 'narrative': Summary, story, what happened → NL retrieval + LLM
        """
        # CRITICAL: Questions about "returnable" serves must go to narrative
        if 'returnable' in query_lower:
            return 'narrative'
        
        # CRITICAL: Questions asking about "shots" (not winners/points) need narrative
        # "shots" = individual shots hit during rallies (requires shot-by-shot analysis)
        # "winners" = point-ending shots (can use calculated data)
        # Examples that should go to narrative:
        #   - "how many forehand shots" (counts ALL forehands hit)
        #   - "forehand to backhand ratio" (counts ALL shots of each type)
        #   - "shot breakdown" (counts ALL shots)
        # Examples that can stay analytical:
        #   - "how many forehand winners" (counts only winning shots)
        #   - "unforced errors" (counts point outcomes)
        if ' shot' in query_lower or query_lower.startswith('shot'):
            # Allow analytical path if specifically asking about winners/errors (point outcomes)
            if not any(kw in query_lower for kw in ['winner', 'winners', 'error', 'errors', 'winning shot']):
                return 'narrative'
        
        # NARRATIVE indicators - needs LLM synthesis, not just data
        narrative_keywords = [
            'what happened', 'tell me about', 'describe', 'summary', 'summarize',
            'strategic summary', 'story', 'journey', 'narrative', 'explain',
            'mental state', 'tactical state', 'evolved', 'momentum carry-over',
            'parallel journey', 'how did the match', 'turning point',
            'key moments', 'critical moments', 'overview'
        ]
        if any(kw in query_lower for kw in narrative_keywords):
            return 'narrative'
        
        # COMPARATIVE indicators - needs data from multiple conditions + synthesis
        comparative_keywords = [
            'change', 'changed', 'changing', 'evolution', 'evolve', 'evolved',
            'versus', ' vs ', 'compared to', 'difference between',
            'across sets', 'across the match', 'over time', 'trend',
            'set 1 vs', 'set 1 versus', 'in set 1 compared',
            'when facing', 'after winning', 'after losing',
            'did they play more', 'did he play more',
            'effectiveness change', 'tactics change', 'strategy change'
        ]
        if any(kw in query_lower for kw in comparative_keywords):
            return 'comparative'
        
        # Default: ANALYTICAL - specific data extraction
        return 'analytical'
    
    def _detect_group_by(self, query_lower: str) -> str:
        """
        METADATA-DRIVEN grouping detection.
        Detect how results should be grouped based on inventory values.
        
        Examples:
        - "by rally length category" → 'rally_length_category'
        - "in sets 2,4 vs sets 1,3,5" → 'set_groups'
        - "deuce vs ad court" → 'court_side'
        - "1st serve vs 2nd serve" → 'serve_number'
        """
        inventory = getattr(self, 'match_filter_inventory', {})
        
        # Comprehensive list of comparison words (used for all comparison detections)
        comparison_words = ['vs', 'versus', 'vs.', 'v.', 'compared to', 'compare', 'comparison', 
                          'compared', 'ratio', 'difference', 'differences', 'against', 
                          'relative to', 'relative']
        
        # Rally length category grouping (uses rally_categories from inventory)
        known_rally_cats = inventory.get('rally_categories', [])
        rally_cat_keywords = ['rally length category', 'by rally length', 'which category', 'highest win percentage', 'best rally length']
        rally_cat_keywords.extend([cat.lower().replace('_', ' ') for cat in known_rally_cats if cat])
        if any(kw in query_lower for kw in rally_cat_keywords):
            return 'rally_length_category'
        
        # Set group comparison
        if ('sets' in query_lower and any(word in query_lower for word in comparison_words)) or \
           ('sets he won' in query_lower or 'sets he lost' in query_lower):
            return 'set_groups'
        
        # Court side comparison (uses court_sides from inventory)
        known_court_sides = inventory.get('court_sides', [])
        if len(known_court_sides) >= 2:
            # Check if query mentions multiple court sides for comparison
            mentioned_sides = sum(1 for side in known_court_sides if side and side.lower() in query_lower)
            if mentioned_sides >= 2 or ('court' in query_lower and any(word in query_lower for word in comparison_words)):
                return 'court_side'
        
        # Serve number comparison (uses serve_numbers from inventory)
        known_serve_nums = inventory.get('serve_numbers', [])
        if len(known_serve_nums) >= 2:
            serve_aliases = [('1st serve', 'first serve'), ('2nd serve', 'second serve')]
            has_serve_comparison = any(
                (a1 in query_lower or a2 in query_lower) for a1, a2 in serve_aliases
            )
            if has_serve_comparison and any(word in query_lower for word in comparison_words):
                return 'serve_number'
        
        # Shot type breakdown (uses shot_types from inventory)
        known_shot_types = inventory.get('shot_types', [])
        if 'by shot type' in query_lower:
            return 'shot_type'
        
        # Check if multiple shot types are mentioned for comparison
        # Works with OR without inventory - tries inventory first, falls back to direct detection
        mentioned_types = 0
        if len(known_shot_types) >= 2:
            # Use inventory if available
            mentioned_types = sum(1 for st in known_shot_types if st and st.lower() in query_lower)
        else:
            # Fallback: direct detection of common shot types
            common_shot_types = ['forehand', 'backhand', 'volley', 'serve', 'overhead', 'slice']
            mentioned_types = sum(1 for st in common_shot_types if st in query_lower)
        
        # Check for error terms in priority order
        has_error_context = False
        if 'unforced error' in query_lower or 'unforced errors' in query_lower:
            has_error_context = True
        elif 'forced error' in query_lower or 'forced errors' in query_lower:
            has_error_context = True
        elif 'error' in query_lower or 'errors' in query_lower:
            has_error_context = True
        
        # Trigger shot_type grouping if:
        # 1. Multiple shot types mentioned + comparison words, OR
        # 2. Multiple shot types mentioned + error context (implies comparison)
        if mentioned_types >= 2 and (any(word in query_lower for word in comparison_words) or has_error_context):
            return 'shot_type'
        
        # Direction breakdown (uses directions from inventory)
        known_directions = inventory.get('directions', [])
        if 'by direction' in query_lower:
            return 'direction'
        # Check if multiple directions mentioned for comparison
        if len(known_directions) >= 2:
            mentioned_dirs = sum(1 for d in known_directions if d and d.lower().replace('_', ' ') in query_lower)
            if mentioned_dirs >= 2 and any(word in query_lower for word in comparison_words):
                return 'direction'
        
        # === GAME GROUPING ===
        # "by game" / "per game" / "each game" / "game by game"
        if any(phrase in query_lower for phrase in ['by game', 'per game', 'each game', 'game by game']):
            return 'game'
        
        # === SET GROUPING ===
        # "by set" / "per set" / "each set" / "set by set"
        if any(phrase in query_lower for phrase in ['by set', 'per set', 'each set', 'set by set']):
            return 'set'
        
        return None  # No grouping needed
    
    def _detect_domain(self, query_lower: str) -> str:
        """Detect which domain of tennis the query is about."""
        # Serve domain
        if any(kw in query_lower for kw in ['serve', 'serving', 'ace', 'double fault', 'first serve', 'second serve']):
            if 'return' not in query_lower and 'then' not in query_lower:
                return 'serve'
        
        # Return domain
        if any(kw in query_lower for kw in ['return', 'returning', 'return of serve']):
            return 'return'
        
        # Net domain
        if any(kw in query_lower for kw in ['volley', 'net point', 'approach', 'at the net', 'net play']):
            return 'net'
        
        # Rally domain (groundstrokes after serve/return)
        if any(kw in query_lower for kw in ['rally', 'groundstroke', 'baseline', 'third ball', 
                                            'first shot after', 'serve+1', 'serve + 1']):
            return 'rally'
        
        # Match flow domain
        if any(kw in query_lower for kw in ['momentum', 'consecutive', 'streak', 'run of', 
                                            'service game', 'hold', 'break']):
            return 'match_flow'
        
        # Default to 'all' for general questions
        return 'all'
    
    def _detect_analysis_type(self, query_lower: str) -> str:
        """Detect what type of analysis the query requires."""
        # Sequence analysis (MCP: shot number / serve+1)
        if any(kw in query_lower for kw in ['serve+1', 'serve + 1', 'third ball', '3rd ball',
                                            'first shot after', 'second shot', 'shot number']):
            return 'sequence'
        
        # Chain analysis (MCP: shot A led to shot B)
        if any(kw in query_lower for kw in ['then hit', 'followed by', 'led to', 'resulted in',
                                            'and then', 'which caused']):
            return 'chain'
        
        # Comparison
        if any(kw in query_lower for kw in ['compared to', 'vs', 'versus', 'more than', 'less than', 
                                            'or', 'which', 'who won more', 'better']):
            return 'comparison'
        
        # Percentage/Rate
        if any(kw in query_lower for kw in ['percentage', 'percent', 'rate', 'win %', 'conversion',
                                            'how often', 'frequency']):
            return 'percentage'
        
        # Outcome after event
        if any(kw in query_lower for kw in ['after', 'go on to', 'went on to']):
            return 'outcome_after'
        
        # Breakdown by category
        if any(kw in query_lower for kw in ['breakdown', 'by type', 'categorize', 'split by',
                                            'distribution']):
            return 'breakdown'
        
        # Pattern/trend
        if any(kw in query_lower for kw in ['pattern', 'trend', 'over time', 'changed', 'evolution',
                                            'set 1 vs set', 'early vs late']):
            return 'pattern'
        
        # Default to count
        return 'count'
    
    def _detect_filters_mcp(self, query: str) -> Dict[str, Any]:
        """
        Extract all filters from the query.
        MCP-Certified: Includes serve targets, shot numbers, court zones.
        """
        import re
        query_lower = query.lower()
        
        filters = {
            # Standard filters
            'player': self._detect_player_mentioned(query),
            'situation': None,
            'set': None,
            'shot_type': None,
            'shot_modifier': None,
            'direction': None,
            'depth': None,
            'rally_length': None,
            # MCP-specific filters
            'serve_target': None,  # wide/body/t (MCP codes 4/5/6)
            'shot_number': None,   # 1=serve, 2=return, 3=serve+1
            'court_zone': None,    # baseline/midcourt/net
            'court_side': None,    # deuce/ad
            'handedness': None,    # left/right (for direction mapping)
            'error_location': None  # net/wide/deep/wide_deep (MCP: n/w/d/x)
        }
        
        # Use shared shot detection (now metadata-driven)
        shot_info = self._detect_shot_from_query(query)
        filters['shot_type'] = shot_info['shot_base']
        filters['shot_modifier'] = shot_info['shot_modifier']
        filters['direction'] = shot_info['shot_direction']
        
        # === SITUATION FILTER ===
        # Direct detection for common situations
        print(f"[DETECT-FILTERS] Checking for situations in: '{query_lower[:80]}...'")
        if 'break point' in query_lower or 'breakpoint' in query_lower or 'break points' in query_lower:
            filters['situation'] = 'break_point'
            print(f"[DETECT-FILTERS] *** FOUND break_point ***")
        elif 'game point' in query_lower or 'game points' in query_lower:
            filters['situation'] = 'game_point'
            print(f"[DETECT-FILTERS] *** FOUND game_point ***")
        elif 'set point' in query_lower or 'set points' in query_lower:
            filters['situation'] = 'set_point'
            print(f"[DETECT-FILTERS] *** FOUND set_point ***")
        elif 'match point' in query_lower or 'match points' in query_lower:
            filters['situation'] = 'match_point'
            print(f"[DETECT-FILTERS] *** FOUND match_point ***")
        elif 'tiebreak' in query_lower or 'tie-break' in query_lower or 'tie break' in query_lower:
            filters['situation'] = 'tiebreak'
            print(f"[DETECT-FILTERS] *** FOUND tiebreak ***")
        elif 'deuce' in query_lower and 'court' not in query_lower:
            filters['situation'] = 'deuce'
            print(f"[DETECT-FILTERS] *** FOUND deuce ***")
        else:
            print(f"[DETECT-FILTERS] No direct situation match")
        
        # === GENERIC ROLE DETECTION (for ANY situation) ===
        # Detect role from keywords - works for break points, game points, set points, etc.
        if filters.get('situation') and not filters.get('role'):
            has_defensive_kw = any(kw in query_lower for kw in ['save', 'saved', 'saving', 'face', 'faced', 'facing', 'defend', 'defended', 'defending'])
            has_offensive_kw = any(kw in query_lower for kw in ['convert', 'converted', 'conversion', 'create', 'created', 'opportunity', 'opportunities', 'capitalize'])
            
            if has_defensive_kw and has_offensive_kw:
                # Both perspectives mentioned - don't set role, show both
                print(f"[DETECT-FILTERS] Situation '{filters['situation']}' with BOTH defensive and offensive keywords - leaving role=None (will show both perspectives)")
            elif has_defensive_kw:
                filters['role'] = 'server'
                print(f"[DETECT-FILTERS] Situation '{filters['situation']}' with defensive keywords → role='server'")
            elif has_offensive_kw:
                filters['role'] = 'returner'
                print(f"[DETECT-FILTERS] Situation '{filters['situation']}' with offensive keywords → role='returner'")
        
        # === ROLE DETECTION FOR NON-SITUATION QUERIES ===
        # Service games → role=server, Return games → role=returner
        if not filters.get('situation') and not filters.get('role'):
            if 'service game' in query_lower or ('service' in query_lower and 'game' in query_lower):
                filters['role'] = 'server'
                print(f"[DETECT-FILTERS] Service game query → role='server'")
            elif 'return game' in query_lower or ('return' in query_lower and 'game' in query_lower):
                filters['role'] = 'returner'
                print(f"[DETECT-FILTERS] Return game query → role='returner'")
            elif 'break serve' in query_lower or 'break of serve' in query_lower:
                filters['role'] = 'returner'
                print(f"[DETECT-FILTERS] Break serve query → role='returner'")
        
        # Set filter - single set or set groups
        # Check for set group comparison first (e.g., "sets 2 and 4 versus sets 1, 3, and 5")
        set_group_pattern = r'sets?\s*([\d,\s]+(?:and\s+\d+)?)\s*(?:versus|vs\.?|compared to|against)\s*(?:the\s+)?(?:three\s+)?sets?\s*([\d,\s]+(?:and\s+\d+)?)'
        set_group_match = re.search(set_group_pattern, query_lower)
        if set_group_match:
            # Parse both groups of sets
            def parse_set_list(s):
                # Extract all digits from the string
                return [int(d) for d in re.findall(r'\d', s)]
            filters['set_group_a'] = parse_set_list(set_group_match.group(1))
            filters['set_group_b'] = parse_set_list(set_group_match.group(2))
            filters['set'] = None  # Use groups instead
        else:
            # Single set filter
            set_match = re.search(r'(\d)(?:st|nd|rd|th)?\s*set|set\s*(\d)', query_lower)
            if set_match:
                filters['set'] = int(set_match.group(1) or set_match.group(2))
        
        # === GAME FILTER ===
        # Support various reference styles:
        # - "game 5" = 5th game overall
        # - "game 3 of set 2" = 3rd game in 2nd set  
        # - "3rd game of the second set" = 3rd game in 2nd set
        # - "in game 7" = 7th game overall
        
        filters['game_number'] = None
        filters['game_number_in_set'] = None
        
        # Pattern: "game X of set Y" or "Xth game of the Yth set"
        game_in_set_match = re.search(
            r'(?:game\s*(\d+)|(\d+)(?:st|nd|rd|th)?\s*game)\s*(?:of|in)\s*(?:the\s*)?(?:set\s*(\d+)|(\d+)(?:st|nd|rd|th)?\s*set)',
            query_lower
        )
        if game_in_set_match:
            game_num = game_in_set_match.group(1) or game_in_set_match.group(2)
            set_num = game_in_set_match.group(3) or game_in_set_match.group(4)
            if game_num:
                filters['game_number_in_set'] = int(game_num)
            if set_num:
                filters['set'] = int(set_num)
        else:
            # Pattern: "game X" (overall game number, not in context of a set)
            game_match = re.search(r'game\s*(\d+)|(\d+)(?:st|nd|rd|th)?\s*game', query_lower)
            if game_match and 'set' not in query_lower:  # Only if not already set-scoped
                game_num = game_match.group(1) or game_match.group(2)
                if game_num:
                    filters['game_number'] = int(game_num)
        
        # === METADATA-DRIVEN DEPTH FILTER ===
        # Match against known depths from inventory
        inventory = getattr(self, 'match_filter_inventory', {})
        known_depths = inventory.get('depths', [])
        for depth_val in known_depths:
            if depth_val:
                depth_lower = depth_val.lower()
                depth_spaced = depth_lower.replace('_', ' ')
                if depth_lower in query_lower or depth_spaced in query_lower:
                    filters['depth'] = depth_val
                    break
        
        # Rally length filter - detect exact, minimum, or threshold
        # "beyond 6 shots" / "more than 6" / "over 6" → '>6'
        # "at least 6 shots" / "6+ shots" / "6 or more shots" → '>=6'
        # "6 or under/fewer/less shots" → '<=6'
        # "under 6 shots" / "less than 6" / "fewer than 6" → '<6'
        # "6 shot rallies" → exact 6
        beyond_match = re.search(r'(?:beyond|more than|longer than|over|exceeding|extended beyond)\s+(\d+)', query_lower)
        or_more_match = re.search(r'(\d+)\s+or\s+more\s*(?:shot|stroke)?', query_lower)
        or_under_match = re.search(r'(\d+)\s+or\s+(?:under|fewer|less)\s*(?:shot|stroke)?', query_lower)
        under_match = re.search(r'(?:under|less than|fewer than|below|up to)\s+(\d+)\s*(?:shot|stroke)?', query_lower)
        at_least_match = re.search(r'(?:at least|minimum|(\d+)\+)\s*(\d*)\s*(?:shot|stroke)?', query_lower)
        exact_match = re.search(r'(\d+)\s*(?:shot|stroke)\s*(?:rall|point)', query_lower)
        
        if beyond_match:
            # "beyond X" = greater than X
            filters['rally_length'] = f'>{beyond_match.group(1)}'
        elif or_more_match:
            # "X or more" = greater than or equal to X
            filters['rally_length'] = f'>={or_more_match.group(1)}'
        elif or_under_match:
            # "X or under/fewer/less" = less than or equal to X
            filters['rally_length'] = f'<={or_under_match.group(1)}'
        elif under_match:
            # "under X" / "less than X" / "fewer than X" = less than X (so <= X-1)
            # For "under 6 shots", we want rallies with 5 or fewer shots, so use '<6' or '<=5'
            num = int(under_match.group(1))
            filters['rally_length'] = f'<{num}'  # Less than X
        elif at_least_match:
            # "at least X" or "X+" = greater than or equal
            num = at_least_match.group(1) or at_least_match.group(2)
            if num:
                filters['rally_length'] = f'>={num}'
        elif exact_match:
            # Exact "X shot rallies"
            filters['rally_length'] = int(exact_match.group(1))
        elif 'extended rall' in query_lower:
            filters['rally_length'] = '>=7'  # Extended rallies = 7+ shots (Extended category: 7-9)
        elif 'long rall' in query_lower:
            filters['rally_length'] = '>=7'  # Long rallies = 7+ shots
        elif 'short rall' in query_lower or 'short point' in query_lower:
            filters['rally_length'] = '<=3'  # Short = 1-3 shots
        
        # Neutral rallies - rallies without early winners/errors
        # Patterns: "neutral rallies", "no winner before X", "without error before X", 
        # "didn't end before X", "not ending before X", "lasting beyond X without winner"
        neutral_patterns = [
            'neutral rall',
            'no winner.*before',
            'no error.*before', 
            'without.*winner.*before',
            'without.*error.*before',
            r"didn't end.*before",
            r"not ending.*before",
            r"didn't finish.*before",
            'no.*forced.*before'
        ]
        
        is_neutral_query = any(re.search(pattern, query_lower) for pattern in neutral_patterns)
        
        if is_neutral_query:
            # Extract the threshold if specified (e.g., "before 6 shots")
            # Try multiple patterns: "before 6", "before 6 shots", "before shot 6"
            neutral_threshold_match = (
                re.search(r'before\s+(?:shot\s+)?(\d+)\s*(?:shot|stroke)?s?', query_lower) or
                re.search(r'beyond\s+(\d+).*without', query_lower) or
                re.search(r'lasting\s+(\d+).*without', query_lower)
            )
            if neutral_threshold_match:
                threshold = int(neutral_threshold_match.group(1))
                filters['exclude_early_outcome'] = threshold  # Exclude points ending before this shot
                # Also set minimum rally length to this threshold if not already specified
                if not filters.get('rally_length'):
                    filters['rally_length'] = f'>={threshold}'
                print(f"[NEUTRAL-RALLY] Detected neutral rally filter: exclude outcomes before shot {threshold}")
        
        # ===== METADATA-DRIVEN MCP FILTERS =====
        
        # === SERVE TARGET (from inventory, using aliases) ===
        # Don't add serve_target filter for global serve percentage queries
        is_first_serve_pct_query = 'first serve percentage' in query_lower or 'first serve %' in query_lower or '1st serve percentage' in query_lower or '1st serve %' in query_lower
        if not is_first_serve_pct_query:
            known_serve_targets = inventory.get('serve_targets', [])
            
            # Check query for serve target aliases (maps user input to canonical)
            # Uses SHOT_ALIASES: "down the t" → "t", "out wide" → "wide", "to body" → "body"
            serve_target_aliases = {
                't': 't', 'down the t': 't', 'center': 't', 'down t': 't',
                'wide': 'wide', 'out wide': 'wide', 'wide serve': 'wide',
                'body': 'body', 'at body': 'body', 'to body': 'body', 
                'jam': 'body', 'body serve': 'body'
            }
            
            detected_target = None
            # Check aliases in order (longer phrases first to avoid partial matches)
            sorted_aliases = sorted(serve_target_aliases.items(), key=lambda x: -len(x[0]))
            for alias, canonical in sorted_aliases:
                # Match phrase in query (case-insensitive) using word boundaries
                # CRITICAL: Use regex to avoid matching 't' in "shot", "to", etc.
                import re
                pattern = r'\b' + re.escape(alias.lower()) + r'\b'
                if re.search(pattern, query_lower):
                    # Normalize using existing system (in case alias matches SHOT_ALIASES)
                    normalized = self._normalize_value(alias) or canonical
                    # Verify normalized value exists in inventory
                    if normalized in known_serve_targets:
                        detected_target = normalized
                        break
            
            if detected_target:
                filters['serve_target'] = detected_target
        
        # === SHOT NUMBER (parsed sequence position) ===
        # PARSED SEQUENCE: shot_number=1 (serve), shot_number=2 (return), shot_number=3 (server response)
        # TENNIS TERMINOLOGY: Rally shot 1 = return (parsed shot_number=2)
        # "return winner" → shot_number=2 (return in parsed sequence)
        # "serve+1 winner" → shot_number=3 (server's first groundstroke)
        if 'serve+1' in query_lower or 'serve + 1' in query_lower or 'third ball' in query_lower or '3rd ball' in query_lower:
            filters['shot_number'] = 3  # Server's first groundstroke (rally shot 2)
            print(f"[DETECT-FILTERS] Set shot_number=3 (serve+1)")
        elif 'first shot after serve' in query_lower:
            filters['shot_number'] = 3
            print(f"[DETECT-FILTERS] Set shot_number=3 (first after serve)")
        elif 'return' in query_lower:
            # Only set shot_number=2 for specific return shot outcomes (winner, ace, error)
            # For "return points won" or "return percentage", use role='returner' without shot_number
            if any(term in query_lower for term in ['return winner', 'return ace', 'return error', 'return unforced']):
                filters['shot_number'] = 2  # Return shot specifically
                print(f"[DETECT-FILTERS] Set shot_number=2 (return shot outcome)")
            filters['role'] = 'returner'  # Always set role for return queries
            print(f"[DETECT-FILTERS] Set role=returner (return query)")
        
        # === COURT ZONE (from inventory) ===
        # Map natural language to known court zones
        court_zone_aliases = {
            'at the net': 'net', 'net approach': 'net', 'volley': 'net',
            'baseline': 'baseline',
            "no man's land": 'midcourt', 'midcourt': 'midcourt'
        }
        for phrase, zone in court_zone_aliases.items():
            if phrase in query_lower:
                filters['court_zone'] = zone
                break
        
        # === COURT SIDE (from inventory) ===
        known_court_sides = inventory.get('court_sides', [])
        for side in known_court_sides:
            if side:
                side_lower = side.lower()
                if f"{side_lower} court" in query_lower or f"{side_lower} side" in query_lower:
                    filters['court_side'] = side
                    break
        # Handle "advantage court" alias
        if not filters.get('court_side') and 'advantage court' in query_lower:
            filters['court_side'] = 'ad'
        
        # === HANDEDNESS (player-specific, not from inventory) ===
        player = filters['player']
        if player:
            player_lower = player.lower()
            if any(lefty in player_lower for lefty in self.KNOWN_LEFT_HANDED_PLAYERS):
                filters['handedness'] = 'left'
            else:
                filters['handedness'] = 'right'
        
        # === ERROR LOCATION (semantic mapping with context) ===
        # These are contextual mappings, not pure inventory lookups
        if 'into the net' in query_lower or 'net error' in query_lower:
            filters['error_location'] = 'net'
        elif 'wide' in query_lower and 'error' in query_lower:
            filters['error_location'] = 'wide'
        elif 'long' in query_lower and 'error' in query_lower:
            filters['error_location'] = 'deep'
        
        return filters
    
    def _detect_metrics_mcp(self, query_lower: str) -> list:
        """
        Detect what metrics the query is asking about.
        MCP-Certified: Distinguishes induced forced errors from clean winners.
        
        SHOT-LEVEL METRICS:
        - total_shots: count ALL shots hit (not just point outcomes)
        - forehand_shots: count all forehand shots
        - backhand_shots: count all backhand shots
        """
        metrics = []
        
        # === SHOT-LEVEL METRICS ===
        # Shot counting is handled dynamically in tree traversal based on metadata.
        # The metric 'shot_count' triggers shot-level counting during traversal.
        # Shot type filtering (forehand, backhand, etc.) is applied via filters, not metric names.
        
        # "how many shots" / "total shots" / "shot count" / "percentage of shots"
        # Also catch patterns like "percentage of [player's] shots were winners"
        is_shot_query = any(phrase in query_lower for phrase in ['how many shot', 'total shot', 'shot count', 
                                                      'number of shot', 'percentage of shot', 
                                                      'percent of shot', '% of shot'])
        # Also check for "percentage...shots" pattern (with words in between)
        is_shot_percentage = ('percentage' in query_lower or 'percent' in query_lower or '%' in query_lower) and \
                           ('shots' in query_lower or 'shot' in query_lower)
        
        if is_shot_query or is_shot_percentage:
            metrics.append('shot_count')
            # The specific outcome metric (winners, errors, etc.) will be detected by other logic below
        
        # "forehand to backhand ratio" / "shot ratio" - needs shot_count with grouping by shot_type
        if ('forehand' in query_lower and 'backhand' in query_lower) and ('ratio' in query_lower or 'shot' in query_lower):
            metrics.append('shot_count')
            # Shot type comparison is handled by group_by='shot_type', not separate metrics
        
        # Return winners (specific metric - return + winner)
        if 'return' in query_lower and 'winner' in query_lower:
            metrics.append('return_winners')
            print(f"[DETECT-METRICS] Detected 'return_winners' (specific metric)")
        # Clean winners (MCP: *)
        elif 'winner' in query_lower and 'induced' not in query_lower:
            metrics.append('winners')
        
        # Induced forced errors (MCP: # - opponent touched but couldn't control)
        if 'forced error' in query_lower or "couldn't get it back" in query_lower or \
           "couldn't return" in query_lower or 'induced' in query_lower:
            metrics.append('induced_forced_errors')
        
        # Unforced errors (MCP: @ - player's own mistake)
        if 'unforced error' in query_lower:
            metrics.append('unforced_errors')
        
        # General errors (needs disambiguation)
        if 'error' in query_lower and 'forced' not in query_lower and 'unforced' not in query_lower:
            metrics.append('errors')
        
        # Aces (clean serve winner, no touch)
        # Be specific: "ace" not "aced" or part of other words like "faced", "placed"
        # Use word boundaries to avoid matching "face", "place", "race", etc.
        import re
        ace_pattern = r'\bace\b|\baces\b'
        if re.search(ace_pattern, query_lower):
            metrics.append('aces')
        
        # Service winners (touched but not returned)
        if 'service winner' in query_lower or 'unreturned serve' in query_lower:
            metrics.append('service_winners')
        
        # Double faults
        if 'double fault' in query_lower:
            metrics.append('double_faults')
        
        # === SERVE PERCENTAGE METRICS ===
        # First serve percentage (% of first serves that went IN)
        if any(phrase in query_lower for phrase in ['first serve percentage', 'first serve %', 
                                                     '1st serve percentage', '1st serve %',
                                                     'first serve in %', 'first serve in percentage']):
            print(f"[DETECT-METRICS] Detected 'first_serve_pct' (accuracy metric)")
            metrics.append('first_serve_pct')
        
        # First serve WIN percentage (% of first serve points WON)
        if any(phrase in query_lower for phrase in ['first serve win percentage', 'first serve win %',
                                                     'first serve won percentage', 'first serve won %',
                                                     '1st serve win %', '1st serve won %',
                                                     'first serve points won']):
            print(f"[DETECT-METRICS] Detected 'first_serve_win_pct' (effectiveness metric)")
            metrics.append('first_serve_win_pct')
        
        # Second serve percentage (% of second serves that went IN - not double faulted)
        if any(phrase in query_lower for phrase in ['second serve percentage', 'second serve %',
                                                     '2nd serve percentage', '2nd serve %',
                                                     'second serve in %', 'second serve in percentage',
                                                     '2nd serve in %', '2nd serve in percentage']):
            print(f"[DETECT-METRICS] Detected 'second_serve_pct' (accuracy metric)")
            metrics.append('second_serve_pct')
        
        # Second serve WIN percentage (% of second serve points WON)
        if any(phrase in query_lower for phrase in ['second serve win percentage', 'second serve win %',
                                                     'second serve won percentage', 'second serve won %',
                                                     '2nd serve win %', '2nd serve won %',
                                                     '2nd serve win percentage', '2nd serve won percentage',
                                                     'second serve points won', '2nd serve points won']):
            print(f"[DETECT-METRICS] Detected 'second_serve_win_pct' (effectiveness metric)")
            metrics.append('second_serve_win_pct')
        
        # Points
        if 'points won' in query_lower or 'won points' in query_lower:
            metrics.append('points_won')
        if 'points lost' in query_lower or 'lost points' in query_lower:
            metrics.append('points_lost')
        
        # === GAME-LEVEL METRICS ===
        # Games won: "how many games", "games won", "total games", "game count"
        # Also handles "number of games won by each player", "games won by Sinner"
        game_patterns = ['games won', 'number of games', 'total games', 'game count', 
                        'how many games', 'games did', 'games each', 'held serve']
        if any(phrase in query_lower for phrase in game_patterns) or \
           re.search(r'games.*won|won.*games', query_lower):
            metrics.append('games_won')
        if 'games lost' in query_lower or 'broken' in query_lower:
            metrics.append('games_lost')
        # Service game holds
        if 'hold' in query_lower and 'how many' in query_lower:
            metrics.append('service_games_held')
        # Service game win percentage
        if 'service game' in query_lower and ('win' in query_lower or 'percentage' in query_lower or '%' in query_lower):
            metrics.append('service_games_held')
        
        # === BREAK POINTS vs BREAKS OF SERVE ===
        # CRITICAL: Check for "break point" FIRST (situation/points) before "break" (games)
        # Break points are POINTS in a specific situation, breaks are GAMES won on opponent's serve
        if 'break point' in query_lower or 'break points' in query_lower or 'breakpoint' in query_lower or 'bp' in query_lower:
            print(f"[DETECT-METRICS] *** BREAK POINT query detected - using points_won ***")
            # This is about break POINTS (situation), not games broken
            # Remove any incorrectly added game metrics
            if 'breaks' in metrics:
                metrics.remove('breaks')
                print(f"[DETECT-METRICS] Removed 'breaks' metric (not for break points)")
            if 'games_lost' in metrics:
                metrics.remove('games_lost')
                print(f"[DETECT-METRICS] Removed 'games_lost' metric (not for break points)")
            # Break point queries count/convert points
            # Ensure points_won is the metric (break points are about points, not specific outcomes)
            if not metrics or 'points_won' not in metrics:
                metrics = ['points_won']  # Break points = points won/lost in that situation
                print(f"[DETECT-METRICS] Set metric to 'points_won' for break points")
        elif 'break' in query_lower:
            # Only count "break" as games_lost if NOT talking about break points
            # Match patterns like "resulted in breaks", "break of serve", "games broken", "break serve", etc.
            if any(phrase in query_lower for phrase in ['resulted in break', 'break of serve', 'break serve', 'games broken', 'break game', 'return game']):
                print(f"[DETECT-METRICS] Detected 'break' (games) query - adding 'breaks' metric")
                metrics.append('breaks')
                # "break serve" implies returner role (you break when returning)
                if 'break serve' in query_lower or 'break of serve' in query_lower:
                    # Role will be set in filter detection if not already set
                    pass
        
        # === SET-LEVEL METRICS ===
        set_patterns = ['sets won', 'number of sets', 'total sets', 'set count',
                       'how many sets', 'sets did', 'sets each']
        if any(phrase in query_lower for phrase in set_patterns) or \
           re.search(r'sets.*won|won.*sets', query_lower):
            metrics.append('sets_won')
        
        # Dominance ratio (MCP concept: winners + induced FE vs own errors)
        if 'dominance' in query_lower or 'aggression' in query_lower:
            metrics.append('dominance_ratio')
        
        final_metrics = metrics if metrics else ['points_won']
        if 'first_serve' in query_lower or '1st serve' in query_lower:
            print(f"[DETECT-METRICS] FINAL metrics returned: {final_metrics}")
        return final_metrics
    
    def _detect_chain_logic(self, query_lower: str) -> Dict[str, str]:
        """
        Detect chain/sequence logic: Shot A → Outcome B
        MCP: Critical for understanding "slice led to error" type queries.
        
        METADATA-DRIVEN: Uses inventory for shot types and outcomes.
        """
        import re
        
        chain = None
        
        # Get known values from inventory
        inventory = getattr(self, 'match_filter_inventory', {})
        known_shot_types = inventory.get('shot_types', ['forehand', 'backhand'])
        known_modifiers = inventory.get('shot_modifiers', ['slice', 'volley', 'drop_shot', 'approach'])
        known_serve_targets = inventory.get('serve_targets', ['wide', 'body', 't'])
        known_outcomes = inventory.get('outcomes', ['winner', 'error', 'forced_error', 'ace', 'double_fault'])
        
        # Build dynamic patterns from inventory
        shot_pattern = '|'.join([s.lower().replace('_', ' ') for s in known_shot_types + known_modifiers])
        serve_pattern = '|'.join([f"{t.lower()} serve" for t in known_serve_targets])
        outcome_pattern = '|'.join([o.lower().replace('_', ' ') for o in known_outcomes])
        
        # Dynamic chain patterns
        chain_patterns = [
            rf'({shot_pattern}).*(?:then|led to|resulted in|caused).*?({outcome_pattern})',
            rf'({serve_pattern}).*(?:then|and then).*?({shot_pattern}|{outcome_pattern})',
            rf'after.*?({outcome_pattern}).*?(hold|break|won|lost)'
        ]
        
        for pattern in chain_patterns:
            match = re.search(pattern, query_lower)
            if match:
                chain = {
                    'from_shot': match.group(1),
                    'to_outcome': match.group(2)
                }
                break
        
        return chain
    
    def _is_set_group_comparison_query(self, query: str) -> bool:
        """
        Detect if query compares metrics between different set groups.
        
        Example queries:
        - "Compare Federer's forehand winners in sets 2 and 4 versus sets 1, 3, and 5"
        - "Winner to error ratio in sets he won vs sets he lost"
        """
        query_lower = query.lower()
        
        # Must have set comparison indicators
        has_set_groups = bool(re.search(r'sets?\s*[\d,\s]+.*(?:versus|vs\.?|compared to|against).*sets?\s*[\d,\s]+', query_lower))
        has_won_lost_comparison = ('sets he won' in query_lower or 'sets he lost' in query_lower or 
                                   'winning sets' in query_lower or 'losing sets' in query_lower)
        
        # Must have ratio or comparison keywords
        has_ratio = any(kw in query_lower for kw in ['ratio', 'versus', 'vs', 'compared', 'comparison', 'to error'])
        
        return (has_set_groups or has_won_lost_comparison) and has_ratio
    
    def _analyze_set_group_comparison(self, query: str) -> Dict[str, Any]:
        """
        Analyze and compare metrics between different set groups.
        
        Handles queries like:
        - "Forehand winner to error ratio in sets 2,4 vs sets 1,3,5"
        """
        import re
        
        query_lower = query.lower()
        
        # Detect player
        player_mentioned = self._detect_player_mentioned(query)
        
        # Detect shot filter
        shot_info = self._detect_shot_from_query(query)
        shot_filter = shot_info['shot_type']
        
        # Detect metrics (winner, error, etc.)
        metrics_to_track = []
        if 'winner' in query_lower:
            metrics_to_track.append('winners')
        
        # CRITICAL: Distinguish between "error" (all errors) vs "unforced error" (specific type)
        if 'unforced error' in query_lower:
            metrics_to_track.append('unforced_errors')
        elif 'forced error' in query_lower:
            metrics_to_track.append('forced_errors')
        elif 'error' in query_lower:
            # Generic "error" means ALL errors (both unforced AND forced)
            metrics_to_track.append('unforced_errors')
            metrics_to_track.append('forced_errors')
        
        if not metrics_to_track:
            metrics_to_track = ['winners', 'unforced_errors']  # Default for ratio queries
        
        # Parse set groups
        filters = self._detect_filters_mcp(query)
        set_group_a = filters.get('set_group_a', [])
        set_group_b = filters.get('set_group_b', [])
        
        # If no explicit groups found, try to infer from "won/lost" language
        if not set_group_a or not set_group_b:
            # Look for patterns like "sets he won (Sets 2 and 4)"
            won_sets_match = re.search(r'sets?\s*(?:he|she)?\s*won\s*\(?(?:sets?)?\s*([\d,\s]+(?:and\s+\d+)?)', query_lower)
            lost_sets_match = re.search(r'sets?\s*(?:he|she)?\s*lost\s*\(?(?:sets?)?\s*([\d,\s]+(?:and\s+\d+)?)', query_lower)
            
            if won_sets_match:
                set_group_a = [int(d) for d in re.findall(r'\d', won_sets_match.group(1))]
            if lost_sets_match:
                set_group_b = [int(d) for d in re.findall(r'\d', lost_sets_match.group(1))]
        
        # Find point-by-point chunks
        pbp_chunks = [c for c in self.chunks if 'point-by-point' in c['metadata'].get('section', '').lower()]
        
        if not pbp_chunks:
            return {'error': 'No point-by-point data available'}
        
        all_text = '\n'.join([c['text'] for c in pbp_chunks])
        point_pattern = r'Point (\d+) \[Server: ([^\|]+)\| Returner: ([^\|]+)\| Score: ([^\]]+)\]: (.+?)(?=Point \d+|\Z)'
        
        results = {
            'player': player_mentioned or 'both players',
            'shot_filter': shot_filter,
            'metrics': metrics_to_track,
            'set_group_a': set_group_a,
            'set_group_b': set_group_b,
            'group_a_data': {metric: 0 for metric in metrics_to_track},
            'group_b_data': {metric: 0 for metric in metrics_to_track},
            'group_a_examples': [],
            'group_b_examples': []
        }
        
        for match in re.finditer(point_pattern, all_text, re.DOTALL):
            point_num = match.group(1)
            server = match.group(2).strip()
            returner = match.group(3).strip()
            score = match.group(4).strip()
            point_text = match.group(5).strip()
            
            # Get current set from score - use robust extraction
            current_set = self._extract_current_set(score)
            if not current_set:
                continue
            
            # Determine which group this set belongs to
            in_group_a = current_set in set_group_a
            in_group_b = current_set in set_group_b
            
            if not in_group_a and not in_group_b:
                continue
            
            # Parse rally
            rally_shots = self._parse_rally_sequence(point_text, server, returner)
            
            # Analyze shots for the specific player
            for shot in rally_shots:
                shot_player = shot.get('player', '')
                shot_desc = shot.get('description', '').lower()
                outcome = shot.get('outcome', '')
                
                # Check player filter
                if player_mentioned and player_mentioned.lower() not in shot_player.lower():
                    continue
                
                # Check shot type filter (e.g., forehand)
                if shot_filter and shot_filter.lower() not in shot_desc:
                    continue
                
                # Track metrics - GENERIC using config
                for metric in metrics_to_track:
                    # Use generic outcome matching from config
                    matched = self._outcome_matches_metric(outcome, metric)
                    
                    if matched:
                        if in_group_a:
                            results['group_a_data'][metric] += 1
                            if len(results['group_a_examples']) < 3:
                                results['group_a_examples'].append({
                                    'point': point_num, 'set': current_set,
                                    'shot': shot_desc, 'outcome': outcome
                                })
                        elif in_group_b:
                            results['group_b_data'][metric] += 1
                            if len(results['group_b_examples']) < 3:
                                results['group_b_examples'].append({
                                    'point': point_num, 'set': current_set,
                                    'shot': shot_desc, 'outcome': outcome
                                })
        
        # Calculate ratios if we have winners and errors
        # CRITICAL: "errors" means ALL errors (unforced + forced)
        if 'winners' in results['group_a_data']:
            total_errors_a = results['group_a_data'].get('unforced_errors', 0) + results['group_a_data'].get('forced_errors', 0)
            if total_errors_a > 0:
                results['group_a_ratio'] = round(results['group_a_data']['winners'] / total_errors_a, 2)
                results['group_a_total_errors'] = total_errors_a
            elif results['group_a_data'].get('unforced_errors', 0) > 0 or results['group_a_data'].get('forced_errors', 0) > 0:
                results['group_a_ratio'] = float('inf')
        
        if 'winners' in results['group_b_data']:
            total_errors_b = results['group_b_data'].get('unforced_errors', 0) + results['group_b_data'].get('forced_errors', 0)
            if total_errors_b > 0:
                results['group_b_ratio'] = round(results['group_b_data']['winners'] / total_errors_b, 2)
                results['group_b_total_errors'] = total_errors_b
            elif results['group_b_data'].get('unforced_errors', 0) > 0 or results['group_b_data'].get('forced_errors', 0) > 0:
                results['group_b_ratio'] = float('inf')
        
        return results
    
    def _format_set_group_comparison(self, analysis: Dict[str, Any]) -> str:
        """Format set group comparison analysis."""
        if 'error' in analysis:
            return f"Unable to perform set group comparison: {analysis['error']}"
        
        shot_desc = analysis['shot_filter'] or 'All Shots'
        group_a_sets = ', '.join(map(str, analysis['set_group_a']))
        group_b_sets = ', '.join(map(str, analysis['set_group_b']))
        
        response = f"**Set Group Comparison: {shot_desc.title()}**\n\n"
        response += f"**Player:** {analysis['player']}\n\n"
        
        response += f"**Group A (Sets {group_a_sets}):**\n"
        response += f"| Metric | Count |\n"
        response += f"|--------|-------|\n"
        for metric, count in analysis['group_a_data'].items():
            response += f"| {metric.replace('_', ' ').title()} | {count} |\n"
        if 'group_a_ratio' in analysis:
            response += f"\n**Winner:Error Ratio:** **{analysis['group_a_ratio']}:1**\n"
        
        response += f"\n**Group B (Sets {group_b_sets}):**\n"
        response += f"| Metric | Count |\n"
        response += f"|--------|-------|\n"
        for metric, count in analysis['group_b_data'].items():
            response += f"| {metric.replace('_', ' ').title()} | {count} |\n"
        if 'group_b_ratio' in analysis:
            response += f"\n**Winner:Error Ratio:** **{analysis['group_b_ratio']}:1**\n"
        
        # Comparison
        if 'group_a_ratio' in analysis and 'group_b_ratio' in analysis:
            ratio_a = analysis['group_a_ratio']
            ratio_b = analysis['group_b_ratio']
            
            response += f"\n**Comparison:**\n"
            if ratio_a > ratio_b:
                diff = round(ratio_a - ratio_b, 2)
                response += f"Sets {group_a_sets} had a **better** winner:error ratio ({ratio_a}:1 vs {ratio_b}:1, +{diff})\n"
            elif ratio_b > ratio_a:
                diff = round(ratio_b - ratio_a, 2)
                response += f"Sets {group_b_sets} had a **better** winner:error ratio ({ratio_b}:1 vs {ratio_a}:1, +{diff})\n"
            else:
                response += f"Both groups had **equal** winner:error ratios ({ratio_a}:1)\n"
        
        return response
    
    def _detect_filters(self, query: str) -> Dict[str, Any]:
        """Legacy wrapper - redirects to MCP version."""
        return self._detect_filters_mcp(query)
    
    def _detect_metrics(self, query_lower: str) -> list:
        """Legacy wrapper - redirects to MCP version."""
        return self._detect_metrics_mcp(query_lower)
    
    # ==========================================================================
    # N-DIMENSIONAL TAXONOMY TREE
    # ==========================================================================
    
    def _build_query_tree(self, classification: Dict) -> Dict:
        """
        Build an N-dimensional query tree from classification.
        
        Tree Structure:
        {
            'type': 'filter' | 'group' | 'metric',
            'dimension': 'situation' | 'serve_target' | etc.,
            'value': value (for filters) or None (for groups),
            'children': [child nodes] or None (for leaf metrics),
            'metric': metric name (for leaf nodes)
        }
        
        Example tree for "On break points, serving to T, compare 1st vs 2nd serve win %":
        
        ROOT
        └─ filter: situation=break_point
           └─ filter: serve_target=t
              └─ group: serve_number
                 ├─ leaf: serve_number=1st → win_percentage
                 └─ leaf: serve_number=2nd → win_percentage
        """
        filters = classification.get('filters', {})
        metrics = classification.get('metrics', ['points_won'])
        
        # Check if this is a set comparison query
        has_set_comparison = filters.get('set_group_a') and filters.get('set_group_b')
        
        # Extract all filter dimensions (order matters for tree depth)
        filter_dimensions = []
        
        # Priority order for filter application
        # NOTE: set_group_a/b are NOT filters - they define comparison groups
        dimension_order = [
            ('situation', filters.get('situation')),
            ('set', filters.get('set')),
            # Skip set_group_a/b - handled as grouping below
            ('serve_number', filters.get('serve_number')),
            ('serve_target', filters.get('serve_target')),
            ('court_side', filters.get('court_side')),
            ('court_zone', filters.get('court_zone')),  # For net points
            ('shot_type', filters.get('shot_type')),
            ('shot_modifier', filters.get('shot_modifier')),
            ('direction', filters.get('direction')),
            ('depth', filters.get('depth')),
            ('shot_number', filters.get('shot_number')),  # Shot number in rally
            ('role', filters.get('role')),
            ('rally_length', filters.get('rally_length')),  # Exact rally length
            ('rally_length_range', filters.get('rally_length_range')),  # Rally length range (min, max)
            ('exclude_early_outcome', filters.get('exclude_early_outcome')),  # Neutral rallies (exclude points ending early)
        ]
        
        # Don't add 'both' as a player filter - it means no filter
        player_filter = filters.get('player')
        if player_filter and player_filter.lower() != 'both':
            dimension_order.append(('player', player_filter))
        
        for dim, val in dimension_order:
            # Skip None and string "null" values
            if val is not None and not (isinstance(val, str) and val.lower() == 'null'):
                # EXCEPTION: Skip shot_type filter when using shot_count metrics
                # shot_count needs ALL points to iterate through shots, filtering happens at SHOT level
                if dim == 'shot_type':
                    is_shot_level_query = any(m.startswith('shot_count') or m.startswith('shots_count') or m in ['shots', 'shot'] for m in metrics)
                    if is_shot_level_query:
                        print(f"[TREE] Skipping shot_type='{val}' filter because shot_count metric filters at shot level, not point level")
                        continue
                # EXCEPTION: Skip shot_type='serve' when role='server' is present
                # (serve effectiveness means ALL service points, not just aces/DFs)
                if dim == 'shot_type' and isinstance(val, str) and val.lower() == 'serve' and filters.get('role') == 'server':
                    print(f"[TREE] Skipping shot_type='serve' filter because role='server' is set")
                    continue
                # EXCEPTION: Skip shot_number=1 when role='server' is present
                # (serve effectiveness includes all shots in the point, not just the serve itself)
                if dim == 'shot_number' and val == 1 and filters.get('role') == 'server':
                    print(f"[TREE] Skipping shot_number=1 filter because role='server' is set")
                    continue
                filter_dimensions.append((dim, val))
        
        # Extract grouping dimensions (can be multiple for N-D)
        group_dimensions = []
        
        # Helper to check if value is valid (not None, not string "null")
        def is_valid(val):
            if val is None:
                return False
            if isinstance(val, str) and val.lower() == 'null':
                return False
            return True
        
        # If set comparison exists, add set_groups as a grouping dimension
        if has_set_comparison:
            group_dimensions.append('set_groups')
        
        # Primary group (if not already set_groups)
        group_by = classification.get('group_by')
        if is_valid(group_by) and group_by != 'set_groups':
            # CRITICAL: Skip shot_type grouping at POINT level when using shot_count metric
            # shot_count needs ALL points to iterate through shots, grouping happens at SHOT level
            # Check for both 'shot_count' (transformed) and 'shots' (pre-transform)
            # Also handle multiple shot_count metrics like ['shot_count', 'shot_count_1']
            is_shot_level_query = any(m.startswith('shot_count') or m.startswith('shots_count') or m in ['shots', 'shot'] for m in metrics)
            print(f"[TREE-DEBUG] Checking shot_type skip: metrics={metrics}, is_shot_level_query={is_shot_level_query}, group_by={group_by}")
            if group_by == 'shot_type' and is_shot_level_query:
                print(f"[TREE] Skipping shot_type grouping at point level (shot_count metric will group at shot level)")
            else:
                group_dimensions.append(group_by)
        
        # Secondary group (2D) - skip if string "null"
        secondary = classification.get('secondary_group_by')
        if is_valid(secondary):
            group_dimensions.append(secondary)
        
        # Tertiary group (3D) - skip if string "null"
        tertiary = classification.get('tertiary_group_by')
        if is_valid(tertiary):
            group_dimensions.append(tertiary)
        
        # Build tree recursively
        root = self._build_tree_node(filter_dimensions, group_dimensions, metrics, classification)
        
        return {
            'root': root,
            'classification': classification,
            'depth': len(filter_dimensions) + len(group_dimensions),
            'dimensions': {
                'filters': filter_dimensions,
                'groups': group_dimensions,
                'metrics': metrics
            }
        }
    
    def _build_tree_node(self, remaining_filters: list, remaining_groups: list, 
                         metrics: list, classification: Dict, depth: int = 0) -> Dict:
        """Recursively build tree nodes."""
        
        # If we have filters remaining, create filter node
        if remaining_filters:
            dim, val = remaining_filters[0]
            return {
                'type': 'filter',
                'dimension': dim,
                'value': val,
                'depth': depth,
                'children': [self._build_tree_node(
                    remaining_filters[1:], remaining_groups, metrics, classification, depth + 1
                )]
            }
        
        # If we have groups remaining, create group node with branches
        if remaining_groups:
            group_dim = remaining_groups[0]
            group_values = self._get_group_values(group_dim, classification)
            
            return {
                'type': 'group',
                'dimension': group_dim,
                'value': None,
                'depth': depth,
                'children': [
                    {
                        'type': 'branch',
                        'dimension': group_dim,
                        'value': val,
                        'label': label,
                        'depth': depth + 1,
                        'children': [self._build_tree_node(
                            [], remaining_groups[1:], metrics, classification, depth + 2
                        )]
                    }
                    for val, label in group_values.items()
                ]
            }
        
        # Leaf node - compute metrics
        return {
            'type': 'leaf',
            'dimension': 'metrics',
            'metrics': metrics,
            'depth': depth,
            'children': None
        }
    
    def _get_group_values(self, group_dim: str, classification: Dict = None) -> Dict[str, str]:
        """
        Get all possible values for a grouping dimension.
        GENERIC: Uses GROUP_CONFIG as single source of truth.
        """
        # Handle set_groups dynamically based on classification
        if group_dim == 'set_groups' and classification:
            filters = classification.get('filters', {})
            set_a = filters.get('set_group_a', [])
            set_b = filters.get('set_group_b', [])
            
            # Create dynamic labels based on actual sets
            set_a_str = ', '.join(str(s) for s in set_a) if set_a else 'A'
            set_b_str = ', '.join(str(s) for s in set_b) if set_b else 'B'
            
            return {
                'a': f'Set {set_a_str}' if len(set_a) == 1 else f'Sets {set_a_str}',
                'b': f'Set {set_b_str}' if len(set_b) == 1 else f'Sets {set_b_str}'
            }
        
        # Handle situation comparison dynamically (tiebreak vs rest)
        if group_dim == 'situation' and classification:
            filters = classification.get('filters', {})
            situation_a = filters.get('situation_group_a')
            situation_b = filters.get('situation_group_b')
            
            if situation_a and situation_b:
                # Create dynamic labels
                label_a = situation_a.replace('_', ' ').title()
                label_b = situation_b.replace('_', ' ').title() if situation_b != 'non_tiebreak' else 'Rest of Match'
                
                return {
                    'a': label_a,
                    'b': label_b
                }
        
        # Handle player grouping dynamically
        # Use actual names as KEYS so filter works correctly
        if group_dim == 'player':
            player1 = self.player1 or 'Player 1'
            player2 = self.player2 or 'Player 2'
            return {
                player1: player1,
                player2: player2
            }
        
        # GENERIC: Use GROUP_CONFIG instead of hard-coded dictionary
        return self._get_all_group_values(group_dim, classification)
    
    def _traverse_tree(self, tree: Dict, points: list) -> Dict:
        """
        Traverse the N-dimensional tree, filtering and grouping points.
        
        Returns nested results matching tree structure.
        """
        root = tree['root']
        classification = tree['classification']
        
        return self._traverse_node(root, points, classification)
    
    def _traverse_node(self, node: Dict, points: list, classification: Dict) -> Dict:
        """Recursively traverse a tree node."""
        
        node_type = node['type']
        dimension = node['dimension']
        value = node.get('value')
        
        if node_type == 'filter':
            # Apply filter to narrow down points
            filtered_points = self._apply_dimension_filter(points, dimension, value, classification)
            print(f"[TRAVERSE] Filter {dimension}={value}: {len(points)} -> {len(filtered_points)} points")
            
            # Continue to children with filtered points
            if node['children']:
                child_results = self._traverse_node(node['children'][0], filtered_points, classification)
            else:
                child_results = {}
            
            return {
                'type': 'filter',
                'dimension': dimension,
                'value': value,
                'points_before': len(points),
                'points_after': len(filtered_points),
                'children': child_results,
                'points': filtered_points  # CRITICAL: Store filtered points for consistent display
            }
        
        elif node_type == 'group':
            # Branch into multiple groups
            print(f"[TRAVERSE] Group {dimension}: {len(points)} points incoming")
            branch_results = {}
            
            for child in node['children']:
                branch_value = child['value']
                branch_label = child['label']
                
                # Filter points for this branch
                branch_points = self._apply_dimension_filter(points, dimension, branch_value, classification)
                print(f"[TRAVERSE]   Branch {branch_value}: {len(branch_points)} points")
                
                # Continue down this branch
                if child['children']:
                    sub_results = self._traverse_node(child['children'][0], branch_points, classification)
                else:
                    sub_results = self._compute_leaf_metrics(branch_points, classification)
                
                branch_results[branch_value] = {
                    'label': branch_label,
                    'count': len(branch_points),
                    'results': sub_results,
                    'points': branch_points  # Store actual points for debugging
                }
            
            return {
                'type': 'group',
                'dimension': dimension,
                'total_points': len(points),
                'branches': branch_results
            }
        
        elif node_type == 'branch':
            # This is a branch within a group - continue to children
            if node['children']:
                result = self._traverse_node(node['children'][0], points, classification)
                if 'points' not in result:
                    result['points'] = points
                return result
            else:
                metrics = self._compute_leaf_metrics(points, classification)
                metrics['points'] = points
                return metrics
        
        elif node_type == 'leaf':
            # Compute metrics at leaf
            metrics = self._compute_leaf_metrics(points, classification)
            metrics['points'] = points  # Store points for consistent display
            return metrics
        
        return {}
    
    def _names_match_robust(self, name1: str, name2: str) -> bool:
        """
        Robust name matching that handles:
        - Case differences
        - Punctuation (N. Djokovic vs Novak Djokovic)
        - Non-breaking spaces
        - Partial matches (last name only)
        """
        if not name1 or not name2:
            return False
        
        # Normalize both names
        def normalize(n):
            n = n.replace('\xa0', ' ').replace('\u00a0', ' ')  # Non-breaking spaces
            n = re.sub(r'[^\w\s]', '', n)  # Remove punctuation (periods, commas)
            n = re.sub(r'\s+', ' ', n).strip().lower()
            return n
        
        n1 = normalize(name1)
        n2 = normalize(name2)
        
        # Exact match after normalization
        if n1 == n2:
            return True
        
        # One contains the other (handles "Djokovic" matching "Novak Djokovic")
        if n1 in n2 or n2 in n1:
            return True
        
        # Last name match (most robust)
        def get_last_name(n):
            parts = n.split()
            return parts[-1] if parts else n
        
        if get_last_name(n1) == get_last_name(n2):
            return True
        
        # Check if any word in one name matches any word in the other
        words1 = set(n1.split())
        words2 = set(n2.split())
        if words1 & words2:  # Intersection - any common words
            return True
        
        return False
    
    def _apply_dimension_filter(self, points: list, dimension: str, value: Any, 
                                 classification: Dict) -> list:
        """
        ROBUST DIMENSION FILTER: Uses metadata for ALL filtering decisions.
        Apply a single dimension filter to points.
        """
        filtered = []
        player1 = self.player1
        player2 = self.player2
        filters = classification.get('filters', {})
        
        for point_data in points:
            # Get cached metadata or compute it
            if '_metadata' not in point_data:
                point_data['_metadata'] = self._get_point_metadata(point_data)
            meta = point_data['_metadata']
            
            # Legacy access for gradual migration
            point_text = meta.get('raw_text', '')
            point_lower = point_text.lower()
            score = meta.get('score', '')
            server = meta.get('server', '')
            returner = meta.get('returner', '')
            
            passes_filter = True
            
            if dimension == 'situation':
                # Handle situation group comparisons (a vs b)
                if value == 'a':
                    situation_a = filters.get('situation_group_a')
                    if situation_a == 'tiebreak':
                        passes_filter = 'tiebreak' in score.lower() or self._is_tiebreak_point(score)
                    elif situation_a == 'break_point':
                        passes_filter = self._is_break_point_score(score)
                    elif situation_a == 'game_point':
                        passes_filter = self._is_game_point_score(score)
                    elif situation_a == 'deuce':
                        passes_filter = self._is_deuce_score(score)
                elif value == 'b':
                    situation_b = filters.get('situation_group_b')
                    if situation_b == 'non_tiebreak':
                        # Non-tiebreak = NOT in tiebreak
                        passes_filter = 'tiebreak' not in score.lower() and not self._is_tiebreak_point(score)
                    elif situation_b == 'non_break_point':
                        passes_filter = not self._is_break_point_score(score)
                # Regular situation filters - GENERIC using SITUATION_CONFIG
                elif value in self.SITUATION_CONFIG:
                    passes_filter = self._check_situation(value, score)
                    # Fallback for tiebreak (check string too)
                    if value == 'tiebreak' and not passes_filter:
                        passes_filter = 'tiebreak' in score.lower() or self._is_tiebreak_point(score)
            
            elif dimension == 'set' or dimension == 'sets':
                current_set = self._extract_current_set(score)
                # Handle both string and int comparisons
                if isinstance(value, str) and value.isdigit():
                    value = int(value)
                passes_filter = (current_set == value)
            
            elif dimension == 'set_group_a' or dimension == 'set_group_b':
                current_set = self._extract_current_set(score)
                set_list = value if isinstance(value, list) else [value]
                passes_filter = (current_set in set_list)
            
            elif dimension == 'set_groups':
                # Handle grouping by set comparison (branch value is 'a' or 'b')
                current_set = self._extract_current_set(score)
                if value == 'a':
                    set_list = filters.get('set_group_a', [])
                elif value == 'b':
                    set_list = filters.get('set_group_b', [])
                else:
                    set_list = []
                passes_filter = (current_set in set_list)
            
            elif dimension == 'serve_number':
                # Use metadata for serve number (1st or 2nd serve attempt)
                serve_num = meta.get('serve_info', {}).get('serve_number', 1)
                if value == 1 or value == '1st':
                    passes_filter = (serve_num == 1)
                elif value == 2 or value == '2nd':
                    passes_filter = (serve_num == 2)
            
            elif dimension == 'shot_number':
                # Shot position in PARSED sequence (1=serve, 2=return, 3=server's response, etc.)
                # CRITICAL: This matches _parse_rally_sequence numbering, NOT tennis rally counting
                # Get rally shots from metadata
                rally_shots = meta.get('rally_shots', [])
                if not rally_shots:
                    # Fallback: parse rally from text
                    point_text = meta.get('raw_text', '')
                    server = meta.get('server', '')
                    returner = meta.get('returner', '')
                    rally_shots = self._parse_rally_sequence(point_text, server, returner) if point_text else []
                
                # Check if the WINNING shot (last shot) has the target shot_number
                # For "return winners": value=2, we want points where winning shot was shot_number=2 (return)
                if rally_shots:
                    # Get the last non-fault shot (the winning shot)
                    actual_shots = [s for s in rally_shots if s.get('outcome') not in ['FAULT', 'LET']]
                    if actual_shots:
                        winning_shot = actual_shots[-1]
                        winning_shot_number = winning_shot.get('shot_number')
                        passes_filter = (winning_shot_number == value)
                    else:
                        passes_filter = False
                else:
                    passes_filter = False
            
            elif dimension == 'serve_target' or dimension == 'serve_direction':
                # Use metadata for serve target WITH NORMALIZATION
                serve_target = meta.get('serve_info', {}).get('serve_target')
                # Use _values_match to handle aliases (t -> down_the_t, etc.)
                passes_filter = self._values_match(value, serve_target) if value else True
            
            elif dimension == 'court_side':
                # Use metadata for court side
                court_side = meta.get('situation', {}).get('court_side')
                passes_filter = (court_side == value)
            
            elif dimension == 'shot_type':
                # GENERIC: For error metrics, use error_shot_type; for others, use winning_shot_type
                metrics = classification.get('metrics', [])
                current_metric = metrics[0] if metrics else None
                error_metrics = ['unforced_errors', 'forced_errors', 'errors']
                
                if current_metric in error_metrics:
                    # Use error_shot_type for error metrics
                    error_info = meta.get('error_info', {})
                    shot_type_to_check = error_info.get('error_shot_type')
                else:
                    # Use winning_shot_type for non-error metrics
                    shot_type_to_check = meta.get('winning_shot', {}).get('shot_type')
                
                # Use _values_match for alias handling and hierarchy expansion
                passes_filter = self._values_match(value, shot_type_to_check) if value else True
            
            elif dimension == 'direction':
                # Use metadata for winning shot direction WITH NORMALIZATION
                winning_direction = meta.get('winning_shot', {}).get('direction')
                # Use _values_match to handle aliases (cc -> crosscourt, dtl -> down_the_line)
                passes_filter = self._values_match(value, winning_direction) if value else True
            
            elif dimension == 'depth':
                # Use metadata for winning shot depth WITH NORMALIZATION
                winning_depth = meta.get('winning_shot', {}).get('depth')
                # Use _values_match to handle aliases and hierarchies
                passes_filter = self._values_match(value, winning_depth) if value else True
            
            elif dimension == 'court_zone':
                # Use metadata to determine if shot was at net WITH HIERARCHY
                at_net = meta.get('winning_shot', {}).get('at_net', False)
                shot_modifier = meta.get('winning_shot', {}).get('shot_modifier', '')
                shot_modifiers = meta.get('winning_shot', {}).get('shot_modifiers', [])
                
                # Get all net-related modifiers from hierarchy
                net_modifiers = self.SHOT_HIERARCHY.get('at_net', ['volley', 'half_volley', 'overhead', 'swinging_volley', 'drop_volley'])
                
                # Net indicators: at_net flag OR any net-related modifier
                is_net_shot = at_net or shot_modifier in net_modifiers or any(m in net_modifiers for m in shot_modifiers)
                
                # GENERIC court zone matching using COURT_ZONE_CONFIG
                zone_config = self.COURT_ZONE_CONFIG.get(value, {})
                expected_net = zone_config.get('detection_value', value == 'net')
                passes_filter = is_net_shot == expected_net
            
            elif dimension == 'shot_modifier':
                # Filter by shot modifier WITH HIERARCHY EXPANSION
                winning_modifiers = meta.get('winning_shot', {}).get('shot_modifiers', [])
                primary_modifier = meta.get('winning_shot', {}).get('shot_modifier')
                if primary_modifier and primary_modifier not in winning_modifiers:
                    winning_modifiers = [primary_modifier] + winning_modifiers
                
                # Check if ANY of the winning shot's modifiers match (using hierarchy)
                passes_filter = any(self._values_match(value, mod) for mod in winning_modifiers) if value else True
            
            elif dimension == 'role':
                player_filter = (filters.get('player') or '').lower()
                # GENERIC role handling using ROLE_CONFIG
                if value in self.ROLE_CONFIG:
                    role_player = self._get_player_for_role(value, server, returner, meta.get('point_winner', ''), point_data.get('error_player', ''))
                    if player_filter and player_filter != 'both':
                        # Player specified with role → filter by that role's player
                        passes_filter = player_filter in role_player.lower() if role_player else True
                    else:
                        # No specific player, role means keep all points (everyone plays both roles)
                        passes_filter = True
            
            elif dimension == 'player':
                # Player filter - context-dependent
                domain = classification.get('domain', '')
                role_filter = filters.get('role')
                group_by = classification.get('group_by', '')
                metrics = classification.get('metrics', [])
                analysis_type = classification.get('analysis_type', '')
                
                # Get point winner from metadata
                point_winner = meta.get('point_winner', '')
                if not point_winner:
                    # Fallback: extract from description
                    desc = (point_data.get('description', '') or point_data.get('point_text', '')).lower()
                    if 'point won by:' in desc:
                        pw_match = re.search(r'point won by:\s*([^\]]+)', desc)
                        if pw_match:
                            point_winner = pw_match.group(1).strip()
                
                # Skip if player is 'both' - this means compare all players
                if (value or '').lower() == 'both':
                    passes_filter = True
                # CRITICAL FIX: When role filter is specified (server/returner),
                # ALWAYS filter by the role, NOT by who won the point
                # This ensures win_percentage is calculated correctly - GENERIC using ROLE_CONFIG
                elif role_filter:
                    role_player = self._get_player_for_role(role_filter, server, returner, point_winner, point_data.get('error_player', ''))
                    passes_filter = self._names_match_robust(value, role_player)
                # For domain-based queries, filter by the domain's associated player - GENERIC
                elif domain and domain in self.DOMAIN_CONFIG:
                    domain_player = self._get_player_for_domain(domain, server, returner)
                    if domain_player:
                        passes_filter = self._names_match_robust(value, domain_player)
                    else:
                        passes_filter = True  # No specific player for this domain
                # When GROUPING by player for "who won more points" type questions WITHOUT role filter,
                # filter by WHO WON THE POINT, not who was involved
                elif group_by == 'player' and ('points_won' in metrics or 'win_percentage' in metrics or analysis_type in ['ratio', 'comparison']):
                    passes_filter = self._names_match_robust(value, point_winner)
                # For shot-based groupings (shot_type/direction/etc.), use metric's player_role to determine who to filter by
                # "Sinner's forehand winners" → player_role='winner' → filter to points Sinner won
                # "Sinner's backhand errors" → player_role='error' → filter to points where Sinner hit the error
                elif group_by in ['shot_type', 'direction', 'shot_modifier', 'depth', 'court_zone', 'shot_number']:
                    # Get the metric's player_role from CLASS CONSTANT (single source of truth)
                    primary_metric = metrics[0] if metrics else None
                    metric_config = TennisChatAgentEmbeddingQALocal.METRIC_CONFIG.get(primary_metric, {})
                    player_role = metric_config.get('player_role', 'both')
                    
                    # GENERIC: Use ROLE_CONFIG to determine which player field to check
                    role_config = self.ROLE_CONFIG.get(player_role, {})
                    player_field = role_config.get('player_field', '')
                    
                    if player_field:
                        # Map player_field to actual player value from metadata/context
                        field_to_player = {
                            'server': server,
                            'returner': returner,
                            'point_winner': point_winner,
                            'error_player': point_data.get('error_player', '')  # CRITICAL: error_player stored in point_data, not meta
                        }
                        target_player = field_to_player.get(player_field, '')
                        passes_filter = self._names_match_robust(value, target_player)
                        
                        # DEBUG: Show player matching for first few points
                        point_num = point_data.get('point_number', '?')
                        if not hasattr(self, '_player_filter_debug_count'):
                            self._player_filter_debug_count = 0
                        if self._player_filter_debug_count < 5:
                            self._player_filter_debug_count += 1
                            print(f"[PLAYER-FILTER-DEBUG] Point {point_num} | Filter: '{value}' | player_field: {player_field} | target_player: '{target_player}' | Match: {passes_filter}")
                    else:
                        # player_role='both' or unknown → filter to points player was involved in
                        passes_filter = self._names_match_robust(value, server) or self._names_match_robust(value, returner)
                # Otherwise, check if player is involved in either role
                else:
                    passes_filter = self._names_match_robust(value, server) or self._names_match_robust(value, returner)
            
            # For grouping dimensions (when used as filter)
            elif dimension == 'serve_direction':
                # Use metadata for serve target (same as serve_target)
                serve_target = meta.get('serve_info', {}).get('serve_target')
                passes_filter = (serve_target == value)
            
            elif dimension == 'shot_direction':
                # Use metadata for winning shot direction
                winning_direction = meta.get('winning_shot', {}).get('direction')
                passes_filter = (winning_direction == value)
            
            elif dimension == 'return_depth':
                # Use metadata for return depth
                return_depth = meta.get('return_info', {}).get('return_depth')
                depth_map = {'shallow': 'shallow', 'deep': 'deep', 'very_deep': 'very_deep', 'unspecified': None}
                passes_filter = (return_depth == depth_map.get(value))
            
            elif dimension == 'rally_length_category':
                # Use metadata for rally category
                rally_category = meta.get('rally_category')
                passes_filter = (rally_category == value)
            
            elif dimension == 'rally_length':
                # Use metadata for rally length (exact or comparison)
                rally_len = meta.get('rally_length', 0)
                if isinstance(value, int):
                    passes_filter = (rally_len == value)
                elif isinstance(value, str):
                    # IMPORTANT: Check '>=' before '>' ('>=' startswith '>')
                    if value.startswith('>='):
                        threshold = int(value[2:])
                        passes_filter = (rally_len >= threshold)
                    elif value.startswith('>'):
                        threshold = int(value[1:])
                        passes_filter = (rally_len > threshold)
                    elif value.startswith('<='):
                        threshold = int(value[2:])
                        passes_filter = (rally_len <= threshold)
                    elif value.startswith('<'):
                        threshold = int(value[1:])
                        passes_filter = (rally_len < threshold)
                    else:
                        passes_filter = True  # Unknown format, don't filter
                else:
                    passes_filter = True  # Unknown format, don't filter
            
            elif dimension == 'rally_length_range':
                # Use metadata for rally length range (min, max)
                rally_len = meta.get('rally_length', 0)
                if isinstance(value, (list, tuple)) and len(value) == 2:
                    min_len, max_len = value
                    min_ok = rally_len >= min_len if min_len is not None else True
                    max_ok = rally_len <= max_len if max_len is not None else True
                    passes_filter = min_ok and max_ok
                else:
                    passes_filter = True  # Unknown format, don't filter
            
            elif dimension == 'exclude_early_outcome':
                # Exclude points that ended before a certain shot (neutral rallies)
                # value = threshold shot number (e.g., 6 means exclude points ending before shot 6)
                rally_len = meta.get('rally_length', 0)
                passes_filter = (rally_len >= value)  # Rally must reach at least this length
            
            elif dimension == 'pressure_level':
                # Use enriched pressure data
                pressure_data = point_data.get('pressure', {})
                tightness = pressure_data.get('score_tightness', 0)
                
                if value == 'low':
                    passes_filter = 0 <= tightness <= 3
                elif value == 'medium':
                    passes_filter = 4 <= tightness <= 6
                elif value == 'high':
                    passes_filter = 7 <= tightness <= 10
            
            elif dimension == 'serve_plus_one_type':
                # Use metadata for serve+1 shot type
                serve_plus_one_type = meta.get('serve_plus_one', {}).get('shot_type')
                
                if value == 'none':
                    passes_filter = not serve_plus_one_type
                else:
                    passes_filter = (serve_plus_one_type == value)
            
            # === NEW ENHANCED DIMENSIONS ===
            elif dimension == 'shot_modifier':
                # Filter by ANY shot modifier in the winning shot
                shot_modifiers = meta.get('winning_shot', {}).get('shot_modifiers', [])
                passes_filter = (value in shot_modifiers)
            
            elif dimension == 'court_position':
                # Filter by court position (net, baseline, approach)
                court_pos = meta.get('winning_shot', {}).get('court_position')
                passes_filter = (court_pos == value)
            
            elif dimension == 'spin':
                # Filter by spin type (topspin, slice, flat)
                spin = meta.get('winning_shot', {}).get('spin')
                passes_filter = (spin == value)
            
            elif dimension == 'is_net_point':
                # Filter for net points specifically
                at_net = meta.get('winning_shot', {}).get('at_net', False)
                passes_filter = (at_net == (value == 'true' or value == True))
            
            elif dimension == 'is_return':
                # Filter for return shots
                actual_shots = meta.get('all_shots', meta.get('actual_shots', []))
                if len(actual_shots) >= 2:
                    return_shot = actual_shots[1]
                    is_return = return_shot.get('is_return', False) or 'return' in return_shot.get('description', '').lower()
                    passes_filter = is_return
                else:
                    passes_filter = False
            
            elif dimension == 'after_rally_length':
                # Use enriched context data
                context = point_data.get('context', {})
                prev_rally = context.get('prev_rally_length', 0)
                
                if value == 'first_point':
                    passes_filter = prev_rally == 0
                elif value == 'after_short':
                    passes_filter = 1 <= prev_rally <= 4
                elif value == 'after_medium':
                    passes_filter = 5 <= prev_rally <= 9
                elif value == 'after_long':
                    passes_filter = prev_rally >= 10
            
            if passes_filter:
                filtered.append(point_data)
        
        return filtered
    
    def _count_game_points(self, game_score: str) -> int:
        """Count total points played in game from score like '30-15'."""
        score_map = {'0': 0, '15': 1, '30': 2, '40': 3, 'AD': 4}
        parts = game_score.replace('-', ' ').split()
        total = 0
        for p in parts:
            total += score_map.get(p.upper(), 0)
        return total
    
    def _is_tiebreak_point(self, score: str) -> bool:
        """Check if score indicates tiebreak."""
        # Tiebreak scores are like "6-6 3-2" where game scores are numeric
        parts = score.split()
        if len(parts) >= 2:
            game_part = parts[-1]
            if '-' in game_part:
                try:
                    a, b = game_part.split('-')
                    int(a)
                    int(b)
                    # If both parts are numeric and set score is 6-6, it's a tiebreak
                    if len(parts) >= 2 and '6-6' in score:
                        return True
                except:
                    pass
        return False
    
    def _calculate_pressure_index(self, score_str: str) -> int:
        """
        Calculate pressure index (0-10) based on score state.
        Higher values indicate more pressure/critical situations.
        """
        if not score_str:
            return 0
        
        score_str_lower = score_str.lower()
        base_pressure = 0
        
        # Check for tiebreak situations (high pressure)
        if self._is_tiebreak_point(score_str):
            base_pressure += 5
        
        # Check for final set scores with tiebreak
        if '7-6' in score_str or '6-7' in score_str:
            base_pressure += 5
        
        # Check for deuce (close game)
        if 'deuce' in score_str_lower or '40-40' in score_str:
            base_pressure += 3
        
        # Check for break point (critical)
        if 'break point' in score_str_lower:
            base_pressure += 4
        
        # Check for close scores (30-30, 40-30, 30-40)
        if '30-30' in score_str or '40-30' in score_str or '30-40' in score_str:
            base_pressure += 2
        
        # Check for advantage situations
        if 'ad-' in score_str_lower or '-ad' in score_str_lower:
            base_pressure += 3
        
        # Check for critical game scores (5-5, 6-5, 5-6 in games)
        import re
        games_patterns = re.findall(r'\b(\d+)-(\d+)\b', score_str)
        for g1, g2 in games_patterns:
            g1_int, g2_int = int(g1), int(g2)
            # Close game scores at end of set
            if (g1_int >= 5 and g2_int >= 5):
                base_pressure += 2
                break
        
        return min(base_pressure, 10)
    
    def _extract_winner_from_point(self, point_dict: Dict) -> Optional[str]:
        """
        Extract the winner of a point from the point description.
        Returns player name or None if not found.
        """
        description = point_dict.get('description', '') or point_dict.get('point_text', '')
        
        # Look for [Point won by: Player Name] tag
        import re
        winner_match = re.search(r'\[Point won by:\s*([^\]]+)\]', description, re.IGNORECASE)
        if winner_match:
            return winner_match.group(1).strip()
        
        # Look for outcomes that indicate winner
        server = point_dict.get('server', '')
        returner = point_dict.get('returner', '')
        
        desc_lower = description.lower()
        
        # Outcomes that indicate server won
        if any(term in desc_lower for term in ['ace', 'service winner', 'double fault']):
            if 'double fault' in desc_lower:
                return returner  # Returner wins on double fault
            return server
        
        # Look for "winner" or "error" near player names
        # This is a simple heuristic - may need refinement
        if 'winner' in desc_lower:
            # Try to determine who hit the winner
            # If it's the last shot in rally, we need more context
            pass
        
        return None
    
    def _enrich_point_data(self):
        """
        Runs ONCE after loading data. Adds 'context', 'pressure', and 'tactics' to every point.
        Turns 'Hard' dynamic questions into 'Easy' static filters.
        
        This enrichment allows queries like:
        - "Did X serve worse after long rallies?" -> filter(prev_rally_length > 15)
        - "Who played better on big points?" -> filter(is_pressure_point == True)
        - "How effective was Serve + Forehand?" -> filter(serve_plus_one_shot == 'Forehand')
        """
        if not self.point_by_point:
            print("[ENRICH] No point-by-point data to enrich")
            return
        
        print("[ENRICH] Running Data Enrichment Pass...")
        
        # State trackers
        prev_rally_length = 0
        prev_winner = None
        match_cumulative_shots = 0
        points_in_current_set = 0
        current_set_score = None
        
        for i, point in enumerate(self.point_by_point):
            # Track which set we're in
            score_str = point.get('score', '')
            if score_str and score_str != current_set_score:
                # Extract set score (first part of score string, e.g., "2-2" from "2-2 6-6 0-0")
                import re
                set_match = re.match(r'(\d+-\d+)', score_str)
                if set_match:
                    new_set_score = set_match.group(1)
                    if new_set_score != current_set_score:
                        current_set_score = new_set_score
                        points_in_current_set = 0  # Reset for new set
            
            points_in_current_set += 1
            
            # 1. Parse rally to get shot count
            rally_shots = self._parse_rally_sequence(
                point.get('description', ''),
                point.get('server', ''),
                point.get('returner', '')
            )
            
            # Count actual shots (exclude faults and lets)
            actual_shots = [s for s in rally_shots if s.get('outcome') not in ['FAULT', 'LET']]
            rally_len = len(actual_shots)
            
            # 1b. Compute and store error_player (needed for error metrics filtering)
            _, _, error_player = self._determine_point_winner(
                actual_shots, 
                point.get('server', ''), 
                point.get('returner', ''),
                return_details=True
            )
            point['error_player'] = error_player or ''
            
            # 2. Extract winner for momentum tracking
            winner = self._extract_winner_from_point(point)
            
            # 3. Add CONTEXT (Fatigue/History/Momentum)
            point['context'] = {
                'prev_rally_length': prev_rally_length,
                'match_cumulative_shots': match_cumulative_shots,  # Proxy for fatigue
                'points_in_set': points_in_current_set,
                'is_momentum_swing': (prev_winner is not None and prev_winner != winner) if winner else False
            }
            
            # 4. Add PRESSURE (Score State) and SITUATIONS
            score_tightness = self._calculate_pressure_index(score_str)
            is_tiebreak = self._is_tiebreak_point(score_str)
            
            # Identify all situations from score (stored for fast access)
            situations = {
                'is_break_point': self._is_break_point_score(score_str),
                'is_game_point': self._is_game_point_score(score_str),
                'is_set_point': self._is_set_point_score(score_str),
                'is_match_point': self._is_match_point_score(score_str),
                'is_deuce': self._is_deuce_score(score_str),
                'is_tiebreak': is_tiebreak,
                'court_side': self._determine_court_side(score_str)
            }
            
            point['pressure'] = {
                'score_tightness': score_tightness,  # 0 (easy) to 10 (critical)
                'is_pressure_point': score_tightness >= 7,  # High-pressure threshold
                'is_critical': score_tightness >= 7 or situations['is_break_point'] or situations['is_match_point'],
                'is_tiebreak': is_tiebreak
            }
            
            # Store situations for fast filtering (computed once during enrichment)
            point['situation'] = situations
            
            # 5. Add SEQUENCE/TACTICS (Serve + 1, Return + 1)
            # Pre-calculate the "Serve + 1" and "Return + 1" shots
            tactics = {
                'serve_plus_one_shot': None,
                'serve_plus_one_outcome': None,
                'return_plus_one_shot': None,
                'return_plus_one_outcome': None,
                'rally_length': rally_len
            }
            
            if len(actual_shots) >= 3:
                # Shot 0=Serve, 1=Return, 2=Server's next shot (Serve+1)
                serve_plus_one = actual_shots[2]
                tactics['serve_plus_one_shot'] = serve_plus_one.get('description')
                tactics['serve_plus_one_outcome'] = serve_plus_one.get('outcome')
            
            if len(actual_shots) >= 4:
                # Shot 3=Returner's next shot after return (Return+1)
                return_plus_one = actual_shots[3]
                tactics['return_plus_one_shot'] = return_plus_one.get('description')
                tactics['return_plus_one_outcome'] = return_plus_one.get('outcome')
            
            point['tactics'] = tactics
            
            # Update state for NEXT point
            prev_rally_length = rally_len
            match_cumulative_shots += rally_len
            if winner:
                prev_winner = winner
        
        print(f"[ENRICH] [OK] Enriched {len(self.point_by_point)} points with:")
        print(f"         - Context (fatigue, momentum, set position)")
        print(f"         - Pressure (tightness index, critical points)")
        print(f"         - Tactics (serve+1, return+1, rally length)")
        
        # Now build the complete filter inventory
        self._build_match_filter_inventory()
    
    def _build_match_filter_inventory(self):
        """
        CRITICAL: Build complete inventory of ALL filterable values from THIS match.
        
        This is the USER's proposed architecture:
        1. Traverse ALL points ONCE at load time
        2. Extract ALL metadata from EVERY shot
        3. Build a complete "filter set" of what actually exists
        4. LLM maps questions to this KNOWN filter set
        
        Benefits:
        - LLM knows exactly what's available (no guessing)
        - Filter values are ground truth from actual data
        - Fast queries (no parsing at query time)
        - Handles complex shots (serve+1, at-net volleys, etc.)
        """
        print("\n[INVENTORY] Building complete match filter inventory...")
        
        # Initialize inventory with sets (for unique values)
        inventory = {
            # === NEW TAXONOMY (primary) ===
            'shot_phases': set(),           # serve, return, rally, net
            'contact_types': set(),         # groundstroke, volley, half_volley, swinging_volley, overhead
            'spins': set(),                 # slice, flat, topspin
            'intents': set(),               # approach, drop_shot, lob, passing_shot, winner_attempt
            'locations': set(),             # baseline, mid_court, net, service_line
            
            # === CORE DIMENSIONS ===
            'shot_types': set(),            # forehand, backhand, serve, overhead
            'directions': set(),            # crosscourt, down_the_line, inside_out, inside_in, down_the_middle
            'depths': set(),                # shallow, deep, very_deep
            'serve_targets': set(),         # wide, body, t
            'outcomes': set(),              # winner, unforced_error, forced_error, ace, etc.
            
            # === LEGACY (read-only, derived - never queried directly) ===
            'spin_types': set(),            # LEGACY: use 'spins' instead (still collected for compat)
            'court_positions': set(),       # LEGACY: use 'locations' instead (still collected for compat)
            'net_play_types': set(),        # LEGACY: derive from location=net + contact_type (read-only)
            
            # === SERVE SPECIFICS ===
            'serve_numbers': set(),         # 1, 2
            
            # === COURT/SITUATION ===
            'court_sides': set(),           # ad, deuce
            'sets_played': set(),           # 1, 2, 3, 4, 5
            
            # === PATTERNS (complex - serve+1, return+1) ===
            'serve_plus_one_patterns': set(),  # e.g., "serve_wide -> forehand_crosscourt"
            'serve_plus_one_shot_types': set(),
            'return_plus_one_patterns': set(),
            
            # === OUTCOME ANALYSIS ===
            'winner_shot_types': set(),
            'error_shot_types': set(),
            
            # === RALLY CATEGORIES ===
            'rally_categories': set(),      # 1-3, 4-6, 7-9, 10+
            
            # === COMBINED TAGS (for complex shots) ===
            'combined_shot_tags': set(),
            
            # === PLAYERS ===
            'players': set(),
            
            # === PRESSURE LEVELS ===
            'pressure_levels': set(),       # low, medium, high
        }
        
        # Counters for statistics
        stats = {
            'total_points': 0,
            'total_shots': 0,
            'aces': 0,
            'double_faults': 0,
            'winners': 0,
            'unforced_errors': 0,
            'forced_errors': 0,
        }
        
        for point in self.point_by_point:
            stats['total_points'] += 1
            
            # Get full metadata for this point (uses cached if available)
            if '_metadata' in point:
                metadata = point['_metadata']
            else:
                metadata = self._get_point_metadata(point)
                point['_metadata'] = metadata  # Cache it
            
            # === EXTRACT PLAYERS ===
            server = metadata.get('server', '')
            returner = metadata.get('returner', '')
            if server:
                inventory['players'].add(server)
            if returner:
                inventory['players'].add(returner)
            
            # === EXTRACT SET AND GAME INFO ===
            set_num = metadata.get('set_number')
            if set_num:
                inventory['sets_played'].add(set_num)
            
            # Track games in set and overall
            game_in_set = metadata.get('game_number_in_set')
            if game_in_set and 'games_per_set' not in inventory:
                inventory['games_per_set'] = {}
            if game_in_set and set_num:
                if set_num not in inventory.get('games_per_set', {}):
                    inventory['games_per_set'] = inventory.get('games_per_set', {})
                    inventory['games_per_set'][set_num] = set()
                inventory['games_per_set'][set_num].add(game_in_set)
            
            # === EXTRACT COURT SIDE ===
            situation = metadata.get('situation', {})
            court_side = situation.get('court_side')
            if court_side:
                inventory['court_sides'].add(court_side)
            
            # === EXTRACT SERVE INFO ===
            serve_info = metadata.get('serve_info', {})
            serve_target = serve_info.get('serve_target')
            if serve_target:
                inventory['serve_targets'].add(serve_target)
            serve_num = serve_info.get('serve_number')
            if serve_num:
                inventory['serve_numbers'].add(serve_num)
            
            # Track outcomes
            if serve_info.get('is_ace'):
                stats['aces'] += 1
                inventory['outcomes'].add('ace')
            if serve_info.get('is_double_fault'):
                stats['double_faults'] += 1
                inventory['outcomes'].add('double_fault')
            
            # === EXTRACT RALLY CATEGORY ===
            rally_cat = metadata.get('rally_category')
            if rally_cat:
                inventory['rally_categories'].add(rally_cat)
            
            # === EXTRACT PRESSURE LEVEL ===
            pressure = point.get('pressure', {})
            tightness = pressure.get('score_tightness', 0)
            if tightness <= 3:
                inventory['pressure_levels'].add('low')
            elif tightness <= 6:
                inventory['pressure_levels'].add('medium')
            else:
                inventory['pressure_levels'].add('high')
            
            # === PROCESS EACH SHOT IN RALLY ===
            # Metadata uses 'all_shots' key (not 'actual_shots')
            actual_shots = metadata.get('all_shots', metadata.get('actual_shots', []))
            for shot_idx, shot in enumerate(actual_shots):
                stats['total_shots'] += 1
                
                # === NEW TAXONOMY COLLECTION ===
                shot_phase = shot.get('shot_phase')
                if shot_phase:
                    inventory['shot_phases'].add(shot_phase)
                
                contact_type = shot.get('contact_type')
                if contact_type:
                    inventory['contact_types'].add(contact_type)
                
                spin = shot.get('spin')
                if spin:
                    inventory['spins'].add(spin)
                    inventory['spin_types'].add(spin)  # LEGACY
                
                intent = shot.get('intent')
                if intent:
                    inventory['intents'].add(intent)
                
                location = shot.get('location')
                if location:
                    inventory['locations'].add(location)
                    inventory['court_positions'].add(location)  # LEGACY
                
                # === CORE DIMENSIONS ===
                shot_type = shot.get('shot_type')
                if shot_type:
                    inventory['shot_types'].add(shot_type)
                
                direction = shot.get('direction')
                if direction:
                    inventory['directions'].add(direction)
                
                depth = shot.get('depth')
                if depth:
                    inventory['depths'].add(depth)
                
                # === DEPRECATED: SHOT MODIFIERS (no longer collected in inventory) ===
                # shot_modifiers is deprecated - use contact_type/spin/intent instead
                # Still included in shot metadata for backward compatibility only
                
                # === BUILD COMBINED SHOT TAGS ===
                # For complex shots like "forehand volley at net crosscourt"
                combined_tag = self._build_combined_shot_tag(shot)
                if combined_tag:
                    inventory['combined_shot_tags'].add(combined_tag)
                
                # === LEGACY: NET PLAY TRACKING (READ-ONLY, DERIVED - never queried directly) ===
                # This is for backward compatibility only. New queries should use location=net + contact_type
                # Derive net play type from location + contact_type + shot_type - GENERIC
                if location == 'net':
                    # Net contact types that can be combined with shot_type
                    net_contact_types = {'volley', 'overhead'}
                    
                    if contact_type in net_contact_types:
                        if shot_type:
                            net_type = f"{shot_type}_{contact_type}"
                        else:
                            net_type = contact_type
                    elif shot_type:
                        net_type = f"{shot_type}_at_net"  # e.g., "forehand_at_net", "backhand_at_net"
                    else:
                        net_type = 'net_play'
                    inventory['net_play_types'].add(net_type)
                
                # === OUTCOME TRACKING ===
                outcome = shot.get('outcome')
                if outcome:
                    outcome_key = outcome.lower().replace(' ', '_')
                    inventory['outcomes'].add(outcome_key)
                    
                    # Track stats using OUTCOME_CONFIG
                    outcome_config = self._get_outcome_config(outcome)
                    winning_shot_type = outcome_config.get('winning_shot_type', '')
                    is_positive = outcome_config.get('is_positive', True)
                    
                    # Track stats using winning_shot_type - GENERIC approach
                    # Use WINNER_TYPES set for winner detection
                    if winning_shot_type in self.WINNER_TYPES:
                        stats['winners'] += 1
                        if shot_type:
                            inventory['winner_shot_types'].add(shot_type)
                    elif 'unforced' in winning_shot_type:
                        stats['unforced_errors'] += 1
                        if shot_type:
                            inventory['error_shot_types'].add(shot_type)
                    elif 'forced' in winning_shot_type and 'unforced' not in winning_shot_type:
                        stats['forced_errors'] += 1
            
            # === SERVE+1 PATTERN ===
            serve_plus_one = metadata.get('serve_plus_one', {})
            sp1_shot_type = serve_plus_one.get('shot_type')
            sp1_direction = serve_plus_one.get('direction')
            if sp1_shot_type:
                inventory['serve_plus_one_shot_types'].add(sp1_shot_type)
                # Build pattern string
                pattern = f"serve -> {sp1_shot_type}"
                if sp1_direction:
                    pattern += f"_{sp1_direction}"
                inventory['serve_plus_one_patterns'].add(pattern)
        
        # Convert sets to sorted lists for JSON serialization
        self.match_filter_inventory = {
            # === NEW TAXONOMY (primary) ===
            'shot_phases': sorted(inventory['shot_phases']),
            'contact_types': sorted(inventory['contact_types']),
            'spins': sorted(inventory['spins']),
            'intents': sorted(inventory['intents']),
            'locations': sorted(inventory['locations']),
            
            # === CORE DIMENSIONS ===
            'shot_types': sorted(inventory['shot_types']),
            'directions': sorted(inventory['directions']),
            'depths': sorted(inventory['depths']),
            
            # === LEGACY (backward compatibility - read-only, never queried directly) ===
            'spin_types': sorted(inventory['spin_types']),  # LEGACY: use 'spins'
            'court_positions': sorted(inventory['court_positions']),  # LEGACY: use 'locations'
            'net_play_types': sorted(inventory['net_play_types']),  # LEGACY: derive from location=net + contact_type
            'serve_targets': sorted(inventory['serve_targets']),
            'serve_numbers': sorted(inventory['serve_numbers']),
            'court_sides': sorted(inventory['court_sides']),
            'sets_played': sorted(inventory['sets_played']),
            'rally_categories': sorted(inventory['rally_categories']),
            'pressure_levels': sorted(inventory['pressure_levels']),
            'outcomes': sorted(inventory['outcomes']),
            'winner_shot_types': sorted(inventory['winner_shot_types']),
            'error_shot_types': sorted(inventory['error_shot_types']),
            'serve_plus_one_shot_types': sorted(inventory['serve_plus_one_shot_types']),
            'serve_plus_one_patterns': sorted(inventory['serve_plus_one_patterns']),
            'combined_shot_tags': sorted(list(inventory['combined_shot_tags'])[:50]),  # Limit to prevent huge list
            'players': sorted(inventory['players']),
            # === NORMALIZATION INFO ===
            # Aliases that map to canonical forms (user can use any, system normalizes)
            'common_aliases': {
                'directions': {'cc': 'crosscourt', 'xc': 'crosscourt', 'dtl': 'down_the_line', 'dtm': 'down_the_middle', 'io': 'inside_out', 'ii': 'inside_in'},
                'shots': {'fh': 'forehand', 'bh': 'backhand'},
                'outcomes': {'ue': 'unforced_error', 'fe': 'forced_error', 'df': 'double_fault'},
                'serve_targets': {'down the t': 't', 'center': 't', 'middle': 't', 'out wide': 'wide', 'to body': 'body', 'at body': 'body', 'jam': 'body'},
            },
            # Hierarchies - supersets that include subsets
            'hierarchies': {
                'volley': 'includes swinging_volley, half_volley, drop_volley',
                'net_shot': 'includes all volleys + overhead',
                'errors': 'includes unforced_error, forced_error, double_fault',
                'winners_all': 'includes winner, ace, service_winner',
            },
        }
        
        # Store stats
        self.match_stats_summary = stats
        
        # Print inventory summary
        print(f"[INVENTORY] [OK] Built filter inventory from {stats['total_points']} points, {stats['total_shots']} shots:")
        print(f"            === NEW TAXONOMY ===")
        print(f"            Shot Phases: {self.match_filter_inventory['shot_phases']}")
        print(f"            Contact Types: {self.match_filter_inventory['contact_types']}")
        print(f"            Spins: {self.match_filter_inventory['spins']}")
        print(f"            Intents: {self.match_filter_inventory['intents']}")
        print(f"            Locations: {self.match_filter_inventory['locations']}")
        print(f"            === CORE DIMENSIONS ===")
        print(f"            Shot Types: {self.match_filter_inventory['shot_types']}")
        print(f"            Directions: {self.match_filter_inventory['directions']}")
        print(f"            Serve Targets: {self.match_filter_inventory['serve_targets']}")
        print(f"            === LEGACY (read-only, derived) ===")
        print(f"            Net Play: {self.match_filter_inventory['net_play_types']}")
        print(f"            === OTHER ===")
        print(f"            Serve+1 Types: {self.match_filter_inventory['serve_plus_one_shot_types']}")
        print(f"            Sets Played: {self.match_filter_inventory['sets_played']}")
        print(f"            Rally Categories: {self.match_filter_inventory['rally_categories']}")
        print(f"            Stats: {stats['aces']} aces, {stats['double_faults']} DFs, "
              f"{stats['winners']} winners, {stats['unforced_errors']} UEs")
    
    def _build_combined_shot_tag(self, shot: Dict) -> str:
        """
        Build a combined tag for complex shots.
        e.g., "forehand volley at net crosscourt" -> "forehand_volley_net_crosscourt"
        
        This allows filtering/searching by any combination of attributes.
        """
        parts = []
        
        shot_type = shot.get('shot_type')
        if shot_type:
            parts.append(shot_type)
        
        # Add modifiers
        modifiers = shot.get('shot_modifiers', [])
        modifier = shot.get('shot_modifier')
        if modifier and modifier not in modifiers:
            modifiers = [modifier] + modifiers
        
        for mod in modifiers:
            if mod and mod != shot_type:
                parts.append(mod)
        
        # Add position
        if shot.get('at_net') or shot.get('court_position') == 'net':
            if 'net' not in parts and 'volley' not in parts:
                parts.append('net')
        
        # Add direction
        direction = shot.get('direction')
        if direction:
            parts.append(direction)
        
        # Add depth
        depth = shot.get('depth')
        if depth:
            parts.append(depth)
        
        return '_'.join(parts) if len(parts) >= 2 else None
    
    def get_available_filters(self) -> Dict:
        """
        Return the complete filter inventory for this match.
        
        This is what the LLM should use to understand what's available to filter on.
        """
        if not hasattr(self, 'match_filter_inventory') or not self.match_filter_inventory:
            return {"error": "Filter inventory not built. Run _build_match_filter_inventory() first."}
        
        return {
            'match': f"{self.player1} vs {self.player2}",
            'total_points': self.match_stats_summary.get('total_points', 0),
            'total_shots': self.match_stats_summary.get('total_shots', 0),
            'available_filters': self.match_filter_inventory,
            'quick_stats': self.match_stats_summary
        }

    def _compute_leaf_metrics(self, points: list, classification: Dict) -> Dict:
        """
        Compute metrics at a leaf node.
        
        UNIFIED PATH: Always track BOTH players. Player filter applied at end.
        This ensures single-player and both-player queries use identical calculation logic.
        """
        
        metrics = classification.get('metrics', ['points_won'])
        filters = classification.get('filters', {})
        player_filter = filters.get('player')
        
        player1 = self.player1
        player2 = self.player2
        
        # UNIFIED: Always track both players - player filter applied at END
        # No more is_both_players branching in the calculation logic
        
        results = {
            'total_points': len(points),
            'player1_wins': 0,
            'player2_wins': 0,
            'player1_name': player1,
            'player2_name': player2,
            'metrics': {},
            'per_player_metrics': {}  # ALWAYS populated - for ALL queries
        }
        
        # ALWAYS initialize per_player_metrics for ALL metrics
        for metric in metrics:
            results['metrics'][metric] = {'count': 0, 'examples': []}
            results['per_player_metrics'][metric] = {
                'player1': {'count': 0, 'total': 0},
                'player2': {'count': 0, 'total': 0}
            }
        
        # === GAME-LEVEL AND SET-LEVEL METRICS ===
        # Games and sets aggregate from points - handle separately
        game_level_metrics = {'games_won', 'games_lost', 'service_games_held', 'breaks', 'sets_won'}
        active_game_metrics = [m for m in metrics if m in game_level_metrics]
        
        if active_game_metrics:
            # Aggregate games from points in this branch
            game_results = self._aggregate_games_from_points(points, filters)
            
            # UNIFIED: ALWAYS track both players for game-level metrics too
            for metric in active_game_metrics:
                if metric == 'games_won':
                    results['per_player_metrics'][metric]['player1']['count'] = game_results.get('player1_games', 0)
                    results['per_player_metrics'][metric]['player1']['total'] = game_results.get('total_games', 0)
                    results['per_player_metrics'][metric]['player2']['count'] = game_results.get('player2_games', 0)
                    results['per_player_metrics'][metric]['player2']['total'] = game_results.get('total_games', 0)
                    results['metrics'][metric]['count'] = game_results.get('player1_games', 0) + game_results.get('player2_games', 0)
                elif metric == 'service_games_held':
                    results['per_player_metrics'][metric]['player1']['count'] = game_results.get('player1_holds', 0)
                    results['per_player_metrics'][metric]['player1']['total'] = game_results.get('player1_service_games', 0)
                    results['per_player_metrics'][metric]['player2']['count'] = game_results.get('player2_holds', 0)
                    results['per_player_metrics'][metric]['player2']['total'] = game_results.get('player2_service_games', 0)
                    results['metrics'][metric]['count'] = game_results.get('player1_holds', 0) + game_results.get('player2_holds', 0)
                elif metric == 'breaks':
                    results['per_player_metrics'][metric]['player1']['count'] = game_results.get('player1_breaks', 0)
                    results['per_player_metrics'][metric]['player1']['total'] = game_results.get('player2_service_games', 0)  # Opp's service games
                    results['per_player_metrics'][metric]['player2']['count'] = game_results.get('player2_breaks', 0)
                    results['per_player_metrics'][metric]['player2']['total'] = game_results.get('player1_service_games', 0)  # Opp's service games
                    results['metrics'][metric]['count'] = game_results.get('player1_breaks', 0) + game_results.get('player2_breaks', 0)
                elif metric == 'sets_won':
                    results['per_player_metrics'][metric]['player1']['count'] = game_results.get('player1_sets', 0)
                    results['per_player_metrics'][metric]['player1']['total'] = game_results.get('total_sets', 0)
                    results['per_player_metrics'][metric]['player2']['count'] = game_results.get('player2_sets', 0)
                    results['per_player_metrics'][metric]['player2']['total'] = game_results.get('total_sets', 0)
                    results['metrics'][metric]['count'] = game_results.get('player1_sets', 0) + game_results.get('player2_sets', 0)
        
        for point_data in points:
            point_text = point_data.get('point_text', point_data.get('description', ''))
            server = point_data.get('server', '')
            returner = point_data.get('returner', '')
            
            # CRITICAL: Extract point winner from [Point won by: Player] tag in NL file
            # This is the AUTHORITATIVE source - already computed during NL generation
            point_winner = None
            winner_match = re.search(r'\[Point won by:\s*([^\]]+)\]', point_text)
            if winner_match:
                point_winner = winner_match.group(1).strip()
            
            # Parse rally for shot counting and other analysis
            rally_shots = self._parse_rally_sequence(point_text, server, returner)
            actual_shots = [s for s in rally_shots if s.get('outcome') != 'FAULT']
            
            # UNIFIED: Use _determine_point_winner for shot type determination
            # Only use it for shot_type/error_player if point_winner not already from [Point won by:] tag
            _, winning_shot_type, error_player = self._determine_point_winner(
                actual_shots, server, returner, return_details=True
            )
            
            # NOTE: error_player is already stored during _enrich_point_data at load time
            
            # Count wins (using robust name matching)
            if point_winner:
                if player1 and self._names_match_robust(player1, point_winner):
                    results['player1_wins'] += 1
                elif player2 and self._names_match_robust(player2, point_winner):
                    results['player2_wins'] += 1
            
            # Track metrics
            # Get serve_number from point metadata (1 = first serve in, 2 = had to use 2nd serve)
            serve_info = point_data.get('serve_info', {})
            serve_number = serve_info.get('serve_number', 1) if serve_info else 1
            # Fallback: detect from text if no serve_info metadata
            if not serve_info or serve_number is None:
                has_second_serve = '2nd serve' in point_text.lower() or 'second serve' in point_text.lower()
                serve_number = 2 if has_second_serve else 1
            
            point_data_for_metric = {
                'point_text': point_text,
                'rally_length': len(actual_shots),
                'server': server,
                'returner': returner,
                'error_player': error_player,
                'point_winner': point_winner,
                'serve_number': serve_number
            }
            
            for metric in metrics:
                # === SHOT-LEVEL METRICS (count individual shots, not point outcomes) ===
                # Dynamic shot counting based on metadata - no hard-coded shot types
                # Handle 'shot_count', 'shot_count_1', 'shots_count', etc. (for multiple metrics_parsed)
                is_shot_count_metric = (metric.startswith('shot_count') or 
                                       metric.startswith('shots_count') or 
                                       metric in ['shots', 'shot'])
                if is_shot_count_metric:
                    # Get filters - check metric_filters first (from metrics_parsed), then global
                    metric_filter_data = classification.get('metric_filters', {}).get(metric, {})
                    per_metric_filters = metric_filter_data.get('filters', {}) if metric_filter_data else {}
                    global_filters = classification.get('filters', {})
                    
                    # Per-metric filters override global filters
                    shot_type_filter = per_metric_filters.get('shot_type') or global_filters.get('shot_type')
                    direction_filter = per_metric_filters.get('direction') or global_filters.get('direction')
                    metric_player_filter = per_metric_filters.get('player') or player_filter
                    group_by = classification.get('group_by')
                    
                    # When group_by='shot_type', we need to count shots BY TYPE
                    # This is different from point-level grouping!
                    if group_by == 'shot_type':
                        # Initialize per-shot-type counts if not present
                        if 'shot_counts_by_type' not in results:
                            results['shot_counts_by_type'] = {}
                        
                        # Debug first point only
                        if not hasattr(self, '_shot_count_debug_done'):
                            self._shot_count_debug_done = True
                            print(f"[SHOT-COUNT-DEBUG] metric='{metric}', metric_player_filter='{metric_player_filter}', shot_type_filter='{shot_type_filter}', group_by='{group_by}'")
                            print(f"[SHOT-COUNT-DEBUG] First point has {len(actual_shots)} shots")
                            if actual_shots:
                                print(f"[SHOT-COUNT-DEBUG] Sample shot: {actual_shots[0]}")
                        
                        # Also track detailed breakdown by contact_type and intent
                        if 'shot_breakdown' not in results:
                            results['shot_breakdown'] = {}
                        
                        for shot in actual_shots:
                            shot_player = shot.get('player', '')
                            shot_type = (shot.get('shot_type') or '').lower()
                            shot_direction = shot.get('direction', '')
                            contact_type = shot.get('contact_type', 'groundstroke')
                            intent = shot.get('intent', '')
                            
                            # Skip if no shot_type
                            if not shot_type:
                                continue
                            
                            # Apply player filter - only count this player's shots
                            if metric_player_filter:
                                match = self._names_match_robust(metric_player_filter, shot_player)
                                # Debug first few shots
                                if not hasattr(self, '_shot_player_debug_count'):
                                    self._shot_player_debug_count = 0
                                if self._shot_player_debug_count < 5:
                                    self._shot_player_debug_count += 1
                                    print(f"[SHOT-PLAYER-DEBUG] filter='{metric_player_filter}' vs shot_player='{shot_player}' -> match={match}")
                                if not match:
                                    continue
                            
                            # Apply shot_type filter from metric_filters (for metrics_parsed)
                            if shot_type_filter and shot_type != shot_type_filter.lower():
                                continue
                            
                            # Apply direction filter if present
                            if direction_filter and shot_direction != direction_filter:
                                continue
                            
                            # Count by shot type (simple total)
                            if shot_type not in results['shot_counts_by_type']:
                                results['shot_counts_by_type'][shot_type] = 0
                            results['shot_counts_by_type'][shot_type] += 1
                            
                            # Track detailed breakdown by contact_type + intent (they don't overlap)
                            if shot_type not in results['shot_breakdown']:
                                results['shot_breakdown'][shot_type] = {
                                    'groundstroke': 0,
                                    'volley': 0,
                                    'swinging_volley': 0,
                                    'half_volley': 0,
                                    'overhead': 0,
                                    'drop_shot': 0,
                                    'lob': 0
                                }
                            
                            # Categorize by contact_type and intent
                            # NOTE: Approach shots are included in groundstrokes (not a separate category)
                            if intent in ['drop_shot', 'lob']:
                                results['shot_breakdown'][shot_type][intent] += 1
                            elif contact_type in ['volley', 'swinging_volley', 'half_volley', 'overhead']:
                                results['shot_breakdown'][shot_type][contact_type] += 1
                            else:  # Default to groundstroke (includes approach shots)
                                results['shot_breakdown'][shot_type]['groundstroke'] += 1
                        
                        continue
                    
                    # Standard shot_count (no grouping) - count all shots matching filters
                    # If there's a shot_type filter, populate shot_counts_by_type for formatting
                    if shot_type_filter and 'shot_counts_by_type' not in results:
                        results['shot_counts_by_type'] = {}
                    
                    shot_count = 0
                    for shot in actual_shots:
                        shot_player = shot.get('player', '')
                        shot_type_val = (shot.get('shot_type') or '').lower()
                        shot_direction = shot.get('direction', '')
                        
                        # Apply player filter (use metric-specific if available)
                        if metric_player_filter and not self._names_match_robust(metric_player_filter, shot_player):
                            continue
                        
                        # Apply shot type filter dynamically from classification
                        if shot_type_filter and shot_type_val != shot_type_filter.lower():
                            continue
                        
                        # Apply direction filter if present
                        if direction_filter and shot_direction != direction_filter:
                            continue
                        
                        shot_count += 1
                        
                        # If filtering by shot_type, track in shot_counts_by_type for formatting
                        if shot_type_filter:
                            if shot_type_val not in results['shot_counts_by_type']:
                                results['shot_counts_by_type'][shot_type_val] = 0
                            results['shot_counts_by_type'][shot_type_val] += 1
                    
                    results['metrics'][metric]['count'] += shot_count
                    continue
                
                # === UNIFIED PATH: ALWAYS track both players ===
                # Player filter is applied at the END, not during tracking
                
                # GENERIC N-METRIC: Check if this metric has its own filter set
                metric_filters_map = classification.get('metric_filters', {})
                metric_specific = metric_filters_map.get(metric, {})
                
                if metric_specific and metric_specific.get('filters'):
                    # Create a modified classification with metric-specific filters
                    # MERGE: start with global filters, then OVERRIDE with metric-specific
                    merged_filters = dict(filters)  # Copy global filters
                    merged_filters.update({k: v for k, v in metric_specific['filters'].items() if v is not None})
                    
                    metric_classification = dict(classification)
                    metric_classification['filters'] = merged_filters
                    
                    # Use the original metric name (not the unique key)
                    actual_metric = metric_specific.get('metric', metric)
                    
                    self._track_per_player_metric(
                        actual_metric, results, point_text, actual_shots,
                        point_winner, winning_shot_type, server,
                        player1, player2, point_data_for_metric, metric_classification
                    )
                else:
                    # No metric-specific filters, use global classification
                    self._track_per_player_metric(
                        metric, results, point_text, actual_shots,
                        point_winner, winning_shot_type, server,
                        player1, player2, point_data_for_metric, classification
                    )
        
        # === UNIFIED: Calculate per-player percentages for ALL metrics ===
        for metric in results.get('per_player_metrics', {}):
            p1_data = results['per_player_metrics'][metric]['player1']
            p2_data = results['per_player_metrics'][metric]['player2']
            
            p1_data['pct'] = round(100 * p1_data['count'] / p1_data['total'], 1) if p1_data['total'] > 0 else 0
            p2_data['pct'] = round(100 * p2_data['count'] / p2_data['total'], 1) if p2_data['total'] > 0 else 0
        
        # Calculate overall point win percentages
        if results['total_points'] > 0:
            results['player1_pct'] = round(100 * results['player1_wins'] / results['total_points'], 1)
            results['player2_pct'] = round(100 * results['player2_wins'] / results['total_points'], 1)
        else:
            results['player1_pct'] = 0
            results['player2_pct'] = 0
        
        # === PLAYER FILTER: Extract single player's data if filtered ===
        # This is the ONLY place where player filter matters - at the END
        if player_filter and player_filter.lower() != 'both':
            # Determine which player was requested
            is_player1 = player1 and self._names_match_robust(player_filter, player1)
            player_key = 'player1' if is_player1 else 'player2'
            
            # Copy that player's per_player_metrics to results['metrics'] for display
            for metric in results.get('per_player_metrics', {}):
                player_data = results['per_player_metrics'][metric][player_key]
                results['metrics'][metric]['count'] = player_data['count']
                results['metrics'][metric]['total'] = player_data['total']
                results['metrics'][metric]['pct'] = player_data['pct']
                # _serve_total is same as total (unified structure)
                results['metrics'][metric]['_serve_total'] = player_data['total']
        
        # DEBUG: Show shot counts if we have them
        if 'shot_counts_by_type' in results and results['shot_counts_by_type']:
            total = sum(results['shot_counts_by_type'].values())
            print(f"[DEBUG] Shot counts by type: {results['shot_counts_by_type']} (total: {total})")
        
        return results
    
    def _track_per_player_metric(self, metric: str, results: Dict, point_text: str, 
                                  actual_shots: list, point_winner: str, winning_shot_type: str,
                                  server: str, player1: str, player2: str, 
                                  point_data_for_metric: Dict, classification: Dict = None) -> None:
        """
        UNIFIED CONFIG-DRIVEN metric tracking for ALL metrics.
        
        ONE code path handles ALL metrics - the config defines:
        - player_role: whose metric (server/returner/winner/error/both)
        - total_filter: which points count toward the denominator
        - count_filter: which points count toward the numerator
        - keywords: optional text patterns to match
        """
        point_lower = point_text.lower()
        filters = classification.get('filters', {}) if classification else {}
        role_filter = filters.get('role')
        returner = point_data_for_metric.get('returner', '')
        error_player = point_data_for_metric.get('error_player', '')
        
        # Generic helper: safely convert any value to lowercase string, handling None
        def safe_lower(val):
            return str(val or '').lower()
        
        # Get serve number from point data
        serve_number = point_data_for_metric.get('serve_number', 1)
        if serve_number is None or serve_number == 0:
            has_second_serve = '2nd serve' in point_lower or 'second serve' in point_lower
            serve_number = 2 if has_second_serve else 1
        
        # === GENERIC FILTER CHECKING - Works for ALL filter types ===
        # Tree traversal filters with global filters, but metric-specific filters need per-metric checks
        # This ensures each metric only counts points matching ITS specific filters
        
        # DEBUG: Track point for detailed filter checking (limit to first 3 points)
        point_num = point_data_for_metric.get('point_number', '?')
        debug_prefix = f"[METRIC-FILTER] Point {point_num} | Metric: {metric}"
        
        # Track debug output count per metric to limit spam
        debug_key = f"_metric_filter_debug_{metric}"
        if not hasattr(self, debug_key):
            setattr(self, debug_key, 0)
        debug_count = getattr(self, debug_key)
        should_debug = debug_count < 3
        
        # serve_number filter
        serve_number_filter = filters.get('serve_number')
        if serve_number_filter is not None:
            if serve_number != serve_number_filter:
                if should_debug:
                    print(f"{debug_prefix} | FILTERED: serve_number={serve_number} != filter={serve_number_filter}")
                return
            if should_debug:
                print(f"{debug_prefix} | ✓ serve_number={serve_number} matches filter={serve_number_filter}")
        
        # situation filter
        situation_filter = filters.get('situation')
        if situation_filter:
            point_situation = point_data_for_metric.get('situation', {})
            situation_key = f"is_{situation_filter}"
            situation_match = point_situation.get(situation_key, False) or point_data_for_metric.get(situation_key, False)
            if not situation_match:
                if should_debug:
                    print(f"{debug_prefix} | FILTERED: situation={situation_filter} not found (key={situation_key})")
                return
            if should_debug:
                print(f"{debug_prefix} | ✓ situation={situation_filter} matches")
        
        # Generic shot-based filter check (for shot_type, direction, court_zone, depth)
        # These filters check if any shot in the rally matches the filter value
        shot_based_filters = ['shot_type', 'direction', 'court_zone', 'depth']
        for filter_key in shot_based_filters:
            filter_val = filters.get(filter_key)
            if filter_val:
                filter_str = safe_lower(filter_val)
                # Special handling for shot_type: also check winning_shot_type
                if filter_key == 'shot_type' and winning_shot_type:
                    winning_match = filter_str in safe_lower(winning_shot_type)
                    if not winning_match:
                        shot_matches = any(safe_lower(shot.get(filter_key)) == filter_str for shot in actual_shots)
                        if not shot_matches:
                            shot_types_found = [safe_lower(s.get(filter_key) or '') for s in actual_shots if s.get(filter_key) is not None]
                            if should_debug:
                                print(f"{debug_prefix} | FILTERED: {filter_key}={filter_str} not found (winning={safe_lower(winning_shot_type)}, shots={shot_types_found})")
                            return
                        if should_debug:
                            print(f"{debug_prefix} | MATCH {filter_key}={filter_str} matches in rally shots (not winning shot)")
                    else:
                        if should_debug:
                            print(f"{debug_prefix} | ✓ {filter_key}={filter_str} matches winning_shot_type={safe_lower(winning_shot_type)}")
                else:
                    shot_matches = any(safe_lower(shot.get(filter_key) or '') == filter_str for shot in actual_shots)
                    if not shot_matches:
                        values_found = [safe_lower(s.get(filter_key) or '') for s in actual_shots if s.get(filter_key) is not None]
                        if should_debug:
                            print(f"{debug_prefix} | FILTERED: {filter_key}={filter_str} not found in shots (found={values_found})")
                        return
                    if should_debug:
                        print(f"{debug_prefix} | MATCH {filter_key}={filter_str} matches in rally shots")
        
        # Generic point-level string filter check (for court_side, serve_target)
        point_string_filters = ['court_side', 'serve_target']
        for filter_key in point_string_filters:
            filter_val = filters.get(filter_key)
            if filter_val:
                filter_str = safe_lower(filter_val)
                point_val = safe_lower(point_data_for_metric.get(filter_key))
                if point_val != filter_str:
                    if should_debug:
                        print(f"{debug_prefix} | FILTERED: {filter_key}={filter_str} != point_value={point_val}")
                    return
                if should_debug:
                    print(f"{debug_prefix} | ✓ {filter_key}={filter_str} matches point_value={point_val}")
        
        # set filter (exact match, not string comparison)
        set_filter = filters.get('set')
        if set_filter is not None:
            point_set = point_data_for_metric.get('set')
            if point_set != set_filter:
                if should_debug:
                    print(f"{debug_prefix} | FILTERED: set={set_filter} != point_set={point_set}")
                return
            if should_debug:
                print(f"{debug_prefix} | ✓ set={set_filter} matches point_set={point_set}")
        
        # DEBUG: Point passed all filters (only show first 3)
        active_filters = {k: v for k, v in filters.items() if v is not None}
        if should_debug:
            print(f"{debug_prefix} | *** PASSED ALL FILTERS: {active_filters} | Will count for metric")
            setattr(self, debug_key, debug_count + 1)
        
        # role filter is handled via player_role override below
        
        # Get config for this metric from CLASS CONSTANT (single source of truth)
        config = TennisChatAgentEmbeddingQALocal.METRIC_CONFIG.get(metric, {'player_role': 'both', 'total_filter': 'always', 'count_filter': 'won'})
        player_role = config['player_role']
        total_filter = config['total_filter']
        count_filter = config['count_filter']
        keywords = config.get('keywords', [])
        exclude_keywords = config.get('exclude_keywords', [])
        
        # Override player_role if role_filter is set (e.g., "as server") - GENERIC
        if role_filter and role_filter in self.ROLE_CONFIG:
            player_role = role_filter
        
        # Helper: check if keywords match
        def keywords_match():
            if not keywords:
                return True
            # Check that at least one keyword matches
            has_keyword = any(kw in point_lower for kw in keywords)
            # Check that NO exclude keywords match
            has_exclude = any(ex in point_lower for ex in exclude_keywords) if exclude_keywords else False
            return has_keyword and not has_exclude
        
        # Helper: check total filter condition
        def passes_total_filter():
            if total_filter == 'always':
                return True
            elif total_filter == 'first_serve':
                return serve_number == 1
            elif total_filter == 'second_serve':
                return serve_number == 2
            elif total_filter == 'on_match':
                return keywords_match()
            return True
        
        # Helper: check count filter condition for a specific player
        def passes_count_filter(player):
            if count_filter == 'always':
                return True
            elif count_filter == 'first_serve_in':
                return serve_number == 1
            elif count_filter == 'second_serve_in':
                return serve_number == 2 and 'double fault' not in point_lower
            elif count_filter == 'won':
                return point_winner and self._names_match_robust(player, point_winner)
            elif count_filter == 'on_match':
                return keywords_match()
            return True
        
        # === UNIFIED TRACKING LOOP - ONE PATH FOR ALL METRICS ===
        for player, player_key in [(player1, 'player1'), (player2, 'player2')]:
            if not player:
                continue
            
            # Determine if this player is relevant for this metric - GENERIC using ROLE_CONFIG
            is_relevant = False
            if player_role == 'both':
                is_relevant = True
            elif player_role == 'performer':
                # Special case: check if player performed the action in any shot
                for shot in actual_shots:
                    shot_desc = shot.get('description', '').lower()
                    shot_player = shot.get('player', '')
                    if self._names_match_robust(player, shot_player) and any(kw in shot_desc for kw in keywords):
                        is_relevant = True
                        break
            else:
                # GENERIC: Use ROLE_CONFIG to determine which player field to check
                role_config = self.ROLE_CONFIG.get(player_role, {})
                player_field = role_config.get('player_field', '')
                if player_field:
                    # Map player_field to actual player value
                    field_to_player = {
                        'server': server,
                        'returner': returner,
                        'point_winner': point_winner,
                        'error_player': error_player
                    }
                    target_player = field_to_player.get(player_field, '')
                    is_relevant = target_player and self._names_match_robust(player, target_player)
            
            if not is_relevant:
                continue
            
            # Check total filter - if passes, increment total
            if passes_total_filter():
                results['per_player_metrics'][metric][player_key]['total'] += 1
                
                # Check count filter - if passes, increment count
                if passes_count_filter(player):
                    results['per_player_metrics'][metric][player_key]['count'] += 1
    
    def _pre_filter_points_for_metric(self, points: list, metric: str, classification: Dict) -> list:
        """
        DEPRECATED: No longer used. Tree traversal handles all filtering.
        Pre-filtering was breaking percentage calculations.
        """
        filters = classification.get('filters', {})
        player_filter = filters.get('player')
        shot_type_filter = filters.get('shot_type') or filters.get('shot_base')
        direction_filter = filters.get('direction')
        shot_modifier_filter = filters.get('shot_modifier')
        
        # Metric configuration: (outcome_type, player_role, excluded_modifiers, excluded_directions)
        METRIC_CONFIG = {
            'winners': ('WINNER', 'winner', [], []),  # ALL winners (volleys, groundstrokes, smashes, etc.)
            'groundstroke_winners': ('WINNER', 'winner', ['volley', 'half_volley', 'swinging_volley'], ['inside_out', 'inside_in']),  # Only groundstrokes
            'baseline_winners': ('WINNER', 'winner', ['volley', 'half_volley', 'swinging_volley'], ['inside_out', 'inside_in']),  # Only baseline shots
            'aces': ('ACE', 'server', [], []),
            'unforced_errors': ('UNFORCED ERROR', 'error', [], []),  # ALL unforced errors
            'forced_errors': ('FORCED ERROR', 'error', [], []),  # ALL forced errors
            'errors': ('ERROR', 'error', [], []),  # ALL errors (unforced + forced)
            'double_faults': ('DOUBLE_FAULT', 'server', [], []),
            'service_winners': ('SERVICE_WINNER', 'server', [], []),
            'rally_winners': ('WINNER', 'winner', ['volley', 'half_volley', 'swinging_volley'], ['inside_out', 'inside_in']),  # Non-serve groundstroke winners
        }
        
        config = METRIC_CONFIG.get(metric)
        if not config:
            return points  # No filtering for this metric
        
        required_outcome, player_role, excluded_modifiers, excluded_directions = config
        
        # Get shot_number filter if specified (for generic shot-specific queries like "winners on shot 3")
        shot_number_filter = filters.get('shot_number')
        
        filtered = []
        
        for point_data in points:
            point_text = point_data.get('point_text', point_data.get('description', ''))
            server = point_data.get('server', '')
            returner = point_data.get('returner', '')
            
            # Parse rally and extract metadata from last shot
            rally_shots = self._parse_rally_sequence(point_text, server, returner)
            actual_shots = [s for s in rally_shots if s.get('outcome') not in ['FAULT', 'LET']]
            
            if not actual_shots:
                continue
            
            # Apply shot_number filter if specified (e.g., shot_number=2 for returns, shot_number=3 for serve+1)
            if shot_number_filter:
                if len(actual_shots) != shot_number_filter:
                    continue
            
            last_shot = actual_shots[-1]
            shot_meta = self._extract_shot_metadata(last_shot.get('description', ''))
            
            # Check outcome using parsed metadata - handle None safely
            shot_meta_outcome = None
            if shot_meta and isinstance(shot_meta, dict):
                shot_meta_outcome = shot_meta.get('outcome')
            # Ensure we have a string before calling upper()
            outcome = last_shot.get('outcome', '') or (shot_meta_outcome if shot_meta_outcome else '').upper()
            
            # Special handling for generic "errors" metric (matches both unforced and forced)
            if required_outcome == 'ERROR':
                if 'ERROR' not in outcome and 'error' not in last_shot.get('description', '').lower():
                    continue
            elif required_outcome not in outcome and required_outcome.lower() not in last_shot.get('description', '').lower():
                continue
            
            # Check excluded modifiers (e.g., no volleys for groundstroke winners)
            if shot_meta.get('shot_modifier') in excluded_modifiers:
                continue
            
            # Check excluded directions (e.g., no inside-out for regular winners)
            if shot_meta.get('direction') in excluded_directions:
                continue
            
            # CRITICAL: Get group_by before applying filters
            # Skip filters for dimensions that are being grouped
            group_by = classification.get('group_by', '')
            secondary_group_by = classification.get('secondary_group_by', '')
            
            # Apply shot type filter using parsed metadata
            # SKIP if shot_type is being grouped (e.g., "forehand vs backhand unforced errors")
            if shot_type_filter and group_by != 'shot_type' and secondary_group_by != 'shot_type':
                if shot_meta.get('shot_type') != shot_type_filter.lower():
                    continue
            
            # Apply direction filter using parsed metadata
            # SKIP if direction is being grouped (e.g., "crosscourt vs down the line winners")
            if direction_filter and group_by != 'direction' and secondary_group_by != 'direction':
                if shot_meta.get('direction') != direction_filter.lower():
                    continue
            
            # Apply shot modifier filter using parsed metadata
            # SKIP if shot_modifier is being grouped
            if shot_modifier_filter and group_by != 'shot_modifier' and secondary_group_by != 'shot_modifier':
                if shot_meta.get('shot_modifier') != shot_modifier_filter.lower():
                    continue
            
            # Apply player filter based on role - GENERIC using ROLE_CONFIG
            # CRITICAL: Skip player filter if player='both' or if we're grouping by player
            # The grouping/tree traversal will handle player separation
            if player_filter and player_filter.lower() != 'both' and group_by != 'player':
                role_config = self.ROLE_CONFIG.get(player_role, {})
                player_field = role_config.get('player_field', '')
                if player_field:
                    field_to_player = {
                        'server': server,
                        'returner': returner,
                        'point_winner': last_shot.get('player', ''),  # For winner/error, use last shot player
                        'error_player': last_shot.get('player', '')
                    }
                    target_player = field_to_player.get(player_field, '')
                    if target_player and not self._names_match_robust(player_filter, target_player):
                        continue
            
            # Additional check for rally_winners: must have rally length > 1
            if metric == 'rally_winners' and len(actual_shots) <= 1:
                continue
            
            filtered.append(point_data)
        
        return filtered
    
    def _analyze_n_dimensional(self, classification: Dict) -> Dict:
        """
        N-DIMENSIONAL TREE ANALYSIS
        
        Handles any depth of filters + any number of grouping dimensions.
        
        Example 5D query:
        "On break points (1), serving to T (2), on Ad court (3), 
         in sets he won (4), compare 1st vs 2nd serve (5) win %"
        """
        # Reset debug counters for this query (fresh start)
        metrics = classification.get('metrics', [])
        for metric in metrics:
            debug_key = f"_metric_filter_debug_{metric}"
            setattr(self, debug_key, 0)
        
        # Reset shot count debug flag
        if hasattr(self, '_shot_count_debug_done'):
            delattr(self, '_shot_count_debug_done')
        
        # Reset error shot type debug count
        if hasattr(self, '_error_shot_debug_count'):
            delattr(self, '_error_shot_debug_count')
        
        # Build the query tree
        tree = self._build_query_tree(classification)
        
        print(f"[TREE] Built with depth={tree['depth']} | Filters: {tree['dimensions']['filters']} | Groups: {tree['dimensions']['groups']} | Metrics: {tree['dimensions']['metrics']}")
        
        # Get all points
        if not hasattr(self, 'point_by_point') or not self.point_by_point:
            return {'error': 'No point-by-point data available'}
        
        points = self.point_by_point
        
        # NO PRE-FILTERING - Tree traversal handles ALL filtering
        print(f"[TREE] Using {len(points)} points")
        
        # Traverse tree
        results = self._traverse_tree(tree, points)
        
        # For debugging: collect points from tree branches with FULL METADATA
        matching_points = []
        
        def _extract_winning_shot_metadata(pt):
            """Extract metadata from the winning shot of a point."""
            point_text = pt.get('point_text', pt.get('description', ''))
            server = pt.get('server', '')
            returner = pt.get('returner', '')
            rally_shots = self._parse_rally_sequence(point_text, server, returner)
            actual_shots = [s for s in rally_shots if s.get('outcome') not in ['FAULT', 'LET']]
            if actual_shots:
                last = actual_shots[-1]
                return {
                    'winner': last.get('player', '?'),
                    'shot_type': last.get('shot_type', '?'),
                    'shot_modifier': last.get('shot_modifier', '-'),
                    'direction': last.get('direction', '?'),
                    'at_net': last.get('at_net', False),
                    'outcome': last.get('outcome', '?'),
                    'rally_length': len(actual_shots)
                }
            return {'winner': '?', 'shot_type': '?', 'shot_modifier': '-', 'direction': '?', 'at_net': False, 'outcome': '?', 'rally_length': 0}
        
        def _extract_situation_info(pt):
            """Extract situation information from point metadata."""
            # Try multiple locations where situation info might be stored
            if '_metadata' in pt and isinstance(pt['_metadata'], dict):
                return pt['_metadata'].get('situation', {})
            elif 'situation' in pt and isinstance(pt['situation'], dict):
                return pt['situation']
            # Fallback: compute from score if available
            elif 'score' in pt:
                score = pt.get('score', '')
                return {
                    'is_break_point': self._is_break_point_score(score),
                    'is_game_point': self._is_game_point_score(score),
                    'is_set_point': self._is_set_point_score(score),
                    'is_match_point': self._is_match_point_score(score),
                    'is_deuce': self._is_deuce_score(score),
                    'is_tiebreak': self._is_tiebreak_point(score)
                }
            return {}
        
        # Helper to filter points based on metric criteria for debug display
        def _filter_points_by_metric(points, metric, player_name=None):
            """
            GENERIC metric-based point filter for debug display.
            Uses METRIC_CONFIG to determine which points to show.
            
            This ensures debug output shows ONLY points where the metric applies
            (e.g., for "aces", show only ace points, not all serve points).
            """
            if not metric or not points:
                return points
            
            # Get metric config from CLASS CONSTANT (single source of truth)
            config = TennisChatAgentEmbeddingQALocal.METRIC_CONFIG.get(metric, {})
            if not config:
                return points
            
            player_role = config.get('player_role', 'both')
            total_filter = config.get('total_filter', 'always')
            count_filter = config.get('count_filter', 'always')
            keywords = config.get('keywords', [])
            
            filtered = []
            for pt in points:
                point_text = pt.get('point_text', pt.get('description', ''))
                point_lower = point_text.lower()
                server = pt.get('server', '')
                returner = pt.get('returner', '')
                
                # Extract point winner from [Point won by: Player] tag
                point_winner = None
                winner_match = re.search(r'\[Point won by:\s*([^\]]+)\]', point_text)
                if winner_match:
                    point_winner = winner_match.group(1).strip()
                
                # Get serve number
                serve_number = 1
                if '2nd serve' in point_lower or 'second serve' in point_lower:
                    serve_number = 2
                
                # GENERIC: Check player role using ROLE_CONFIG
                if player_role != 'both' and player_name:
                    role_config = self.ROLE_CONFIG.get(player_role, {})
                    player_field = role_config.get('player_field', '')
                    
                    # Map player_field to actual player value
                    field_to_player = {
                        'server': server,
                        'returner': returner,
                        'point_winner': point_winner
                    }
                    target_player = field_to_player.get(player_field, '')
                    
                    # If role doesn't match player, skip this point
                    if not target_player or not self._names_match_robust(player_name, target_player):
                        continue
                
                # GENERIC: Check total filter (denominator condition)
                passes_total = False
                if total_filter == 'always':
                    passes_total = True
                elif total_filter == 'first_serve':
                    passes_total = (serve_number == 1)
                elif total_filter == 'second_serve':
                    passes_total = (serve_number == 2)
                elif total_filter == 'on_match':
                    passes_total = any(kw in point_lower for kw in keywords) if keywords else True
                else:
                    passes_total = True
                
                if not passes_total:
                    continue
                
                # GENERIC: Check count filter (numerator condition - what makes it "count")
                matches_metric = False
                if count_filter == 'always':
                    matches_metric = True
                elif count_filter == 'on_match':
                    # Keyword-based metrics (aces, winners, errors, etc.)
                    matches_metric = any(kw in point_lower for kw in keywords) if keywords else False
                elif count_filter == 'won':
                    # Point won by the player
                    if player_name and point_winner:
                        matches_metric = self._names_match_robust(player_name, point_winner)
                    else:
                        matches_metric = True  # If no player filter, show all won points
                elif count_filter == 'first_serve_in':
                    # First serve in (not a fault)
                    matches_metric = (serve_number == 1)
                elif count_filter == 'second_serve_in':
                    # Second serve in (not a double fault)
                    matches_metric = (serve_number == 2 and 'double fault' not in point_lower)
                else:
                    matches_metric = True
                
                if matches_metric:
                    filtered.append(pt)
            
            return filtered
        
        # UNIFIED POINT EXTRACTION: Get filtered points from tree traversal result
        # This ensures display shows EXACTLY the same points that were analyzed
        def _get_deepest_points(node_results, depth=0):
            """Recursively find points from the DEEPEST node (not first node with points)."""
            indent = "  " * depth
            if not node_results:
                return []
            
            node_type = node_results.get('type', 'unknown')
            
            # For filter nodes, ALWAYS go to children first (they have more filtered points)
            if node_type == 'filter':
                dim = node_results.get('dimension', '?')
                val = node_results.get('value', '?')
                pts_before = node_results.get('points_before', '?')
                pts_after = node_results.get('points_after', '?')
                print(f"{indent}[EXTRACT] Filter {dim}={val}: {pts_before}->{pts_after}")
                
                if 'children' in node_results and node_results['children']:
                    child_points = _get_deepest_points(node_results['children'], depth + 1)
                    if child_points:
                        return child_points
                # Only if no children, use this node's points
                if 'points' in node_results:
                    print(f"{indent}[EXTRACT] Using filter's points: {len(node_results['points'])}")
                    return node_results['points']
            
            # For group nodes, collect from all branches
            elif node_type == 'group' and 'branches' in node_results:
                print(f"{indent}[EXTRACT] Group with {len(node_results['branches'])} branches")
                all_points = []
                for branch_key, branch_data in node_results['branches'].items():
                    if 'points' in branch_data:
                        print(f"{indent}[EXTRACT]   Branch '{branch_key}': {len(branch_data['points'])} points")
                        all_points.extend(branch_data['points'])
                    elif 'results' in branch_data:
                        sub_points = _get_deepest_points(branch_data['results'], depth + 1)
                        all_points.extend(sub_points)
                print(f"{indent}[EXTRACT] Total from group: {len(all_points)}")
                return all_points
            
            # Fallback: if node has 'points' directly
            if 'points' in node_results:
                print(f"{indent}[EXTRACT] Fallback - using direct points: {len(node_results['points'])}")
                return node_results['points']
            
            return []
        
        # Get filtered points from tree result
        print(f"[DEBUG] Starting point extraction from tree (results type: {results.get('type')})")
        filtered_points = _get_deepest_points(results, 0)
        print(f"[DEBUG] Extracted {len(filtered_points)} filtered points from tree")
        
        # === GENERIC N-METRIC: Collect debug points separately for each metric ===
        metrics = classification.get('metrics', [])
        metric_filters_map = classification.get('metric_filters', {})
        matching_points_by_metric = None  # Initialize for scope
        
        # If we have metric-specific filters, collect points per metric
        if metric_filters_map:
            matching_points_by_metric = {}
            for metric_key in metrics:
                metric_specific = metric_filters_map.get(metric_key, {})
                actual_metric = metric_specific.get('metric', metric_key)
                
                # Create a helper function to filter points with metric-specific filters
                def _filter_points_with_metric_filters(points_list, metric_name, metric_filters_dict):
                    """Filter points using metric-specific filters + metric config."""
                    if not metric_filters_dict or not points_list:
                        return _filter_points_by_metric(points_list, metric_name)
                    
                    filtered = []
                    for pt in points_list:
                        # Apply metric-specific filters first
                        pt_filters = pt.get('filters', {})
                        serve_number = pt.get('serve_info', {}).get('serve_number', 1) if pt.get('serve_info') else 1
                        if '2nd serve' in (pt.get('point_text', pt.get('description', '')) or '').lower():
                            serve_number = 2
                        
                        # Check serve_number filter
                        if metric_filters_dict.get('serve_number') is not None:
                            if serve_number != metric_filters_dict['serve_number']:
                                continue
                        
                        # Check other filters from metric_filters_dict
                        # (situation, shot_type, direction, etc. are checked via _filter_points_by_metric)
                        
                        # Then apply metric config filter
                        metric_filtered = _filter_points_by_metric([pt], metric_name)
                        if metric_filtered:
                            filtered.append(pt)
                    
                    return filtered
                
                # Collect points for this metric
                metric_points = []
                
                if results.get('type') == 'group' and 'branches' in results:
                    for branch_key, branch_data in results['branches'].items():
                        branch_points = branch_data.get('points', [])
                        if not branch_points and 'results' in branch_data:
                            branch_points = _get_deepest_points(branch_data['results'], 0)
                        
                        branch_label = branch_data.get('label', branch_key)
                        # Filter with metric-specific filters + metric config
                        metric_filtered = _filter_points_with_metric_filters(
                            branch_points, actual_metric, metric_specific.get('filters', {})
                        )
                        print(f"[DEBUG] Metric '{metric_key}' Branch '{branch_label}': {len(branch_points)} total -> {len(metric_filtered)} matching")
                        
                        for pt in metric_filtered:
                            meta = _extract_winning_shot_metadata(pt)
                            situation_info = _extract_situation_info(pt)
                            metric_points.append({
                                'point_number': pt.get('point_number', 0),
                                'server': pt.get('server', ''),
                                'returner': pt.get('returner', ''),
                                'score': pt.get('score', ''),
                                'description': pt.get('description', ''),
                                'group': branch_label,
                                'situation': situation_info,
                                'metric': metric_key,  # Tag which metric this point belongs to
                                **meta
                            })
                else:
                    # Filter-only results
                    metric_filtered = _filter_points_with_metric_filters(
                        filtered_points, actual_metric, metric_specific.get('filters', {})
                    )
                    print(f"[DEBUG] Metric '{metric_key}': {len(filtered_points)} total -> {len(metric_filtered)} matching")
                    
                    for pt in metric_filtered:
                        meta = _extract_winning_shot_metadata(pt)
                        situation_info = _extract_situation_info(pt)
                        metric_points.append({
                            'point_number': pt.get('point_number', 0),
                            'server': pt.get('server', ''),
                            'returner': pt.get('returner', ''),
                            'score': pt.get('score', ''),
                            'description': pt.get('description', ''),
                            'situation': situation_info,
                            'metric': metric_key,  # Tag which metric this point belongs to
                            **meta
                        })
                
                matching_points_by_metric[metric_key] = metric_points
            
            # Store per-metric points
            matching_points = []  # Flattened for backward compatibility
            for metric_key, points in matching_points_by_metric.items():
                matching_points.extend(points)
        else:
            # LEGACY: Single metric - use primary metric
            primary_metric = metrics[0] if metrics else None
            
            if results.get('type') == 'group' and 'branches' in results:
                # Collect points from each group branch with group labels
                print(f"[DEBUG] Grouped results: {len(results.get('branches', {}))} branches")
                for branch_key, branch_data in results['branches'].items():
                    branch_points = branch_data.get('points', [])
                    if not branch_points and 'results' in branch_data:
                        branch_points = _get_deepest_points(branch_data['results'], 0)
                    
                    # CRITICAL: Filter points by metric for debug display
                    branch_label = branch_data.get('label', branch_key)
                    if primary_metric:
                        metric_filtered_points = _filter_points_by_metric(branch_points, primary_metric, branch_label)
                        print(f"[DEBUG] Branch '{branch_label}': {len(branch_points)} total -> {len(metric_filtered_points)} matching {primary_metric}")
                        branch_points = metric_filtered_points
                    else:
                        print(f"[DEBUG] Branch '{branch_label}': {len(branch_points)} points")
                    
                    for pt in branch_points:
                        meta = _extract_winning_shot_metadata(pt)
                        situation_info = _extract_situation_info(pt)
                        
                        matching_points.append({
                            'point_number': pt.get('point_number', 0),
                            'server': pt.get('server', ''),
                            'returner': pt.get('returner', ''),
                            'score': pt.get('score', ''),
                            'description': pt.get('description', ''),
                            'group': branch_label,
                            'situation': situation_info,
                            **meta
                        })
            else:
                # For filter-only results, use the tree's filtered points
                if primary_metric:
                    metric_filtered_points = _filter_points_by_metric(filtered_points, primary_metric)
                    print(f"[DEBUG] Metric filter: {len(filtered_points)} total -> {len(metric_filtered_points)} matching {primary_metric}")
                    filtered_points = metric_filtered_points
                
                for pt in filtered_points:
                    meta = _extract_winning_shot_metadata(pt)
                    situation_info = _extract_situation_info(pt)
                    
                    matching_points.append({
                        'point_number': pt.get('point_number', 0),
                        'server': pt.get('server', ''),
                        'returner': pt.get('returner', ''),
                        'score': pt.get('score', ''),
                        'description': pt.get('description', ''),
                        'situation': situation_info,
                        **meta
                    })
        
        print(f"[DEBUG] Final matching_points count: {len(matching_points)}")
        
        # Return structure with per-metric points if available
        return_dict = {
            'tree': tree,
            'results': results,
            'classification': classification,
            'player1': self.player1,
            'player2': self.player2,
            'matching_points': matching_points
        }
        
        # Add per-metric points if we have multi-metric query
        if metric_filters_map and 'matching_points_by_metric' in locals():
            return_dict['matching_points_by_metric'] = matching_points_by_metric
        
        return return_dict
    
    def _format_n_dimensional_results(self, analysis: Dict) -> str:
        """Format N-dimensional tree analysis results."""
        if 'error' in analysis:
            return f"Unable to perform analysis: {analysis['error']}"
        
        tree = analysis['tree']
        results = analysis['results']
        classification = analysis['classification']
        
        dimensions = tree['dimensions']
        filters = dimensions['filters']
        groups = dimensions['groups']
        metrics = dimensions['metrics']
        
        player1 = analysis['player1']
        player2 = analysis['player2']
        player_filter = classification.get('filters', {}).get('player')
        
        response = f"**Analysis** (Tree Depth: {tree['depth']})\n\n"
        
        # Show filter path
        if filters:
            response += "**Filter Path:**\n"
            for i, (dim, val) in enumerate(filters):
                indent = "  " * i
                response += f"{indent}└─ {dim}: {val}\n"
            response += "\n"
        
        # Format results based on structure
        response += self._format_tree_results(results, groups, metrics, player1, player2, player_filter)
        
        # Add comparison summary if we have group comparison with 2+ groups
        if groups and len(groups) >= 1:
            response += self._add_group_comparison_summary(results, metrics, player1, player2, classification)
        
        # DEBUG: Show matching points if filtering actually happened
        # Skip if all points returned (no filtering = noise, not useful debug info)
        matching_points = analysis.get('matching_points', [])
        matching_points_by_metric = analysis.get('matching_points_by_metric')
        total_points = len(self.point_by_point) if hasattr(self, 'point_by_point') else 283
        
        print(f"[DEBUG] matching_points count: {len(matching_points)}, total_points: {total_points}")
        
        # Show debug if:
        # 1. We have matching points
        # 2. AND either filtering reduced the count OR we have grouped results OR we have situation filters
        # CRITICAL: Always show debug for situation queries (break points, game points, etc.) - these are important!
        has_grouping = bool(groups)
        has_filtering = len(matching_points) < total_points
        has_situation = bool(filters and any(f[0] == 'situation' for f in filters))
        
        if matching_points and (has_filtering or has_grouping or has_situation):
            # === GENERIC N-METRIC: Show points grouped by metric ===
            if matching_points_by_metric:
                # Multi-metric query - show points per metric
                response += f"\n\n**DEBUG: Points by Metric:**\n"
                for metric_key, metric_points in matching_points_by_metric.items():
                    metric_specific = classification.get('metric_filters', {}).get(metric_key, {})
                    actual_metric = metric_specific.get('metric', metric_key)
                    metric_filters = metric_specific.get('filters', {})
                    
                    # Build filter description for this metric
                    filter_parts = []
                    for k, v in metric_filters.items():
                        if v is not None:
                            filter_parts.append(f"{k}={v}")
                    filter_str = f" (filters: {', '.join(filter_parts)})" if filter_parts else ""
                    
                    response += f"\n**Metric: {actual_metric}{filter_str}** ({len(metric_points)} points):\n"
                    for i, pt in enumerate(metric_points, 1):
                        response += self._format_debug_point(pt, i)
            else:
                # Single metric - show all points together
                filter_desc = []
                if has_situation:
                    situation_val = next((f[1] for f in filters if f[0] == 'situation'), None)
                    if situation_val:
                        filter_desc.append(f"situation={situation_val}")
                if has_filtering:
                    filter_desc.append("filtered")
                if has_grouping:
                    filter_desc.append("grouped")
                
                filter_str = f" ({', '.join(filter_desc)})" if filter_desc else ""
                total_msg = f"Showing {len(matching_points)} of {total_points} points{filter_str}"
                response += f"\n\n**DEBUG: {total_msg}:**\n"
                for i, pt in enumerate(matching_points, 1):
                    response += self._format_debug_point(pt, i)
        
        return response
    
    def _format_debug_point(self, pt: Dict, index: int) -> str:
        """Format a single debug point for display."""
        response = f"\n{index}. **Point {pt.get('point_number', '?')}** [{pt.get('server', '?')} serving]\n"
        response += f"   Score: {pt.get('score', '?')}\n"
        
        # Show situation information if available
        situation_info = pt.get('situation', {})
        if isinstance(situation_info, dict):
            situation_flags = []
            if situation_info.get('is_break_point'):
                situation_flags.append("BREAK POINT")
            if situation_info.get('is_game_point'):
                situation_flags.append("GAME POINT")
            if situation_info.get('is_set_point'):
                situation_flags.append("SET POINT")
            if situation_info.get('is_match_point'):
                situation_flags.append("MATCH POINT")
            if situation_info.get('is_deuce'):
                situation_flags.append("DEUCE")
            if situation_info.get('is_tiebreak'):
                situation_flags.append("TIEBREAK")
            if situation_flags:
                response += f"   **Situation:** {', '.join(situation_flags)}\n"
        
        # Show FULL extracted metadata
        winner = pt.get('winner', '?')
        shot_type = pt.get('shot_type', '?')
        shot_mod = pt.get('shot_modifier', '-')
        direction = pt.get('direction', '?')
        at_net = pt.get('at_net', False)
        outcome = pt.get('outcome', '?')
        rally_len = pt.get('rally_length', '?')
        group = pt.get('group', '-')
        
        response += f"   **Winning Shot:** {shot_type}"
        if shot_mod and shot_mod != '-':
            response += f" {shot_mod}"
        response += f" | Direction: {direction}"
        if at_net:
            response += " (AT NET)"
        response += f"\n"
        response += f"   Winner: {winner} | Outcome: {outcome} | Rally: {rally_len} shots"
        if group and group != '-':
            response += f" | Group: {group}"
        response += f"\n"
        response += f"   {pt.get('description', '')}\n"
        
        return response
        
        return response
    
    def _filter_points_for_display(self, points: list, classification: Dict) -> list:
        """
        **DEPRECATED** - This function is no longer needed.
        
        **WHY DEPRECATED:**
        The tree traversal now stores filtered points at each node. Analysis and display
        now use the SAME points from the tree - there's no need to re-filter.
        
        The architectural fix was:
        1. _traverse_node() now stores 'points' at filter/group/leaf nodes
        2. _analyze_n_dimensional() extracts these points for 'matching_points'
        3. Display shows 'matching_points' directly - ONE code path, ONE source of truth
        
        This function remains for reference but is not called. It can be safely deleted.
        
        ------- ORIGINAL DOCSTRING -------
        Filter points to show only RELEVANT ones based on query context.
        
        **ROBUSTNESS GUARANTEE:**
        This function uses the EXACT SAME filters from taxonomy classification that were
        used during analysis. There is ONE SOURCE OF TRUTH (classification['filters'])
        and both analysis and display traverse the same path.
        
        **Why this matters:**
        - Question: "Baseline points in Set 2 vs Set 4"
        - Analysis filters: {court_zone: 'baseline', set_group_a: [2], set_group_b: [4]}
        - Display MUST use these same filters
        - Result: User sees baseline points from sets 2&4, not all 283 points
        
        **Comprehensive Filter Coverage:**
        ✓ situation (break_point, game_point, set_point, match_point, deuce)
        ✓ role (server, returner)  
        ✓ player (with robust name matching)
        ✓ shot_type, shot_base, shot_modifier
        ✓ direction (crosscourt, down_the_line, etc.)
        ✓ court_zone, court_position, at_net
        ✓ set, set_group_a, set_group_b
        ✓ serve_target (wide, body, T)
        ✓ serve_number (1st serve, 2nd serve)
        ✓ court_side (deuce, ad)
        ✓ rally_length, rally_length_range
        ✓ depth (shallow, deep)
        ✓ error_location (net, wide, long)
        ✓ shot_number (serve=1, return=2, serve+1=3)
        ✓ Percentage question detection (shows all points for context)
        
        **Validation:**
        - Warns if unknown filters detected
        - Logs which filters are applied
        - Reports filtering statistics
        - Returns ALL filtered points (no limit)
        
        Returns: List of ALL filtered points matching the analysis criteria
        """
        if not points:
            return []
        
        filters = classification.get('filters', {})
        metrics = classification.get('metrics', [])
        question = classification.get('actual_question', '') or classification.get('question', '')
        question_lower = question.lower() if question else ''
        
        # Detect if this is a percentage/rate question (affects filtering logic)
        is_percentage_question = any(kw in question_lower for kw in ['percentage', 'win rate', 'win %', 'percent', 'rate', '%'])
        
        # === ROBUSTNESS: Validate all filters are handled ===
        KNOWN_FILTERS = {
            'player', 'situation', 'set', 'shot_type', 'shot_base', 'shot_modifier', 
            'direction', 'depth', 'rally_length', 'rally_length_range', 'serve_target', 
            'shot_number', 'court_zone', 'court_position', 'court_side', 'handedness', 
            'error_location', 'role', 'serve_number', 'at_net', 
            'set_group_a', 'set_group_b', 'situation_group_a', 'situation_group_b',
            'chain_logic', '_current_outcome', '_rally_length', '_server', '_returner',
            '_pressure_tightness', '_serve_plus_one_shot', '_prev_rally_length', '_metadata'
        }
        
        # Exclude non-point filters (metadata-only or grouping dimensions)
        NON_POINT_FILTERS = {'handedness'}  # These don't filter points, just metadata
        active_filters = {k: v for k, v in filters.items() 
                         if v is not None and not k.startswith('_') and k not in NON_POINT_FILTERS}
        
        # Remove shot_number from active filters if role is set (role takes precedence)
        if filters.get('role') and 'shot_number' in active_filters:
            del active_filters['shot_number']
            print(f"[DISPLAY-FILTER] Excluding shot_number from active filters (role='{filters['role']}' takes precedence)")
        
        # Remove 'player' from active filters if it's 'both' (doesn't filter, just groups)
        player_val = active_filters.get('player', '')
        if player_val and isinstance(player_val, str) and player_val.lower() == 'both':
            del active_filters['player']
            print(f"[DISPLAY-FILTER] Excluding player='both' from active filters (grouping, not filtering)")
        
        # === GENERAL RULE: Skip filters when grouping by related dimension ===
        # When grouping BY a dimension, don't also filter BY it (use class constant)
        group_by = classification.get('group_by', '')
        secondary_group_by = classification.get('secondary_group_by', '')
        all_groups = {group_by, secondary_group_by} - {None, ''}
        
        for grp in all_groups:
            if grp in self.GROUP_TO_FILTER_EXCLUSIONS:
                for filter_key in self.GROUP_TO_FILTER_EXCLUSIONS[grp]:
                    if filter_key in active_filters:
                        del active_filters[filter_key]
                        print(f"[DISPLAY-FILTER] Excluding '{filter_key}' from active filters (grouping by '{grp}' instead)")
        
        unknown_filters = set(active_filters.keys()) - KNOWN_FILTERS
        
        if unknown_filters:
            print(f"[DISPLAY-FILTER] WARNING: Unknown filters detected: {unknown_filters}")
            print(f"[DISPLAY-FILTER] These filters may not be applied correctly to debug output!")
        
        # Log which filters are being applied
        if active_filters:
            print(f"[DISPLAY-FILTER] Applying filters: {list(active_filters.keys())}")
        
        filtered = []
        
        # === PROCESS EACH POINT ===
        # Apply EXACT SAME filter logic used in _analyze_by_taxonomy() and _analyze_n_dimensional()
        # This ensures debug output shows only the points that were actually analyzed
        
        for pt in points:
            keep = True  # Innocent until proven filtered out
            
            # Filter by situation (break point, game point, etc.) - GENERIC using SITUATION_CONFIG
            situation_filter = filters.get('situation')
            if situation_filter:
                pt_score = pt.get('score', '')
                pt_desc = pt.get('description', '').lower()
                
                # Use generic situation check from config
                if not self._check_situation(situation_filter, pt_score):
                    # Fallback to description check for situations not yet in config
                    situation_in_desc = situation_filter.replace('_', ' ').lower() in pt_desc
                    if not situation_in_desc:
                        keep = False
            
            # Filter by role (server/returner) - use structured filter
            role_filter = filters.get('role')
            player_filter = filters.get('player')
            # NOTE: If player='both', skip player matching - we want ALL server/returner points
            is_both_players = not player_filter or (player_filter and player_filter.lower() == 'both')
            
            if role_filter and player_filter and not is_both_players:
                pt_server = pt.get('server', '')
                pt_returner = pt.get('returner', '')
                
                # GENERIC role filter using ROLE_CONFIG
                role_player = self._get_player_for_role(role_filter, pt_server, pt_returner)
                if not self._names_match_robust(player_filter, role_player):
                        keep = False
            # When role is set but player='both', don't filter by player - include all points with that role
            
            # Filter by shot type (forehand, backhand, etc.)
            # EXCEPTION: Don't filter by shot_type='serve' when role='server' is set
            # (serve effectiveness means ALL service points, not just aces)
            shot_filter = filters.get('shot_type') or filters.get('shot_base')
            if shot_filter:
                is_serve_context = (shot_filter.lower() == 'serve' and filters.get('role') == 'server')
                if not is_serve_context:
                    pt_shot = (pt.get('shot_type') or '').lower()
                    if shot_filter.lower() not in pt_shot and pt_shot not in shot_filter.lower():
                        keep = False
            
            # Filter by court position/zone (at net, baseline) - use structured filter
            # Check both 'court_position', 'court_zone', and 'at_net' (classifier may use any)
            court_filter = filters.get('court_position') or filters.get('court_zone')
            at_net_filter = filters.get('at_net')
            
            if court_filter:
                court_filter_lower = court_filter.lower() if isinstance(court_filter, str) else ''
                if 'net' in court_filter_lower:
                    if not pt.get('at_net', False):
                        keep = False
                elif 'baseline' in court_filter_lower:
                    if pt.get('at_net', False):
                        keep = False
            
            # Direct boolean at_net filter (True = must be at net, False = must not be at net)
            if at_net_filter is not None:
                if at_net_filter and not pt.get('at_net', False):
                    keep = False
                elif not at_net_filter and pt.get('at_net', False):
                    keep = False
            
            # Filter by player (but only if not already filtered by role above)
            # Role filter already handles player matching for server/returner contexts
            # Skip if player='both' (that means compare all players, not filter to one)
            if filters.get('player') and not filters.get('role'):
                player_filter = filters.get('player')
                if player_filter.lower() != 'both':
                    pt_winner = pt.get('winner', '')
                    # Normalize both for comparison
                    if not self._names_match_robust(player_filter, pt_winner):
                        keep = False
            
            # Filter by shot modifier (volley, slice, etc.)
            if filters.get('shot_modifier'):
                mod_filter = (filters.get('shot_modifier') or '').lower()
                pt_mod = (pt.get('shot_modifier') or '').lower()
                if mod_filter not in pt_mod and pt_mod not in mod_filter:
                    keep = False
            
            # Filter by direction
            if filters.get('direction'):
                dir_filter = (filters.get('direction') or '').lower()
                pt_dir = (pt.get('direction') or '').lower()
                if dir_filter not in pt_dir and pt_dir not in dir_filter:
                    keep = False
            
            # Filter by set - use structured filter
            set_filter = filters.get('set')
            if set_filter:
                pt_set = self._extract_current_set(pt.get('score', ''))
                if pt_set and pt_set != set_filter:
                    keep = False
            
            # Filter by set groups (for set comparisons like "Set 2 vs Set 4")
            set_group_a = filters.get('set_group_a', [])
            set_group_b = filters.get('set_group_b', [])
            if set_group_a or set_group_b:
                pt_set = self._extract_current_set(pt.get('score', ''))
                # Show points from either group
                valid_sets = set_group_a + set_group_b
                if pt_set and valid_sets and pt_set not in valid_sets:
                    keep = False
            
            # Filter by serve target (wide, body, T) - use structured filter
            serve_target_filter = filters.get('serve_target')
            if serve_target_filter:
                pt_desc_lower = pt.get('description', '').lower()
                # Check first 50 chars for serve target (in serve description)
                first_50 = pt_desc_lower[:50]
                if serve_target_filter == 'wide' and 'wide' not in first_50:
                    keep = False
                elif serve_target_filter == 'body' and 'body' not in first_50:
                    keep = False
                elif serve_target_filter == 't' and 'down the t' not in first_50:
                    keep = False
            
            # Filter by serve number (1st serve vs 2nd serve) - use structured filter
            serve_number_filter = filters.get('serve_number')
            if serve_number_filter:
                pt_desc_lower = pt.get('description', '').lower()
                first_80 = pt_desc_lower[:80]
                has_fault = 'fault' in first_80
                has_2nd_serve = '2nd serve' in pt_desc_lower
                is_2nd_serve_point = has_fault or has_2nd_serve
                
                if serve_number_filter == 1 and is_2nd_serve_point:
                    keep = False
                elif serve_number_filter == 2 and not is_2nd_serve_point:
                    keep = False
            
            # Filter by court side (deuce/ad) - use structured filter
            court_side_filter = filters.get('court_side')
            if court_side_filter:
                # Determine court side from score's game point score
                score = pt.get('score', '')
                # Extract the game score (last part like "30-15")
                parts = score.strip().split()
                if parts:
                    game_score = parts[-1]
                    # GENERIC court side detection using COURT_SIDE_CONFIG
                    if court_side_filter in self.COURT_SIDE_CONFIG:
                        patterns = self.COURT_SIDE_CONFIG[court_side_filter].get('game_score_patterns', [])
                        if not any(s in game_score for s in patterns):
                            keep = False
            
            # Filter by rally length - supports exact, ">X", ">=X", "<=X" formats
            # EXCEPTION: Skip rally_length filter if grouping by rally_length_category
            rally_length_filter = filters.get('rally_length')
            local_group_by = classification.get('group_by', '')
            local_groups = {local_group_by, classification.get('secondary_group_by', '')} - {None, ''}
            if rally_length_filter and 'rally_length_category' not in local_groups:
                pt_rally_len = pt.get('rally_length', 0)
                if isinstance(rally_length_filter, int):
                    # Exact match
                    if pt_rally_len != rally_length_filter:
                        keep = False
                elif isinstance(rally_length_filter, str):
                    # Parse comparison operators: ">6", ">=7", "<=3"
                    if rally_length_filter.startswith('>='):
                        threshold = int(rally_length_filter[2:])
                        if pt_rally_len < threshold:
                            keep = False
                    elif rally_length_filter.startswith('>'):
                        threshold = int(rally_length_filter[1:])
                        if pt_rally_len <= threshold:
                            keep = False
                    elif rally_length_filter.startswith('<='):
                        threshold = int(rally_length_filter[2:])
                        if pt_rally_len > threshold:
                            keep = False
                    elif rally_length_filter.startswith('<'):
                        threshold = int(rally_length_filter[1:])
                        if pt_rally_len >= threshold:
                            keep = False
            
            # Filter by rally length range - use structured filter
            rally_range = filters.get('rally_length_range')
            if rally_range:
                rally_len = pt.get('rally_length', 0)
                if isinstance(rally_range, tuple) and len(rally_range) == 2:
                    min_len, max_len = rally_range
                    if rally_len < min_len or rally_len > max_len:
                        keep = False
            
            # Filter by depth (shallow, deep) - use structured filter
            depth_filter = filters.get('depth')
            if depth_filter:
                pt_desc_lower = pt.get('description', '').lower()
                if depth_filter == 'deep' and 'deep' not in pt_desc_lower:
                    keep = False
                elif depth_filter == 'shallow' and 'shallow' not in pt_desc_lower:
                    keep = False
            
            # Filter by error location (net, wide, long) - use structured filter
            error_location_filter = filters.get('error_location')
            if error_location_filter:
                pt_desc_lower = pt.get('description', '').lower()
                outcome = pt.get('outcome', '').upper()
                # Only apply to error points - GENERIC pattern matching
                if 'ERROR' in outcome:
                    # Check if error location pattern is in description
                    location_pattern = f"({error_location_filter})"
                    if location_pattern not in pt_desc_lower:
                        keep = False
            
            # Filter by shot number (1=serve, 2=return, 3=serve+1, etc.) - use structured filter
            # EXCEPTION: Don't filter by shot_number when role is set
            # (role='server' means ALL service points, not just outcomes of specific shots)
            shot_number_filter = filters.get('shot_number')
            role_filter = filters.get('role')
            if shot_number_filter and not role_filter:
                # Only apply shot_number filter if NO role filter is active
                    # This would require parsing the rally and counting shot number
                    # For now, approximate: if shot_number=3, looking for "serve+1" or 3rd shot
                    pt_desc_lower = pt.get('description', '').lower()
                    if shot_number_filter == 1:
                        # First shot is serve
                        if not any(kw in pt_desc_lower[:30] for kw in ['serve', '1st serve', '2nd serve']):
                            keep = False
                    elif shot_number_filter == 2:
                        # Second shot is return
                        if 'return' not in pt_desc_lower[:50]:
                            keep = False
                    # For higher shot numbers, would need full rally parsing
                    # Skip for now as it's complex
            
            # Filter by outcome type for specific metrics - GENERIC using config
            # BUT: Skip outcome filtering if asking about percentages/rates (need all points for context)
            if metrics and not is_percentage_question:
                metric = metrics[0]
                outcome = (pt.get('outcome') or '').upper()
                
                # Use generic outcome matching from METRIC_CONFIG
                if not self._outcome_matches_metric(outcome, metric):
                    keep = False
            
            if keep:
                filtered.append(pt)
        
        # === ROBUSTNESS: Log filtering results ===
        total_input = len(points)
        total_output = len(filtered)
        filter_ratio = (total_output / total_input * 100) if total_input > 0 else 0
        
        print(f"[DISPLAY-FILTER] Filtered {total_input} points -> {total_output} points ({filter_ratio:.1f}% matched)")
        
        if total_output == 0 and active_filters:
            print(f"[DISPLAY-FILTER] WARNING: No points matched filters! Check if filters are too restrictive.")
        
        if total_output == total_input and active_filters:
            print(f"[DISPLAY-FILTER] WARNING: All points passed filters! Filters may not be working.")
        
        # Return all filtered points (no limit)
        return filtered
    
    def _is_count_based_query(self, classification: Dict) -> bool:
        """
        Detect if query is asking for counts (how many) rather than percentages.
        Examples: "how many aces", "count of", "number of"
        """
        # Check the actual question text if available
        actual_question = classification.get('actual_question', '') or classification.get('question', '')
        if actual_question:
            question_lower = actual_question.lower()
            count_keywords = ['how many', 'count', 'number of', 'total number']
            if any(kw in question_lower for kw in count_keywords):
                return True
        
        # Check if metric is inherently count-based (aces, double faults always show counts)
        metrics = classification.get('metrics', [])
        count_metrics = ['aces', 'double_faults', 'service_winners', 'winners', 'errors', 
                        'unforced_errors', 'forced_errors', 'break_points']
        if any(m in count_metrics for m in metrics):
            # Only if it's a count query - if asking for win % on aces, show percentages
            if actual_question:
                if 'percentage' not in actual_question.lower() and 'win %' not in actual_question.lower():
                    return True
        
        return False
    
    def _add_group_comparison_summary(self, results: Dict, metrics: list, player1: str, player2: str, classification: Dict = None) -> str:
        """Add a summary comparing metric changes across groups - FULLY DYNAMIC."""
        
        # Extract branches from results
        branches = results.get('branches', {})
        dimension = results.get('dimension', '')
        if not branches:
            # Try to find branches in children
            if results.get('type') == 'filter' and results.get('children'):
                child = results['children']
                if isinstance(child, dict):
                    branches = child.get('branches', {})
                    dimension = child.get('dimension', '')
        
        if not branches or len(branches) < 2:
            return ""
        
        # Get the primary metric being analyzed
        primary_metric = metrics[0] if metrics else 'points_won'
        metric_label = primary_metric.replace('_', ' ').title()
        
        # Detect if this is a count-based query (e.g., "how many aces")
        show_counts_first = classification and self._is_count_based_query(classification)
        
        # SPECIAL CASE: When grouping by PLAYER, each branch IS a player
        # Don't do a cross-comparison, just show each player's total
        if dimension == 'player':
            response = f"\n\n**📊 {metric_label} Summary:**\n\n"
            
            for key, branch in branches.items():
                label = branch.get('label', key)
                sub_results = branch.get('results', {})
                per_player = sub_results.get('per_player_metrics', {}).get(primary_metric, {})
                
                if per_player:
                    # Get data for this specific player
                    if label.lower() == player1.lower():
                        player_data = per_player.get('player1', {})
                    elif label.lower() == player2.lower():
                        player_data = per_player.get('player2', {})
                    else:
                        player_data = per_player.get('player1', {}) or per_player.get('player2', {})
                    
                    count = player_data.get('count', 0)
                    total = player_data.get('total', 0)
                    pct = player_data.get('pct', 0)
                    
                    if show_counts_first:
                        response += f"- **{label}**: **{count} {metric_label.lower()}**\n"
                    else:
                        response += f"- **{label}**: {pct}% ({count} of {total})\n"
            
            # Add conclusion comparing the two players
            if len(branches) == 2:
                branch_list = list(branches.values())
                b1, b2 = branch_list[0], branch_list[1]
                label1 = b1.get('label', '')
                label2 = b2.get('label', '')
                
                results1 = b1.get('results', {})
                results2 = b2.get('results', {})
                per_player1 = results1.get('per_player_metrics', {}).get(primary_metric, {})
                per_player2 = results2.get('per_player_metrics', {}).get(primary_metric, {})
                
                # Get count for player 1
                if label1.lower() == player1.lower():
                    count1 = per_player1.get('player1', {}).get('count', 0)
                elif label1.lower() == player2.lower():
                    count1 = per_player1.get('player2', {}).get('count', 0)
                else:
                    count1 = per_player1.get('player1', {}).get('count', 0) or per_player1.get('player2', {}).get('count', 0)
                
                # Get count for player 2
                if label2.lower() == player1.lower():
                    count2 = per_player2.get('player1', {}).get('count', 0)
                elif label2.lower() == player2.lower():
                    count2 = per_player2.get('player2', {}).get('count', 0)
                else:
                    count2 = per_player2.get('player1', {}).get('count', 0) or per_player2.get('player2', {}).get('count', 0)
                
                if show_counts_first and count1 != count2:
                    diff = abs(count1 - count2)
                    winner = label1 if count1 > count2 else label2
                    response += f"\n**📊 Conclusion:** {winner} had **{diff} more {metric_label.lower()}**\n"
            
            return response
        
        # NORMAL CASE: Comparing conditions (Set 1 vs Set 2, etc.)
        response = f"\n\n**📊 {metric_label} Comparison:**\n\n"
        
        # Collect data for each group
        group_data = []
        for key, branch in branches.items():
            label = branch.get('label', key)
            sub_results = branch.get('results', {})
            
            # Get per-player metrics if available
            per_player = sub_results.get('per_player_metrics', {}).get(primary_metric, {})
            
            if per_player:
                # Use per-player tracking
                p1_data = per_player.get('player1', {})
                p2_data = per_player.get('player2', {})
                group_data.append({
                    'label': label,
                    'p1_value': p1_data.get('pct', p1_data.get('count', 0)),
                    'p2_value': p2_data.get('pct', p2_data.get('count', 0)),
                    'p1_count': p1_data.get('count', p1_data.get('total', 0)),
                    'p2_count': p2_data.get('count', p2_data.get('total', 0)),
                    'p1_total': p1_data.get('total', sub_results.get('total_points', 0)),
                    'p2_total': p2_data.get('total', sub_results.get('total_points', 0)),
                    'is_percentage': 'pct' in p1_data
                })
            else:
                # Use overall win percentages
                group_data.append({
                    'label': label,
                    'p1_value': sub_results.get('player1_pct', 0),
                    'p2_value': sub_results.get('player2_pct', 0),
                    'p1_count': sub_results.get('player1_wins', 0),
                    'p2_count': sub_results.get('player2_wins', 0),
                    'p1_total': sub_results.get('player1_wins', 0),
                    'p2_total': sub_results.get('player2_wins', 0),
                    'is_percentage': True
                })
        
        if len(group_data) >= 2:
            g1, g2 = group_data[0], group_data[1]
            
            # Calculate changes
            p1_change = g1['p1_value'] - g2['p1_value']
            p2_change = g1['p2_value'] - g2['p2_value']
            
            unit = '%' if g1['is_percentage'] else ''
            
            # Format output based on query type
            response += f"**{player1}:**\n"
            if show_counts_first:
                # Show counts prominently for "how many" queries
                response += f"- {g1['label']}: **{g1['p1_count']} {metric_label.lower()}**\n"
                response += f"- {g2['label']}: **{g2['p2_count']} {metric_label.lower()}**\n"
                count_change = g1['p1_count'] - g2['p2_count']
                response += f"- Change: **{count_change:+.0f} {metric_label.lower()}**\n\n"
            else:
                # Show percentages for win rate queries
                response += f"- {g1['label']}: {g1['p1_value']}{unit} ({g1['p1_total']} total)\n"
                response += f"- {g2['label']}: {g2['p1_value']}{unit} ({g2['p2_total']} total)\n"
                response += f"- Change: **{p1_change:+.1f}{unit}**\n\n"
            
            response += f"**{player2}:**\n"
            if show_counts_first:
                # Show counts prominently for "how many" queries
                response += f"- {g1['label']}: **{g1['p2_count']} {metric_label.lower()}**\n"
                response += f"- {g2['label']}: **{g2['p2_count']} {metric_label.lower()}**\n"
                count_change = g1['p2_count'] - g2['p2_count']
                response += f"- Change: **{count_change:+.0f} {metric_label.lower()}**\n\n"
            else:
                # Show percentages for win rate queries
                response += f"- {g1['label']}: {g1['p2_value']}{unit} ({g1['p2_total']} total)\n"
                response += f"- {g2['label']}: {g2['p2_value']}{unit} ({g2['p2_total']} total)\n"
                response += f"- Change: **{p2_change:+.1f}{unit}**\n\n"
            
            # Determine who changed more (bigger drop = more negative change)
            if show_counts_first:
                # For count queries, compare absolute counts
                p1_total_count = g1['p1_count'] + g2['p1_count']
                p2_total_count = g1['p2_count'] + g2['p2_count']
                if p1_total_count > p2_total_count:
                    diff = p1_total_count - p2_total_count
                    response += f"**📊 Conclusion:** {player1} had **{diff} more {metric_label.lower()}** overall\n"
                elif p2_total_count > p1_total_count:
                    diff = p2_total_count - p1_total_count
                    response += f"**📊 Conclusion:** {player2} had **{diff} more {metric_label.lower()}** overall\n"
                else:
                    response += f"**📊 Conclusion:** Both players had equal {metric_label.lower()}\n"
            else:
                # For percentage queries, compare changes
                p1_drop = -p1_change  # Positive means dropped
                p2_drop = -p2_change
                
                if p1_drop > p2_drop + 0.1:  # P1 dropped more
                    response += f"**📉 Conclusion:** {player1}'s {metric_label.lower()} dropped more ({abs(p1_drop - p2_drop):.1f}{unit} greater decline)\n"
                elif p2_drop > p1_drop + 0.1:  # P2 dropped more
                    response += f"**📉 Conclusion:** {player2}'s {metric_label.lower()} dropped more ({abs(p2_drop - p1_drop):.1f}{unit} greater decline)\n"
                else:
                    response += f"**📉 Conclusion:** Both players had similar changes in {metric_label.lower()}\n"
        
        return response
    
    def _format_tree_results(self, results: Dict, groups: list, metrics: list,
                             player1: str, player2: str, player_filter: str, depth: int = 0) -> str:
        """Recursively format tree results."""
        response = ""
        indent = "  " * depth
        
        if results.get('type') == 'filter':
            # Show filter narrowing
            response += f"{indent}**{results['dimension']}={results['value']}**: "
            response += f"{results['points_before']} → {results['points_after']} points\n"
            
            if results.get('children'):
                response += self._format_tree_results(results['children'], groups, metrics,
                                                     player1, player2, player_filter, depth)
        
        elif results.get('type') == 'group':
            # Show grouping table
            dimension = results['dimension']
            branches = results.get('branches', {})
            
            response += f"\n**Grouped by: {dimension.replace('_', ' ').title()}**\n\n"
            
            # Special handling for PLAYER grouping - each row IS a player
            if dimension == 'player':
                primary_metric = metrics[0] if metrics else 'count'
                metric_label = primary_metric.replace('_', ' ').title()
                
                response += f"| Player | Total | Won | Win % |\n"
                response += "|---|---|---|---|\n"
                
                for val, branch_data in branches.items():
                    label = branch_data['label']  # Player name
                    count = branch_data['count']  # Points where this player served/returned
                    sub_results = branch_data.get('results', {})
                    
                    if sub_results.get('type') == 'group':
                        response += f"\n**{label}:**\n"
                        response += self._format_tree_results(sub_results, groups[1:] if len(groups) > 1 else [],
                                                             metrics, player1, player2, player_filter, depth + 1)
                    else:
                        # For player branch, wins = points won by that player
                        # The player in this branch IS the player who served/returned
                        p1_wins = sub_results.get('player1_wins', 0)
                        p2_wins = sub_results.get('player2_wins', 0)
                        
                        # Determine wins for this specific player
                        if label.lower() == player1.lower() if player1 else False:
                            wins = p1_wins
                        elif label.lower() == player2.lower() if player2 else False:
                            wins = p2_wins
                        else:
                            # Fallback: use whichever is non-zero
                            wins = p1_wins if p1_wins > 0 else p2_wins
                        
                        win_pct = round(wins / count * 100) if count > 0 else 0
                        response += f"| **{label}** | {count} | {wins} | {win_pct}% |\n"
                
                return response
            
            # Check if we have per-player metrics (for both-player queries on non-player grouping)
            first_branch = next(iter(branches.values()), {})
            first_results = first_branch.get('results', {})
            has_per_player = bool(first_results.get('per_player_metrics'))
            
            # Dynamic per-player table for any metric (when NOT grouping by player)
            # IMPORTANT: Only use per-player table when NO player filter (showing both players)
            # When filtered to single player, use simple format showing just that player's counts
            if has_per_player and metrics and not player_filter:
                primary_metric = metrics[0]
                metric_label = primary_metric.replace('_', ' ').title()
                
                response += f"| {dimension.title()} | {player1} Total | {player1} Won | {player1} % | {player2} Total | {player2} Won | {player2} % |\n"
                response += "|" + "---|" * 7 + "\n"
                
                for val, branch_data in branches.items():
                    label = branch_data['label']
                    sub_results = branch_data.get('results', {})
                    
                    if sub_results.get('type') == 'group':
                        response += f"\n**{label}:**\n"
                        response += self._format_tree_results(sub_results, groups[1:] if len(groups) > 1 else [],
                                                             metrics, player1, player2, player_filter, depth + 1)
                    else:
                        per_player = sub_results.get('per_player_metrics', {}).get(primary_metric, {})
                        p1_data = per_player.get('player1', {})
                        p2_data = per_player.get('player2', {})
                        
                        response += f"| **{label}** | {p1_data.get('total', 0)} | {p1_data.get('count', 0)} | {p1_data.get('pct', 0)}% | {p2_data.get('total', 0)} | {p2_data.get('count', 0)} | {p2_data.get('pct', 0)}% |\n"
                
                return response
            
            # Build table header based on what we're showing
            if 'win_percentage' in metrics or 'points_won' in metrics:
                response += f"| {dimension.title()} | Total | {player1} | {player2} | "
                if player_filter:
                    response += f"{player_filter} Win% |\n"
                else:
                    response += f"P1 Win% |\n"
                response += "|" + "---|" * 5 + "\n"
            else:
                response += f"| {dimension.title()} | Total |"
                for m in metrics:
                    response += f" {m.replace('_', ' ').title()} |"
                response += "\n"
                response += "|" + "---|" * (len(metrics) + 2) + "\n"
            
            for val, branch_data in branches.items():
                label = branch_data['label']
                count = branch_data['count']
                sub_results = branch_data.get('results', {})
                
                # Get leaf data
                if sub_results.get('type') == 'group':
                    # Nested group - recurse
                    response += f"\n**{label}:**\n"
                    response += self._format_tree_results(sub_results, groups[1:] if len(groups) > 1 else [],
                                                         metrics, player1, player2, player_filter, depth + 1)
                else:
                    # Leaf node - show metrics
                    p1_wins = sub_results.get('player1_wins', 0)
                    p2_wins = sub_results.get('player2_wins', 0)
                    p1_pct = sub_results.get('player1_pct', 0)
                    p2_pct = sub_results.get('player2_pct', 0)
                    
                    if 'win_percentage' in metrics or 'points_won' in metrics:
                        pct = p1_pct if (player_filter and player1 and player_filter.lower() in player1.lower()) else p2_pct if player_filter else p1_pct
                        response += f"| **{label}** | {count} | {p1_wins} | {p2_wins} | {pct}% |\n"
                    else:
                        response += f"| **{label}** | {count} |"
                        for m in metrics:
                            m_count = sub_results.get('metrics', {}).get(m, {}).get('count', 0)
                            response += f" {m_count} |"
                        response += "\n"
        
        elif 'total_points' in results:
            # Leaf node directly
            
            # === SHOT-LEVEL RESULTS (when counting individual shots grouped by type) ===
            if 'shot_counts_by_type' in results and results['shot_counts_by_type']:
                shot_counts = results['shot_counts_by_type']
                total_shots = sum(shot_counts.values())
                
                response += f"\n**Shot Counts by Type:**\n"
                response += f"| Shot Type | Count | Percentage |\n"
                response += "|---|---|---|\n"
                
                # Sort by count descending
                for shot_type, count in sorted(shot_counts.items(), key=lambda x: -x[1]):
                    pct = round(100 * count / total_shots, 1) if total_shots > 0 else 0
                    response += f"| **{shot_type.title()}** | {count} | {pct}% |\n"
                
                response += f"\n**Total Shots: {total_shots}**\n"
                
                # Calculate ratio if forehand and backhand both present
                if 'forehand' in shot_counts and 'backhand' in shot_counts:
                    fh = shot_counts['forehand']
                    bh = shot_counts['backhand']
                    if bh > 0:
                        ratio = round(fh / bh, 2)
                        response += f"**Forehand to Backhand Ratio: {ratio} : 1**\n"
                
                # Display detailed breakdown by contact_type + intent
                if 'shot_breakdown' in results and results['shot_breakdown']:
                    response += f"\n**Detailed Breakdown by Shot Subtype:**\n"
                    for shot_type, breakdown in results['shot_breakdown'].items():
                        response += f"\n**{shot_type.title()} Breakdown:**\n"
                        response += f"| Subtype | Count |\n"
                        response += "|---|---|\n"
                        
                        # Sort by count descending
                        for subtype, count in sorted(breakdown.items(), key=lambda x: -x[1]):
                            if count > 0:  # Only show non-zero counts
                                response += f"| {subtype.replace('_', ' ').title()} | {count} |\n"
                
                return response
            
            response += f"\n**Results:**\n"
            response += f"- Total Points: {results['total_points']}\n"
            response += f"- {player1}: {results.get('player1_wins', 0)} ({results.get('player1_pct', 0)}%)\n"
            response += f"- {player2}: {results.get('player2_wins', 0)} ({results.get('player2_pct', 0)}%)\n"
            
            # Get all metric counts
            metrics_results = results.get('metrics', {})
            per_player = results.get('per_player_metrics', {})
            total_shots = metrics_results.get('total_shots', {}).get('count', 0)
            
            # Game-level metrics get special formatting
            game_metrics = {'games_won', 'service_games_held', 'breaks', 'sets_won'}
            
            # Percentage metrics - show as X% (count of total)
            pct_metrics = {'first_serve_pct', 'first_serve_win_pct', 'second_serve_pct', 'second_serve_win_pct',
                          'win_percentage', 'points_won'}
            
            # SHOT-LEVEL PERCENTAGE: Detect cross-metric percentage (e.g., winners / shot_count)
            # When we have TWO metrics and one is shot_count, calculate percentage across metrics
            metrics_list = list(metrics_results.keys())
            shot_count_metrics = [m for m in metrics_list if m.startswith('shot_count') or m.startswith('shots_count') or m in ['shots', 'shot']]
            non_shot_metrics = [m for m in metrics_list if m not in shot_count_metrics]
            
            is_shot_percentage = (len(metrics_list) == 2 and 
                                 len(shot_count_metrics) == 1 and 
                                 len(non_shot_metrics) == 1)
            
            print(f"[FORMAT-DEBUG] metrics_list={metrics_list}, shot_count_metrics={shot_count_metrics}, non_shot_metrics={non_shot_metrics}, is_shot_percentage={is_shot_percentage}")
            
            if is_shot_percentage:
                # CROSS-METRIC PERCENTAGE: Calculate percentage of first metric relative to shot_count
                numerator_metric = non_shot_metrics[0]
                denominator_metric = shot_count_metrics[0]
                
                # Try both 'count' and 'total' for shot_count (it might be stored as total)
                numerator_count = metrics_results.get(numerator_metric, {}).get('count', 0)
                denominator_data = metrics_results.get(denominator_metric, {})
                denominator_count = denominator_data.get('count', 0) or denominator_data.get('total', 0)
                
                # If shot_count is not in metrics_results (due to player filter), check per_player_metrics
                # shot_count might be stored per-player or as a total
                if denominator_count == 0 and per_player and denominator_metric in per_player:
                    # Try to get total from per_player_metrics (sum of both players)
                    p1_data = per_player.get(denominator_metric, {}).get('player1', {})
                    p2_data = per_player.get(denominator_metric, {}).get('player2', {})
                    p1_total = p1_data.get('count', 0) or p1_data.get('total', 0)
                    p2_total = p2_data.get('count', 0) or p2_data.get('total', 0)
                    denominator_count = p1_total + p2_total
                    print(f"[FORMAT-DEBUG] Got shot_count from per_player_metrics: p1={p1_total}, p2={p2_total}, total={denominator_count}")
                
                # If still 0, shot_count might be stored directly in results (not in metrics dict)
                # Check if there's a 'shot_count' or 'total_shots' field in results
                if denominator_count == 0:
                    # shot_count might be computed but not stored in metrics - check debug output from traversal
                    # For now, try to compute from matching_points if available
                    # But actually, we should trust the metric count - if it's 0, there might be a bug
                    print(f"[FORMAT-DEBUG] WARNING: shot_count is 0 in metrics_results and per_player_metrics")
                
                print(f"[FORMAT-DEBUG] Inside is_shot_percentage block: numerator={numerator_metric} ({numerator_count}), denominator={denominator_metric} (count={denominator_data.get('count', 0)}, total={denominator_data.get('total', 0)}, final={denominator_count})")
                
                if denominator_count > 0:
                    pct = round(100 * numerator_count / denominator_count, 1)
                    response += f"- {numerator_metric.replace('_', ' ').title()}: {pct}% ({numerator_count} of {denominator_count} shots)\n"
                    print(f"[FORMAT] Shot-level percentage: {numerator_metric} = {numerator_count}/{denominator_count} shots = {pct}%")
                else:
                    print(f"[FORMAT-DEBUG] denominator_count is 0 or None, using fallback message")
                    response += f"- {numerator_metric.replace('_', ' ').title()}: 0% (no shots)\n"
                
                # Skip iterating over individual metrics since we handled the calculation
                print(f"[FORMAT-DEBUG] Skipping standard metric iteration, response so far: {response[:200]}")
            else:
                # STANDARD METRIC ITERATION: Process each metric independently
                for m, m_data in metrics_results.items():
                    count = m_data.get('count', 0)
                    total = m_data.get('total', 0) or m_data.get('_serve_total', 0)  # Unified: use total
                    
                    if m in game_metrics and m in per_player:
                        # Format game-level metrics with per-player breakdown
                        p1_data = per_player.get(m, {}).get('player1', {})
                        p2_data = per_player.get(m, {}).get('player2', {})
                        response += f"\n**{m.replace('_', ' ').title()}:**\n"
                        response += f"  - {player1}: {p1_data.get('count', 0)}\n"
                        response += f"  - {player2}: {p2_data.get('count', 0)}\n"
                    elif m in pct_metrics or total > 0:
                        # UNIFIED: All metrics with a total get percentage display
                        if total > 0:
                            pct = round(100 * count / total, 1)
                            response += f"- {m.replace('_', ' ').title()}: {pct}% ({count} of {total})\n"
                        else:
                            response += f"- {m.replace('_', ' ').title()}: 0% (no data)\n"
                    else:
                        response += f"- {m.replace('_', ' ').title()}: {count}"
                        
                        # Calculate percentage of shots if we have total_shots
                        if total_shots > 0 and m != 'total_shots':
                            pct = round(100 * count / total_shots, 1)
                            response += f" ({pct}% of total shots)"
                        
                        response += "\n"
        
        return response
    
    def _analyze_by_taxonomy(self, classification: Dict[str, Any]) -> Dict[str, Any]:
        """
        **DEPRECATED** - Use _analyze_n_dimensional instead.
        
        This function is kept for reference but all callers have been migrated
        to use _analyze_n_dimensional which provides:
        - Unified tracking with _track_per_player_metric
        - Single code path for all metrics
        - Player filter applied at end (not during calculation)
        
        Original description:
        UNIFIED ANALYZER: Handles all query types via taxonomy classification.
        
        Supports:
        - Filtering (player, situation, set, serve target, shot number, etc.)
        - Grouping (by rally length, set, court side, shot type, etc.)
        - Metrics (winners, errors, aces, points won, etc.)
        - Comparisons and breakdowns
        """
        import warnings
        warnings.warn("_analyze_by_taxonomy is deprecated, use _analyze_n_dimensional", DeprecationWarning)
        import re
        
        domain = classification['domain']
        analysis_type = classification['analysis_type']
        filters = classification['filters']
        metrics = classification['metrics']
        group_by = classification.get('group_by')  # NEW: Grouping support
        
        # Use structured point-by-point data (loaded from JSON)
        if not hasattr(self, 'point_by_point') or not self.point_by_point:
            return {'error': 'No structured point-by-point data available. Load match first.'}
        
        point_data_list = self.point_by_point
        print(f"[TAXONOMY] Using {len(point_data_list)} structured points")
        
        player_filter = filters.get('player')
        player1 = self.player1
        player2 = self.player2
        
        # Initialize results based on whether grouping is needed
        if group_by:
            results = self._init_grouped_results(classification, group_by, player1, player2)
        else:
            results = {
                'classification': classification,
                'total_points': 0,
                'metrics_data': {metric: {'count': 0, 'points': []} for metric in metrics},
                'player1': player1,
                'player2': player2,
                'player1_wins': 0,
                'player2_wins': 0,
                'matching_points': []  # Track all matching points for debugging
            }
        
        for point_data in point_data_list:
            point_num = point_data.get('point_number', 0)
            server = point_data.get('server', '')
            returner = point_data.get('returner', '')
            score = point_data.get('score', '')
            point_text = point_data.get('point_text', point_data.get('description', ''))
            point_lower = point_text.lower()
            
            # === APPLY FILTERS ===
            # Situation filter - GENERIC using SITUATION_CONFIG
            situation_filter = filters.get('situation')
            if situation_filter and not self._check_situation(situation_filter, score):
                    continue
            
            # Set filter
            set_filter = filters.get('set')
            if set_filter:
                current_set = self._extract_current_set(score)
                if current_set and current_set != set_filter:
                    continue
            
            # Serve target filter (wide/body/t) - GENERIC using filter value directly
            serve_target_filter = filters.get('serve_target')
            if serve_target_filter:
                # Normalize and check if target is in point description
                target_patterns = {'wide': 'wide', 'body': 'body', 't': 'down the t', 'center': 'center'}
                pattern = target_patterns.get(serve_target_filter.lower(), serve_target_filter.lower())
                if pattern not in point_lower[:50]:
                    continue
            
            # Serve number filter (1st serve vs 2nd serve)
            serve_number_filter = filters.get('serve_number')
            if serve_number_filter:
                has_fault = 'fault' in point_lower[:80]  # Fault in first 80 chars = 1st serve missed
                has_2nd_serve = '2nd serve' in point_lower
                is_2nd_serve_point = has_fault or has_2nd_serve
                
                if serve_number_filter == 1 and is_2nd_serve_point:
                    continue  # Skip 2nd serve points when filtering for 1st serve
                elif serve_number_filter == 2 and not is_2nd_serve_point:
                    continue  # Skip 1st serve points when filtering for 2nd serve
            
            # Role filter (server or returner)
            role_filter = filters.get('role')
            if role_filter:
                player_filter_for_role = (filters.get('player') or '').lower()
                if player_filter_for_role:
                    # GENERIC role filter using ROLE_CONFIG
                    role_player = self._get_player_for_role(role_filter, server, returner)
                    if player_filter_for_role not in role_player.lower():
                        continue  # Skip if player wasn't in the expected role
            
            # Rally length range filter
            rally_range = filters.get('rally_length_range')
            # Will be applied after parsing rally
            
            # Net point filter
            net_point_filter = filters.get('at_net')
            # Will be applied after parsing rally
            
            # === PARSE RALLY ===
            rally_shots = self._parse_rally_sequence(point_text, server, returner)
            actual_shots = [s for s in rally_shots if s.get('outcome') != 'FAULT']
            rally_length = len(actual_shots)
            
            # === DETERMINE POINT OUTCOME ===
            # First try to extract from [Point won by:] tag (authoritative)
            point_winner = None
            winner_match = re.search(r'\[Point won by:\s*([^\]]+)\]', point_text)
            if winner_match:
                point_winner = winner_match.group(1).strip()
            
            winning_shot_type = None
            error_player = None
            error_shot_type = None  # backhand, forehand, etc.
            
            if actual_shots:
                last_shot = actual_shots[-1]
                outcome = last_shot.get('outcome', '')
                last_player = last_shot.get('player', '')
                last_description = last_shot.get('description', '').lower()
                
                # GENERIC OUTCOME HANDLING using OUTCOME_CONFIG
                outcome_config = self._get_outcome_config(outcome)
                winning_shot_type = outcome_config.get('winning_shot_type', '')
                player_attribution = outcome_config.get('player_attribution', '')
                is_positive = outcome_config.get('is_positive', True)
                
                # Determine point winner based on outcome attribution
                if not point_winner:
                    if player_attribution == 'server':
                        point_winner = server if is_positive else returner
                    elif player_attribution == 'error':
                        # Error player loses, opponent wins
                        point_winner = returner if last_player == server else server
                        error_player = last_player
                    elif player_attribution == 'winner':
                        point_winner = last_player
                    else:
                        point_winner = last_player
                
                # Refine winner type based on description (for winner shots)
                if winning_shot_type == 'winner':
                    if 'volley' in last_description:
                        winning_shot_type = 'volley_winner'
                    elif 'inside-out' in last_description or 'inside-in' in last_description:
                        winning_shot_type = 'specialty_winner'
                    elif 'at net' in last_description:
                        winning_shot_type = 'net_winner'
                
                # Set error_player for error outcomes
                if player_attribution == 'error':
                    error_player = last_player
                    # Detect shot type of the error from description - find FIRST (leftmost) occurrence
                    # GENERIC: Check which shot type appears first in the description
                    shot_type_detected = None
                    earliest_pos = len(last_description)
                    for shot in ['backhand', 'forehand', 'serve']:
                        pos = last_description.find(shot)
                        if pos != -1 and pos < earliest_pos:
                            earliest_pos = pos
                            shot_type_detected = shot
                    if shot_type_detected:
                        error_shot_type = shot_type_detected
            
            # === METRIC FILTERING - GENERIC using CLASS-LEVEL METRIC_CONFIG ===
            shot_type_filter = filters.get('shot_type') or filters.get('shot_base')
            player_filter = filters.get('player')
            
            # Apply metric-specific filters using CLASS-LEVEL config
            if metrics:
                metric = metrics[0]  # Primary metric
                config = self.METRIC_CONFIG.get(metric, {})
                player_role = config.get('player_role', 'both')
                keywords = config.get('keywords', [])
                
                # Filter by winning_shot_type using keywords from config
                if keywords:
                    shot_matches = False
                    winning_lower = (winning_shot_type or '').lower()
                    
                    # GENERIC keyword matching - check if winning_shot_type matches ANY keyword
                    for kw in keywords:
                        kw_lower = kw.lower()
                        if kw_lower == 'winner':
                            # Special: use WINNER_TYPES set for winner detection
                            if winning_shot_type in self.WINNER_TYPES:
                                shot_matches = True
                                break
                        elif kw_lower in winning_lower or winning_lower in kw_lower.replace(' ', '_'):
                            shot_matches = True
                            break
                    
                    if not shot_matches:
                            continue
                    
                # Determine target player for this metric based on player_role - GENERIC using ROLE_CONFIG
                target_player = point_winner  # Default
                target_shot = actual_shots[-1].get('description', '').lower() if actual_shots else ''
                    
                role_config = self.ROLE_CONFIG.get(player_role, {})
                player_field = role_config.get('player_field', '')
                if player_field:
                    field_to_player = {
                        'server': server,
                        'returner': returner,
                        'point_winner': point_winner,
                        'error_player': error_player
                    }
                    target_player = field_to_player.get(player_field, point_winner)
                    
                    # For error metrics, also update target_shot
                    if player_field == 'error_player':
                        target_shot = error_shot_type if error_shot_type else ''
                
                # Apply shot type filter using parsed metadata - GENERIC
                is_error_metric = player_field == 'error_player'
                if shot_type_filter:
                    if is_error_metric and target_shot and target_shot != shot_type_filter.lower():
                        continue
                    elif not is_error_metric and actual_shots:
                        last_shot = actual_shots[-1]
                        shot_meta = self._extract_shot_metadata(last_shot.get('description', ''))
                        if shot_meta.get('shot_type') != shot_type_filter.lower():
                            continue
                    
                    # NOTE: Player filtering is now handled by _check_metric_match for consistency
                    pass
            
            # === DETERMINE GROUP (if grouping) ===
            group_key = None
            if group_by:
                # For shot_direction/shot_type grouping, use the target shot description
                target_shot_desc = ''
                if group_by in ['shot_direction', 'shot_type'] and actual_shots:
                    target_shot_desc = actual_shots[-1].get('description', '').lower()
                
                # Set dynamic values in filters for outcome/shot_number/player grouping
                if group_by == 'outcome':
                    filters['_current_outcome'] = winning_shot_type
                if group_by == 'shot_number':
                    filters['_rally_length'] = rally_length
                if group_by == 'player':
                    filters['_server'] = server
                    filters['_returner'] = returner
                    filters['_point_winner'] = point_winner
                    filters['_error_player'] = error_player
                    filters['_current_metric'] = metrics[0] if metrics else None
                
                # Set enriched data in filters for new grouping dimensions
                if group_by == 'pressure_level':
                    pressure_data = point_data.get('pressure', {})
                    filters['_pressure_tightness'] = pressure_data.get('score_tightness', 0)
                if group_by == 'serve_plus_one_type':
                    tactics = point_data.get('tactics', {})
                    filters['_serve_plus_one_shot'] = tactics.get('serve_plus_one_shot', '')
                if group_by == 'after_rally_length':
                    context = point_data.get('context', {})
                    filters['_prev_rally_length'] = context.get('prev_rally_length', 0)
                
                # Get or compute metadata for this point
                if '_metadata' not in point_data:
                    point_data['_metadata'] = self._get_point_metadata(point_data)
                point_meta = point_data['_metadata']
                
                group_key = self._determine_group_key(group_by, rally_length, score, point_lower, filters, target_shot_desc, rally_shots=actual_shots, metadata=point_meta)
                if group_key is None:
                    continue  # Skip if can't determine group
            
            # === TRACK RESULTS ===
            if group_by and group_key:
                # Grouped tracking
                if group_key in results['groups']:
                    results['groups'][group_key]['total'] += 1
                    
                    # Track points won per player
                    if point_winner:
                        # For player grouping, group_key is 'player1' or 'player2'
                        if group_by == 'player':
                            # group_key is already 'player1' or 'player2'
                            if group_key == 'player1':
                                results['groups'][group_key]['player1_wins'] += 1
                            elif group_key == 'player2':
                                results['groups'][group_key]['player2_wins'] += 1
                        else:
                            # For other groupings, determine player by name match
                            if player1 and player1.lower() in point_winner.lower():
                                results['groups'][group_key]['player1_wins'] += 1
                            elif player2 and player2.lower() in point_winner.lower():
                                results['groups'][group_key]['player2_wins'] += 1
                    
                    # Track if ANY metric matched (for matching_points)
                    any_metric_matched_grouped = False
                    
                    # Track specific metrics per player (flexible, not hardcoded)
                    # Check each metric type and increment appropriate counter
                    for metric in metrics:
                        if metric in ['unforced_errors', 'double_faults'] and error_player:
                            # Error-based metrics: count who made the error
                            any_metric_matched_grouped = True
                            results['groups'][group_key].setdefault('player1_' + metric, 0)
                            results['groups'][group_key].setdefault('player2_' + metric, 0)
                            
                            # For player grouping, group_key is 'player1' or 'player2'
                            if group_by == 'player':
                                if group_key == 'player1':
                                    results['groups'][group_key]['player1_' + metric] += 1
                                elif group_key == 'player2':
                                    results['groups'][group_key]['player2_' + metric] += 1
                            else:
                                # For other groupings, determine player by name match
                                if player1 and player1.lower() in error_player.lower():
                                    results['groups'][group_key]['player1_' + metric] += 1
                                elif player2 and player2.lower() in error_player.lower():
                                    results['groups'][group_key]['player2_' + metric] += 1
                        elif metric in ['winners', 'groundstroke_winners', 'baseline_winners', 'rally_winners']:
                            # Check if this is a winner type (use class constant)
                            if winning_shot_type not in self.WINNER_TYPES:
                                continue  # Not a winner, skip
                            
                            # Apply shot-type filtering based on metric
                            skip_point = False
                            
                            # For groundstroke/baseline/rally winners: exclude volleys and specialty shots
                            if metric in ['groundstroke_winners', 'baseline_winners', 'rally_winners']:
                                if actual_shots:
                                    last_shot = actual_shots[-1]
                                    shot_meta = self._extract_shot_metadata(last_shot.get('description', ''))
                                    shot_modifier = shot_meta.get('shot_modifier', '')
                                    direction = shot_meta.get('direction', '')
                                    
                                    # Exclude net shots (volleys) and specialty directions
                                    if shot_modifier in ['volley', 'half_volley', 'swinging_volley']:
                                        skip_point = True
                                    if direction in ['inside_out', 'inside_in']:
                                        skip_point = True
                            
                            if skip_point:
                                continue  # Skip this point for winner counting
                            
                            # Count winners (all or filtered based on metric)
                            any_metric_matched_grouped = True
                            metric_key = metric  # Use actual metric name for storage
                            results['groups'][group_key].setdefault(f'player1_{metric_key}', 0)
                            results['groups'][group_key].setdefault(f'player2_{metric_key}', 0)
                            if point_winner:
                                # For player grouping, group_key is 'player1' or 'player2'
                                if group_by == 'player':
                                    if group_key == 'player1':
                                        results['groups'][group_key][f'player1_{metric_key}'] += 1
                                    elif group_key == 'player2':
                                        results['groups'][group_key][f'player2_{metric_key}'] += 1
                                else:
                                    # For other groupings (set, rally_length, etc.), determine player by name match
                                    if player1 and player1.lower() in point_winner.lower():
                                        results['groups'][group_key][f'player1_{metric_key}'] += 1
                                    elif player2 and player2.lower() in point_winner.lower():
                                        results['groups'][group_key][f'player2_{metric_key}'] += 1
                            # GENERIC metric tracking using METRIC_CONFIG
                            else:
                                # Get metric config to determine who to attribute to
                                metric_cfg = self.METRIC_CONFIG.get(metric, {})
                                player_role = metric_cfg.get('player_role', 'both')
                                keywords = metric_cfg.get('keywords', [])
                                
                                # Check if this metric matches the current point's outcome
                                shot_matches = True
                                if keywords:
                                    winning_lower = (winning_shot_type or '').lower()
                                    if 'winner' in keywords:
                                        shot_matches = winning_shot_type in self.WINNER_TYPES
                                    elif 'ace' in keywords:
                                        shot_matches = winning_lower == 'ace'
                                    elif 'double fault' in keywords:
                                        shot_matches = winning_lower == 'double_fault'
                                    elif 'forced error' in keywords:
                                        shot_matches = winning_lower == 'forced_error'
                                    elif 'unforced error' in keywords:
                                        shot_matches = winning_lower == 'unforced_error'
                                else:
                                    shot_matches = any(kw.lower() in winning_lower for kw in keywords)
                                
                                if shot_matches:
                                    any_metric_matched_grouped = True
                                results['groups'][group_key].setdefault(f'player1_{metric}', 0)
                                results['groups'][group_key].setdefault(f'player2_{metric}', 0)
                                
                                # Determine which player to attribute based on player_role - GENERIC using ROLE_CONFIG
                                attribution_player = ''
                                role_config = self.ROLE_CONFIG.get(player_role, {})
                                player_field = role_config.get('player_field', '')
                                if player_field:
                                    field_to_player = {
                                        'server': server,
                                        'returner': returner,
                                        'point_winner': point_winner,
                                        'error_player': error_player
                                    }
                                    attribution_player = field_to_player.get(player_field, point_winner)
                                else:  # 'both' or unknown
                                    attribution_player = point_winner
                            
                            # For player grouping, group_key is 'player1' or 'player2'
                            if group_by == 'player':
                                    results['groups'][group_key][f'{group_key}_{metric}'] += 1
                            else:
                                    # Determine which player to credit
                                    if player1 and attribution_player and player1.lower() in attribution_player.lower():
                                        results['groups'][group_key][f'player1_{metric}'] += 1
                                    elif player2 and attribution_player and player2.lower() in attribution_player.lower():
                                        results['groups'][group_key][f'player2_{metric}'] += 1
                    
                    # Track secondary metrics (for correlation queries) - GENERIC
                    secondary_metric = classification.get('secondary_metric')
                    if secondary_metric:
                        # Convert metric name to shot type for comparison
                        secondary_shot_type = secondary_metric.rstrip('s').replace('_', ' ')
                        winning_lower = (winning_shot_type or '').replace('_', ' ')
                        
                        if secondary_shot_type in winning_lower or winning_lower in secondary_shot_type:
                            results['groups'][group_key].setdefault(secondary_metric, 0)
                            results['groups'][group_key][secondary_metric] += 1
                        
                        # Store example
                        if len(results['groups'][group_key].get('examples', [])) < 3:
                            results['groups'][group_key].setdefault('examples', []).append({
                            'point': point_num, 'winner': point_winner, 'length': rally_length,
                            'error_player': error_player, 'error_shot': error_shot_type,
                            'outcome': winning_shot_type,
                            'excerpt': point_text.strip()
                            })
                    
                    # Store matching point for debugging (only if metric matched!)
                    # For metrics like win_percentage or points_won with no specific metric, store all points
                    if any_metric_matched_grouped or not metrics or metrics[0] in ['points_won', 'win_percentage', 'points_lost']:
                        # Track actual matching points per group
                        if 'matching_points' not in results['groups'][group_key]:
                            results['groups'][group_key]['matching_points'] = []
                        
                        # Extract metadata for display filtering
                        shot_meta_grp = {}
                        if actual_shots:
                            last_shot_grp = actual_shots[-1]
                            shot_meta_grp = self._extract_shot_metadata(last_shot_grp.get('description', ''))
                        
                        results['groups'][group_key]['matching_points'].append({
                            'point_number': point_num,
                            'server': server,
                            'returner': returner,
                            'score': score,
                            'winner': point_winner,
                            'outcome': winning_shot_type,
                            'rally_length': rally_length,
                            'description': point_text,
                            # Add metadata for display filter
                            'shot_type': shot_meta_grp.get('shot_type'),
                            'shot_modifier': shot_meta_grp.get('shot_modifier'),
                            'direction': shot_meta_grp.get('direction'),
                            'at_net': shot_meta_grp.get('at_net', False)
                        })
                        
                        # Also store in top-level matching_points for grouped analysis
                        if 'matching_points' not in results:
                            results['matching_points'] = []
                        
                        # Extract metadata for display filtering (top-level)
                        shot_meta_top = {}
                        if actual_shots:
                            last_shot_top = actual_shots[-1]
                            shot_meta_top = self._extract_shot_metadata(last_shot_top.get('description', ''))
                        
                        results['matching_points'].append({
                            'point_number': point_num,
                            'server': server,
                            'returner': returner,
                            'score': score,
                            'winner': point_winner,
                            'outcome': winning_shot_type,
                            'rally_length': rally_length,
                            'description': point_text,
                            # Add metadata for display filter
                            'shot_type': shot_meta_top.get('shot_type'),
                            'shot_modifier': shot_meta_top.get('shot_modifier'),
                            'direction': shot_meta_top.get('direction'),
                            'at_net': shot_meta_top.get('at_net', False)
                        })
                
                results['total_points'] += 1
            else:
                # Non-grouped tracking
                results['total_points'] += 1
                
                if point_winner:
                    if player1 and player1.lower() in point_winner.lower():
                        results['player1_wins'] += 1
                    elif player2 and player2.lower() in point_winner.lower():
                        results['player2_wins'] += 1
                
                # Track metrics
                # Create point_data for complex metric checks
                point_data_for_metric = {
                    'point_text': point_text,
                    'rally_length': rally_length,
                    'server': server,
                    'returner': returner,
                    'error_player': error_player
                }
                
                # Track if ANY metric matched (for matching_points deduplication)
                any_metric_matched = False
                
                for metric in metrics:
                    matched = self._check_metric_match(metric, winning_shot_type, point_winner, 
                                                       server, player_filter, point_data_for_metric)
                    if matched:
                        any_metric_matched = True
                        results['metrics_data'][metric]['count'] += 1
                        if len(results['metrics_data'][metric]['points']) < 5:
                            results['metrics_data'][metric]['points'].append({
                                'point': point_num, 'winner': point_winner, 
                                'shot_type': winning_shot_type, 'excerpt': point_text.strip()
                            })
                
                # Store matching point for debugging (once per point, even if multiple metrics match)
                if any_metric_matched:
                    if 'matching_points' not in results:
                        results['matching_points'] = []
                    
                    # Extract metadata for display filtering
                    shot_meta_nogrp = {}
                    if actual_shots:
                        last_shot_nogrp = actual_shots[-1]
                        shot_meta_nogrp = self._extract_shot_metadata(last_shot_nogrp.get('description', ''))
                    
                    results['matching_points'].append({
                        'point_number': point_num,
                        'server': server,
                        'returner': returner,
                        'score': score,
                        'winner': point_winner,
                        'outcome': winning_shot_type,
                        'rally_length': rally_length,
                        'description': point_text,
                        # Add metadata for display filter
                        'shot_type': shot_meta_nogrp.get('shot_type'),
                        'shot_modifier': shot_meta_nogrp.get('shot_modifier'),
                        'direction': shot_meta_nogrp.get('direction'),
                        'at_net': shot_meta_nogrp.get('at_net', False)
                    })
        
        # === CALCULATE PERCENTAGES ===
        if group_by:
            self._calculate_group_percentages(results, player_filter)
        else:
            if results['total_points'] > 0:
                results['player1_pct'] = round(100 * results['player1_wins'] / results['total_points'], 1)
                results['player2_pct'] = round(100 * results['player2_wins'] / results['total_points'], 1)
        
        return results
    
    def _init_grouped_results(self, classification: Dict, group_by: str, player1: str, player2: str) -> Dict:
        """
        METADATA-DRIVEN group initialization.
        Initialize results structure using values from match_filter_inventory.
        """
        results = {
            'classification': classification,
            'group_by': group_by,
            'total_points': 0,
            'player1': player1,
            'player2': player2,
            'groups': {},
            'best_group_for_player': None
        }
        
        # Get inventory for dynamic group generation
        inventory = getattr(self, 'match_filter_inventory', {})
        
        # Helper to create group entry
        def make_group(label):
            return {'label': label, 'total': 0, 'player1_wins': 0, 'player2_wins': 0, 'player1_metric': 0, 'player2_metric': 0}
        
        # GENERIC: Get display config from GROUP_CONFIG
        config = self._get_group_config(group_by)
        if not config:
            # Unknown group_by - return empty groups (will be populated dynamically during traversal)
            return results
        
        display_source = config.get('display_source', 'dynamic')
        
        # Handle custom display functions
        if display_source == 'custom':
            custom_display = config.get('custom_display')
            if custom_display == 'get_player_display':
                results['groups'] = self._get_player_display(classification)
            elif custom_display == 'get_set_groups_display':
                results['groups'] = self._get_set_groups_display(classification)
            return results
        
        # Handle inventory-based groups
        if display_source == 'inventory':
            inventory_key = config.get('inventory_key')
            default_branches = config.get('default_branches', [])
            always_include = config.get('always_include', [])
            include_modifiers = config.get('include_modifiers', False)
            
            # Get branches from inventory or use defaults
            branches = inventory.get(inventory_key, default_branches) if inventory_key else default_branches
            
            # Create groups with labels using GENERIC helper
            groups = {}
            for branch in branches:
                label = self._get_display_label(group_by, branch, classification)
                groups[str(branch)] = make_group(label)
            
            # Always include specified branches
            for branch in always_include:
                branch_str = str(branch)
                if branch_str not in groups:
                    label = self._get_display_label(group_by, branch, classification)
                    groups[branch_str] = make_group(label)
            
            # Include modifiers if specified (e.g., for shot_type)
            if include_modifiers:
                known_mods = inventory.get('shot_modifiers', [])
                for mod in known_mods:
                    mod_str = str(mod)
                    if mod_str not in groups:
                        label = self._get_display_label(group_by, mod, classification)
                        groups[mod_str] = make_group(label)
            
            results['groups'] = groups
            return results
        
        # Handle predefined groups (fixed branches)
        if display_source == 'predefined':
            default_branches = config.get('default_branches', [])
            
            groups = {}
            for branch in default_branches:
                branch_str = str(branch)
                label = self._get_display_label(group_by, branch, classification)
                groups[branch_str] = make_group(label)
            
            results['groups'] = groups
            return results
        
        # Handle dynamic groups (discovered during traversal)
        # Return empty groups - will be populated as points are processed
        if display_source == 'dynamic':
            results['groups'] = {}
            return results
        
        # Fallback: return empty groups
        results['groups'] = {}
        return results
    
    def _prepare_group_structure_LEGACY(self, classification: Dict, player1: str, player2: str) -> Dict:
        """
        LEGACY - DEPRECATED: Not used anywhere. Kept for reference only.
        This function has hard-coded labels and should NOT be used.
        Use _init_grouped_results instead, which uses GROUP_CONFIG generically.
        """
        group_by = classification.get('group_by', '')  # Extract from classification
        results = {
            'classification': classification,
            'group_by': group_by,
            'total_points': 0,
            'player1': player1,
            'player2': player2,
            'groups': {},
            'best_group_for_player': None
        }
        
        # Get inventory for dynamic group generation
        inventory = getattr(self, 'match_filter_inventory', {})
        
        # Helper to create group entry
        def make_group(label):
            return {'label': label, 'total': 0, 'player1_wins': 0, 'player2_wins': 0, 'player1_metric': 0, 'player2_metric': 0}
        
        # Define groups based on group_by type
        if group_by == 'rally_length_category':
            # Use rally categories from inventory if available
            known_cats = inventory.get('rally_categories', ['1-3', '4-6', '7-9', '10+'])
            rally_labels = {'1-3': 'Short (1-3 shots)', '4-6': 'Medium (4-6 shots)', 
                          '7-9': 'Extended (7-9 shots)', '10+': 'Long (10+ shots)'}
            results['groups'] = {cat: make_group(rally_labels.get(cat, cat)) for cat in known_cats}
            
        elif group_by == 'court_side':
            # Use court sides from inventory
            known_sides = inventory.get('court_sides', ['deuce', 'ad'])
            side_labels = {'deuce': 'Deuce Court', 'ad': 'Ad Court'}
            results['groups'] = {side: make_group(side_labels.get(side, side.title() + ' Court')) for side in known_sides}
            
        elif group_by == 'serve_number':
            # Use serve numbers from inventory
            known_serves = inventory.get('serve_numbers', ['1st', '2nd'])
            serve_labels = {'1st': '1st Serve', '2nd': '2nd Serve', '1': '1st Serve', '2': '2nd Serve'}
            results['groups'] = {sn: make_group(serve_labels.get(sn, f'{sn} Serve')) for sn in known_serves}
            
        elif group_by == 'serve_direction':
            # Use serve targets from inventory
            known_targets = inventory.get('serve_targets', ['wide', 'body', 't'])
            target_labels = {'wide': 'Wide', 'body': 'Body', 't': 'T (Down the Middle)'}
            results['groups'] = {t: make_group(target_labels.get(t, t.title())) for t in known_targets}
            
        elif group_by == 'shot_direction':
            # Use directions from inventory
            known_dirs = inventory.get('directions', ['crosscourt', 'down_the_line', 'inside_out', 'inside_in', 'down_the_middle'])
            dir_labels = {
                'crosscourt': 'Crosscourt', 'down_the_line': 'Down the Line', 
                'inside_out': 'Inside-Out', 'inside_in': 'Inside-In', 'down_the_middle': 'Down the Middle'
            }
            results['groups'] = {d: make_group(dir_labels.get(d, d.replace('_', ' ').title())) for d in known_dirs}
            
        elif group_by == 'return_depth':
            # Use depths from inventory
            known_depths = inventory.get('depths', ['shallow', 'deep', 'very_deep'])
            depth_labels = {'shallow': 'Shallow', 'deep': 'Deep', 'very_deep': 'Very Deep', 'unspecified': 'Unspecified'}
            results['groups'] = {d: make_group(depth_labels.get(d, d.replace('_', ' ').title())) for d in known_depths}
            # Add unspecified if needed
            if 'unspecified' not in results['groups']:
                results['groups']['unspecified'] = make_group('Unspecified')
                
        elif group_by == 'shot_type':
            # Use shot types from inventory
            known_types = inventory.get('shot_types', ['forehand', 'backhand'])
            type_labels = {
                'forehand': 'Forehand', 'backhand': 'Backhand', 'volley': 'Volley',
                'overhead': 'Overhead/Smash', 'drop_shot': 'Drop Shot', 'serve': 'Serve'
            }
            results['groups'] = {t: make_group(type_labels.get(t, t.replace('_', ' ').title())) for t in known_types}
            # Also include modifiers that can be shot types
            known_mods = inventory.get('shot_modifiers', [])
            for mod in known_mods:
                if mod not in results['groups']:
                    results['groups'][mod] = make_group(mod.replace('_', ' ').title())
                    
        elif group_by == 'outcome':
            # Use outcomes from inventory
            known_outcomes = inventory.get('outcomes', ['winner', 'ace', 'forced_error', 'unforced_error', 'double_fault'])
            outcome_labels = {
                'winner': 'Winner', 'ace': 'Ace', 'forced_error': 'Forced Error (Induced)',
                'unforced_error': 'Unforced Error', 'double_fault': 'Double Fault'
            }
            results['groups'] = {o: make_group(outcome_labels.get(o, o.replace('_', ' ').title())) for o in known_outcomes}
            
        elif group_by == 'shot_number':
            # Shot numbers are positional, not from inventory
            results['groups'] = {
                '1': make_group('Serve (1st shot)'),
                '2': make_group('Return (2nd shot)'),
                '3': make_group('Serve+1 (3rd shot)'),
                '4+': make_group('Rally (4+ shots)')
            }
            
        elif group_by == 'sets':
            # Use sets played from inventory
            known_sets = inventory.get('sets_played', [1, 2, 3, 4, 5])
            results['groups'] = {str(s): make_group(f'Set {s}') for s in known_sets}
            
        elif group_by == 'player':
            results['groups'] = {
                'player1': make_group(player1),
                'player2': make_group(player2)
            }
            
        elif group_by == 'set_groups':
            filters = classification.get('filters', {})
            set_a = filters.get('set_group_a', [])
            set_b = filters.get('set_group_b', [])
            set_a_label = f"Set{'s' if len(set_a) > 1 else ''} {', '.join(map(str, set_a))}" if set_a else "Group A"
            set_b_label = f"Set{'s' if len(set_b) > 1 else ''} {', '.join(map(str, set_b))}" if set_b else "Group B"
            results['groups'] = {
                'group_a': {'label': set_a_label, 'sets': set_a, **make_group(set_a_label)},
                'group_b': {'label': set_b_label, 'sets': set_b, **make_group(set_b_label)}
            }
            
        elif group_by == 'pressure_level':
            # Use pressure levels from inventory
            known_pressures = inventory.get('pressure_levels', ['low', 'medium', 'high'])
            pressure_labels = {'low': 'Low Pressure (0-3)', 'medium': 'Medium Pressure (4-6)', 'high': 'High Pressure (7-10)'}
            results['groups'] = {p: make_group(pressure_labels.get(p, p.title())) for p in known_pressures}
            
        elif group_by == 'serve_plus_one_type':
            # Use serve+1 types from inventory
            known_sp1 = inventory.get('serve_plus_one_shot_types', ['forehand', 'backhand', 'volley'])
            sp1_labels = {
                'forehand': 'Serve+1 Forehand', 'backhand': 'Serve+1 Backhand', 
                'volley': 'Serve+1 Volley', 'none': 'No Serve+1 (ended on serve/return)'
            }
            results['groups'] = {t: make_group(sp1_labels.get(t, f'Serve+1 {t.title()}')) for t in known_sp1}
            if 'none' not in results['groups']:
                results['groups']['none'] = make_group('No Serve+1 (ended on serve/return)')
                
        elif group_by == 'after_rally_length':
            results['groups'] = {
                'after_short': make_group('After Short Rally (1-4 shots)'),
                'after_medium': make_group('After Medium Rally (5-9 shots)'),
                'after_long': make_group('After Long Rally (10+ shots)'),
                'first_point': make_group('First Point (no previous rally)')
            }
        
        elif group_by == 'shot_modifier':
            # Use shot modifiers from inventory
            known_mods = inventory.get('shot_modifiers', ['slice', 'volley', 'drop_shot', 'approach'])
            results['groups'] = {mod: make_group(mod.replace('_', ' ').title()) for mod in known_mods}
            
        elif group_by == 'spin':
            # Use spin types from inventory
            known_spins = inventory.get('spin_types', ['topspin', 'slice', 'flat'])
            spin_labels = {'topspin': 'Topspin', 'slice': 'Slice', 'flat': 'Flat'}
            results['groups'] = {s: make_group(spin_labels.get(s, s.title())) for s in known_spins}
            
        elif group_by == 'court_position':
            # Use court positions from inventory
            known_positions = inventory.get('court_positions', ['baseline', 'net', 'approach'])
            position_labels = {'baseline': 'Baseline', 'net': 'Net', 'approach': 'Approach'}
            results['groups'] = {p: make_group(position_labels.get(p, p.title())) for p in known_positions}
            
        elif group_by == 'depth':
            # Use depths from inventory (for all shots, not just returns)
            known_depths = inventory.get('depths', ['shallow', 'deep', 'very_deep'])
            depth_labels = {'shallow': 'Shallow', 'deep': 'Deep', 'very_deep': 'Very Deep'}
            results['groups'] = {d: make_group(depth_labels.get(d, d.replace('_', ' ').title())) for d in known_depths}
            
        elif group_by == 'net_play_type':
            # Use net play types from inventory
            known_net_types = inventory.get('net_play_types', [])
            results['groups'] = {nt: make_group(nt.replace('_', ' ').title()) for nt in known_net_types}
        
        return results
    
    def _determine_group_key(self, group_by: str, rally_length: int, score: str, point_lower: str, filters: Dict, target_shot_desc: str = '', rally_shots: list = None, metadata: Dict = None) -> str:
        """
        FULLY GENERIC GROUP KEY DETERMINATION using GROUP_CONFIG.
        New groupings can be added to GROUP_CONFIG without code changes!
        """
        # Use metadata if provided (preferred)
        meta = metadata or {}
        
        # Build point_data dict for extraction
        point_data = {
            'rally_length': rally_length,
            'score': score,
            'point_lower': point_lower,
        }
        
        # Use generic extraction method
        group_key = self._extract_group_key(
            group_by=group_by,
            point_data=point_data,
            metadata=meta,
            filters=filters,
            score=score,
            point_lower=point_lower,
            rally_length=rally_length
        )
        
        # If extraction returned None, check if it's a known group_by that needs special handling
        if group_key is None and group_by in self.GROUP_CONFIG:
            # Config exists but extraction failed - return None (point will be skipped)
            return None
        
        # If group_by not in config, this is a NEW grouping request
        # Return None to skip (user needs to add it to GROUP_CONFIG)
        if group_key is None and group_by not in self.GROUP_CONFIG:
            print(f"[WARNING] Unknown group_by '{group_by}' - add to GROUP_CONFIG to enable")
            return None
        
        return group_key
    
    def _check_metric_match(self, metric: str, winning_shot_type: str, point_winner: str, 
                           server: str, player_filter: str, point_data: Dict = None) -> bool:
        """
        GENERIC CONFIG-DRIVEN metric matching.
        Uses METRIC_CONFIG and ROLE_CONFIG - NO hardcoded metric checks!
        """
        # Treat player_filter='both' as no filter (compare all players)
        if player_filter and player_filter.lower() == 'both':
            player_filter = None
        
        # Get metric config - SINGLE SOURCE OF TRUTH
        config = self.METRIC_CONFIG.get(metric, {})
        
        # If no config found, use a generic fallback
        if not config:
            # Check if metric is a winner type
            if 'winner' in metric.lower():
                config = {'player_role': 'winner', 'total_filter': 'always', 'count_filter': 'on_match', 'keywords': ['winner']}
            elif 'error' in metric.lower():
                config = {'player_role': 'error', 'total_filter': 'always', 'count_filter': 'on_match', 'keywords': ['error']}
            else:
                config = {'player_role': 'both', 'total_filter': 'always', 'count_filter': 'won'}
        
        player_role = config.get('player_role', 'both')
        count_filter = config.get('count_filter', 'won')
        total_filter = config.get('total_filter', 'always')
        keywords = config.get('keywords', [])
        
        # Get relevant players using ROLE_CONFIG
        returner = point_data.get('returner', '') if point_data else ''
        error_player = point_data.get('error_player', '') if point_data else ''
        serve_number = point_data.get('serve_number') if point_data else None
        rally_length = point_data.get('rally_length', 0) if point_data else 0
        
        # Determine the relevant player based on player_role - GENERIC using field_to_player mapping
        role_config = self.ROLE_CONFIG.get(player_role, {})
        player_field = role_config.get('player_field', '')
        
        # GENERIC mapping from field name to actual player value
        field_to_player = {
            'server': server,
            'returner': returner,
            'point_winner': point_winner,
            'error_player': error_player
        }
        
        relevant_player = ''
        if player_field and player_field in field_to_player:
            relevant_player = field_to_player[player_field]
        elif player_role == 'both':
            # For 'both', check if player is involved in point at all
            relevant_player = point_winner  # Default to winner for 'both'
        
        # Check player filter - GENERIC using relevant_player
        if player_filter:
            if player_role == 'both':
                # Player filter matches if player won
                if not self._names_match_robust(player_filter, point_winner):
                    return False
            elif relevant_player:
                # Player filter matches the relevant player for this metric's role
                if not self._names_match_robust(player_filter, relevant_player):
                    return False
        
        # Check total_filter (for percentage calculations - which points to include in denominator)
        if total_filter == 'first_serve':
            if serve_number != 1:
                return False
        elif total_filter == 'second_serve':
            if serve_number != 2:
                return False
        
        # Check count_filter (which points to count in numerator) - GENERIC
        if count_filter == 'won':
            # Point must be won by the relevant player
            # For roles like 'server'/'returner': check if they won
            # For 'winner': always counts (they ARE the winner)
            # For 'error': always counts (error occurred)
            # For 'both' with player_filter: check if that player won
            if player_role in ['winner', 'error']:
                pass  # These roles always count for 'won' filter
            elif player_role == 'both' and player_filter:
                if not self._names_match_robust(point_winner, player_filter):
                    return False
            elif relevant_player:
                # For other roles (server, returner), check if they won
                if not self._names_match_robust(point_winner, relevant_player):
                    return False
        
        elif count_filter == 'first_serve_in':
            return serve_number == 1
        
        elif count_filter == 'second_serve_in':
            return serve_number == 2
        
        elif count_filter == 'on_match':
            # Check keywords against winning_shot_type
            if keywords:
                # Normalize winning_shot_type for comparison
                shot_type_lower = winning_shot_type.lower() if winning_shot_type else ''
                
                # Check if WINNER_TYPES should be used
                if 'winner' in keywords:
                    if winning_shot_type not in self.WINNER_TYPES and 'winner' not in shot_type_lower:
                        return False
                elif 'ace' in keywords:
                    if shot_type_lower != 'ace':
                        return False
                elif 'double fault' in keywords:
                    if shot_type_lower != 'double_fault':
                        return False
                elif 'forced error' in keywords:
                    if shot_type_lower != 'forced_error':
                        return False
                elif 'unforced error' in keywords:
                    if shot_type_lower != 'unforced_error':
                        return False
                elif 'error' in keywords:
                    if shot_type_lower not in ['unforced_error', 'forced_error']:
                        return False
                else:
                    # Generic keyword matching
                    if not any(kw.lower() in shot_type_lower for kw in keywords):
                        return False
        
        # Additional metric-specific conditions using config
        # Rally length conditions for rally_winners
        min_rally = config.get('min_rally_length', 0)
        if min_rally > 0 and rally_length < min_rally:
            return False
        
        return True
    
    def _calculate_group_percentages(self, results: Dict, player_filter: str) -> None:
        """Calculate win percentages for each group and find best group."""
        best_pct = -1
        best_group = None
        
        player1 = results['player1']
        player2 = results['player2']
        
        for group_key, group_data in results['groups'].items():
            if group_data['total'] > 0:
                group_data['player1_pct'] = round(100 * group_data['player1_wins'] / group_data['total'], 1)
                group_data['player2_pct'] = round(100 * group_data['player2_wins'] / group_data['total'], 1)
                
                # Track best group for the player filter
                if player_filter:
                    if player1 and player_filter.lower() in player1.lower():
                        if group_data['player1_pct'] > best_pct:
                            best_pct = group_data['player1_pct']
                            best_group = group_key
                    elif player2 and player_filter.lower() in player2.lower():
                        if group_data['player2_pct'] > best_pct:
                            best_pct = group_data['player2_pct']
                            best_group = group_key
            else:
                group_data['player1_pct'] = 0
                group_data['player2_pct'] = 0
        
        if best_group:
            results['best_group_for_player'] = {
                'group': best_group,
                'label': results['groups'][best_group]['label'],
                'win_pct': best_pct,
                'player': player_filter
            }
    
    def _analyze_2d_grouping(self, classification: Dict) -> Dict[str, Any]:
        """
        2D Grouping Analysis - Cross-tabulation of two dimensions.
        
        Example: shot_direction (IO/DTL) × set_groups (sets won/lost)
        Output: Matrix showing metric for each combination
        """
        filters = classification.get('filters', {})
        metrics = classification.get('metrics', ['points_won'])
        group_by = classification.get('group_by')
        secondary_group = classification.get('secondary_group_by')
        
        if not group_by or not secondary_group:
            return {'error': '2D grouping requires both group_by and secondary_group_by'}
        
        player1 = self.player1
        player2 = self.player2
        player_filter = filters.get('player')
        
        # Initialize 2D results structure
        primary_groups = self._get_group_labels(group_by, classification)
        secondary_groups = self._get_group_labels(secondary_group, classification)
        
        results = {
            'classification': classification,
            'group_by': group_by,
            'secondary_group_by': secondary_group,
            'total_points': 0,
            'player1': player1,
            'player2': player2,
            'matrix': {}  # {primary_key: {secondary_key: {data}}}
        }
        
        # Initialize matrix
        for p_key, p_label in primary_groups.items():
            results['matrix'][p_key] = {
                'label': p_label,
                'secondary': {}
            }
            for s_key, s_label in secondary_groups.items():
                results['matrix'][p_key]['secondary'][s_key] = {
                    'label': s_label,
                    'total': 0,
                    'player1_wins': 0,
                    'player2_wins': 0,
                    'player1_metric': 0,
                    'player2_metric': 0
                }
        
        # Parse point-by-point
        if not hasattr(self, 'point_by_point') or not self.point_by_point:
            return {'error': 'No point-by-point data available'}
        
        for point_num, point_data in enumerate(self.point_by_point, 1):
            point_text = point_data.get('point_text', point_data.get('description', ''))
            if not point_text:
                continue
            
            point_lower = point_text.lower()
            score = point_data.get('score', '')
            server = point_data.get('server', '')
            returner = point_data.get('returner', '')
            
            # Parse rally
            rally_shots = self._parse_rally_sequence(point_text, server, returner)
            actual_shots = [s for s in rally_shots if s.get('outcome') != 'FAULT']
            rally_length = len(actual_shots)
            
            # UNIFIED: Use _determine_point_winner
            point_winner, winning_shot_type, error_player = self._determine_point_winner(
                actual_shots, server, returner, return_details=True
            )
            
            # Determine primary group key
            target_shot_desc = actual_shots[-1].get('description', '').lower() if actual_shots else ''
            filters['_current_outcome'] = winning_shot_type
            filters['_rally_length'] = rally_length
            # Add player-related context for metric-aware grouping
            filters['_server'] = server
            filters['_returner'] = returner
            filters['_point_winner'] = point_winner
            filters['_error_player'] = error_player
            filters['_current_metric'] = metrics[0] if metrics else None
            
            # Get or compute metadata for this point
            if '_metadata' not in point_data:
                point_data['_metadata'] = self._get_point_metadata(point_data)
            point_meta = point_data['_metadata']
            
            primary_key = self._determine_group_key(group_by, rally_length, score, point_lower, filters, target_shot_desc, rally_shots=actual_shots, metadata=point_meta)
            secondary_key = self._determine_group_key(secondary_group, rally_length, score, point_lower, filters, target_shot_desc, rally_shots=actual_shots, metadata=point_meta)
            
            if primary_key is None or secondary_key is None:
                continue
            
            if primary_key not in results['matrix'] or secondary_key not in results['matrix'][primary_key]['secondary']:
                continue
            
            # Track results
            cell = results['matrix'][primary_key]['secondary'][secondary_key]
            cell['total'] += 1
            results['total_points'] += 1
            
            if point_winner:
                if player1 and player1.lower() in point_winner.lower():
                    cell['player1_wins'] += 1
                elif player2 and player2.lower() in point_winner.lower():
                    cell['player2_wins'] += 1
        
        return results
    
    def _get_group_labels(self, group_by: str, classification: Dict = None) -> Dict[str, str]:
        """
        Get the group keys and labels for a given group_by type.
        GENERIC: Uses GROUP_CONFIG as single source of truth.
        """
        return self._get_all_group_values(group_by, classification)
    
    def _analyze_momentum(self, classification: Dict) -> Dict[str, Any]:
        """
        Momentum Analysis - Track game-by-game or set-by-set momentum shifts.
        
        Example: "After winning a break point, did they play more aggressively?"
        """
        filters = classification.get('filters', {})
        player_filter = filters.get('player')
        
        if not hasattr(self, 'point_by_point') or not self.point_by_point:
            return {'error': 'No point-by-point data available for momentum analysis'}
        
        # Track momentum by games
        game_results = []
        current_game = {'game_num': 0, 'points_p1': 0, 'points_p2': 0, 'server': None}
        prev_game_score = ""
        break_point_converts = []
        after_break_aggression = []
        
        player1 = self.player1
        player2 = self.player2
        
        for point_data in self.point_by_point:
            point_text = point_data.get('point_text', point_data.get('description', ''))
            score = point_data.get('score', '')
            server = point_data.get('server', '')
            
            # Detect new game
            game_score = score.split()[-1] if score else ""  # Last part is game score
            set_game_score = ' '.join(score.split()[:-1]) if score else ""
            
            if set_game_score != prev_game_score:
                if current_game['game_num'] > 0:
                    game_results.append(current_game.copy())
                current_game = {
                    'game_num': len(game_results) + 1,
                    'points_p1': 0,
                    'points_p2': 0,
                    'server': server,
                    'winners': 0,
                    'errors': 0
                }
                prev_game_score = set_game_score
            
            # UNIFIED: Use _determine_point_winner
            returner = point_data.get('returner', '')
            rally_shots = self._parse_rally_sequence(point_text, server, returner)
            actual_shots = [s for s in rally_shots if s.get('outcome') != 'FAULT']
            
            point_winner, shot_type, _ = self._determine_point_winner(
                actual_shots, server, returner, return_details=True
            )
            is_winner = shot_type in ['ace', 'winner', 'service_winner']
            is_error = shot_type in ['unforced_error', 'forced_error', 'double_fault']
            
            if point_winner:
                if player1 and player1.lower() in point_winner.lower():
                    current_game['points_p1'] += 1
                elif player2 and player2.lower() in point_winner.lower():
                    current_game['points_p2'] += 1
            
            if is_winner:
                current_game['winners'] = current_game.get('winners', 0) + 1
            if is_error:
                current_game['errors'] = current_game.get('errors', 0) + 1
            
            # Track break point conversions
            if self._is_break_point_score(score):
                returner = point_data.get('returner', '')
                if point_winner and returner.lower() in point_winner.lower():
                    break_point_converts.append({
                        'game': current_game['game_num'],
                        'player': returner,
                        'score': score
                    })
        
        # Calculate momentum trends
        momentum_shifts = []
        for i, game in enumerate(game_results[:-1]):
            next_game = game_results[i + 1]
            
            # Check if a break happened
            if game['server'] and next_game['server']:
                was_break = game['points_p1'] > game['points_p2'] if player2 and player2.lower() in game['server'].lower() else game['points_p2'] > game['points_p1']
                
                if was_break:
                    momentum_shifts.append({
                        'after_game': i + 1,
                        'type': 'break',
                        'aggression_next': (next_game.get('winners', 0) - next_game.get('errors', 0))
                    })
        
        return {
            'classification': classification,
            'game_results': game_results,
            'break_point_converts': break_point_converts,
            'momentum_shifts': momentum_shifts,
            'player1': player1,
            'player2': player2
        }
    
    def _format_momentum_analysis(self, analysis: Dict[str, Any]) -> str:
        """Format momentum analysis results."""
        if 'error' in analysis:
            return f"Unable to perform momentum analysis: {analysis['error']}"
        
        game_results = analysis['game_results']
        momentum_shifts = analysis['momentum_shifts']
        break_converts = analysis['break_point_converts']
        player1 = analysis['player1']
        player2 = analysis['player2']
        
        response = f"**Momentum Analysis**\n\n"
        response += f"**Total Games Analyzed:** {len(game_results)}\n"
        response += f"**Break Points Converted:** {len(break_converts)}\n\n"
        
        if momentum_shifts:
            response += "**Momentum After Breaks:**\n"
            for shift in momentum_shifts:
                aggression = shift['aggression_next']
                direction = "more aggressive" if aggression > 0 else "more conservative" if aggression < 0 else "neutral"
                response += f"- After Game {shift['after_game']}: Player played {direction} ({aggression:+d} W-E)\n"
        
        response += "\n**Per-Game Summary:**\n"
        response += "| Game | Server | P1 | P2 | W | E |\n"
        response += "|------|--------|----|----|---|---|\n"
        for g in game_results[:20]:  # First 20 games
            response += f"| {g['game_num']} | {g.get('server', 'N/A')[:10]} | {g['points_p1']} | {g['points_p2']} | {g.get('winners', 0)} | {g.get('errors', 0)} |\n"
        
        return response
    
    def _analyze_chain_logic(self, classification: Dict) -> Dict[str, Any]:
        """
        Chain Logic Analysis - Track Shot A leading to Shot B patterns.
        
        Example: "How many times did a backhand slice lead to an unforced error?"
        """
        filters = classification.get('filters', {})
        chain = filters.get('chain_logic', {})
        
        shot_a_raw = chain.get('shot_a')  # Can be string or dict
        shot_b_raw = chain.get('shot_b')  # Can be string or dict
        
        # Convert dict format to list of keywords for flexible matching
        def normalize_shot(shot_data):
            keywords = []
            
            if isinstance(shot_data, dict):
                # Extract all values from dict and split into individual words
                for key in ['shot_type', 'shot_modifier', 'hand', 'direction']:
                    val = shot_data.get(key)
                    if val:
                        # Split multi-word values: "forehand volley" → ["forehand", "volley"]
                        keywords.extend(val.lower().split())
            elif isinstance(shot_data, str):
                # Split string into individual keywords
                keywords.extend(shot_data.lower().split())
            
            # Remove duplicates while preserving order
            seen = set()
            unique_keywords = []
            for kw in keywords:
                if kw not in seen:
                    seen.add(kw)
                    unique_keywords.append(kw)
            
            return unique_keywords if unique_keywords else None
        
        shot_a_keywords = normalize_shot(shot_a_raw)
        shot_b_keywords = normalize_shot(shot_b_raw)
        
        # CRITICAL: Parse Shot B for special cases
        # "unforced error from opponent" -> opponent's shot with unforced error outcome
        # "winner" -> current player's winning shot
        shot_b_opponent = False  # Is Shot B by the opponent?
        shot_b_outcome = None    # What outcome to check? (unforced error, forced error, winner)
        
        shot_b_str = ' '.join(shot_b_keywords) if shot_b_keywords else (shot_b_raw if isinstance(shot_b_raw, str) else '')
        shot_b_lower = shot_b_str.lower()
        
        # Check if Shot B is by opponent
        if 'opponent' in shot_b_lower or 'from opponent' in shot_b_lower:
            shot_b_opponent = True
            # Remove "opponent" and "from" from keywords - these are modifiers, not shot descriptors
            shot_b_keywords = [kw for kw in (shot_b_keywords or []) if kw not in ['opponent', 'from']]
        
        # Check for outcome-only Shot B (unforced error, forced error, winner)
        if 'unforced' in shot_b_lower and 'error' in shot_b_lower:
            shot_b_outcome = 'UNFORCED ERROR'
        elif 'forced' in shot_b_lower and 'error' in shot_b_lower:
            shot_b_outcome = 'FORCED ERROR'
        elif 'winner' in shot_b_lower:
            shot_b_outcome = 'WINNER'
        
        # For display purposes
        shot_a_type = ' '.join(shot_a_keywords) if shot_a_keywords else None
        shot_b_type = shot_b_str if shot_b_str else ' '.join(shot_b_keywords) if shot_b_keywords else None
        
        if not shot_a_keywords:
            # Try to detect from query
            query_lower = classification.get('actual_question', '').lower()
            
            # Pattern: "X led to Y" or "X followed by Y"
            if 'led to' in query_lower or 'lead to' in query_lower:
                parts = query_lower.split('led to' if 'led to' in query_lower else 'lead to')
                shot_a_keywords = [parts[0].strip()] if parts[0].strip() else None
            elif 'followed by' in query_lower:
                parts = query_lower.split('followed by')
                shot_a_keywords = [parts[0].strip()] if parts[0].strip() else None
            
            # Update display strings
            shot_a_type = ' '.join(shot_a_keywords) if shot_a_keywords else None
        
        if not shot_a_keywords:
            return {'error': 'Chain logic requires Shot A specification'}
        
        player_filter = filters.get('player')
        set_filter = filters.get('set')
        serve_target_filter = filters.get('serve_target')  # wide, body, t
        shot_type_filter = filters.get('shot_type')  # forehand, backhand, etc.
        
        # SHOT POSITION FILTER: Extract from query/chain_logic
        # "second shot" = position 2 (return), "third shot" = position 3 (serve+1)
        shot_a_position = None
        query_lower = classification.get('actual_question', '').lower()
        
        if 'second shot' in query_lower or 'as his return' in query_lower or 'as her return' in query_lower or 'the return' in query_lower:
            shot_a_position = 2  # Return = shot #2
        elif 'third shot' in query_lower or 'third ball' in query_lower or 'serve+1' in query_lower or 'serve + 1' in query_lower:
            shot_a_position = 3  # Serve + 1 = shot #3
        elif 'first shot' in query_lower or 'the serve' in query_lower:
            shot_a_position = 1  # Serve = shot #1
        elif 'fourth shot' in query_lower:
            shot_a_position = 4
        
        if shot_a_position:
            print(f"[CHAIN] Shot A position filter: position {shot_a_position}")
        
        if not hasattr(self, 'point_by_point') or not self.point_by_point:
            return {'error': 'No point-by-point data available'}
        
        chain_matches = []
        total_shot_a = 0
        
        for point_data in self.point_by_point:
            point_text = point_data.get('point_text', point_data.get('description', ''))
            score = point_data.get('score', '')
            server = point_data.get('server', '')
            returner = point_data.get('returner', '')
            
            # Extract point winner from [Point won by:] tag (authoritative source)
            point_winner = None
            winner_match = re.search(r'\[Point won by:\s*([^\]]+)\]', point_text)
            if winner_match:
                point_winner = winner_match.group(1).strip()
            
            # Set filter
            if set_filter:
                current_set = self._extract_current_set(score)
                if current_set != set_filter:
                    continue
            
            # Parse rally
            rally_shots = self._parse_rally_sequence(point_text, server, returner)
            actual_shots = [s for s in rally_shots if s.get('outcome') != 'FAULT']
            
            # Look for Shot A → Shot B pattern
            for i, shot in enumerate(actual_shots[:-1]):
                shot_desc = (shot.get('description') or '').lower()
                shot_player = shot.get('player') or ''
                shot_position = shot.get('shot_number')  # USE METADATA (1=serve, 2=return, 3=serve+1, etc.)
                
                # SHOT POSITION FILTER: Skip if not the required position
                if shot_a_position and shot_position and shot_position != shot_a_position:
                    continue
                
                # Check if this is Shot A - ALL keywords must be present
                shot_a_match = all(kw in shot_desc for kw in shot_a_keywords)
                
                if shot_a_match:
                    # Player filter for Shot A
                    if player_filter and not self._names_match_robust(player_filter, shot_player):
                        continue
                    
                    # Serve target filter (wide, body, t)
                    if serve_target_filter:
                        if serve_target_filter == 'wide':
                            if 'wide' not in shot_desc:
                                continue
                        elif serve_target_filter == 'body':
                            if 'body' not in shot_desc and 'to body' not in shot_desc:
                                continue
                        elif serve_target_filter == 't':
                            if 'down the t' not in shot_desc and 'to t' not in shot_desc:
                                continue
                    
                    total_shot_a += 1
                    
                    # CRITICAL: Determine which shot to check for Shot B
                    # If Shot A is a serve, "next shot" (or "very next shot") means serve + 1 (skip the return)
                    # Otherwise, "next shot" means the immediate next shot
                    is_serve = 'serve' in shot_desc or '1st serve' in shot_desc or '2nd serve' in shot_desc
                    
                    if is_serve and player_filter:
                        # Serve → Serve + 1 pattern: Skip the return (i+1), check serve + 1 (i+2)
                        # This handles both "next shot" and "very next shot" queries
                        if i + 2 < len(actual_shots):
                            next_shot = actual_shots[i + 2]  # Serve + 1 (skip return)
                            next_player = next_shot.get('player') or ''
                            # CRITICAL: Serve + 1 must be by the same player as the serve
                            if not self._names_match_robust(player_filter, next_player):
                                continue  # Serve + 1 is by wrong player
                            next_desc = (next_shot.get('description') or '').lower()
                            next_outcome = (next_shot.get('outcome') or '').lower()
                        else:
                            continue  # Not enough shots for serve + 1
                    else:
                        # Regular pattern: Check immediate next shot
                        if i + 1 < len(actual_shots):
                            next_shot = actual_shots[i + 1]
                            next_desc = (next_shot.get('description') or '').lower()
                            next_outcome = (next_shot.get('outcome') or '').lower()
                            next_player = next_shot.get('player') or ''
                        else:
                            continue  # No next shot
                    
                    # Check if Shot B matches
                    # NEW: Handle three cases:
                    # 1. shot_b_outcome set (e.g., "unforced error") - check outcome field
                    # 2. shot_b_opponent set (e.g., "from opponent") - next shot by other player
                    # 3. Regular keywords - check description
                    shot_b_match = False
                    
                    # CASE 1: Outcome-based Shot B (e.g., "unforced error from opponent") - GENERIC
                    if shot_b_outcome:
                        # Check if next shot's outcome matches - GENERIC using keyword from shot_b_outcome
                        outcome_upper = (next_outcome or '').upper()
                        desc_lower = (next_desc or '').lower()
                        
                        # Convert shot_b_outcome to keyword for matching
                        outcome_keyword = shot_b_outcome.lower().replace('_', ' ')
                        shot_b_match = outcome_keyword in outcome_upper.lower() or outcome_keyword in desc_lower
                        
                        # Check if opponent requirement is met
                        if shot_b_match and shot_b_opponent and player_filter:
                            # Shot B should be by the OTHER player (not player_filter)
                            if self._names_match_robust(player_filter, next_player):
                                shot_b_match = False  # Shot B is by same player, not opponent
                    else:
                        # CASE 2: Regular keyword matching
                        # Separate outcome keywords from shot type keywords
                        outcome_keywords = ['winner', 'unforced', 'forced', 'error', 'ace', 'double', 'fault']
                        shot_type_keywords_b = [kw for kw in (shot_b_keywords or []) if kw not in outcome_keywords]
                        outcome_only_keywords = [kw for kw in (shot_b_keywords or []) if kw in outcome_keywords]
                        
                        # Check shot type keywords (must be in description)
                        shot_type_match = True
                        if shot_type_keywords_b:
                            shot_type_match = all(kw in next_desc for kw in shot_type_keywords_b)
                        
                        # Check outcome keywords (can be in outcome OR description)
                        outcome_match = True
                        if outcome_only_keywords:
                            outcome_match = all(
                                (kw in next_outcome) or (kw in next_desc)
                                for kw in outcome_only_keywords
                            )
                        
                        shot_b_match = shot_type_match and outcome_match
                        
                        # Check opponent requirement
                        if shot_b_match and shot_b_opponent and player_filter:
                            if self._names_match_robust(player_filter, next_player):
                                shot_b_match = False  # Shot B is by same player, not opponent
                        # If NOT opponent mode and player filter exists, Shot B must be by player
                        elif shot_b_match and not shot_b_opponent and player_filter:
                            if not self._names_match_robust(player_filter, next_player):
                                shot_b_match = False
                    
                    # Shot type filter for Shot B (e.g., forehand winner)
                    if shot_b_match and shot_type_filter:
                        if shot_type_filter.lower() not in next_desc:
                            continue
                    
                    if shot_b_match:
                        # Determine if player won the point
                        won = None
                        if point_winner and player_filter:
                            won = self._names_match_robust(player_filter, point_winner)
                        
                        chain_matches.append({
                            'point': point_text,
                            'score': score,
                            'shot_a': shot_desc,
                            'shot_b': f"{next_desc} ({next_outcome})",
                            'player_a': shot_player,
                            'player_b': next_player,
                            'shot_a_number': shot_position,
                            'shot_b_number': next_shot.get('shot_number'),
                            'won': won
                        })
        
        # Calculate win percentage for chain sequences
        wins = sum(1 for m in chain_matches if m.get('won') == True)
        total_chain = len(chain_matches)
        win_pct = round(100 * wins / total_chain, 1) if total_chain > 0 else 0
        
        return {
            'classification': classification,
            'shot_a': shot_a_type,
            'shot_b': shot_b_type,
            'player': player_filter,
            'total_shot_a': total_shot_a,
            'chain_matches': chain_matches,
            'total_chain_sequences': total_chain,
            'wins': wins,
            'win_percentage': win_pct,
            'conversion_rate': round(100 * total_chain / total_shot_a, 1) if total_shot_a > 0 else 0
        }
    
    def _format_chain_logic_analysis(self, analysis: Dict[str, Any]) -> str:
        """Format chain logic analysis results."""
        if 'error' in analysis:
            return f"Unable to perform chain logic analysis: {analysis['error']}"
        
        shot_a = analysis['shot_a']
        shot_b = analysis['shot_b']
        player = analysis.get('player', 'Player')
        total_a = analysis['total_shot_a']
        matches = analysis['chain_matches']
        total_chain = analysis.get('total_chain_sequences', len(matches))
        wins = analysis.get('wins', 0)
        win_pct = analysis.get('win_percentage', 0)
        rate = analysis['conversion_rate']
        
        response = f"**Chain Logic Analysis: {shot_a.title()} → {shot_b.title()}**\n\n"
        
        if player:
            response += f"**Player:** {player}\n"
        
        response += f"**Total {shot_a.title()} Shots:** {total_a}\n"
        response += f"**Led to {shot_b.title()}:** {total_chain} ({rate}% conversion)\n\n"
        
        # Win percentage section
        response += f"**Win Percentage on {shot_a.title()} → {shot_b.title()} sequences:**\n"
        response += f"- Points Won: {wins} / {total_chain}\n"
        response += f"- **Win %: {win_pct}%**\n\n"
        
        if matches:
            response += f"**Examples ({min(len(matches), 10)} shown):**\n\n"
            for m in matches[:10]:
                won_str = "✅ WON" if m.get('won') else "❌ LOST" if m.get('won') == False else ""
                shot_a_num = m.get('shot_a_number', '?')
                shot_b_num = m.get('shot_b_number', '?')
                response += f"- **Score:** {m['score']} {won_str}\n"
                response += f"  - **Shot A (#{shot_a_num}):** {m['shot_a']} by {m['player_a']}\n"
                response += f"  - **Shot B (#{shot_b_num}):** {m['shot_b']} by {m['player_b']}\n"
                response += f"  - Rally: {m['point']}\n\n"
        
        return response
    
    def _format_2d_analysis(self, analysis: Dict[str, Any]) -> str:
        """Format 2D grouping analysis as a cross-tabulation table."""
        if 'error' in analysis:
            return f"Unable to perform 2D analysis: {analysis['error']}"
        
        classification = analysis['classification']
        filters = classification.get('filters', {})
        player_filter = filters.get('player')
        
        group_by = analysis['group_by']
        secondary_group = analysis['secondary_group_by']
        matrix = analysis['matrix']
        
        response = f"**2D Cross-Tabulation: {group_by.replace('_', ' ').title()} × {secondary_group.replace('_', ' ').title()}**\n\n"
        if player_filter:
            response += f"**Player:** {player_filter}\n"
        response += f"**Total Points:** {analysis['total_points']}\n\n"
        
        # Build header row
        secondary_labels = []
        for p_key in matrix:
            for s_key, s_data in matrix[p_key]['secondary'].items():
                if s_data['label'] not in secondary_labels:
                    secondary_labels.append(s_data['label'])
        
        response += f"| {group_by.replace('_', ' ').title()} |"
        for s_label in secondary_labels:
            response += f" {s_label} |"
        response += "\n"
        
        response += "|" + "----|" * (len(secondary_labels) + 1) + "\n"
        
        # Build data rows
        for p_key, p_data in matrix.items():
            row_label = p_data['label']
            response += f"| **{row_label}** |"
            for s_label in secondary_labels:
                # Find matching cell
                for s_key, s_data in p_data['secondary'].items():
                    if s_data['label'] == s_label:
                        total = s_data['total']
                        p1_pct = round(100 * s_data['player1_wins'] / total, 1) if total > 0 else 0
                        response += f" {total} ({p1_pct}%) |"
                        break
            response += "\n"
        
        return response
    
    def _analyze_with_ratio(self, classification: Dict) -> Dict[str, Any]:
        """
        Ratio Analysis - Calculate ratio between two metrics.
        
        Example: Winners to Unforced Errors ratio
        """
        filters = classification.get('filters', {})
        metrics = classification.get('metrics', [])
        ratio_metrics = classification.get('ratio_metrics', metrics[:2] if len(metrics) >= 2 else None)
        
        if not ratio_metrics or len(ratio_metrics) < 2:
            return {'error': 'Ratio analysis requires two metrics'}
        
        metric_a, metric_b = ratio_metrics[0], ratio_metrics[1]
        
        # UNIFIED: Use _analyze_n_dimensional for both metrics at once
        classification_combined = classification.copy()
        classification_combined['metrics'] = [metric_a, metric_b]
        result = self._analyze_n_dimensional(classification_combined)
        
        if 'error' in result:
            return result
        
        # Extract counts from unified results structure
        tree_results = result.get('results', {})
        per_player = tree_results.get('per_player_metrics', {})
        player_filter = classification.get('filters', {}).get('player')
        
        # Get counts - use per_player_metrics (always populated)
        if player_filter and player_filter.lower() != 'both':
            # Single player - get that player's counts
            is_player1 = self._names_match_robust(player_filter, self.player1)
            player_key = 'player1' if is_player1 else 'player2'
            count_a = per_player.get(metric_a, {}).get(player_key, {}).get('count', 0)
            count_b = per_player.get(metric_b, {}).get(player_key, {}).get('count', 0)
        else:
            # Both players - sum counts
            count_a = (per_player.get(metric_a, {}).get('player1', {}).get('count', 0) +
                      per_player.get(metric_a, {}).get('player2', {}).get('count', 0))
            count_b = (per_player.get(metric_b, {}).get('player1', {}).get('count', 0) +
                      per_player.get(metric_b, {}).get('player2', {}).get('count', 0))
        
        ratio = count_a / count_b if count_b > 0 else float('inf')
        
        return {
            'classification': classification,
            'metric_a': metric_a,
            'metric_b': metric_b,
            'count_a': count_a,
            'count_b': count_b,
            'ratio': ratio,
            'total_points': tree_results.get('total_points', 0)
        }
    
    def _format_ratio_analysis(self, analysis: Dict[str, Any]) -> str:
        """Format ratio analysis results."""
        if 'error' in analysis:
            return f"Unable to perform ratio analysis: {analysis['error']}"
        
        metric_a = analysis['metric_a'].replace('_', ' ').title()
        metric_b = analysis['metric_b'].replace('_', ' ').title()
        count_a = analysis['count_a']
        count_b = analysis['count_b']
        ratio = analysis['ratio']
        
        response = f"**Ratio Analysis: {metric_a} to {metric_b}**\n\n"
        response += f"| Metric | Count |\n"
        response += f"|--------|-------|\n"
        response += f"| **{metric_a}** | {count_a} |\n"
        response += f"| **{metric_b}** | {count_b} |\n\n"
        
        if ratio != float('inf'):
            response += f"**Ratio:** {ratio:.2f}:1 ({metric_a} : {metric_b})\n"
            if ratio > 1:
                response += f"📈 {ratio:.1f}x more {metric_a.lower()} than {metric_b.lower()}\n"
            elif ratio < 1:
                response += f"📉 {1/ratio:.1f}x more {metric_b.lower()} than {metric_a.lower()}\n"
            else:
                response += f"➡️ Equal amounts of both\n"
        else:
            response += f"**Ratio:** Cannot calculate (no {metric_b.lower()})\n"
        
        return response
    
    def _analyze_trend_across_sets(self, classification: Dict) -> Dict[str, Any]:
        """
        Trend Analysis - Track how a metric changes across sets.
        
        Example: How did Djokovic's 1st serve % change across sets?
        """
        filters = classification.get('filters', {})
        metrics = classification.get('metrics', ['points_won'])
        metric = metrics[0] if metrics else 'points_won'
        player_filter = filters.get('player')
        
        # UNIFIED: Use _analyze_n_dimensional with set grouping
        classification['group_by'] = 'sets'
        result = self._analyze_n_dimensional(classification)
        
        if 'error' in result:
            return result
        
        # Extract per-set data from unified results structure
        tree_results = result.get('results', {})
        branches = tree_results.get('branches', {}) if tree_results.get('type') == 'group' else {}
        trend_data = []
        
        for set_num in ['1', '2', '3', '4', '5']:
            if set_num in branches:
                branch = branches[set_num]
                branch_results = branch.get('results', {})
                total = branch_results.get('total_points', 0)
                if total > 0:
                    p1_wins = branch_results.get('player1_wins', 0)
                    p2_wins = branch_results.get('player2_wins', 0)
                    p1_pct = round(100 * p1_wins / total, 1)
                    p2_pct = round(100 * p2_wins / total, 1)
                    trend_data.append({
                        'set': int(set_num),
                        'total': total,
                        'player1_wins': p1_wins,
                        'player2_wins': p2_wins,
                        'player1_pct': p1_pct,
                        'player2_pct': p2_pct
                    })
        
        # Calculate trend
        if len(trend_data) >= 2:
            if player_filter and self.player1 and player_filter.lower() in self.player1.lower():
                values = [d['player1_pct'] for d in trend_data]
            elif player_filter and self.player2 and player_filter.lower() in self.player2.lower():
                values = [d['player2_pct'] for d in trend_data]
            else:
                values = [d['player1_pct'] for d in trend_data]
            
            # Simple trend direction
            start, end = values[0], values[-1]
            diff = end - start
            trend_direction = 'increasing' if diff > 5 else 'decreasing' if diff < -5 else 'stable'
        else:
            trend_direction = 'insufficient data'
        
        return {
            'classification': classification,
            'metric': metric,
            'trend_data': trend_data,
            'trend_direction': trend_direction,
            'player1': self.player1,
            'player2': self.player2
        }
    
    def _format_trend_analysis(self, analysis: Dict[str, Any]) -> str:
        """Format trend analysis results."""
        if 'error' in analysis:
            return f"Unable to perform trend analysis: {analysis['error']}"
        
        metric = analysis['metric'].replace('_', ' ').title()
        trend_data = analysis['trend_data']
        trend_direction = analysis['trend_direction']
        player1 = analysis['player1']
        player2 = analysis['player2']
        
        filters = analysis['classification'].get('filters', {})
        player_filter = filters.get('player')
        
        response = f"**Trend Analysis: {metric} Across Sets**\n\n"
        
        response += f"| Set | Total | {player1} | {player2} |\n"
        response += f"|-----|-------|-----------|----------|\n"
        
        for d in trend_data:
            response += f"| **Set {d['set']}** | {d['total']} | {d['player1_wins']} ({d['player1_pct']}%) | {d['player2_wins']} ({d['player2_pct']}%) |\n"
        
        response += f"\n**Trend:** "
        if trend_direction == 'increasing':
            response += f"📈 {player_filter or player1}'s {metric.lower()} **increased** across the match\n"
        elif trend_direction == 'decreasing':
            response += f"📉 {player_filter or player1}'s {metric.lower()} **decreased** across the match\n"
        else:
            response += f"➡️ {player_filter or player1}'s {metric.lower()} remained **stable** across the match\n"
        
        return response
    
    def _format_taxonomy_analysis(self, analysis: Dict[str, Any]) -> str:
        """Format taxonomy-based analysis results - handles both grouped and non-grouped."""
        if 'error' in analysis:
            return f"Unable to perform analysis: {analysis['error']}"
        
        classification = analysis['classification']
        filters = classification['filters']
        metrics = classification.get('metrics', [])
        group_by = analysis.get('group_by')
        
        player = filters.get('player') or 'Both Players'
        situation = (filters.get('situation') or 'all points').replace('_', ' ').title()
        
        # DEBUG: Print what we're working with
        print(f"[FORMAT] group_by={group_by}, has_groups={'groups' in analysis}, groups={analysis.get('groups', {}).keys() if 'groups' in analysis else 'N/A'}")
        print(f"[FORMAT] metrics={metrics}, filters={filters}")
        
        # === GROUPED ANALYSIS FORMAT ===
        if group_by and 'groups' in analysis:
            print(f"[FORMAT] Routing to GROUPED analysis formatter")
            return self._format_grouped_analysis(analysis)
        
        # === NON-GROUPED ANALYSIS FORMAT ===
        response = f"**Point Outcome Analysis**\n\n"
        response += f"**Player:** {player}\n"
        response += f"**Situation:** {situation}\n"
        response += f"**Total Points Analyzed:** {analysis['total_points']}\n\n"
        
        # Show metrics comparison
        if len(metrics) > 1:
            response += f"**Comparison:**\n"
            response += f"| Metric | Count |\n"
            response += f"|--------|-------|\n"
            for metric in metrics:
                data = analysis.get('metrics_data', {}).get(metric, {'count': 0})
                metric_label = metric.replace('_', ' ').title()
                response += f"| {metric_label} | **{data['count']}** |\n"
            
            # Determine winner of comparison
            if len(metrics) == 2:
                m1, m2 = metrics[0], metrics[1]
                c1 = analysis.get('metrics_data', {}).get(m1, {'count': 0})['count']
                c2 = analysis.get('metrics_data', {}).get(m2, {'count': 0})['count']
                m1_label = m1.replace('_', ' ').title()
                m2_label = m2.replace('_', ' ').title()
                
                if c1 > c2:
                    response += f"\n**Answer:** {player} had more **{m1_label}** ({c1}) than **{m2_label}** ({c2})\n"
                elif c2 > c1:
                    response += f"\n**Answer:** {player} had more **{m2_label}** ({c2}) than **{m1_label}** ({c1})\n"
                else:
                    response += f"\n**Answer:** {player} had equal **{m1_label}** and **{m2_label}** ({c1} each)\n"
        elif len(metrics) == 1:
            metric = metrics[0]
            data = analysis['metrics_data'].get(metric, {'count': 0})
            metric_label = metric.replace('_', ' ').title()
            response += f"**{metric_label}:** {data['count']}\n"
        
        # Show examples for each metric
        for metric in metrics:
            data = analysis.get('metrics_data', {}).get(metric, {'count': 0, 'points': []})
            if data.get('points'):
                metric_label = metric.replace('_', ' ').title()
                response += f"\n**{metric_label} Examples:**\n"
                for ex in data['points'][:3]:
                    response += f"- Point {ex.get('point', '?')} ({ex.get('score', '?')}): {ex.get('excerpt', '')}...\n"
        
        # DEBUG: Show matching points if filtering actually happened
        # Skip if all points returned (no filtering = noise)
        matching_points = analysis.get('matching_points', [])
        total_points = len(self.point_by_point) if hasattr(self, 'point_by_point') else 283
        
        if matching_points and len(matching_points) < total_points:
            total_msg = f"Showing {len(matching_points)} of {total_points} points (filtered)"
            response += f"\n\n**DEBUG: {total_msg}:**\n"
            for i, pt in enumerate(matching_points, 1):
                response += f"\n{i}. **Point {pt.get('point_number', '?')}** [{pt.get('server', '?')} serving]\n"
                response += f"   Score: {pt.get('score', '?')}\n"
                winner = pt.get('winner', '?')
                outcome = pt.get('outcome', '?')
                rally_len = pt.get('rally_length', '?')
                response += f"   Winner: {winner} | Outcome: {outcome} | Rally: {rally_len} shots\n"
                response += f"   {pt.get('description', '')}\n"
        
        return response
    
    def _format_grouped_analysis(self, analysis: Dict[str, Any]) -> str:
        """
        Format grouped analysis results - PURELY VARIABLE-DRIVEN.
        
        Uses classification variables to determine output format:
        - group_by: determines grouping dimension (sets, rally length, court side, etc.)
        - metrics: determines what we're counting (errors, winners, points_won, etc.)
        - player_filter: single player focus vs both players
        - shot_type: adds shot context to labels
        """
        classification = analysis['classification']
        filters = classification['filters']
        group_by = analysis['group_by']
        groups = analysis['groups']
        metrics = classification.get('metrics', [])
        
        # Metrics where win % is MEANINGLESS (outcome is inherent)
        # Winners/Aces = always won the point
        # Errors/Double Faults = always lost the point (use class constant)
        show_win_pct = not any(m in self.SELF_EVIDENT_OUTCOME_METRICS for m in metrics)
        
        player1 = analysis.get('player1', 'Player 1')
        player2 = analysis.get('player2', 'Player 2')
        player_filter = filters.get('player')
        shot_type = filters.get('shot_type') or filters.get('shot_base')
        
        # === BUILD LABELS FROM VARIABLES ===
        metric_name = metrics[0].replace('_', ' ').title() if metrics else 'Points Won'
        shot_desc = f"{shot_type.title()} " if shot_type else ""
        group_label = group_by.replace('_', ' ').title() if group_by else 'Category'
        
        # Title combines: [Shot] [Metric] by [Group]
        title = f"{shot_desc}{metric_name} by {group_label}"
        
        response = f"**{title}**\n\n"
        
        # === SHOW ACTIVE FILTERS ===
        if player_filter:
            response += f"**Player:** {player_filter}\n"
        if shot_type:
            response += f"**Shot Type:** {shot_type.title()}\n"
        if metrics:
            response += f"**Metric:** {metric_name}\n"
        response += f"**Total Points Analyzed:** {analysis['total_points']}\n\n"
        
        # === BUILD TABLE FROM VARIABLES ===
        # Determine if single player focus or both players
        is_single_player = bool(player_filter)
        
        # Determine who is the focus player for win % (returner for serve_direction queries)
        focus_player = None
        if player_filter:
            focus_player = player_filter
            is_player1 = player1 and player_filter.lower() in player1.lower()
        
        # GENERIC: Get display type from GROUP_CONFIG
        group_config = self._get_group_config(group_by)
        display_type = group_config.get('display_type', 'default') if group_config else 'default'
        
        # Format table header based on display_type - GENERIC
        if display_type == 'role_based':
            # Role-based grouping (e.g., serve_direction shows returner perspective)
            role_label = group_label.replace('_', ' ').title()
            response += f"**{role_label} Breakdown:**\n\n"
            if show_win_pct:
                response += f"| {group_label.replace('_', ' ').title()} | Total | {focus_player or 'Returner'} Won | {focus_player or 'Returner'} Lost | Win % |\n"
                response += f"|-----------|-------|------|------|-------|\n"
            else:
                response += f"| {group_label.replace('_', ' ').title()} | {player1} | {player2} |\n"
                response += f"|-----------|-------|-------|\n"
        elif display_type == 'player':
            # Player grouping - each group IS a player
            response += f"**{shot_desc}{metric_name} by {group_label}:**\n\n"
            if show_win_pct:
                response += f"| {group_label} | Total | Won | Lost | Win % |\n"
                response += f"|-----|-------|-----|------|-------|\n"
            else:
                response += f"| {group_label} | Count |\n"
                response += f"|-----|-------|\n"
        elif is_single_player:
            response += f"**{shot_desc}{metric_name} by {group_label}:**\n\n"
            if show_win_pct:
                response += f"| {group_label} | Total | Won | Lost | Win % |\n"
                response += f"|-----|-------|-----|------|-------|\n"
            else:
                response += f"| {group_label} | Count |\n"
                response += f"|-----|-------|\n"
        else:
            response += f"**{shot_desc}{metric_name} by {group_label}:**\n\n"
            if show_win_pct:
                response += f"| {group_label} | Total | {player1} | {player2} | {player1} % |\n"
                response += f"|-----|-------|-----|-----|-------|\n"
            else:
                response += f"| {group_label} | {player1} | {player2} |\n"
                response += f"|-----|-------|-------|\n"
        
        # === ITERATE GROUPS ===
        group_keys = ['group_a', 'group_b'] if 'group_a' in groups else list(groups.keys())
        group_data_list = []  # Store for finding most frequent
        
        for group_key in group_keys:
            if group_key not in groups:
                continue
            group_data = groups[group_key]
            label = group_data.get('label', group_key)
            total = group_data.get('total', 0)
            
            # Dynamically access metric-specific counts (e.g., player1_winners, player1_aces, etc.)
            # Fallback to player1_wins for points won or when no specific metric tracking
            metric_key = metrics[0] if metrics else 'wins'
            p1_wins = group_data.get(f'player1_{metric_key}', group_data.get('player1_wins', 0))
            p2_wins = group_data.get(f'player2_{metric_key}', group_data.get('player2_wins', 0))
            
            # GENERIC: Handle player display type - each group IS a player
            if display_type == 'player':
                if group_key == 'player1':
                    won = p1_wins  # This group is player1, use their count
                    lost = p2_wins  # Will be 0
                elif group_key == 'player2':
                    won = p2_wins  # This group is player2, use their count
                    lost = p1_wins  # Will be 0
                else:
                    won = p1_wins
                    lost = p2_wins
                
                # CRITICAL: For win_percentage metric with player grouping, calculate against MATCH total
                # NOT branch total (branch only contains won points, giving 100%)
                # Use total_points from analysis results (grand total across all branches)
                if 'win_percentage' in metrics:
                    match_total = analysis.get('total_points', 0)
                    if match_total == 0:
                        # Fallback: sum all branch totals
                        match_total = sum(g.get('total', 0) for g in groups.values())
                    win_pct = round(100 * won / match_total, 1) if match_total > 0 else 0
                else:
                    # For other metrics, use branch total
                    win_pct = round(100 * won / total, 1) if total > 0 else 0
            # Calculate win % for focus player
            elif is_single_player and is_player1:
                won = p1_wins
                lost = total - p1_wins
                win_pct = round(100 * p1_wins / total, 1) if total > 0 else 0
            elif is_single_player:
                won = p2_wins
                lost = total - p2_wins
                win_pct = round(100 * p2_wins / total, 1) if total > 0 else 0
            else:
                won = p1_wins
                lost = p2_wins
                win_pct = round(100 * p1_wins / total, 1) if total > 0 else 0
            
            group_data_list.append({
                'key': group_key, 'label': label, 'total': total, 
                'won': won, 'lost': lost, 'win_pct': win_pct
            })
            
            # Format row based on whether we're showing win %
            if is_single_player and show_win_pct:
                response += f"| **{label}** | {total} | {won} | {lost} | **{win_pct}%** |\n"
            elif is_single_player and not show_win_pct:
                response += f"| **{label}** | {won} |\n"
            elif not is_single_player and show_win_pct:
                response += f"| **{label}** | {total} | {won} | {lost} | **{win_pct}%** |\n"
            elif group_by == 'player' and not show_win_pct:
                # For player grouping without win %, show just the count for THAT player
                response += f"| **{label}** | {won} |\n"
            else:  # Other groupings, both players, no win %
                response += f"| **{label}** | {won} | {lost} |\n"
        
        # === ANSWER SECTION ===
        if group_data_list:
            response += f"\n**Answer:**\n"
            
            # Find most frequent (highest total)
            most_frequent = max(group_data_list, key=lambda x: x['total'])
            
            response += f"📊 **Most Frequent:** {most_frequent['label']} ({most_frequent['total']} total, {most_frequent['total']/analysis['total_points']*100:.0f}% of analyzed points)\n"
            
            # Only show win % insights if relevant
            if show_win_pct:
                # Find highest win %
                highest_win_pct = max(group_data_list, key=lambda x: x['win_pct'])
                
                # Find lowest win %
                lowest_win_pct = min(group_data_list, key=lambda x: x['win_pct'] if x['total'] > 0 else 100)
                
                response += f"🎯 **Success Rate vs {most_frequent['label']}:** {most_frequent['win_pct']}% ({most_frequent['won']} won, {most_frequent['lost']} lost)\n\n"
                
                if highest_win_pct['key'] != most_frequent['key']:
                    response += f"✅ **Best Success:** vs {highest_win_pct['label']} ({highest_win_pct['win_pct']}%)\n"
                if lowest_win_pct['key'] != most_frequent['key'] and lowest_win_pct['total'] > 0:
                    response += f"⚠️ **Worst Success:** vs {lowest_win_pct['label']} ({lowest_win_pct['win_pct']}%)\n"
            else:
                # For self-evident metrics, just show the counts
                response += f"🎯 **{metric_name} at {most_frequent['label']}:** {most_frequent['won']}\n\n"
            
            # For 2-group comparisons (like set_groups), also show ratio
            if len(group_data_list) == 2:
                val_a = group_data_list[0]['won']
                val_b = group_data_list[1]['won']
                if val_a > 0:
                    ratio = val_b / val_a
                    if ratio >= 2:
                        response += f"\n✅ **More than doubled!** ({val_a} → {val_b}, **{ratio:.1f}x**)\n"
                    elif ratio > 1:
                        response += f"\n📈 +{((ratio-1)*100):.0f}% change ({val_a} → {val_b})\n"
                    elif ratio < 1:
                        response += f"\n📉 -{((1-ratio)*100):.0f}% change ({val_a} → {val_b})\n"
        
        # === EXAMPLES (optional) ===
        for group_key in group_keys:
            if group_key not in groups:
                continue
            examples = groups[group_key].get('examples', [])
            if examples:
                label = groups[group_key].get('label', group_key)
                response += f"\n**{label} Examples:**\n"
                for ex in examples[:2]:
                    response += f"- Point {ex.get('point', '?')}: {ex.get('excerpt', '')}\n"
        
        # === DEBUG: SHOW MATCHING POINTS BY GROUP (only if filtering happened) ===
        total_points = len(self.point_by_point) if hasattr(self, 'point_by_point') else 283
        total_in_groups = sum(len(groups.get(gk, {}).get('matching_points', [])) for gk in group_keys if gk in groups)
        
        # Only show debug if filtering actually reduced the count
        if total_in_groups > 0 and total_in_groups < total_points:
            response += f"\n\n**DEBUG: Matching Points by {group_label} ({total_in_groups} of {total_points} filtered):**\n"
            for group_key in group_keys:
                if group_key not in groups:
                    continue
                group_data = groups[group_key]
                label = group_data.get('label', group_key)
                matching_points = group_data.get('matching_points', [])
                
                if matching_points:
                    total_msg = f"{len(matching_points)} points"
                    response += f"\n**{label}: {total_msg}**\n"
                for i, pt in enumerate(matching_points, 1):
                    response += f"{i}. Point {pt.get('point_number', '?')} [{pt.get('server', '?')} serving] "
                    winner = pt.get('winner', '?')
                    outcome = pt.get('outcome', '?')
                    rally_len = pt.get('rally_length', '?')
                    response += f"Score: {pt.get('score', '?')} | Winner: {winner} | "
                    response += f"Outcome: {outcome} | Rally: {rally_len} shots\n"
                    response += f"   {pt.get('description', '')}\n"
        
        return response
    
    def _detect_question_intent(self, question: str, classification: Dict) -> Dict:
        """
        Detect the intent behind the question to guide response formatting.
        Returns hints about what format the user likely expects.
        """
        question_lower = question.lower()
        
        intent = {
            'wants_count': False,      # "how many", "count", "number of"
            'wants_percentage': False,  # "percentage", "win rate", "% of"
            'wants_comparison': False,  # "compared to", "vs", "better than"
            'wants_trend': False,       # "over time", "throughout", "by set"
            'wants_breakdown': False,   # "breakdown", "by", "grouped by"
            'is_simple_lookup': False,  # "who won", "what was the score"
            'primary_format': 'auto'    # Let LLM decide
        }
        
        # Count-based queries
        if any(kw in question_lower for kw in ['how many', 'count', 'number of', 'total number', 'total aces', 'total winners']):
            intent['wants_count'] = True
            intent['primary_format'] = 'count'
        
        # Percentage-based queries
        if any(kw in question_lower for kw in ['percentage', 'win rate', 'win %', '% of', 'rate of', 'efficiency']):
            intent['wants_percentage'] = True
            intent['primary_format'] = 'percentage'
        
        # Comparison queries
        if any(kw in question_lower for kw in ['compared to', ' vs ', 'versus', 'better than', 'worse than', 'difference between']):
            intent['wants_comparison'] = True
            if intent['primary_format'] == 'auto':
                intent['primary_format'] = 'comparison'
        
        # Trend/time-based queries
        if any(kw in question_lower for kw in ['over time', 'throughout', 'by set', 'across sets', 'trend', 'changed']):
            intent['wants_trend'] = True
        
        # Breakdown queries
        if any(kw in question_lower for kw in ['breakdown', 'grouped by', 'by direction', 'by court', 'split by']):
            intent['wants_breakdown'] = True
        
        # Simple lookups
        if any(kw in question_lower for kw in ['who won', 'what was the score', 'final score', 'who served']):
            intent['is_simple_lookup'] = True
            intent['primary_format'] = 'simple'
        
        # Metric-specific hints
        metrics = classification.get('metrics', [])
        if metrics:
            metric = metrics[0]
            if metric in ['aces', 'double_faults', 'winners', 'errors', 'unforced_errors']:
                # These are naturally count-based unless asking for rate
                if not intent['wants_percentage']:
                    intent['wants_count'] = True
                    intent['primary_format'] = 'count'
        
        return intent
    
    def _synthesize_with_narrative(self, question: str, data_response: str, classification: Dict) -> str:
        """
        Combine calculated data with narrative context for insightful answers.
        
        CRITICAL HIERARCHY:
        1. Calculated data (data_response) = SOURCE OF TRUTH for ALL numbers/statistics
        2. Narrative context = Additional insight/context ONLY (never use numbers from here)
        3. LLM synthesizes: Present calculated numbers clearly + add tactical insight
        
        IMPROVED: Gives LLM freedom to format data appropriately based on question intent.
        
        This method:
        1. Detects what format the user likely expects (count vs percentage vs comparison)
        2. Passes raw data + formatting hints to LLM
        3. Lets LLM decide the best presentation format
        4. Retrieves narrative context for insight
        """
        filters = classification.get('filters', {})
        metrics = classification.get('metrics', [])
        
        # === GENERIC N-METRIC: Check if metrics are related for synthesis ===
        synthesize_related = classification.get('synthesize_related_metrics', False)
        metric_context_type = classification.get('metric_context_type')
        
        if synthesize_related:
            print(f"[SYNTHESIS] Related metrics detected (context: {metric_context_type}) - will synthesize together")
        
        # DETECT QUESTION INTENT
        intent = self._detect_question_intent(question, classification)
        print(f"[SYNTHESIS] Question intent: {intent['primary_format']}")
        
        # Build context-aware search query for narrative retrieval
        search_terms = []
        if filters.get('player'):
            search_terms.append(filters['player'])
        if filters.get('shot_type'):
            search_terms.append(filters['shot_type'])
        
        # For related metrics, use context type; otherwise use first metric
        if synthesize_related and metric_context_type:
            search_terms.append(metric_context_type)
        elif metrics:
            # For multi-metric, include all metrics
            for metric in metrics:
                metric_filters = classification.get('metric_filters', {}).get(metric, {})
                actual_metric = metric_filters.get('metric', metric)
                search_terms.append(actual_metric.replace('_', ' '))
        
        # Get set info if comparing sets
        set_a = filters.get('set_group_a', [])
        set_b = filters.get('set_group_b', [])
        if set_a:
            search_terms.append(f"Set {set_a[0]}")
        if set_b:
            search_terms.append(f"Set {set_b[0]}")
        
        narrative_query = " ".join(search_terms) if search_terms else question
        
        # Retrieve relevant narrative chunks
        print(f"[SYNTHESIS] Retrieving narrative for: {narrative_query}")
        relevant_chunks = self.retrieve_relevant_chunks(narrative_query, top_k=5)
        
        narrative_context = ""
        if relevant_chunks:
            narrative_context = "\n\n".join([chunk.get('text', chunk) if isinstance(chunk, dict) else str(chunk) 
                                             for chunk in relevant_chunks[:5]])
        
        # BUILD FORMATTING GUIDANCE based on intent
        format_guidance = self._build_format_guidance(intent, metrics)
        
        # EXTRACT DEBUG SECTION - Keep in response but don't print to terminal
        # The debug section will show in the UI response, but we don't spam terminal with point lists
        debug_section = ""
        if "**DEBUG:" in data_response:
            debug_idx = data_response.find("**DEBUG:")
            debug_section = data_response[debug_idx:]
            data_for_llm = data_response[:debug_idx].strip()
            
            # Extract point count for terminal log (but don't print the actual points)
            import re
            point_count_match = re.search(r'Showing (\d+) of (\d+)', debug_section)
            if point_count_match:
                shown_points = int(point_count_match.group(1))
                total_points = int(point_count_match.group(2))
                print(f"[DEBUG] {shown_points} of {total_points} matching points (shown in response, not terminal)")
        else:
            data_for_llm = data_response
        
        # If question asks specifically about MATCH score/result, add it to the data
        # Be careful: "who won" alone is too broad (e.g., "who won more points")
        question_lower = question.lower()
        score_terms = ['final score', 'match score', 'who won the match', 'match result', 'match outcome']
        
        # More specific check: "score" alone only triggers if asking about "the score" or "final"
        asks_about_score = (
            any(term in question_lower for term in score_terms) or
            ('what was the score' in question_lower) or
            ('what is the score' in question_lower)
        )
        
        if asks_about_score:
            if hasattr(self, 'match_score') and self.match_score:
                data_for_llm += f"\n\n**Match Score:** {self.match_score}"
                print(f"[SYNTHESIS] Added match score to data: {self.match_score}")
        
        # Note: Match duration is typically in narrative context, not calculated data
        # The LLM should extract it from narrative if available
        
        # Use LLM to synthesize data + narrative into insight with FORMATTING FREEDOM
        synthesis_prompt = f"""You are a tennis analyst answering analytical questions using calculated match data.

⚠️ **ABSOLUTE RULE:** This is an ANALYTICAL QUESTION requiring NUMBERS. You MUST use ONLY the numbers from the CALCULATED DATA section below. DO NOT use ANY numbers, statistics, or counts from the narrative context. The narrative is for CONTEXT and INSIGHT only.

**USER'S QUESTION:** {question}

**QUESTION INTENT:** {intent['primary_format']}
{format_guidance}

═══════════════════════════════════════════════════════════════════════════════
📊 **CALCULATED DATA (SOURCE OF TRUTH - USE THESE NUMBERS ONLY):**
═══════════════════════════════════════════════════════════════════════════════
{data_for_llm}
═══════════════════════════════════════════════════════════════════════════════

📖 **NARRATIVE CONTEXT (for insight/context ONLY - DO NOT extract numbers from here):**
{narrative_context if narrative_context else "No additional context available."}

═══════════════════════════════════════════════════════════════════════════════

**YOUR TASK:**

1. **ANSWER WITH CALCULATED DATA NUMBERS ONLY:**
   - Extract ALL numbers (counts, percentages, etc.) from the CALCULATED DATA section above
   - NEVER use numbers from the narrative context (they may be outdated or incorrect)
   - Format the numbers in the way that best answers the user's question{f"   - **RELATED METRICS:** If the question asks about multiple related metrics (e.g., 'first serve % and first serve win %'), synthesize them together in a cohesive answer that shows how they relate to each other." if synthesize_related else ""}

2. **PRESENT THE ANSWER CLEARLY:**
   - If asking "how many" → Lead with the COUNT (e.g., "Sinner hit **33 winners**, Medvedev hit **29 winners**")
   - If asking "percentage" → Lead with the PERCENTAGE
   - If asking "comparison" → Show side-by-side comparison with numbers from calculated data
   - If asking about "final score" or "match score" → Include the Match Score from the calculated data section
   - If asking about "how long" or "duration" → Look for this information in the narrative context (it's not in calculated data){f"   - **MULTI-METRIC:** If multiple metrics are provided, present them together showing their relationship (e.g., 'First serve % was X%, and on those first serves, win % was Y%')" if synthesize_related else ""}
   - Use tables, bullets, or plain text - whatever is clearest

3. **ADD BRIEF TACTICAL INSIGHT (2-3 sentences):**
   - Use the narrative context to understand WHY or add strategic perspective
   - But still reference only calculated data numbers in your insight
   - Example: "Sinner's 33 winners suggest an aggressive baseline approach..."{f"   - **RELATED METRICS INSIGHT:** When multiple related metrics are provided, explain how they relate (e.g., 'A high first serve % combined with a strong first serve win % indicates effective serving')" if synthesize_related else ""}
   - **EXCEPTION:** Match duration/time is NOT in calculated data - you may extract this from narrative context if the question asks for it

**FORBIDDEN:**
- ❌ Using any numbers from the narrative context
- ❌ Contradicting the calculated data
- ❌ Showing percentages when they asked for counts
- ❌ Answering a different question than what was asked
- ❌ **NEVER mention "win rate" or "win percentage" for winners, aces, errors, or double faults**
  (Winners/aces are always won points, errors/DFs are always lost points - stating this is redundant)

Format in markdown."""

        try:
            # Get model config from classification (if available)
            model_config = classification.get('_model_config', {})
            model_name = model_config.get('model_name', self.model if hasattr(self, 'model') else 'gemini-2.5-flash')
            temperature = model_config.get('temperature', 0.7)
            
            if self.llm_provider == "gemini":
                import google.generativeai as genai
                
                # Configure generation (3.0 Flash has built-in reasoning capabilities)
                # Use simple dict for generation config
                gen_config = {"temperature": temperature}
                
                try:
                    model = genai.GenerativeModel(model_name)
                    response = model.generate_content(synthesis_prompt, generation_config=gen_config)
                    llm_response = response.text.strip()
                except Exception as e:
                    # If 3 Flash not available, fallback to 2.5 Flash
                    if ("3-flash" in model_name.lower() or "3.0-flash" in model_name.lower()) and ("not found" in str(e).lower() or "404" in str(e)):
                        print(f"[SYNTHESIS] Model {model_name} not available, falling back to 2.5 Flash")
                        fallback_model = genai.GenerativeModel(self.model_25_flash)
                        response = fallback_model.generate_content(synthesis_prompt, generation_config=gen_config)
                        llm_response = response.text.strip()
                    else:
                        raise  # Re-raise if it's a different error
            else:
                # Fallback to default for non-Gemini
                model = genai.GenerativeModel('gemini-2.5-flash')
                response = model.generate_content(synthesis_prompt)
                llm_response = response.text.strip()
            
            # PREPEND VAGUE TERM INTERPRETATION (Step E: Disclose interpretation)
            if classification.get('_vague_term'):
                interpretation = classification.get('_vague_interpretation', '')
                vague_metrics = classification.get('_vague_metrics', [])
                context = classification.get('_vague_context', 'default')
                disclosure = f"*Interpreting '{classification['_vague_term']}' ({context} context): {interpretation}*\n*Metrics analyzed: {', '.join(vague_metrics)}*\n\n"
                llm_response = disclosure + llm_response
            
            # APPEND DEBUG SECTION so user can verify the data
            if debug_section:
                llm_response += "\n\n---\n\n" + debug_section
            
            return llm_response
        except Exception as e:
            print(f"[SYNTHESIS] LLM error: {e}, returning data only")
            return data_response
    
    def _build_format_guidance(self, intent: Dict, metrics: list) -> str:
        """Build specific formatting guidance based on detected intent."""
        guidance_parts = []
        
        if intent['wants_count']:
            guidance_parts.append("→ User wants COUNTS (raw numbers). Show counts prominently, not percentages.")
        
        if intent['wants_percentage']:
            guidance_parts.append("→ User wants PERCENTAGES/RATES. Calculate and show percentages clearly.")
        
        if intent['wants_comparison']:
            guidance_parts.append("→ User wants COMPARISON. Show side-by-side and state who was better/worse.")
        
        if intent['wants_trend']:
            guidance_parts.append("→ User wants TREND over time. Show progression across sets/games.")
        
        if intent['wants_breakdown']:
            guidance_parts.append("→ User wants BREAKDOWN by category. Show grouped/categorized data.")
        
        if intent['is_simple_lookup']:
            guidance_parts.append("→ Simple lookup question. Give a direct, brief answer.")
        
        if metrics:
            metric_name = metrics[0].replace('_', ' ').title()
            guidance_parts.append(f"→ Primary metric: {metric_name}")
        
        if not guidance_parts:
            guidance_parts.append("→ Use your judgment on the best format to answer this question.")
        
        return "\n".join(guidance_parts)
    
    def _handle_narrative_query(self, question: str, classification: Dict, top_k: int = None) -> str:
        """
        Handle narrative queries using NL retrieval + LLM synthesis.
        
        For questions like:
        - "What happened in Set 3?"
        - "Provide a strategic summary"
        - "Tell the parallel journey of both players"
        """
        print("[NARRATIVE] Retrieving relevant context from NL file...")
        
        # Determine appropriate chunk count for narrative
        if top_k is None:
            top_k = self._determine_optimal_chunk_count(question)
            top_k = max(top_k, 8)  # Narratives need more context
        
        # Retrieve relevant chunks
        relevant_chunks = self.retrieve_relevant_chunks(question, top_k)
        
        if not relevant_chunks:
            return "I couldn't find relevant information to answer your question."
        
        print(f"[NARRATIVE] Retrieved {len(relevant_chunks)} chunks, generating synthesis...")
        
        # Build context from retrieved chunks
        context_pieces = [chunk['text'] for chunk in relevant_chunks]
        context_text = "\n\n---\n\n".join(context_pieces)
        
        # Build match overview for context
        match_overview = ""
        total_points = 283  # default
        if hasattr(self, 'match_stats_summary') and self.match_stats_summary:
            stats = self.match_stats_summary
            total_points = stats.get('total_points', 283)
            match_overview = f"""
MATCH DATA AVAILABLE:
- Total Points: {total_points} (complete point-by-point records)
- Players: {stats.get('players', 'N/A')}
- Match Score: {stats.get('match_score', 'N/A')}
- Every point includes: shot types, directions, depths, outcomes, rally lengths, score context
"""
        
        enhanced_prompt = f"""You are analyzing a tennis match with COMPLETE point-by-point data.
{match_overview}

⚠️ CRITICAL - DATA AVAILABILITY:
The match file contains ALL {total_points} points with:
- Full shot-by-shot descriptions for every point
- Every serve placement, rally sequence, and outcome
- Score context and situation (break points, game points, etc.)
- Player actions and shot selections

The context below is RETRIEVED from this complete dataset. Work with what you have.

QUESTION: {question}

RELEVANT ANALYSIS FROM MATCH DATA:
{context_text}

Instructions:
- Answer using the provided match analysis
- For strategic/tactical questions, draw insights from the patterns and data shown
- If the retrieved context doesn't fully answer the question, provide insights based on what IS shown
- **ABSOLUTELY FORBIDDEN**: Never say "point-by-point data is not available" or "data doesn't include point-by-point narratives" - this is factually incorrect. ALL point data exists in the system.
- Provide specific, detailed answers based on the context

Answer:"""
        
        # Use LLM to synthesize narrative answer with appropriate model
        try:
            # Get model config from classification (if available)
            model_config = classification.get('_model_config', {})
            model_name = model_config.get('model_name', self.model)
            temperature = model_config.get('temperature', 0.7)
            
            if self.llm_provider == "gemini":
                import google.generativeai as genai
                
                # Configure generation (3.0 Flash has built-in reasoning capabilities)
                # Use simple dict for generation config
                gen_config = {"temperature": temperature}
                
                try:
                    model = genai.GenerativeModel(model_name)
                    response = model.generate_content(enhanced_prompt, generation_config=gen_config)
                    answer = response.text
                except Exception as e:
                    # If 3 Flash not available, fallback to 2.5 Flash
                    if ("3-flash" in model_name.lower() or "3.0-flash" in model_name.lower()) and ("not found" in str(e).lower() or "404" in str(e)):
                        print(f"[NARRATIVE] Model {model_name} not available, falling back to 2.5 Flash")
                        fallback_model = genai.GenerativeModel(self.model_25_flash)
                        response = fallback_model.generate_content(enhanced_prompt, generation_config=gen_config)
                        answer = response.text
                    else:
                        raise  # Re-raise if it's a different error
            else:
                # For non-Gemini, use standard method
                answer = self.answer_query_with_llm(question, relevant_chunks)
                
        except Exception as e:
            print(f"[NARRATIVE] Error in LLM synthesis: {e}")
            answer = self.answer_query_with_llm(question, relevant_chunks)
        
        return answer
    
    def _handle_comparative_query(self, question: str, classification: Dict, top_k: int = None) -> str:
        """
        Handle comparative queries: extract data from multiple conditions, then synthesize.
        
        For questions like:
        - "How did Federer's first serves change when facing break points?"
        - "How did tactics change in Set 1 vs Set 3?"
        - "Serve effectiveness across sets"
        """
        print("[COMPARATIVE] Extracting data for comparison...")
        
        query_lower = question.lower()
        player = classification['filters'].get('player')
        
        # Determine what's being compared
        comparison_data = {}
        
        # Set comparison (Set 1 vs Set 3, etc.)
        if 'set 1' in query_lower and ('set 3' in query_lower or 'set 5' in query_lower):
            sets_to_compare = []
            for i in [1, 2, 3, 4, 5]:
                if f'set {i}' in query_lower or f'{i}st set' in query_lower or f'{i}nd set' in query_lower or f'{i}rd set' in query_lower or f'{i}th set' in query_lower:
                    sets_to_compare.append(i)
            
            if len(sets_to_compare) >= 2:
                for set_num in sets_to_compare:
                    # UNIFIED: Use _analyze_n_dimensional for each set
                    set_classification = classification.copy()
                    set_classification['filters'] = classification['filters'].copy()
                    set_classification['filters']['set'] = set_num
                    set_classification['group_by'] = None
                    
                    analysis = self._analyze_n_dimensional(set_classification)
                    if 'error' not in analysis:
                        tree_results = analysis.get('results', {})
                        comparison_data[f'Set {set_num}'] = {
                            'total_points': tree_results.get('total_points', 0),
                            'player1_wins': tree_results.get('player1_wins', 0),
                            'player2_wins': tree_results.get('player2_wins', 0),
                            'player1_pct': tree_results.get('player1_pct', 0),
                            'player2_pct': tree_results.get('player2_pct', 0)
                        }
        
        # Situation comparison (break points vs non-break points)
        if 'break point' in query_lower or 'facing' in query_lower:
            # UNIFIED: Use _analyze_n_dimensional for break point stats
            bp_classification = classification.copy()
            bp_classification['filters'] = classification['filters'].copy()
            bp_classification['filters']['situation'] = 'break_point'
            bp_classification['group_by'] = None
            
            bp_analysis = self._analyze_n_dimensional(bp_classification)
            if 'error' not in bp_analysis:
                tree_results = bp_analysis.get('results', {})
                comparison_data['Break Points'] = {
                    'total_points': tree_results.get('total_points', 0),
                    'player1_wins': tree_results.get('player1_wins', 0),
                    'player2_wins': tree_results.get('player2_wins', 0)
                }
            
            # Get non-break point stats (all points minus break points)
            all_classification = classification.copy()
            all_classification['filters'] = classification['filters'].copy()
            all_classification['filters']['situation'] = None
            all_classification['group_by'] = None
            
            all_analysis = self._analyze_n_dimensional(all_classification)
            if 'error' not in all_analysis:
                tree_results = all_analysis.get('results', {})
                comparison_data['All Points'] = {
                    'total_points': tree_results.get('total_points', 0),
                    'player1_wins': tree_results.get('player1_wins', 0),
                    'player2_wins': tree_results.get('player2_wins', 0)
                }
        
        # Format comparison results
        if comparison_data:
            response = self._format_comparative_analysis(question, comparison_data, classification)
            
            # If we have structured data, also get LLM interpretation
            if len(comparison_data) >= 2:
                # Add LLM synthesis for deeper insight
                context_text = f"Comparison data:\n"
                for condition, data in comparison_data.items():
                    context_text += f"- {condition}: {data}\n"
                
                synthesis_prompt = f"Based on this data, briefly interpret the comparison for: {question}\n\n{context_text}"
                
                # Get LLM interpretation
                try:
                    llm_insight = self.answer_query_with_llm(synthesis_prompt, [])
                    if llm_insight and len(llm_insight) > 50:
                        response += f"\n**Interpretation:**\n{llm_insight}"
                except:
                    pass  # Skip LLM synthesis if it fails
            
            return response
        
        # Fallback to narrative handling if no structured comparison possible
        print("[COMPARATIVE] No structured comparison found, falling back to narrative")
        return self._handle_narrative_query(question, classification, top_k)
    
    def _format_comparative_analysis(self, question: str, comparison_data: Dict, classification: Dict) -> str:
        """Format comparative analysis results."""
        player1 = self.player1 or 'Player 1'
        player2 = self.player2 or 'Player 2'
        
        response = f"**Comparative Analysis**\n\n"
        response += f"**Query:** {question}\n\n"
        
        response += f"| Condition | Total | {player1} | {player2} |\n"
        response += f"|-----------|-------|-----------|----------|\n"
        
        for condition, data in comparison_data.items():
            total = data.get('total_points', 0)
            p1 = data.get('player1_wins', 0)
            p2 = data.get('player2_wins', 0)
            p1_pct = round(100 * p1 / total, 1) if total > 0 else 0
            p2_pct = round(100 * p2 / total, 1) if total > 0 else 0
            response += f"| **{condition}** | {total} | {p1} ({p1_pct}%) | {p2} ({p2_pct}%) |\n"
        
        return response
    
    def _is_return_depth_situational_query(self, query: str) -> bool:
        """
        Detect if query asks about return depth in specific situations or win percentage.
        
        Example queries that return True:
        - "How deep were Alcaraz's returns on break points?"
        - "Return depth on game points"
        - "Did Djokovic hit deep returns when facing break point?"
        - "Win percentage on very deep returns"
        - "Points won when return was deep"
        """
        query_lower = query.lower()
        
        # Must have return + depth keywords
        return_keywords = ['return', 'returns', 'returning']
        depth_keywords = ['deep', 'shallow', 'short', 'depth', 'very deep']
        
        # Situation keywords (optional for win percentage queries)
        situation_keywords = ['break point', 'game point', 'set point', 'match point', 
                             'deuce', 'crucial', 'important', 'pressure', 'key point']
        
        # Win percentage keywords
        win_keywords = ['win percentage', 'won percentage', 'win rate', 'won rate',
                       'points won', 'won points', 'win when', 'won when', 'percentage on']
        
        has_return = any(kw in query_lower for kw in return_keywords)
        has_depth = any(kw in query_lower for kw in depth_keywords)
        has_situation = any(kw in query_lower for kw in situation_keywords)
        has_win_query = any(kw in query_lower for kw in win_keywords)
        
        # Return + depth + (situation OR win query)
        return has_return and has_depth and (has_situation or has_win_query or True)
    
    def _analyze_return_depth_in_situations(self, query: str) -> Dict[str, Any]:
        """
        Analyze return depth in specific game situations.
        
        Parses point-by-point data to find situational points and
        categorizes returns by depth (deep/shallow) from descriptions.
        Also tracks win/loss outcomes for each depth category.
        """
        import re
        
        query_lower = query.lower()
        
        # Detect if query asks for specific depth filter
        depth_filter = None
        if 'very deep' in query_lower:
            depth_filter = 'very_deep'
        elif 'shallow' in query_lower or 'short' in query_lower:
            depth_filter = 'shallow'
        elif 'deep' in query_lower:
            depth_filter = 'deep'  # Will match both "deep" and "very deep" unless very_deep already set
        
        # Detect which player is being asked about
        player_mentioned = self._detect_player_mentioned(query)
        
        # Detect situation type
        situation_type = None
        if 'break point' in query_lower:
            situation_type = 'break_point'
        elif 'game point' in query_lower:
            situation_type = 'game_point'
        elif 'set point' in query_lower:
            situation_type = 'set_point'
        elif 'match point' in query_lower:
            situation_type = 'match_point'
        elif 'deuce' in query_lower:
            situation_type = 'deuce'
        else:
            situation_type = 'all'
        
        # Find point-by-point chunks
        pbp_chunks = [c for c in self.chunks if 'point-by-point' in c['metadata'].get('section', '').lower()]
        
        if not pbp_chunks:
            return {'error': 'No point-by-point data available for return depth analysis'}
        
        all_text = '\n'.join([c['text'] for c in pbp_chunks])
        
        point_pattern = r'Point (\d+) \[Server: ([^\|]+)\| Returner: ([^\|]+)\| Score: ([^\]]+)\]: (.+?)(?=Point \d+|\Z)'
        
        results = {
            'player': player_mentioned or 'both players',
            'situation': situation_type,
            'depth_filter': depth_filter,
            'total_situation_points': 0,
            'returns_analyzed': 0,
            'deep_returns': 0,
            'shallow_returns': 0,
            'very_deep_returns': 0,
            'neutral_returns': 0,
            # Outcome tracking per depth
            'depth_outcomes': {
                'very_deep': {'won': 0, 'lost': 0, 'examples': []},
                'deep': {'won': 0, 'lost': 0, 'examples': []},
                'shallow': {'won': 0, 'lost': 0, 'examples': []},
                'neutral': {'won': 0, 'lost': 0, 'examples': []}
            },
            'return_examples': {
                'deep': [],
                'shallow': [],
                'very_deep': []
            }
        }
        
        for match in re.finditer(point_pattern, all_text, re.DOTALL):
            point_num = match.group(1)
            server = match.group(2).strip()
            returner = match.group(3).strip()
            score = match.group(4).strip()
            point_text = match.group(5).strip()
            
            # Check if this is the situation we're looking for - GENERIC using _check_situation
            is_target_situation = False
            if situation_type == 'all':
                is_target_situation = True
            elif situation_type:
                is_target_situation = self._check_situation(situation_type, score)
            else:
                is_target_situation = True
            
            if not is_target_situation:
                continue
            
            # Check player filter - returner must be the player
            if player_mentioned:
                if player_mentioned.lower() not in returner.lower():
                    continue
            
            results['total_situation_points'] += 1
            
            # Parse rally to find the return shot (2nd shot in sequence)
            rally_shots = self._parse_rally_sequence(point_text, server, returner)
            
            if len(rally_shots) >= 2:
                # The return is the 2nd shot (index 1)
                return_shot = rally_shots[1]
                return_desc = return_shot.get('description', '').lower()
                
                results['returns_analyzed'] += 1
                
                # Categorize by depth
                depth_category = 'neutral'
                if 'very deep' in return_desc or 'baseline' in return_desc:
                    depth_category = 'very_deep'
                    results['very_deep_returns'] += 1
                elif 'deep' in return_desc:
                    depth_category = 'deep'
                    results['deep_returns'] += 1
                elif 'shallow' in return_desc or 'short' in return_desc:
                    depth_category = 'shallow'
                    results['shallow_returns'] += 1
                else:
                    results['neutral_returns'] += 1
                
                # Determine who won the point (returner wins or loses)
                returner_won = self._did_returner_win_point(rally_shots, returner)
                
                # Track outcome for this depth category
                if returner_won:
                    results['depth_outcomes'][depth_category]['won'] += 1
                else:
                    results['depth_outcomes'][depth_category]['lost'] += 1
                
                # Store examples (limit to 5 per category)
                example_data = {
                    'point': point_num,
                    'server': server,
                    'returner': returner,
                    'score': score,
                    'return_description': return_shot.get('description', ''),
                    'outcome': 'WON' if returner_won else 'LOST',
                    'full_point': point_text.strip()
                }
                
                if depth_category != 'neutral' and len(results['return_examples'][depth_category]) < 5:
                    results['return_examples'][depth_category].append(example_data)
                
                if len(results['depth_outcomes'][depth_category]['examples']) < 5:
                    results['depth_outcomes'][depth_category]['examples'].append(example_data)
        
        # Calculate percentages
        if results['returns_analyzed'] > 0:
            results['deep_percentage'] = round(100 * (results['deep_returns'] + results['very_deep_returns']) / results['returns_analyzed'], 1)
            results['shallow_percentage'] = round(100 * results['shallow_returns'] / results['returns_analyzed'], 1)
        else:
            results['deep_percentage'] = 0
            results['shallow_percentage'] = 0
        
        return results
    
    def _format_return_depth_analysis(self, analysis: Dict[str, Any]) -> str:
        """Format return depth situational analysis into readable response."""
        if 'error' in analysis:
            return f"Unable to perform return depth analysis: {analysis['error']}"
        
        situation_name = analysis['situation'].replace('_', ' ').title() if analysis['situation'] != 'all' else 'All Points'
        
        response = f"**Return Depth Analysis: {situation_name}**\n\n"
        response += f"**Player:** {analysis['player']}\n\n"
        
        response += f"**Results:**\n"
        response += f"- Total {situation_name.lower()} situations: **{analysis['total_situation_points']}**\n"
        response += f"- Returns analyzed: **{analysis['returns_analyzed']}**\n\n"
        
        if analysis['returns_analyzed'] > 0:
            response += f"**Depth Breakdown:**\n"
            response += f"| Depth | Count | Percentage |\n"
            response += f"|-------|-------|------------|\n"
            response += f"| Very Deep | {analysis['very_deep_returns']} | {round(100 * analysis['very_deep_returns'] / analysis['returns_analyzed'], 1)}% |\n"
            response += f"| Deep | {analysis['deep_returns']} | {round(100 * analysis['deep_returns'] / analysis['returns_analyzed'], 1)}% |\n"
            response += f"| Shallow/Short | {analysis['shallow_returns']} | {analysis['shallow_percentage']}% |\n"
            response += f"| Neutral/Unmarked | {analysis['neutral_returns']} | {round(100 * analysis['neutral_returns'] / analysis['returns_analyzed'], 1)}% |\n"
            
            response += f"\n**Summary:** On {situation_name.lower()}, **{analysis['deep_percentage']}%** of {analysis['player']}'s returns were deep or very deep.\n"
            
            # Show win percentages by depth
            depth_outcomes = analysis.get('depth_outcomes', {})
            if depth_outcomes:
                response += f"\n**Win Percentage by Return Depth:**\n"
                response += f"| Depth | Points Won | Points Lost | Win % |\n"
                response += f"|-------|------------|-------------|-------|\n"
                
                for depth_type in ['very_deep', 'deep', 'shallow', 'neutral']:
                    outcomes = depth_outcomes.get(depth_type, {'won': 0, 'lost': 0})
                    total = outcomes['won'] + outcomes['lost']
                    if total > 0:
                        win_pct = round(100 * outcomes['won'] / total, 1)
                        depth_label = depth_type.replace('_', ' ').title()
                        response += f"| {depth_label} | {outcomes['won']} | {outcomes['lost']} | **{win_pct}%** |\n"
                
                # If there's a depth filter, highlight that specific answer
                depth_filter = analysis.get('depth_filter')
                if depth_filter and depth_filter in depth_outcomes:
                    outcomes = depth_outcomes[depth_filter]
                    total = outcomes['won'] + outcomes['lost']
                    if total > 0:
                        win_pct = round(100 * outcomes['won'] / total, 1)
                        depth_label = depth_filter.replace('_', ' ')
                        response += f"\n**Answer:** {analysis['player']}'s win percentage on points where the return was **{depth_label}** was **{win_pct}%** ({outcomes['won']} won, {outcomes['lost']} lost out of {total} points).\n"
            
            # Show examples with outcomes
            for depth_type in ['very_deep', 'deep', 'shallow']:
                examples = analysis['return_examples'].get(depth_type, [])
                if examples:
                    response += f"\n**{depth_type.replace('_', ' ').title()} Return Examples:**\n"
                    for ex in examples[:3]:
                        outcome_str = f"[{ex.get('outcome', 'N/A')}]" if 'outcome' in ex else ""
                        response += f"- Point {ex['point']} {outcome_str} (Score: {ex['score']}): {ex['return_description']}\n"
        else:
            response += f"\n*Note: No return depth data could be extracted from point-by-point descriptions.*\n"
            response += f"\nThis may be because the point-by-point data doesn't include explicit depth markers "
            response += f"like 'deep', 'shallow', or 'short' in return descriptions.\n"
        
        return response
    
    def _is_game_outcome_after_event_query(self, query: str) -> bool:
        """
        Detect if query asks about game outcomes after specific events.
        
        Example queries that return True:
        - "How many times did a player double fault and then lose that game?"
        - "After hitting an ace, did the server go on to hold?"
        - "Double fault and then got broken"
        """
        query_lower = query.lower()
        
        # Event keywords
        event_keywords = ['double fault', 'ace', 'break point', 'deuce']
        
        # Outcome tracking keywords
        outcome_keywords = [
            'lose that', 'lost that', 'lose the game', 'lost the game',
            'win that', 'won that', 'hold', 'held', 'break', 'broken',
            'go on to', 'went on to', 'then lose', 'then win', 'then hold'
        ]
        
        has_event = any(kw in query_lower for kw in event_keywords)
        has_outcome = any(kw in query_lower for kw in outcome_keywords)
        
        return has_event and has_outcome
    
    def _analyze_game_outcome_after_event(self, query: str) -> Dict[str, Any]:
        """
        Analyze game outcomes after specific events occur.
        
        Handles queries like:
        - "Double fault and then lost that service game"
        - "Ace and then held serve"
        """
        import re
        
        query_lower = query.lower()
        
        # Detect which player is being asked about
        player_mentioned = self._detect_player_mentioned(query)
        
        # Detect the event type
        event_type = None
        if 'double fault' in query_lower:
            event_type = 'double_fault'
        elif 'ace' in query_lower:
            event_type = 'ace'
        elif 'break point' in query_lower:
            event_type = 'break_point'
        
        # Detect the desired outcome
        outcome_filter = None
        if any(kw in query_lower for kw in ['lose', 'lost', 'broken', 'break']):
            outcome_filter = 'lost_game'
        elif any(kw in query_lower for kw in ['win', 'won', 'hold', 'held']):
            outcome_filter = 'won_game'
        
        # Find point-by-point chunks
        pbp_chunks = [c for c in self.chunks if 'point-by-point' in c['metadata'].get('section', '').lower()]
        
        if not pbp_chunks:
            return {'error': 'No point-by-point data available for game outcome analysis'}
        
        all_text = '\n'.join([c['text'] for c in pbp_chunks])
        
        point_pattern = r'Point (\d+) \[Server: ([^\|]+)\| Returner: ([^\|]+)\| Score: ([^\]]+)\]: (.+?)(?=Point \d+|\Z)'
        
        # Track events by game (set-game combination)
        events_by_game = {}  # key: "set_score-game_score-server", value: list of events
        game_outcomes = {}   # key: same, value: 'held' or 'broken'
        
        results = {
            'player': player_mentioned or 'all players',
            'event_type': event_type,
            'outcome_filter': outcome_filter,
            'total_events': 0,
            'events_followed_by_loss': 0,
            'events_followed_by_win': 0,
            'matching_instances': []
        }
        
        # First pass: collect all events and track game boundaries
        current_game_key = None
        current_game_server = None
        current_game_events = []
        
        for match in re.finditer(point_pattern, all_text, re.DOTALL):
            point_num = match.group(1)
            server = match.group(2).strip()
            returner = match.group(3).strip()
            score = match.group(4).strip()
            point_text = match.group(5).strip()
            
            # Parse score to get set-game-point scores
            # Handle formats like "Djokovic 0-0 1-2" or "0-0 1-2 15-30"
            score_components = self._parse_score_components(score)
            if not score_components:
                continue
            set_score = score_components['set']
            game_score = score_components['game']
            point_score = score_components.get('point', '0-0')
            
            # Create game key
            game_key = f"{set_score}-{game_score}-{server}"
            
            # Check if we've moved to a new game
            if game_key != current_game_key:
                # Save previous game's events if any
                if current_game_key and current_game_events:
                    events_by_game[current_game_key] = current_game_events
                
                current_game_key = game_key
                current_game_server = server
                current_game_events = []
            
            # Check for the event in this point - GENERIC using event_type as keyword
            point_lower = point_text.lower()
            event_found = False
            
            # Convert event_type to keyword (e.g., 'double_fault' -> 'double fault')
            event_keyword = event_type.replace('_', ' ').lower() if event_type else ''
            if event_keyword and event_keyword in point_lower:
                    event_found = True
            
            if event_found:
                # Check player filter
                if player_mentioned:
                    # For double faults/aces, the server hits them
                    if player_mentioned.lower() not in server.lower():
                        continue
                
                results['total_events'] += 1
                current_game_events.append({
                    'point': point_num,
                    'server': server,
                    'returner': returner,
                    'score': score,
                    'point_text': point_text.strip()
                })
            
            # Check if this point ended the game (detect game-ending scores)
            # Game ends when someone reaches game point and wins
            if self._is_game_ending_point(point_score, point_text):
                # Determine who won the game
                game_won_by_server = self._did_server_win_point(point_text)
                
                if current_game_key:
                    game_outcomes[current_game_key] = 'held' if game_won_by_server else 'broken'
        
        # Don't forget the last game
        if current_game_key and current_game_events:
            events_by_game[current_game_key] = current_game_events
        
        # Second pass: match events with game outcomes
        for game_key, events in events_by_game.items():
            outcome = game_outcomes.get(game_key)
            
            if not outcome:
                continue
            
            for event in events:
                if outcome == 'broken':
                    results['events_followed_by_loss'] += 1
                    if outcome_filter == 'lost_game' or outcome_filter is None:
                        results['matching_instances'].append({
                            **event,
                            'game_outcome': 'Server LOST (broken)',
                            'game_key': game_key
                        })
                else:
                    results['events_followed_by_win'] += 1
                    if outcome_filter == 'won_game' or outcome_filter is None:
                        results['matching_instances'].append({
                            **event,
                            'game_outcome': 'Server HELD',
                            'game_key': game_key
                        })
        
        return results
    
    def _is_game_ending_point(self, point_score: str, point_text: str) -> bool:
        """Check if a point score represents game point that was converted."""
        # Game-ending scores for server: 40-0, 40-15, 40-30, Ad-40
        # Game-ending scores for returner: 0-40, 15-40, 30-40, 40-Ad
        point_lower = point_text.lower()
        
        # Check for explicit game/set indicators
        if 'game' in point_lower or 'break' in point_lower:
            return True
        
        # Check for winning shots that would end the game
        if any(outcome in point_lower for outcome in ['winner', 'ace', 'double fault', 'error']):
            # Check if score was at game point
            game_point_scores = ['40-0', '40-15', '40-30', '0-40', '15-40', '30-40', 'ad-40', '40-ad']
            return any(gp in point_score.lower() for gp in game_point_scores)
        
        return False
    
    def _did_server_win_point(self, point_text: str, server: str = '', returner: str = '') -> bool:
        """Determine if the server won the point using parsed metadata."""
        # Use metadata for robust determination
        point_data = {'point_text': point_text, 'server': server, 'returner': returner}
        meta = self._get_point_metadata(point_data)
        
        point_winner = meta.get('point_winner')
        if point_winner and server:
            return self._names_match_robust(server, point_winner)
        
        # Fallback: ace or service winner always goes to server
        winning_shot = meta.get('winning_shot', {})
        outcome = (winning_shot.get('outcome') or '').upper()
        if outcome in ['ACE', 'SERVICE_WINNER']:
            return True
        
        # Legacy fallback
        rally_parts = point_text.split(';')
        if rally_parts:
            last_shot = rally_parts[-1].lower()
            shot_index = len(rally_parts)
            is_server_shot = (shot_index % 2 == 1)  # Odd shots are server's
            
            if 'winner' in last_shot:
                return is_server_shot
            elif 'error' in last_shot or 'double fault' in last_shot:
                return not is_server_shot
        
        return False
    
    def _did_returner_win_point(self, rally_shots: list, returner: str) -> bool:
        """Determine if the returner won the point based on parsed rally data - GENERIC."""
        if not rally_shots:
            return False
        
        last_shot = rally_shots[-1]
        outcome = last_shot.get('outcome', '')
        last_shot_player = last_shot.get('player', '')
        
        # GENERIC outcome handling using OUTCOME_CONFIG
        outcome_config = self._get_outcome_config(outcome)
        winning_shot_type = outcome_config.get('winning_shot_type', '')
        player_attribution = outcome_config.get('player_attribution', '')
        is_positive = outcome_config.get('is_positive', True)
        
        # Determine who wins based on outcome config
        if player_attribution == 'server':
            # Server-attributed outcome (ace, double fault, service winner)
            return not is_positive  # Returner wins if it's negative for server (e.g., double fault)
        elif player_attribution == 'winner':
            # Winner-attributed outcome - check who hit the shot
            return returner.lower() in last_shot_player.lower() if last_shot_player else False
        elif player_attribution == 'error':
            # Error-attributed outcome - error player loses
            is_returner_error = returner.lower() in last_shot_player.lower() if last_shot_player else False
            return not is_returner_error  # Returner wins if server made error
        
        # Fallback - legacy handling for any unhandled outcomes
        if 'error' in winning_shot_type:
            return True
        
        # Fallback: check description
        desc = last_shot.get('description', '').lower()
        if 'winner' in desc:
            return returner.lower() in last_shot_player.lower()
        elif 'error' in desc:
            return returner.lower() not in last_shot_player.lower()
        
        return False
    
    def _format_game_outcome_analysis(self, analysis: Dict[str, Any]) -> str:
        """Format game outcome after event analysis into readable response."""
        if 'error' in analysis:
            return f"Unable to perform game outcome analysis: {analysis['error']}"
        
        event_name = (analysis['event_type'] or 'event').replace('_', ' ').title()
        
        response = f"**Game Outcome Analysis: After {event_name}**\n\n"
        response += f"**Player Filter:** {analysis['player']}\n\n"
        
        response += f"**Results:**\n"
        response += f"- Total {event_name}s found: **{analysis['total_events']}**\n"
        response += f"- Server went on to LOSE the game: **{analysis['events_followed_by_loss']}**\n"
        response += f"- Server went on to HOLD: **{analysis['events_followed_by_win']}**\n\n"
        
        if analysis['total_events'] > 0:
            loss_rate = round(100 * analysis['events_followed_by_loss'] / analysis['total_events'], 1)
            response += f"**Answer:** After a {event_name.lower()}, the server lost the game **{analysis['events_followed_by_loss']}** times "
            response += f"({loss_rate}% of {event_name.lower()}s led to a break).\n"
        
        # Show matching instances
        if analysis['matching_instances']:
            shown = min(10, len(analysis['matching_instances']))
            response += f"\n**{shown} Example Instances:**\n"
            response += "-" * 50 + "\n"
            
            for i, inst in enumerate(analysis['matching_instances'][:10], 1):
                response += f"\n**{i}. Point {inst['point']}** - {inst['game_outcome']}\n"
                response += f"   Score: {inst['score']}\n"
                response += f"   Server: {inst['server']}\n"
                response += f"   Point: {inst['point_text']}...\n"
                response += "-" * 50 + "\n"
            
            if len(analysis['matching_instances']) > 10:
                response += f"\n*...and {len(analysis['matching_instances']) - 10} more instances*\n"
        
        if analysis['total_events'] == 0:
            response += f"\n*Note: No {event_name.lower()}s were found in this match.*"
        
        return response
    
    def _is_rally_length_query(self, query: str) -> bool:
        """
        Detect if query asks about points based on rally length.
        
        Example queries that return True:
        - "Who won more points that lasted longer than 15 shots?"
        - "How many rallies went over 10 shots?"
        - "Win percentage on long rallies (7+ shots)"
        """
        rally_keywords = [
            'rally', 'rallies', 'shots long', 'shot rally',
            'longer than', 'more than', 'over.*shots', 'shots or more',
            '+ shots', 'long rally', 'long rallies', 'short rally', 'short rallies',
            'lasted.*shots', 'went.*shots'
        ]
        import re
        query_lower = query.lower()
        return any(re.search(kw, query_lower) for kw in rally_keywords)
    
    def _analyze_rally_length(self, query: str) -> Dict[str, Any]:
        """
        Analyze points based on rally length.
        
        Handles queries like:
        - "Who won more points longer than 15 shots?"
        - "Win percentage on 10+ shot rallies"
        """
        import re
        
        query_lower = query.lower()
        
        # Extract rally length threshold
        length_threshold = None
        # Look for patterns like "15 shots", "longer than 10", "10+ shots", "over 7 shots"
        patterns = [
            r'longer than (\d+)',
            r'more than (\d+)',
            r'over (\d+)',
            r'(\d+)\+',
            r'(\d+) shots or more',
            r'(\d+)-shot',
            r'(\d+) shot',
            r'at least (\d+)'
        ]
        for pattern in patterns:
            match = re.search(pattern, query_lower)
            if match:
                length_threshold = int(match.group(1))
                break
        
        if length_threshold is None:
            # Default thresholds for "long" vs "short"
            if 'long' in query_lower:
                length_threshold = 9  # 9+ shots = long rally
            elif 'short' in query_lower:
                length_threshold = 4  # 4 or fewer = short
            else:
                length_threshold = 10  # default
        
        is_greater_than = 'short' not in query_lower
        
        # Find point-by-point chunks
        pbp_chunks = [c for c in self.chunks if 'point-by-point' in c['metadata'].get('section', '').lower()]
        
        if not pbp_chunks:
            return {'error': 'No point-by-point data available for rally length analysis'}
        
        all_text = '\n'.join([c['text'] for c in pbp_chunks])
        
        point_pattern = r'Point (\d+) \[Server: ([^\|]+)\| Returner: ([^\|]+)\| Score: ([^\]]+)\]: (.+?)(?=Point \d+|\Z)'
        
        # Get player names
        player1 = self.player1
        player2 = self.player2
        
        results = {
            'length_threshold': length_threshold,
            'is_greater_than': is_greater_than,
            'total_qualifying_points': 0,
            'player1': player1,
            'player2': player2,
            'player1_wins': 0,
            'player2_wins': 0,
            'matching_points': []
        }
        
        for match in re.finditer(point_pattern, all_text, re.DOTALL):
            point_num = match.group(1)
            server = match.group(2).strip()
            returner = match.group(3).strip()
            score = match.group(4).strip()
            point_text = match.group(5).strip()
            
            # Use existing _parse_rally_sequence for consistent shot counting
            # This properly handles serve faults, double faults, lets, etc.
            rally_shots = self._parse_rally_sequence(point_text, server, returner)
            
            # Count only actual rally shots (exclude faults that don't start rallies)
            # Filter out FAULT outcomes as they don't count toward rally length
            actual_shots = [s for s in rally_shots if s.get('outcome') != 'FAULT']
            rally_length = len(actual_shots)
            
            # Check if rally matches our criteria
            if is_greater_than:
                if rally_length <= length_threshold:
                    continue
            else:
                if rally_length > length_threshold:
                    continue
            
            results['total_qualifying_points'] += 1
            
            # UNIFIED: Use _determine_point_winner
            point_winner = self._determine_point_winner(actual_shots, server, returner)
            
            if point_winner:
                # Match winner to player1 or player2
                if player1 and player1.lower() in point_winner.lower():
                    results['player1_wins'] += 1
                elif player2 and player2.lower() in point_winner.lower():
                    results['player2_wins'] += 1
                
                results['matching_points'].append({
                    'point': point_num,
                    'server': server,
                    'returner': returner,
                    'score': score,
                    'rally_length': rally_length,
                    'winner': point_winner,
                    'full_rally': point_text.strip()
                })
        
        # Calculate percentages
        if results['total_qualifying_points'] > 0:
            results['player1_percentage'] = round(100 * results['player1_wins'] / results['total_qualifying_points'], 1)
            results['player2_percentage'] = round(100 * results['player2_wins'] / results['total_qualifying_points'], 1)
        else:
            results['player1_percentage'] = 0
            results['player2_percentage'] = 0
        
        return results
    
    def _is_rally_category_breakdown_query(self, query: str) -> bool:
        """Detect if query asks for breakdown by rally length categories."""
        query_lower = query.lower()
        
        # Keywords indicating category breakdown needed
        breakdown_indicators = [
            'category', 'categories',
            'breakdown', 'break down',
            'by rally length', 'by length',
            '1-3', '4-6', '7-9', '10+',
            'short rallies', 'medium rallies', 'long rallies',
            'highest win percentage',
            'best rally length',
            'which rally length',
            'find the exact'
        ]
        
        return any(kw in query_lower for kw in breakdown_indicators)
    
    def _analyze_rally_length_by_category(self, query: str) -> Dict[str, Any]:
        """
        Analyze win percentages by rally length categories.
        
        Categories: 1-3 (short), 4-6 (medium), 7-9 (extended), 10+ (long)
        """
        import re
        
        query_lower = query.lower()
        
        # Detect if looking for a specific player's best category
        player_mentioned = self._detect_player_mentioned(query)
        
        # Define categories
        categories = {
            '1-3': {'min': 1, 'max': 3, 'label': 'Short (1-3 shots)'},
            '4-6': {'min': 4, 'max': 6, 'label': 'Medium (4-6 shots)'},
            '7-9': {'min': 7, 'max': 9, 'label': 'Extended (7-9 shots)'},
            '10+': {'min': 10, 'max': 999, 'label': 'Long (10+ shots)'}
        }
        
        # Find point-by-point chunks
        pbp_chunks = [c for c in self.chunks if 'point-by-point' in c['metadata'].get('section', '').lower()]
        
        if not pbp_chunks:
            return {'error': 'No point-by-point data available'}
        
        all_text = '\n'.join([c['text'] for c in pbp_chunks])
        point_pattern = r'Point (\d+) \[Server: ([^\|]+)\| Returner: ([^\|]+)\| Score: ([^\]]+)\]: (.+?)(?=Point \d+|\Z)'
        
        # Get player names
        player1 = self.player1
        player2 = self.player2
        
        results = {
            'player1': player1,
            'player2': player2,
            'player_mentioned': player_mentioned,
            'categories': {},
            'total_points': 0,
            'best_category_for_player': None
        }
        
        # Initialize category stats
        for cat_key, cat_info in categories.items():
            results['categories'][cat_key] = {
                'label': cat_info['label'],
                'total': 0,
                'player1_wins': 0,
                'player2_wins': 0,
                'examples': []
            }
        
        for match in re.finditer(point_pattern, all_text, re.DOTALL):
            point_num = match.group(1)
            server = match.group(2).strip()
            returner = match.group(3).strip()
            score = match.group(4).strip()
            point_text = match.group(5).strip()
            
            # Parse rally
            rally_shots = self._parse_rally_sequence(point_text, server, returner)
            actual_shots = [s for s in rally_shots if s.get('outcome') != 'FAULT']
            rally_length = len(actual_shots)
            
            if rally_length == 0:
                continue
            
            results['total_points'] += 1
            
            # Determine category
            cat_key = None
            for key, info in categories.items():
                if info['min'] <= rally_length <= info['max']:
                    cat_key = key
                    break
            
            if not cat_key:
                continue
            
            results['categories'][cat_key]['total'] += 1
            
            # UNIFIED: Use _determine_point_winner
            point_winner = self._determine_point_winner(actual_shots, server, returner)
            
            if point_winner:
                if player1 and player1.lower() in point_winner.lower():
                    results['categories'][cat_key]['player1_wins'] += 1
                elif player2 and player2.lower() in point_winner.lower():
                    results['categories'][cat_key]['player2_wins'] += 1
                
                # Store example
                if len(results['categories'][cat_key]['examples']) < 3:
                    results['categories'][cat_key]['examples'].append({
                        'point': point_num,
                        'length': rally_length,
                        'winner': point_winner,
                        'score': score
                    })
        
        # Calculate percentages and find best category
        best_cat = None
        best_pct = -1
        
        for cat_key, cat_data in results['categories'].items():
            if cat_data['total'] > 0:
                cat_data['player1_pct'] = round(100 * cat_data['player1_wins'] / cat_data['total'], 1)
                cat_data['player2_pct'] = round(100 * cat_data['player2_wins'] / cat_data['total'], 1)
                
                # Check if this is the best category for the mentioned player
                if player_mentioned:
                    if player1 and player_mentioned.lower() in player1.lower():
                        if cat_data['player1_pct'] > best_pct:
                            best_pct = cat_data['player1_pct']
                            best_cat = cat_key
                    elif player2 and player_mentioned.lower() in player2.lower():
                        if cat_data['player2_pct'] > best_pct:
                            best_pct = cat_data['player2_pct']
                            best_cat = cat_key
            else:
                cat_data['player1_pct'] = 0
                cat_data['player2_pct'] = 0
        
        if best_cat:
            results['best_category_for_player'] = {
                'category': best_cat,
                'label': categories[best_cat]['label'],
                'win_percentage': best_pct,
                'player': player_mentioned
            }
        
        return results
    
    def _format_rally_category_analysis(self, analysis: Dict[str, Any]) -> str:
        """Format rally length category analysis."""
        if 'error' in analysis:
            return f"Unable to perform rally category analysis: {analysis['error']}"
        
        player1 = analysis['player1']
        player2 = analysis['player2']
        
        response = f"**Rally Length Category Analysis**\n\n"
        response += f"**Players:** {player1} vs {player2}\n"
        response += f"**Total Points Analyzed:** {analysis['total_points']}\n\n"
        
        response += f"**Win Percentage by Rally Length Category:**\n\n"
        response += f"| Category | Total | {player1} Wins | {player1} % | {player2} Wins | {player2} % |\n"
        response += f"|----------|-------|--------------|------------|--------------|------------|\n"
        
        for cat_key in ['1-3', '4-6', '7-9', '10+']:
            cat_data = analysis['categories'][cat_key]
            response += f"| **{cat_data['label']}** | {cat_data['total']} | "
            response += f"{cat_data['player1_wins']} | **{cat_data['player1_pct']}%** | "
            response += f"{cat_data['player2_wins']} | **{cat_data['player2_pct']}%** |\n"
        
        # Highlight best category for mentioned player
        if analysis['best_category_for_player']:
            best = analysis['best_category_for_player']
            response += f"\n**Answer:** {best['player']}'s highest win percentage was in **{best['label']}** "
            response += f"with **{best['win_percentage']}%**\n"
        
        return response
    
    def _format_rally_length_analysis(self, analysis: Dict[str, Any]) -> str:
        """Format rally length analysis results into a readable response."""
        if 'error' in analysis:
            return f"Unable to perform rally length analysis: {analysis['error']}"
        
        threshold = analysis['length_threshold']
        comparison = "longer than" if analysis['is_greater_than'] else "shorter than or equal to"
        
        response = f"**Rally Length Analysis**\n\n"
        response += f"**Criteria:** Points {comparison} **{threshold} shots**\n\n"
        
        response += f"**Results:**\n"
        response += f"- Total qualifying points: **{analysis['total_qualifying_points']}**\n\n"
        
        if analysis['total_qualifying_points'] > 0:
            p1 = analysis['player1'] or 'Player 1'
            p2 = analysis['player2'] or 'Player 2'
            
            response += f"**Winner Breakdown:**\n"
            response += f"| Player | Points Won | Percentage |\n"
            response += f"|--------|-----------|------------|\n"
            response += f"| **{p1}** | {analysis['player1_wins']} | {analysis['player1_percentage']}% |\n"
            response += f"| **{p2}** | {analysis['player2_wins']} | {analysis['player2_percentage']}% |\n"
            
            # Determine who won more
            if analysis['player1_wins'] > analysis['player2_wins']:
                diff = analysis['player1_wins'] - analysis['player2_wins']
                response += f"\n**Answer:** **{p1}** won more points on rallies {comparison} {threshold} shots "
                response += f"({analysis['player1_wins']} vs {analysis['player2_wins']}, +{diff})\n"
            elif analysis['player2_wins'] > analysis['player1_wins']:
                diff = analysis['player2_wins'] - analysis['player1_wins']
                response += f"\n**Answer:** **{p2}** won more points on rallies {comparison} {threshold} shots "
                response += f"({analysis['player2_wins']} vs {analysis['player1_wins']}, +{diff})\n"
            else:
                response += f"\n**Answer:** Both players won equal points on rallies {comparison} {threshold} shots "
                response += f"({analysis['player1_wins']} each)\n"
        
        # Show sample of matching points (limit to 10)
        if analysis['matching_points']:
            shown = min(10, len(analysis['matching_points']))
            response += f"\n**Sample of {shown} Matching Points (of {len(analysis['matching_points'])} total):**\n"
            response += "-" * 50 + "\n"
            
            for i, p in enumerate(analysis['matching_points'], 1):  # Show ALL points
                response += f"\n**{i}. Point {p['point']}** ({p['rally_length']} shots) - Won by **{p['winner']}**\n"
                response += f"   Score: {p['score']}\n"
                response += f"   Rally: {p['full_rally']}\n"
                response += "-" * 50 + "\n"
        
        if analysis['total_qualifying_points'] == 0:
            response += f"\n*Note: No rallies {comparison} {threshold} shots were found in this match.*"
        
        return response
    
    def _is_shot_outcome_query(self, query: str) -> bool:
        """
        Detect if query asks about shots that resulted in specific outcomes.
        
        Example queries that return True:
        - "How many backhand slices did Alcaraz hit that resulted in an error from Djokovic?"
        - "What shots induced forced errors?"
        - "How many forehand winners did Nadal hit?"
        - "Which shots caused unforced errors?"
        """
        outcome_keywords = [
            'resulted in', 'caused', 'induced', 'led to', 'forcing',
            'forced error', 'unforced error', 'winner', 'error from',
            'made.*error', 'hit.*winner', 'produced'
        ]
        shot_keywords = [
            'backhand', 'forehand', 'slice', 'drop shot', 'volley',
            'approach', 'lob', 'shot', 'groundstroke'
        ]
        query_lower = query.lower()
        
        import re
        has_outcome = any(re.search(kw, query_lower) for kw in outcome_keywords)
        has_shot = any(kw in query_lower for kw in shot_keywords)
        return has_outcome and has_shot
    
    def _analyze_shot_outcomes(self, query: str) -> Dict[str, Any]:
        """
        Analyze shots that resulted in specific outcomes (forced errors, winners, etc.).
        
        FIXES APPLIED:
        1. Set filter - Only include points from specified set
        2. Shot number filter - "second shot" or "return" = only shot_idx == 1
        3. Correct outcome detection - "Unforced Error" checked BEFORE "forced error"
        """
        import re
        
        query_lower = query.lower()
        
        # Detect which player hit the shot
        player_mentioned = self._detect_player_mentioned(query)
        
        # Use shared shot detection helper
        shot_info = self._detect_shot_from_query(query)
        shot_base = shot_info['shot_base']
        shot_modifier = shot_info['shot_modifier']
        shot_type = shot_info['shot_type']
        
        # FIX #1: Detect set filter
        set_filter = None
        set_patterns = [
            (r'in set 1|set 1\b|first set|1st set', 1),
            (r'in set 2|set 2\b|second set|2nd set', 2),
            (r'in set 3|set 3\b|third set|3rd set', 3),
            (r'in set 4|set 4\b|fourth set|4th set', 4),
            (r'in set 5|set 5\b|fifth set|5th set', 5),
        ]
        for pattern, set_num in set_patterns:
            if re.search(pattern, query_lower):
                set_filter = set_num
                break
        
        # FIX #2: Detect shot number filter
        shot_number_filter = None
        if 'second shot' in query_lower or 'as his return' in query_lower or 'as her return' in query_lower:
            shot_number_filter = 2  # Return = shot #2 (index 1)
        elif 'the return' in query_lower and ('as' in query_lower or 'on' in query_lower):
            shot_number_filter = 2
        elif 'first shot' in query_lower or 'as his serve' in query_lower:
            shot_number_filter = 1  # Serve = shot #1 (index 0)
        elif 'third shot' in query_lower or 'third ball' in query_lower or 'serve+1' in query_lower:
            shot_number_filter = 3  # Serve+1 = shot #3 (index 2)
        elif 'fourth shot' in query_lower:
            shot_number_filter = 4
        
        # FIX #3: Detect desired outcome - Check UNFORCED before FORCED
        outcome_type = None
        if 'unforced error' in query_lower:
            outcome_type = 'unforced_error'
        elif 'forced error' in query_lower:
            outcome_type = 'forced_error'
        elif 'directly led to' in query_lower or 'led to' in query_lower:
            # "led to an error" - check what kind
            if 'unforced' in query_lower:
                outcome_type = 'unforced_error'
            else:
                outcome_type = 'induced_error'  # Shot was so good opponent erred
        elif 'error from' in query_lower:
            outcome_type = 'induced_error'  # Player A's shot caused Player B's error
        elif 'winner' in query_lower:
            outcome_type = 'winner'
        elif 'error' in query_lower:
            outcome_type = 'any_error'
        
        # Find point-by-point chunks
        pbp_chunks = [c for c in self.chunks if 'point-by-point' in c['metadata'].get('section', '').lower()]
        
        if not pbp_chunks:
            return {'error': 'No point-by-point data available for shot outcome analysis'}
        
        all_text = '\n'.join([c['text'] for c in pbp_chunks])
        
        point_pattern = r'Point (\d+) \[Server: ([^\|]+)\| Returner: ([^\|]+)\| Score: ([^\]]+)\]: (.+?)(?=Point \d+|\Z)'
        
        results = {
            'player': player_mentioned or 'both players',
            'shot_type': shot_type,
            'shot_number_filter': shot_number_filter,
            'set_filter': set_filter,
            'outcome_type': outcome_type,
            'total_shots_found': 0,
            'shots_with_outcome': 0,
            'matching_points': []
        }
        
        for match in re.finditer(point_pattern, all_text, re.DOTALL):
            point_num = match.group(1)
            server = match.group(2).strip()
            returner = match.group(3).strip()
            score = match.group(4).strip()
            point_text = match.group(5).strip()
            
            # FIX #1: Apply set filter
            # Score format can be: "Djokovic 0-0 1-2" (name + sets + games)
            # or "0-0 1-2 15-30" (sets + games + points)
            if set_filter:
                current_set = self._extract_current_set(score)
                if current_set and current_set != set_filter:
                    continue
            
            # Split point into shots
            shots = [s.strip() for s in point_text.split(';') if s.strip()]
            
            if len(shots) < 2:
                continue
            
            # Determine which shots belong to which player
            # Shot 1 = serve (server), Shot 2 = return (returner), Shot 3 = server, etc.
            for shot_idx, shot in enumerate(shots):
                shot_lower = shot.lower()
                
                # FIX #2: Apply shot number filter
                human_shot_number = shot_idx + 1  # Convert to 1-indexed
                if shot_number_filter and human_shot_number != shot_number_filter:
                    continue
                
                # Determine who hit this shot
                if shot_idx % 2 == 0:  # Even index = server's shot (0=serve, 2=3rd ball, etc.)
                    shot_player = server
                else:  # Odd index = returner's shot
                    shot_player = returner
                
                # Check if this matches the player we're looking for
                if player_mentioned:
                    if player_mentioned.lower() not in shot_player.lower():
                        continue
                
                # Check if shot matches the type we're looking for
                shot_matches = False
                if shot_type:
                    # Build patterns to match
                    if shot_base and shot_modifier:
                        if shot_base in shot_lower and shot_modifier in shot_lower:
                            shot_matches = True
                        elif shot_base in shot_lower and 'chip' in shot_lower and shot_modifier == 'slice':
                            shot_matches = True
                    elif shot_base and shot_base in shot_lower:
                        shot_matches = True
                    elif shot_modifier and (shot_modifier in shot_lower or ('chip' in shot_lower and shot_modifier == 'slice')):
                        shot_matches = True
                else:
                    shot_matches = True  # No filter, match all
                
                if not shot_matches:
                    continue
                
                results['total_shots_found'] += 1
                
                # Now check if this shot resulted in the desired outcome
                # The outcome appears on the NEXT shot (opponent's response)
                next_shot_idx = shot_idx + 1
                
                outcome_matches = False
                outcome_description = ""
                
                if next_shot_idx < len(shots):
                    next_shot = shots[next_shot_idx].lower()
                    
                    # GENERIC outcome matching using outcome_type as keyword
                    outcome_keyword = outcome_type.replace('_', ' ').lower() if outcome_type else ''
                    
                    # Handle special cases for error types (check unforced first)
                    if outcome_keyword == 'unforced error' and 'unforced error' in next_shot:
                            outcome_matches = True
                            outcome_description = "led to unforced error by opponent"
                    elif outcome_keyword == 'forced error' and 'forced error' in next_shot and 'unforced' not in next_shot:
                            outcome_matches = True
                            outcome_description = "forced error by opponent"
                    elif outcome_keyword in ['induced error', 'any error'] and 'error' in next_shot:
                            error_type = "unforced error" if 'unforced' in next_shot else "forced error"
                            outcome_matches = True
                            outcome_description = f"led to {error_type} by opponent"
                    elif outcome_keyword == 'winner' and 'winner' in shot_lower:
                        # Winner is on the player's OWN shot, not next shot
                            outcome_matches = True
                            outcome_description = "winner"
                    elif outcome_keyword and outcome_keyword in next_shot:
                        # Generic fallback for other outcome types
                        outcome_matches = True
                        outcome_description = outcome_type.replace('_', ' ')
                elif outcome_type and outcome_type.replace('_', ' ').lower() == 'winner':
                    # Check if current shot is a winner (last shot)
                    if 'winner' in shot_lower:
                        outcome_matches = True
                        outcome_description = "winner"
                
                if outcome_matches:
                    results['shots_with_outcome'] += 1
                    results['matching_points'].append({
                        'point': point_num,
                        'server': server,
                        'returner': returner,
                        'score': score,
                        'shot_player': shot_player,
                        'shot': shot,
                        'shot_index': shot_idx + 1,
                        'outcome': outcome_description,
                        'full_rally': point_text.strip()
                    })
        
        return results
    
    def _format_shot_outcome_analysis(self, analysis: Dict[str, Any]) -> str:
        """Format shot outcome analysis results into a readable response."""
        if 'error' in analysis:
            return f"Unable to perform shot outcome analysis: {analysis['error']}"
        
        shot_desc = analysis['shot_type'] or 'any shot'
        outcome_desc = (analysis['outcome_type'] or 'any outcome').replace('_', ' ')
        
        # Build filters description
        filters = []
        if analysis.get('set_filter'):
            filters.append(f"Set {analysis['set_filter']}")
        if analysis.get('shot_number_filter'):
            shot_names = {1: 'Serve', 2: 'Return', 3: 'Serve+1', 4: '4th Shot'}
            filters.append(f"{shot_names.get(analysis['shot_number_filter'], f'Shot #{analysis['shot_number_filter']}')} only")
        filter_desc = " | ".join(filters) if filters else "All Points"
        
        response = f"**Shot Outcome Analysis**\n\n"
        response += f"**Player:** {analysis['player']}\n"
        response += f"**Shot Type:** {shot_desc}\n"
        response += f"**Filters:** {filter_desc}\n"
        response += f"**Looking For:** {outcome_desc}\n\n"
        
        response += f"**Results:**\n"
        response += f"- Total {shot_desc} shots found: **{analysis['total_shots_found']}**\n"
        response += f"- Shots resulting in {outcome_desc}: **{analysis['shots_with_outcome']}**\n"
        
        if analysis['total_shots_found'] > 0:
            percentage = round(100 * analysis['shots_with_outcome'] / analysis['total_shots_found'], 1)
            response += f"- Percentage: **{percentage}%**\n"
        
        # Show all matching points
        if analysis['matching_points']:
            response += f"\n**All {len(analysis['matching_points'])} Matching Instances:**\n"
            response += "-" * 50 + "\n"
            
            for i, p in enumerate(analysis['matching_points'], 1):
                response += f"\n**{i}. Point {p['point']}**\n"
                response += f"   **Score:** {p['score']}\n"
                response += f"   **{p['shot_player']}'s Shot (#{p['shot_index']}):** {p['shot']}\n"
                response += f"   **Outcome:** {p['outcome']}\n"
                response += f"   **Full Rally:**\n   {p['full_rally']}\n"
                response += "-" * 50 + "\n"
        
        if analysis['shots_with_outcome'] == 0:
            response += f"\n*Note: No {shot_desc} shots by {analysis['player']} resulted in {outcome_desc}.*"
        
        return response
    
    def _analyze_serve_patterns(self, query: str) -> Dict[str, Any]:
        """
        Analyze serve patterns with specific filters (set, tiebreak, court side).
        
        FIXES APPLIED:
        1. 1st serve filter - Only counts 1st serve direction, excludes 2nd serve after fault
        2. Court side comparison - Analyzes both Deuce AND Ad when comparison requested
        3. Win percentage - Tracks points won/lost, not just serve counts
        """
        import re
        
        query_lower = query.lower()
        
        # Detect which player is being asked about
        player_mentioned = self._detect_player_mentioned(query)
        
        # FIX #1: Detect 1st serve vs 2nd serve filter
        serve_number_filter = None
        if '1st serve' in query_lower or 'first serve' in query_lower:
            serve_number_filter = 1
        elif '2nd serve' in query_lower or 'second serve' in query_lower:
            serve_number_filter = 2
        
        # Detect set filter
        set_filter = None
        set_patterns = [
            (r'fifth set|5th set|set 5|set five', 5),
            (r'fourth set|4th set|set 4|set four', 4),
            (r'third set|3rd set|set 3|set three', 3),
            (r'second set|2nd set|set 2|set two', 2),
            (r'first set|1st set|set 1|set one', 1),
        ]
        for pattern, set_num in set_patterns:
            if re.search(pattern, query_lower):
                set_filter = set_num
                break
        
        # Detect tiebreak filter
        is_tiebreak_filter = 'tiebreak' in query_lower or 'tie-break' in query_lower or 'tie break' in query_lower
        
        # FIX #2: Detect if comparison between court sides is requested
        is_court_comparison = 'compared to' in query_lower or ' vs ' in query_lower or 'versus' in query_lower
        
        # Detect court side filter OR comparison
        court_side_filter = None
        compare_deuce_ad = False
        if is_court_comparison and ('deuce' in query_lower or 'ad' in query_lower):
            compare_deuce_ad = True  # Will analyze both
        elif 'deuce' in query_lower:
            court_side_filter = 'deuce'
        elif 'ad side' in query_lower or 'ad court' in query_lower or 'advantage' in query_lower:
            court_side_filter = 'ad'
        
        # Detect specific direction filter (e.g., "to the T")
        direction_filter = None
        if "to the t" in query_lower or "down the t" in query_lower or "'t'" in query_lower:
            direction_filter = 't'
        elif 'wide' in query_lower:
            direction_filter = 'wide'
        elif 'body' in query_lower:
            direction_filter = 'body'
        
        # Find point-by-point chunks
        pbp_chunks = [c for c in self.chunks if 'point-by-point' in c['metadata'].get('section', '').lower()]
        
        if not pbp_chunks:
            return {'error': 'No point-by-point data available for serve pattern analysis'}
        
        all_text = '\n'.join([c['text'] for c in pbp_chunks])
        point_pattern = r'Point (\d+) \[Server: ([^\|]+)\| Returner: ([^\|]+)\| Score: ([^\]]+)\]: (.+?)(?=Point \d+|\Z)'
        
        # Initialize results structure with win tracking
        results = {
            'player': player_mentioned or 'both players',
            'analysis_type': 'serve_patterns',
            'set_filter': set_filter,
            'serve_number_filter': serve_number_filter,
            'tiebreak_filter': is_tiebreak_filter,
            'court_side_filter': court_side_filter,
            'compare_deuce_ad': compare_deuce_ad,
            'direction_filter': direction_filter,
            'total_serves': 0,
            # FIX #3: Track wins/losses by direction and court side
            'by_direction': {
                't': {'count': 0, 'won': 0, 'lost': 0, 'points': []},
                'wide': {'count': 0, 'won': 0, 'lost': 0, 'points': []},
                'body': {'count': 0, 'won': 0, 'lost': 0, 'points': []},
                'other': {'count': 0, 'won': 0, 'lost': 0, 'points': []}
            },
            # For court comparison
            'deuce_side': {
                't': {'count': 0, 'won': 0, 'lost': 0},
                'wide': {'count': 0, 'won': 0, 'lost': 0},
                'body': {'count': 0, 'won': 0, 'lost': 0}
            },
            'ad_side': {
                't': {'count': 0, 'won': 0, 'lost': 0},
                'wide': {'count': 0, 'won': 0, 'lost': 0},
                'body': {'count': 0, 'won': 0, 'lost': 0}
            },
            # Legacy fields for compatibility
            'serves_to_t': 0, 'serves_wide': 0, 'serves_body': 0, 'serves_other': 0,
            't_points': [], 'wide_points': [], 'body_points': [], 'matching_points': []
        }
        
        for match in re.finditer(point_pattern, all_text, re.DOTALL):
            point_num = match.group(1)
            server = match.group(2).strip()
            returner = match.group(3).strip()
            score = match.group(4).strip()
            point_text = match.group(5).strip()
            point_lower = point_text.lower()
            
            # Check if the player of interest was serving
            if player_mentioned:
                if player_mentioned.lower() not in server.lower():
                    continue
            
            # Parse score
            score_parts = score.strip().split()
            
            # Check set filter - use robust extraction
            if set_filter:
                current_set = self._extract_current_set(score)
                if current_set and current_set != set_filter:
                    continue
            
            # Check tiebreak filter - look for 6-6, 7-6, or 6-7 in games score
            if is_tiebreak_filter:
                # Find games score (X-X pattern where X is typically 0-7)
                games_patterns = re.findall(r'\b(\d+)-(\d+)\b', score)
                is_tiebreak = False
                for g1, g2 in games_patterns:
                    g1_int, g2_int = int(g1), int(g2)
                    # Games scores in tiebreak are 6-6, 7-6, or 6-7
                    if (g1_int == 6 and g2_int == 6) or \
                       (g1_int == 7 and g2_int == 6) or \
                       (g1_int == 6 and g2_int == 7):
                        is_tiebreak = True
                        break
                if not is_tiebreak:
                    continue
            
            # Determine court side
            point_score = score_parts[-1] if score_parts else ""
            is_deuce_side = self._is_deuce_side_serve(point_score, is_tiebreak_filter, score_parts)
            
            # Apply court side filter (if not comparing) - GENERIC
            if court_side_filter and not compare_deuce_ad:
                # Check if court side matches filter
                expected_deuce = (court_side_filter == 'deuce')
                if expected_deuce != is_deuce_side:
                    continue
            
            # FIX #1: Extract serve direction from ONLY the specified serve (1st or 2nd)
            serve_direction = self._extract_serve_direction_filtered(point_lower, serve_number_filter)
            
            if serve_direction is None:
                # If filtering for 1st serve and point was won on 2nd serve, skip
                continue
            
            # Apply direction filter if specified
            if direction_filter and serve_direction != direction_filter:
                continue
            
            results['total_serves'] += 1
            
            # FIX #3: Determine if server won the point
            server_won = self._did_server_win_point(point_text)
            
            # Track by direction
            results['by_direction'][serve_direction]['count'] += 1
            if server_won:
                results['by_direction'][serve_direction]['won'] += 1
            else:
                results['by_direction'][serve_direction]['lost'] += 1
            
            # Track by court side (for comparison)
            court_key = 'deuce_side' if is_deuce_side else 'ad_side'
            if serve_direction in results[court_key]:
                results[court_key][serve_direction]['count'] += 1
                if server_won:
                    results[court_key][serve_direction]['won'] += 1
                else:
                    results[court_key][serve_direction]['lost'] += 1
            
            # Store point data
            point_data = {
                'point': point_num,
                'server': server,
                'returner': returner,
                'score': score,
                'serve_direction': serve_direction,
                'is_deuce_side': is_deuce_side,
                'court_side': 'Deuce' if is_deuce_side else 'Ad',
                'server_won': server_won,
                'full_text': point_text.strip()
            }
            
            if len(results['by_direction'][serve_direction]['points']) < 5:
                results['by_direction'][serve_direction]['points'].append(point_data)
            
            # Legacy compatibility
            if serve_direction == 't':
                results['serves_to_t'] += 1
                results['t_points'].append(point_data)
            elif serve_direction == 'wide':
                results['serves_wide'] += 1
                results['wide_points'].append(point_data)
            elif serve_direction == 'body':
                results['serves_body'] += 1
                results['body_points'].append(point_data)
            else:
                results['serves_other'] += 1
            
            results['matching_points'].append(point_data)
        
        # Calculate win percentages
        for direction in ['t', 'wide', 'body']:
            data = results['by_direction'][direction]
            if data['count'] > 0:
                data['win_pct'] = round(100 * data['won'] / data['count'], 1)
            else:
                data['win_pct'] = 0
            
            # Same for court sides
            for court in ['deuce_side', 'ad_side']:
                court_data = results[court][direction]
                if court_data['count'] > 0:
                    court_data['win_pct'] = round(100 * court_data['won'] / court_data['count'], 1)
                else:
                    court_data['win_pct'] = 0
        
        # Legacy percentages
        if results['total_serves'] > 0:
            results['t_percentage'] = round(100 * results['serves_to_t'] / results['total_serves'], 1)
            results['wide_percentage'] = round(100 * results['serves_wide'] / results['total_serves'], 1)
            results['body_percentage'] = round(100 * results['serves_body'] / results['total_serves'], 1)
        else:
            results['t_percentage'] = results['wide_percentage'] = results['body_percentage'] = 0
        
        return results
    
    def _extract_current_set(self, score: str) -> int:
        """
        Extract current set number from score string.
        
        Handles multiple formats:
        - "Djokovic 0-0 1-2" (name + sets + games) → Set 1
        - "Djokovic 1-0 0-0" (name + sets + games) → Set 2
        - "0-0 1-2 15-30" (sets + games + points) → Set 1
        - "2-1 3-2 40-30" (sets + games + points) → Set 4
        """
        import re
        
        # Find all X-X patterns
        patterns = re.findall(r'(\d+)-(\d+)', score)
        
        if not patterns:
            return None
        
        # First X-X pattern that could be a set score (typically 0-0 to 3-2 range)
        for p1, p2 in patterns:
            p1_int, p2_int = int(p1), int(p2)
            # Set scores are typically 0-3 range, games can be 0-7+
            # If both are ≤ 3, it's likely the set score
            if p1_int <= 3 and p2_int <= 3:
                return p1_int + p2_int + 1
        
        # Fallback: use first pattern (may be inaccurate for some formats)
        p1, p2 = patterns[0]
        return int(p1) + int(p2) + 1
    
    def _parse_score_components(self, score: str) -> dict:
        """
        Parse score string into components: set, game, point.
        
        Handles:
        - "Djokovic 0-0 1-2" → {'set': '0-0', 'game': '1-2'}
        - "Djokovic 0-0 1-2 15-30" → {'set': '0-0', 'game': '1-2', 'point': '15-30'}
        - "0-0 1-2 15-30" → {'set': '0-0', 'game': '1-2', 'point': '15-30'}
        """
        import re
        
        # Find all X-X digit patterns for set and game
        digit_patterns = re.findall(r'(\d+)-(\d+)', score)
        
        if len(digit_patterns) < 2:
            return None
        
        set_score = None
        game_score = None
        point_score = None
        
        for i, (p1, p2) in enumerate(digit_patterns):
            p1_int, p2_int = int(p1), int(p2)
            
            if set_score is None and p1_int <= 3 and p2_int <= 3:
                set_score = f"{p1}-{p2}"
            elif set_score is not None and game_score is None:
                game_score = f"{p1}-{p2}"
            elif set_score is not None and game_score is not None and point_score is None:
                # This could be point score in tiebreak (e.g., "3-2")
                point_score = f"{p1}-{p2}"
        
        # Also check for point patterns like "15-30", "40-AD", "AD-40"
        point_pattern = re.search(r'(0|15|30|40|AD)-(0|15|30|40|AD)', score, re.IGNORECASE)
        if point_pattern and not point_score:
            point_score = point_pattern.group(0)
        
        if set_score and game_score:
            return {
                'set': set_score,
                'game': game_score,
                'point': point_score or '0-0'
            }
        
        return None
    
    def _is_deuce_side_serve(self, point_score: str, is_tiebreak: bool, score_parts: list) -> bool:
        """Determine if serve is from deuce side based on score."""
        import re
        # Tiebreak: even total points = deuce side
        if is_tiebreak and len(score_parts) >= 3:
            tb_score = score_parts[2]
            tb_match = re.match(r'(\d+)-(\d+)', tb_score)
            if tb_match:
                total_points = int(tb_match.group(1)) + int(tb_match.group(2))
                return (total_points % 2 == 0)
        
        # Regular game: count points to determine side
        # 0-0, 15-15, 30-30 = deuce (0, 2, 4 points)
        # 15-0, 0-15, 30-15, 15-30, etc. = ad (odd points)
        point_values = {'0': 0, '15': 1, '30': 2, '40': 3, 'AD': 4}
        parts = point_score.split('-')
        if len(parts) == 2:
            try:
                p1 = point_values.get(parts[0], 0)
                p2 = point_values.get(parts[1], 0)
                total = p1 + p2
                return (total % 2 == 0)
            except:
                pass
        return True  # Default to deuce
    
    def _extract_serve_direction_filtered(self, point_lower: str, serve_number_filter: int) -> str:
        """
        Extract serve direction for ONLY the specified serve number.
        
        FIX: If 1st serve filter is set but point was won on 2nd serve after fault,
        we should either: (a) skip the point, or (b) categorize by 1st serve direction.
        
        For simplicity, if 1st serve was a fault, we skip the point.
        """
        import re
        
        # Check for fault pattern: "1st serve [direction], fault"
        first_serve_fault = bool(re.search(r'1st serve.*?fault', point_lower))
        
        if serve_number_filter == 1:
            if first_serve_fault:
                # 1st serve was a fault - skip this point for 1st serve analysis
                return None
            else:
                # 1st serve went in - extract its direction
                # Look for "1st serve [direction]" at the start
                match = re.match(r'1st serve\s*(wide|down the t|to body|to the t|body)', point_lower)
                if match:
                    dir_text = match.group(1)
                    if 'wide' in dir_text:
                        return 'wide'
                    elif 't' in dir_text:
                        return 't'
                    elif 'body' in dir_text:
                        return 'body'
                # Try broader patterns
                if point_lower.startswith('1st serve wide') or 'wide;' in point_lower[:30]:
                    return 'wide'
                elif 'down the t' in point_lower[:40] or point_lower.startswith('1st serve down the t'):
                    return 't'
                elif point_lower.startswith('1st serve to body') or 'body;' in point_lower[:30]:
                    return 'body'
                return 'other'
        
        elif serve_number_filter == 2:
            if not first_serve_fault:
                # 1st serve went in, there was no 2nd serve - skip
                return None
            # Extract 2nd serve direction
            match = re.search(r'2nd serve\s*(wide|down the t|to body|to the t|body)', point_lower)
            if match:
                dir_text = match.group(1)
                if 'wide' in dir_text:
                    return 'wide'
                elif 't' in dir_text:
                    return 't'
                elif 'body' in dir_text:
                    return 'body'
            # Broader search after "2nd serve"
            second_serve_idx = point_lower.find('2nd serve')
            if second_serve_idx >= 0:
                after_second = point_lower[second_serve_idx:second_serve_idx+40]
                if 'wide' in after_second:
                    return 'wide'
                elif 'down the t' in after_second or 'to the t' in after_second:
                    return 't'
                elif 'body' in after_second:
                    return 'body'
            return 'other'
        
        else:
            # No filter - use any serve direction (the one that was played)
            if point_lower.startswith('1st serve') and 'fault' not in point_lower[:50]:
                # 1st serve went in
                if 'wide' in point_lower[:30]:
                    return 'wide'
                elif 'down the t' in point_lower[:40]:
                    return 't'
                elif 'body' in point_lower[:30]:
                    return 'body'
            else:
                # Check 2nd serve
                second_serve_idx = point_lower.find('2nd serve')
                if second_serve_idx >= 0:
                    after_second = point_lower[second_serve_idx:second_serve_idx+40]
                    if 'wide' in after_second:
                        return 'wide'
                    elif 'down the t' in after_second or 'to the t' in after_second:
                        return 't'
                    elif 'body' in after_second:
                        return 'body'
            return 'other'
    
    def _format_serve_pattern_analysis(self, analysis: Dict[str, Any]) -> str:
        """Format serve pattern analysis results with WIN PERCENTAGES and COURT COMPARISON."""
        if 'error' in analysis:
            return f"Unable to perform serve pattern analysis: {analysis['error']}"
        
        # Build filter description
        filters = []
        if analysis.get('serve_number_filter') == 1:
            filters.append("1st Serve Only")
        elif analysis.get('serve_number_filter') == 2:
            filters.append("2nd Serve Only")
        if analysis.get('set_filter'):
            filters.append(f"Set {analysis['set_filter']}")
        if analysis.get('tiebreak_filter'):
            filters.append("Tiebreak")
        if analysis.get('direction_filter'):
            filters.append(f"To {analysis['direction_filter'].upper()}")
        filter_desc = " | ".join(filters) if filters else "All Points"
        
        response = f"**Serve Pattern Analysis**\n\n"
        response += f"**Player:** {analysis['player']}\n"
        response += f"**Filters:** {filter_desc}\n"
        response += f"**Total Serves Analyzed:** {analysis['total_serves']}\n\n"
        
        if analysis['total_serves'] == 0:
            response += f"\n*Note: No serves matching the specified filters were found.*"
            return response
        
        # Check if this is a court comparison query
        if analysis.get('compare_deuce_ad') or (analysis.get('direction_filter') and not analysis.get('court_side_filter')):
            # FIX #2: Show comparison between Deuce and Ad courts
            direction = analysis.get('direction_filter') or 't'
            classification = analysis.get('classification')
            direction_label = self._get_display_label('serve_direction', direction, classification)
            
            deuce_data = analysis['deuce_side'].get(direction, {'count': 0, 'won': 0, 'lost': 0, 'win_pct': 0})
            ad_data = analysis['ad_side'].get(direction, {'count': 0, 'won': 0, 'lost': 0, 'win_pct': 0})
            
            response += f"**Comparison: Serves to {direction_label}**\n\n"
            response += f"| Court Side | Serves | Won | Lost | Win % |\n"
            response += f"|------------|--------|-----|------|-------|\n"
            response += f"| **Deuce Court** | {deuce_data['count']} | {deuce_data['won']} | {deuce_data['lost']} | **{deuce_data.get('win_pct', 0)}%** |\n"
            response += f"| **Ad Court** | {ad_data['count']} | {ad_data['won']} | {ad_data['lost']} | **{ad_data.get('win_pct', 0)}%** |\n"
            
            # Answer the comparison
            if deuce_data['count'] > 0 and ad_data['count'] > 0:
                deuce_pct = deuce_data.get('win_pct', 0)
                ad_pct = ad_data.get('win_pct', 0)
                
                response += f"\n**Answer:** {analysis['player']}'s win percentage when serving to the **{direction_label}**:\n"
                response += f"- **Deuce Court:** {deuce_pct}% ({deuce_data['won']}/{deuce_data['count']})\n"
                response += f"- **Ad Court:** {ad_pct}% ({ad_data['won']}/{ad_data['count']})\n"
                
                if deuce_pct > ad_pct:
                    response += f"\n→ **{deuce_pct - ad_pct:.1f} percentage points better on Deuce Court**\n"
                elif ad_pct > deuce_pct:
                    response += f"\n→ **{ad_pct - deuce_pct:.1f} percentage points better on Ad Court**\n"
                else:
                    response += f"\n→ **Equal win percentage on both courts**\n"
        else:
            # Standard breakdown with win percentages
            response += f"**Serve Direction Breakdown (with Win %):**\n"
            response += f"| Direction | Count | Won | Lost | Win % |\n"
            response += f"|-----------|-------|-----|------|-------|\n"
            
            classification = analysis.get('classification')
            for direction in ['t', 'wide', 'body']:
                data = analysis['by_direction'][direction]
                if data['count'] > 0:
                    label = self._get_display_label('serve_direction', direction, classification)
                    response += f"| **{label}** | {data['count']} | {data['won']} | {data['lost']} | **{data['win_pct']}%** |\n"
            
            # Best direction
            best_dir = max(['t', 'wide', 'body'], key=lambda d: analysis['by_direction'][d].get('win_pct', 0))
            best_data = analysis['by_direction'][best_dir]
            if best_data['count'] > 0:
                best_label = self._get_display_label('serve_direction', best_dir, classification)
                response += f"\n**Best Direction:** Serves to **{best_label}** ({best_data['win_pct']}% win rate)\n"
        
        # Show sample points
        direction_filter = analysis.get('direction_filter')
        if direction_filter:
            points = analysis['by_direction'][direction_filter]['points']
            if points:
                response += f"\n**Sample Points ({len(points)}):**\n"
                response += "-" * 40 + "\n"
                for p in points[:5]:
                    won_str = "[WON]" if p.get('server_won') else "[LOST]"
                    response += f"Point {p['point']} {won_str} ({p['court_side']} side, Score: {p['score']})\n"
                    response += f"  {p['full_text']}\n"
        
        return response
    
    def _analyze_rally_sequences(self, query: str) -> Dict[str, Any]:
        """
        Analyze rally sequences - e.g., "first shot after serve was a forehand".
        
        This handles queries like:
        - "Win percentage when first shot after serve was a forehand"
        - "What happens when server's 3rd ball is a backhand?"
        """
        import re
        
        query_lower = query.lower()
        
        # Detect which player is being asked about
        player_mentioned = self._detect_player_mentioned(query)
        
        # Use shared shot detection helper
        shot_info = self._detect_shot_from_query(query)
        shot_type = shot_info['shot_type']
        
        # Find point-by-point chunks
        pbp_chunks = [c for c in self.chunks if 'point-by-point' in c['metadata'].get('section', '').lower()]
        
        if not pbp_chunks:
            return {'error': 'No point-by-point data available for rally sequence analysis'}
        
        # Parse all points
        all_text = '\n'.join([c['text'] for c in pbp_chunks])
        
        # Match point format
        point_pattern = r'Point (\d+) \[Server: ([^\|]+)\| Returner: ([^\|]+)\| Score: ([^\]]+)\]: (.+?)(?=Point \d+|\Z)'
        
        results = {
            'player': player_mentioned or 'both players',
            'analysis_type': 'first_shot_after_serve',
            'shot_type': shot_type,
            'total_serve_points': 0,
            'points_with_matching_shot': 0,
            'points_won': 0,
            'points_lost': 0,
            'win_percentage': 0,
            'matching_points': []
        }
        
        for match in re.finditer(point_pattern, all_text, re.DOTALL):
            point_num = match.group(1)
            server = match.group(2).strip()
            returner = match.group(3).strip()
            score = match.group(4).strip()
            point_text = match.group(5).strip()
            
            # Check if the player of interest was serving
            if player_mentioned:
                player_is_server = player_mentioned.lower() in server.lower()
                if not player_is_server:
                    continue
            
            results['total_serve_points'] += 1
            
            # Parse the rally to find the server's first shot after the serve
            # Rally format: "1st serve ...; [return]; [server's 3rd ball]; [returner's shot]; ..."
            # Split by semicolons to get individual shots
            shots = [s.strip() for s in point_text.split(';') if s.strip()]
            
            if len(shots) < 3:
                # Not enough shots (ace, unreturned serve, or return error)
                continue
            
            # shots[0] = serve (1st or 2nd)
            # shots[1] = return
            # shots[2] = server's first shot after serve (3rd ball)
            third_ball = shots[2].lower() if len(shots) > 2 else ""
            
            # Check if the third ball matches the shot type
            if shot_type:
                if shot_type.lower() not in third_ball:
                    continue
            
            results['points_with_matching_shot'] += 1
            
            # Determine if server won the point
            # Look for outcome indicators at the end
            point_won = False
            point_text_lower = point_text.lower()
            
            # Server wins if: ace, winner by server, forced error by returner, unforced error by returner
            # Need to check the LAST shot to determine winner
            last_shot = shots[-1].lower() if shots else ""
            
            # Check for server winning patterns
            if 'ace' in point_text_lower:
                point_won = True
            elif 'winner' in last_shot:
                # Check if it's an odd-numbered shot (server's shot: 1, 3, 5, etc.)
                shot_index = len(shots)
                if shot_index % 2 == 1:  # Odd = server's shot (1=serve, 3=3rd ball, etc.)
                    point_won = True
            elif 'forced error' in last_shot or 'unforced error' in last_shot:
                # Check if it's an even-numbered shot (returner's shot: 2, 4, 6, etc.)
                shot_index = len(shots)
                if shot_index % 2 == 0:  # Even = returner's shot
                    point_won = True
            elif ',winner' in point_text_lower:
                # Alternative winner format - check position
                winner_pos = point_text_lower.rfind(',winner')
                text_before_winner = point_text_lower[:winner_pos]
                shots_before = text_before_winner.count(';')
                if shots_before % 2 == 0:  # Server's shot (0=serve, 2=3rd ball, etc. before semicolons)
                    point_won = True
            
            if point_won:
                results['points_won'] += 1
            else:
                results['points_lost'] += 1
            
            results['matching_points'].append({
                'point': point_num,
                'server': server,
                'returner': returner,
                'score': score,
                'third_ball': shots[2] if len(shots) > 2 else "N/A",
                'full_text': point_text.strip(),
                'won': point_won
            })
        
        # Calculate win percentage
        if results['points_with_matching_shot'] > 0:
            results['win_percentage'] = round(100 * results['points_won'] / results['points_with_matching_shot'], 1)
        
        return results
    
    def _format_rally_sequence_analysis(self, analysis: Dict[str, Any]) -> str:
        """Format rally sequence analysis results into a readable response."""
        if 'error' in analysis:
            return f"Unable to perform rally sequence analysis: {analysis['error']}"
        
        shot_desc = analysis['shot_type'] or 'any shot'
        
        response = f"**Rally Sequence Analysis: First Shot After Serve**\n\n"
        response += f"**Player:** {analysis['player']}\n"
        response += f"**Shot Type Analyzed:** {shot_desc}\n\n"
        
        response += f"**Results:**\n"
        response += f"- Total service points analyzed: **{analysis['total_serve_points']}**\n"
        response += f"- Points where first shot after serve was {shot_desc}: **{analysis['points_with_matching_shot']}**\n"
        response += f"- Points won: **{analysis['points_won']}**\n"
        response += f"- Points lost: **{analysis['points_lost']}**\n"
        response += f"- **Win Percentage: {analysis['win_percentage']}%**\n"
        
        # Show all matching points
        if analysis['matching_points']:
            response += f"\n**All {len(analysis['matching_points'])} Matching Points:**\n"
            response += "-" * 50 + "\n"
            
            for i, p in enumerate(analysis['matching_points'], 1):
                outcome = "WON" if p['won'] else "LOST"
                response += f"\n**{i}. Point {p['point']}** [{outcome}]\n"
                response += f"   **Score:** {p['score']}\n"
                response += f"   **Server:** {p['server']} | **Returner:** {p['returner']}\n"
                response += f"   **3rd Ball (First Shot After Serve):** {p['third_ball']}\n"
                response += f"   **Full Rally:**\n   {p['full_text']}\n"
                response += "-" * 50 + "\n"
        
        if analysis['points_with_matching_shot'] == 0:
            if analysis['shot_type']:
                response += f"\n*Note: No points found where {analysis['player']}'s first shot after serve was a {shot_desc}.*"
            else:
                response += f"\n*Note: No qualifying serve points found for {analysis['player']}.*"
        
        return response
    
    def _is_break_point_score(self, score_str: str) -> bool:
        """
        Determine if a score represents a break point for the returner.
        Break point = returner has chance to win the game (win the break).
        
        Score format in point-by-point: "X-Y A-B C-D" where:
        - X-Y = Sets (from server's perspective)
        - A-B = Games (from server's perspective)  
        - C-D = Points in current game (server points - returner points)
        
        Break point scenarios (from SERVER's perspective, meaning RETURNER has BP):
        - 0-40 (three break points)
        - 15-40 (two break points)
        - 30-40 (one break point)
        - 40-AD (advantage returner = break point)
        """
        import re
        # Extract just the points portion (last part of score)
        parts = score_str.strip().split()
        if not parts:
            return False
        
        # Get the points score (should be last element like "30-40" or "40-AD")
        points_part = parts[-1] if parts else ""
        
        # Handle various formats
        points_match = re.match(r'(\d+|AD)-(\d+|AD)', points_part, re.IGNORECASE)
        if not points_match:
            return False
        
        server_points = points_match.group(1).upper()
        returner_points = points_match.group(2).upper()
        
        # Break point for returner (server facing break point):
        # - 0-40, 15-40, 30-40 (server trailing by potential game loss)
        # - 40-AD (advantage to returner)
        break_point_scores = [
            ('0', '40'), ('15', '40'), ('30', '40'),
            ('40', 'AD')
        ]
        
        return (server_points, returner_points) in break_point_scores
    
    def _is_game_point_score(self, score_str: str) -> bool:
        """
        Determine if server has game point (about to win their service game).
        """
        import re
        parts = score_str.strip().split()
        if not parts:
            return False
        
        points_part = parts[-1] if parts else ""
        points_match = re.match(r'(\d+|AD)-(\d+|AD)', points_part, re.IGNORECASE)
        if not points_match:
            return False
        
        server_points = points_match.group(1).upper()
        returner_points = points_match.group(2).upper()
        
        # Game point for server:
        # - 40-0, 40-15, 40-30 (server at 40, returner not)
        # - AD-40 (advantage to server)
        game_point_scores = [
            ('40', '0'), ('40', '15'), ('40', '30'),
            ('AD', '40')
        ]
        
        return (server_points, returner_points) in game_point_scores
    
    def _is_deuce_score(self, score_str: str) -> bool:
        """Determine if score is at deuce (40-40)."""
        import re
        parts = score_str.strip().split()
        if not parts:
            return False
        
        points_part = parts[-1] if parts else ""
        return points_part.upper() in ['40-40', 'DEUCE']
    
    def _is_set_point_score(self, score_str: str) -> bool:
        """
        Determine if a score represents a set point.
        Set point = player has chance to win the current set.
        
        Score format: "X-Y A-B C-D" where:
        - X-Y = Sets (from server's perspective)
        - A-B = Games (from server's perspective)
        - C-D = Points in current game (server points - returner points)
        
        Set point scenarios:
        1. Server serving for set: Game score is 5-X (X < 5) AND game point (40-0, 40-15, 40-30, AD-40)
        2. Returner serving for set: Game score is X-5 (X < 5) AND break point (0-40, 15-40, 30-40, 40-AD)
        3. Tiebreak: At 6-6 in games, any point in tiebreak is a set point
        """
        import re
        if not score_str:
            return False
        
        parts = score_str.strip().split()
        if len(parts) < 2:
            return False
        
        # Extract game score (second part, e.g., "5-3" or "6-6")
        game_match = re.match(r'(\d+)-(\d+)', parts[1] if len(parts) > 1 else '')
        if not game_match:
            return False
        
        games_server = int(game_match.group(1))
        games_returner = int(game_match.group(2))
        
        # Check if in tiebreak (6-6, 7-6, 6-7)
        if (games_server == 6 and games_returner == 6) or \
           (games_server == 7 and games_returner == 6) or \
           (games_server == 6 and games_returner == 7):
            return True
        
        # Check if server is serving for set (5-X where X < 5)
        if games_server == 5 and games_returner < 5:
            # Check if server has game point
            return self._is_game_point_score(score_str)
        
        # Check if returner is serving for set (X-5 where X < 5)
        if games_returner == 5 and games_server < 5:
            # Check if returner has game point (which is break point for server)
            return self._is_break_point_score(score_str)
        
        return False
    
    def _is_match_point_score(self, score_str: str) -> bool:
        """
        Determine if a score represents a match point.
        Match point = player has chance to win the entire match.
        
        Score format: "X-Y A-B C-D" where:
        - X-Y = Sets (from server's perspective)
        - A-B = Games (from server's perspective)
        - C-D = Points in current game (server points - returner points)
        
        Match point scenarios:
        1. Best of 3: Player up 2-0 in sets AND has set point
        2. Best of 5: Player up 3-0 or 3-1 in sets AND has set point
        3. Any format: Player up by 1 set in final set AND has set point
        """
        import re
        if not score_str:
            return False
        
        parts = score_str.strip().split()
        if len(parts) < 1:
            return False
        
        # Extract set score (first part, e.g., "2-0" or "3-1")
        set_match = re.match(r'(\d+)-(\d+)', parts[0])
        if not set_match:
            return False
        
        sets_server = int(set_match.group(1))
        sets_returner = int(set_match.group(2))
        
        # Determine if this is a potential match point
        # Match point requires:
        # 1. Player is up by enough sets to win on next set, AND
        # 2. That player has set point in current set
        
        # Server can win match if:
        # - Best of 3: Up 2-0 (needs 1 more set) OR up 1-0 in final set (set 3)
        # - Best of 5: Up 3-0 or 3-1 (needs 1 more set) OR up 2-1 in final set (set 5)
        server_can_win = False
        if sets_server == 2 and sets_returner == 0:  # Best of 3, up 2-0
            server_can_win = True
        elif sets_server == 3 and sets_returner <= 1:  # Best of 5, up 3-0 or 3-1
            server_can_win = True
        elif sets_server == 1 and sets_returner == 0 and len(parts) > 1:  # Final set, up 1-0
            # Check if this is set 3 (best of 3) or set 5 (best of 5)
            # We can't determine format from score alone, but if it's the final set and they're up, it's MP
            server_can_win = True
        
        # Returner can win match if:
        # - Best of 3: Up 0-2 (needs 1 more set) OR up 0-1 in final set (set 3)
        # - Best of 5: Up 0-3 or 1-3 (needs 1 more set) OR up 1-2 in final set (set 5)
        returner_can_win = False
        if sets_returner == 2 and sets_server == 0:  # Best of 3, up 0-2
            returner_can_win = True
        elif sets_returner == 3 and sets_server <= 1:  # Best of 5, up 0-3 or 1-3
            returner_can_win = True
        elif sets_returner == 1 and sets_server == 0 and len(parts) > 1:  # Final set, up 0-1
            returner_can_win = True
        
        # If server can win match, check if they have set point
        if server_can_win:
            # Server has set point if they're serving for set (5-X) with game point
            if len(parts) > 1:
                game_match = re.match(r'(\d+)-(\d+)', parts[1])
                if game_match:
                    games_server = int(game_match.group(1))
                    games_returner = int(game_match.group(2))
                    if games_server == 5 and games_returner < 5:
                        return self._is_game_point_score(score_str)
        
        # If returner can win match, check if they have set point
        if returner_can_win:
            # Returner has set point if they're serving for set (X-5) with game point (break point for server)
            if len(parts) > 1:
                game_match = re.match(r'(\d+)-(\d+)', parts[1])
                if game_match:
                    games_server = int(game_match.group(1))
                    games_returner = int(game_match.group(2))
                    if games_returner == 5 and games_server < 5:
                        return self._is_break_point_score(score_str)
        
        return False
    
    def _analyze_shots_in_situations(self, query: str) -> Dict[str, Any]:
        """
        Parse point-by-point data to analyze shots in specific situations.
        Returns analysis data for queries like 'backhand DTL on break point'.
        
        Args:
            query: User's question about situational shot selection
            
        Returns:
            Dictionary with analysis results including counts and examples
        """
        import re
        
        query_lower = query.lower()
        
        # Detect which player is being asked about
        player_mentioned = self._detect_player_mentioned(query)
        
        # Use shared shot detection helper
        shot_info = self._detect_shot_from_query(query)
        shot_base = shot_info['shot_base']
        shot_modifier = shot_info['shot_modifier']
        shot_type = shot_info['shot_type']
        shot_direction = shot_info['shot_direction']
        
        # Detect situation type
        situation_type = None
        if 'break point' in query_lower:
            situation_type = 'break_point'
        elif 'game point' in query_lower:
            situation_type = 'game_point'
        elif 'deuce' in query_lower:
            situation_type = 'deuce'
        elif 'set point' in query_lower:
            situation_type = 'set_point'
        elif 'match point' in query_lower:
            situation_type = 'match_point'
        
        # Find point-by-point chunks
        pbp_chunks = [c for c in self.chunks if 'point-by-point' in c['metadata'].get('section', '').lower()]
        
        if not pbp_chunks:
            return {'error': 'No point-by-point data available for situational analysis'}
        
        # Parse all points
        all_text = '\n'.join([c['text'] for c in pbp_chunks])
        
        # Match point format: "Point X [Server: NAME | Returner: NAME | Score: X-X X-X X-X]: description"
        point_pattern = r'Point (\d+) \[Server: ([^\|]+)\| Returner: ([^\|]+)\| Score: ([^\]]+)\]: (.+?)(?=Point \d+|\Z)'
        
        results = {
            'player': player_mentioned or 'both players',
            'total_situations': 0,
            'total_shots_by_player': 0,
            'shots_matching_criteria': 0,
            'points_with_shot': [],
            'shot_type': shot_type,
            'shot_direction': shot_direction,
            'situation': situation_type or 'all',
            'all_situation_points': []
        }
        
        for match in re.finditer(point_pattern, all_text, re.DOTALL):
            point_num = match.group(1)
            server = match.group(2).strip()
            returner = match.group(3).strip()
            score = match.group(4).strip()
            point_text = match.group(5).strip()
            
            # Check if this point matches the situation - GENERIC using _check_situation
            situation_matches = False
            if situation_type is None:
                situation_matches = True  # No specific situation filter
            else:
                situation_matches = self._check_situation(situation_type, score)
            
            if not situation_matches:
                continue
            
            results['total_situations'] += 1
            results['all_situation_points'].append({
                'point': point_num,
                'server': server,
                'returner': returner,
                'score': score
            })
            
            # Determine if the player of interest was involved and had the shot
            # Player could be server or returner
            player_is_server = player_mentioned and player_mentioned.lower() in server.lower()
            player_is_returner = player_mentioned and player_mentioned.lower() in returner.lower()
            player_involved = player_is_server or player_is_returner or not player_mentioned
            
            if not player_involved:
                continue
            
            # Build shot pattern to search for
            # Point-by-point format: "[shot_base] [modifier] [direction]"
            # e.g., "backhand slice crosscourt", "forehand drop shot down the line"
            shot_patterns = []
            
            # Escape regex special characters to avoid errors
            def safe_re(s):
                return re.escape(s) if s else ''
            
            if shot_base and shot_modifier and shot_direction:
                # Most specific: e.g., "backhand slice crosscourt"
                shot_patterns.append(f'{safe_re(shot_base)}.*{safe_re(shot_modifier)}.*{safe_re(shot_direction)}')
                shot_patterns.append(f'{safe_re(shot_base)} {safe_re(shot_modifier)}.*{safe_re(shot_direction)}')
            elif shot_base and shot_modifier:
                # e.g., "backhand slice" (any direction)
                shot_patterns.append(f'{safe_re(shot_base)}.*{safe_re(shot_modifier)}')
                shot_patterns.append(f'{safe_re(shot_base)} {safe_re(shot_modifier)}')
                # Also try "chip/slice" format in data
                if shot_modifier == 'slice':
                    shot_patterns.append(f'{safe_re(shot_base)}.*chip')
                    shot_patterns.append(f'{safe_re(shot_base)}.*slice')
            elif shot_base and shot_direction:
                # e.g., "backhand crosscourt" (any modifier)
                shot_patterns.append(f'{safe_re(shot_base)}.*{safe_re(shot_direction)}')
            elif shot_modifier and shot_direction:
                # e.g., "slice crosscourt" (any base)
                shot_patterns.append(f'{safe_re(shot_modifier)}.*{safe_re(shot_direction)}')
            elif shot_type:
                # Just the shot type - use simple string match, not regex
                shot_patterns.append(safe_re(shot_type))
                # Handle slice/chip variations
                if 'slice' in (shot_type or '').lower():
                    shot_patterns.append('chip')
            elif shot_direction:
                shot_patterns.append(safe_re(shot_direction))
            
            # Count shots by player in this point
            if shot_patterns:
                for pattern in shot_patterns:
                    # Skip empty or invalid patterns
                    if not pattern or pattern.strip() == '':
                        continue
                    try:
                        if re.search(pattern, point_text, re.IGNORECASE):
                            results['shots_matching_criteria'] += 1
                            results['points_with_shot'].append({
                                'point': point_num,
                                'server': server,
                                'returner': returner,
                                'score': score,
                                'full_text': point_text.strip(),  # Store full point description
                                'excerpt': point_text.strip()
                            })
                            break  # Count each point only once
                    except re.error as e:
                        # Skip invalid regex patterns
                        print(f"[WARN] Invalid regex pattern '{pattern}': {e}")
                        continue
        
        # Calculate percentage
        if results['total_situations'] > 0:
            results['percentage'] = round(100 * results['shots_matching_criteria'] / results['total_situations'], 1)
        else:
            results['percentage'] = 0
        
        return results
    
    def _format_situational_analysis(self, analysis: Dict[str, Any]) -> str:
        """Format the situational analysis results into a readable response."""
        if 'error' in analysis:
            return f"Unable to perform situational analysis: {analysis['error']}"
        
        situation_name = analysis['situation'].replace('_', ' ').title() if analysis['situation'] != 'all' else 'All Points'
        shot_desc = f"{analysis['shot_type'] or ''} {analysis['shot_direction'] or ''}".strip() or 'any shot'
        
        response = f"**Situational Shot Analysis**\n\n"
        response += f"**Player:** {analysis['player']}\n"
        response += f"**Situation:** {situation_name}\n"
        response += f"**Shot Analyzed:** {shot_desc}\n\n"
        
        response += f"**Results:**\n"
        response += f"- Total {situation_name.lower()}s in match: **{analysis['total_situations']}**\n"
        response += f"- Points containing {shot_desc}: **{analysis['shots_matching_criteria']}**\n"
        
        if analysis['total_situations'] > 0:
            response += f"- Percentage: **{analysis['percentage']}%**\n"
        
        # Show ALL matching points with full descriptions
        if analysis['points_with_shot']:
            response += f"\n**All {len(analysis['points_with_shot'])} Matching Points:**\n"
            response += "-" * 50 + "\n"
            for i, p in enumerate(analysis['points_with_shot'], 1):
                response += f"\n**{i}. Point {p['point']}**\n"
                response += f"   **Score:** {p['score']}\n"
                response += f"   **Server:** {p['server']} | **Returner:** {p['returner']}\n"
                response += f"   **Full Rally:**\n   {p.get('full_text', p['excerpt'])}\n"
                response += "-" * 50 + "\n"
        
        if analysis['total_situations'] == 0:
            response += f"\n*Note: No {situation_name.lower()}s were found in this match.*"
        elif analysis['shots_matching_criteria'] == 0:
            response += f"\n*Note: No {shot_desc} shots were found during {situation_name.lower()}s in this match.*"
        
        return response
    
    def _llm_parse_query(self, question: str) -> Dict[str, Any]:
        """
        Use LLM to parse query into structured classification.
        
        This is the FIRST step - LLM understands the query structure before taxonomy routing.
        
        Returns structured JSON with:
        - player: Which player is being asked about
        - shot_type: backhand, forehand, serve, etc.
        - shot_modifier: slice, topspin, drop shot, etc.
        - metric: winners, unforced_errors, aces, etc.
        - situation: break_point, game_point, deuce, etc.
        - set_filter: specific set number or None
        - set_comparison: {set_a: [1], set_b: [3]} for comparisons
        - direction: crosscourt, down_the_line, etc.
        - query_type: analytical, comparative, narrative
        - actual_question: What the user really wants to know
        """
        import json
        
        player1 = self.player1 or "Player 1"
        player2 = self.player2 or "Player 2"
        
        # Build match context including set winners
        match_context = f"{player1} vs {player2}"
        if hasattr(self, 'match_score') and self.match_score:
            match_context += f"\nMatch Score: {self.match_score}"
            
            # Add which sets each player won
            if hasattr(self, 'set_winners') and self.set_winners:
                p1_sets_won = self._get_sets_won_by_player(player1)
                p2_sets_won = self._get_sets_won_by_player(player2)
                if p1_sets_won:
                    match_context += f"\n{player1} won sets: {p1_sets_won}"
                if p2_sets_won:
                    match_context += f"\n{player2} won sets: {p2_sets_won}"
        
        # === ADD FILTER INVENTORY - CRITICAL FOR GROUNDED QUERIES ===
        # LLM now knows EXACTLY what values exist in this match
        filter_inventory_text = ""
        if hasattr(self, 'match_filter_inventory') and self.match_filter_inventory:
            inv = self.match_filter_inventory
            filter_inventory_text = f"""
AVAILABLE FILTERS IN THIS MATCH (use ONLY these values):

=== NEW TAXONOMY (PRIMARY - USE THESE) ===
- Shot Phases: {inv.get('shot_phases', [])} (serve, return, rally, net)
- Contact Types: {inv.get('contact_types', [])} (groundstroke, volley, half_volley, swinging_volley, overhead)
- Spins: {inv.get('spins', [])} (slice, flat, topspin)
- Intents: {inv.get('intents', [])} (approach, drop_shot, lob, passing_shot, winner_attempt)
- Locations: {inv.get('locations', [])} (baseline, mid_court, net, service_line)

=== CORE DIMENSIONS ===
- Shot Types: {inv.get('shot_types', [])} (forehand, backhand, serve) - NOTE: overhead/smash is a contact_type, not shot_type
- Directions: {inv.get('directions', [])} (crosscourt, down_the_line, inside_out, inside_in, down_the_middle)
- Serve Targets: {inv.get('serve_targets', [])} (wide, body, t)
- Depths: {inv.get('depths', [])} (shallow, deep, very_deep)
- Outcomes: {inv.get('outcomes', [])} (winner, unforced_error, forced_error, ace, etc.)

=== LEGACY (backward compatibility - prefer new taxonomy above) ===
- Modifiers (LEGACY): {inv.get('shot_modifiers', [])} - Use contact_types/spins/intents instead
- Court Positions (LEGACY): {inv.get('court_positions', [])} - Use locations instead
- Net Play Types (LEGACY): {inv.get('net_play_types', [])} - Derive from location=net + contact_type

=== OTHER FILTERS ===
- Court Sides: {inv.get('court_sides', [])}
- Sets Played: {inv.get('sets_played', [])}
- Rally Categories: {inv.get('rally_categories', [])}
- Serve+1 Shot Types: {inv.get('serve_plus_one_shot_types', [])}
- Pressure Levels: {inv.get('pressure_levels', [])}
- Players: {inv.get('players', [])}
"""
            if hasattr(self, 'match_stats_summary') and self.match_stats_summary:
                stats = self.match_stats_summary
                filter_inventory_text += f"""
MATCH STATS SUMMARY:
- Total Points: {stats.get('total_points', 0)}
- Total Shots: {stats.get('total_shots', 0)}
- Aces: {stats.get('aces', 0)}
- Double Faults: {stats.get('double_faults', 0)}
- Winners: {stats.get('winners', 0)}
- Unforced Errors: {stats.get('unforced_errors', 0)}

COMPREHENSIVE ALIAS MAPPINGS (system auto-normalizes):
- Directions: cc/xc/cross-court = crosscourt, dtl/line = down_the_line, dtm = down_the_middle, io = inside_out, ii = inside_in
- Shot Types: fh = forehand, bh = backhand, sv = serve, ret = return, oh = overhead, smash = overhead
- Modifiers: chip/underspin = slice, vb/vol = volley, ds/dropshot = drop_shot, app = approach, sv = swinging_volley, hv = half_volley
- Depths: short = shallow
- Outcomes: wnr/w = winner, ue/unforced = unforced_error, fe/forced = forced_error, df = double_fault
- Serve Targets (CONTEXT: for serves only): "down the t"/"center"/"middle" → t, "out wide" → wide, "to body"/"at body"/"jam" → body

IMPORTANT CONTACT TYPE MAPPINGS:
- "smash" / "smashes" / "overhead" → contact_type: "overhead" (NOT shot_type)
- Overheads/smashes use shot_type: "forehand" or "backhand" (the stroke used), contact_type: "overhead"

CRITICAL CONTEXT-DEPENDENT MAPPINGS:
- "down the middle" / "center" / "middle" has TWO different meanings:
  1. For GROUNDSTROKES (direction): "down_the_middle" (rally shot direction)
  2. For SERVES (serve_target): "t" (serve to the T / center of service box)
  
- When user asks about SERVES: "serves down the middle" / "serves to center" → serve_target: "t"
- When user asks about RALLY SHOTS: "forehand down the middle" → direction: "down_the_middle"
- Context is KEY - look at whether it's about serves or groundstrokes

ALIAS MAPPING RULES:
- ALWAYS map user phrases to the inventory values listed above
- Use context (serves vs groundstrokes) to determine correct mapping
- Prioritize exact inventory matches over aliases

HIERARCHIES (superset filters include all subsets):
- 'volley' matches: volley, swinging_volley, half_volley, drop_volley
- 'net_shot' matches: all volleys + overhead
- 'errors' matches: unforced_error, forced_error, double_fault
"""
        
        parse_prompt = f"""You are a tennis query parser. Parse this question into structured JSON.

MATCH CONTEXT:
{match_context}
{filter_inventory_text}
QUESTION: {question}

Return ONLY valid JSON (no markdown, no explanation) with these fields:
{{
  "player": "name of player being asked about, or 'both' or null",
  
  // === NEW TAXONOMY (PRIMARY - use these for cleaner queries) ===
  "shot_phase": "serve|return|rally|net|null - tactical phase of the shot",
  "contact_type": "groundstroke|volley|half_volley|swinging_volley|overhead|null - how ball is struck",
  "spin": "slice|flat|topspin|null - ball rotation",
  "intent": "approach|drop_shot|lob|passing_shot|winner_attempt|null - tactical purpose",
  "location": "baseline|mid_court|net|service_line|null - court position",
  
  // === LEGACY FIELDS (for backward compatibility, prefer new taxonomy above) ===
  "shot_type": "forehand|backhand|serve|null - base stroke type. NOTE: overhead/smash is NOT a shot_type, use contact_type: overhead",
  "shot_modifier": "DEPRECATED - use contact_type/spin/intent instead. slice|topspin|flat|approach|volley|null",
  
  // === METRICS (N-metric support) ===
  // GENERIC: Each sub-question gets its OWN COMPLETE filter set
  // The LLM decides what filters each metric needs - code doesn't know about specific metrics
  "metrics_parsed": [
    // Array of metric objects - ONE per distinct question/metric in the query
    // EACH metric has its OWN filters - they are INDEPENDENT, not inherited
    {{
      "metric": "the metric name - use BASE metric names like: first_serve_pct, first_serve_win_pct, win_percentage, winners, aces, double_faults, unforced_errors, forced_errors, points_won, etc. NEVER use compound names like 'ace_percentage' or 'winner_percentage' - use 'aces' or 'winners' and the system calculates percentage",
      "filters": {{
        // COMPLETE filter set for THIS metric only - include ALL relevant filters
        // CRITICAL: first_serve_pct needs serve_number=null (ALL serves) to calculate percentage correctly
        // first_serve_win_pct needs serve_number=1 (only first serves that went in)
        "serve_number": "1|2|null - Use 1 for first_serve_win_pct, null for first_serve_pct",
        "role": "server|returner|null", 
        "situation": "break_point|game_point|etc|null",
        "shot_type": "forehand|backhand|serve|null",
        "direction": "crosscourt|down_the_line|null",
        "court_zone": "net|baseline|null",
        "depth": "shallow|deep|null"
        // ... any other filter this specific metric needs
      }},
      "context": "serve|return|rally|net|situation|null - for grouping related metrics"
    }}
  ],
  // LEGACY (kept for backward compatibility, prefer metrics_parsed above)
  "metric": "primary metric for simple single-metric queries",
  "secondary_metric": "DEPRECATED - use metrics_parsed instead",
  "situation": "break_point|game_point|set_point|match_point|deuce|tiebreak|null",
  "situation_comparison": {{"situation_a": "tiebreak", "situation_b": "non_tiebreak"}} or null - for comparing tiebreak vs rest of match",
  "role": "server|returner|null - when asking about a player in a specific role",
  "serve_number": "1 for 1st serve, 2 for 2nd serve, or null for both. CRITICAL: first_serve_pct MUST be null (needs ALL serves), first_serve_win_pct MUST be 1",
  "serve_target": "wide|body|t|null - specific serve direction as filter",
  "court_side": "deuce|ad|null - specific court side as filter",
  "court_zone": "net|baseline|null - CRITICAL: Use 'net' for 'net points' queries, NOT shot_type volley!",
  "set_filter": "single set number (1-5) or null",
  "set_comparison": {{"set_a": [list of sets for first group], "set_b": [list of sets for second group]}},
  "group_by": "sets|set_groups|rally_length_category|court_side|serve_number|serve_direction|shot_direction|return_depth|shot_type|shot_modifier|spin|court_position|depth|outcome|shot_number|game_outcome|player|situation|pressure_level|serve_plus_one_type|net_play_type|null",
  "secondary_group_by": "for 2D analysis - same options as group_by, or null",
  "tertiary_group_by": "for 3D analysis - same options as group_by, or null (rarely needed)",
  "n_dimensional": "true if query has 3+ combined dimensions (filters + groups), else false",
  "direction": "crosscourt|down_the_line|inside_out|inside_in|down_the_middle|null",
  "depth": "shallow|deep|very_deep|null",
  "chain_logic": {{"shot_a": "first shot type", "shot_b": "outcome/result"}} or null - for "X led to Y" patterns,
  "analysis_type": "count|percentage|comparison|ratio|trend|2d_cross_tab|chain|momentum|null",
  "query_type": "analytical|narrative - 'analytical' if clear calculable metric, 'narrative' if vague/strategic question",
  "metric_clarity": "clear|vague - 'clear' if the question specifies exactly what to measure (e.g., 'ace count', 'first serve %'), 'vague' if unclear (e.g., 'how did serves change?', 'forehand effectiveness')",
  "actual_question": "brief restatement of what user wants to know"
}}

CRITICAL RULES:
0. **NEW TAXONOMY USAGE**: 
   - For "net play" / "at the net" / "volleys": set location: "net" and contact_type: "volley" (NOT shot_modifier)
   - For "approach shots": set intent: "approach" (NOT shot_modifier)
   - For "drop shots": set intent: "drop_shot" (NOT shot_type)
   - For "slice forehand": set shot_type: "forehand" AND spin: "slice" (NOT shot_modifier)
   - For "topspin backhand": set shot_type: "backhand" AND spin: "topspin"
   - The new taxonomy separates concerns: shot_type (what), contact_type (how), spin (rotation), intent (why), location (where)
   - DERIVE net play from location + contact_type, don't use legacy net_play_types

1. **METRIC CLARITY CHECK**: If the question is vague about WHAT to measure (e.g., "How did serves change?" - change in what?), set:
   - metric_clarity: "vague"
   - query_type: "narrative"
   Even if it seems analytical, vague questions need narrative context to answer properly.
   Examples of VAGUE: "How did X's serves change?", "Did serving improve?", "Forehand effectiveness", "Performance on break points"
   Examples of CLEAR: "First serve win %", "Ace count", "Break point conversion %", "Forehand winner count"

2. **NET POINTS**: When query asks about "net points", set location: "net" and metric: "net_points_won". Do NOT set shot_type: "volley"!
3. When comparing "sets he won vs sets he lost", ALWAYS populate BOTH set_a AND set_b
4. **COMPARISON DETECTION**: If query contains "compared to", "vs", "versus", "on X vs Y", "X vs Y", comparing ONE dimension's values:
   - Use group_by (NOT metrics_parsed)
   - That dimension goes ONLY in group_by, NOT in filters
   - Leave the filter as null
   - Examples:
   - "Ad Court compared to Deuce Court" → {{"group_by": "court_side", "court_side": null}}
   - "T vs Wide vs Body" → {{"group_by": "serve_direction", "serve_target": null}}
   - "Forehand vs Backhand winners" → {{"group_by": "shot_type", "shot_type": null, "metric": "winners"}}
   - "Sinner's forehand vs backhand errors" → {{"player": "Jannik Sinner", "group_by": "shot_type", "shot_type": null, "metric": "errors"}}
   - "Errors on forehand vs backhand" → {{"group_by": "shot_type", "shot_type": null, "metric": "errors"}}
   - "Crosscourt vs Down the Line" → {{"group_by": "shot_direction", "direction": null}}
   - "1st serve vs 2nd serve" → {{"group_by": "serve_number", "serve_number": null}}
   - "Shallow vs Deep returns" → {{"group_by": "return_depth", "depth": null}}
   - "Short vs Long rallies" → {{"group_by": "rally_length_category"}}
   - DO NOT use metrics_parsed for these - use group_by!
5. For ratio questions (winners to errors), set analysis_type: "ratio"
6. For trend questions (across sets), set analysis_type: "trend"
7. For 2D analysis (direction ratio in sets won vs lost), use BOTH group_by AND secondary_group_by
8. For "when serving/returning", set role: "server" or "returner"
9. For complex queries with 3+ conditions (e.g., "on break points, serving to T, on Ad court"), set n_dimensional: true
10. Each filter (serve_target, court_side, situation, etc.) NARROWS the data - use as many as mentioned in the query UNLESS it's a comparison (see rule 4)
11. **BOTH PLAYERS DETECTION**: When query asks about "each player", "both players", "each", "which player", "who", "compare players", "player comparison", or similar terms indicating comparison of both players, ALWAYS set:
   - player: "both"
   - group_by: "player"
   Examples:
   - "How many winners did each player have?" → {{"player": "both", "group_by": "player", "metric": "winners"}}
   - "How many winners did each have?" → {{"player": "both", "group_by": "player", "metric": "winners"}}
   - "Compare aces for both players" → {{"player": "both", "group_by": "player", "metric": "aces"}}
   - "Which player hit more forehand winners?" → {{"player": "both", "group_by": "player", "shot_type": "forehand", "metric": "winners"}}
   - "Who had more break points saved?" → {{"player": "both", "group_by": "player", "situation": "break_point", "metric": "points_won"}}
   - "Aces by player" → {{"player": "both", "group_by": "player", "metric": "aces"}}

EXAMPLES BY ANALYSIS TYPE:

COUNTING:
- "How many aces?" → {{"metric": "aces", "analysis_type": "count"}}
- "Forehand winners in Set 3" → {{"shot_type": "forehand", "metric": "winners", "set_filter": 3}}

GROUPING/COMPARISON (CRITICAL - dimension being compared goes in group_by, NOT filter):
- "T vs Wide serves" → {{"group_by": "serve_direction", "serve_target": null}}
- "T vs Wide vs Body" → {{"group_by": "serve_direction", "serve_target": null}}
- "Forehand vs Backhand winners" → {{"group_by": "shot_type", "shot_type": null, "metric": "winners"}}
- "Sinner's forehand vs backhand winners" → {{"player": "Jannik Sinner", "group_by": "shot_type", "shot_type": null, "metric": "winners"}}
- "How many forehand winners did Sinner hit compared to backhand winners?" → {{"player": "Jannik Sinner", "group_by": "shot_type", "shot_type": null, "metric": "winners"}}
- "How many unforced errors did Sinner make on forehand vs backhand?" → {{"player": "Jannik Sinner", "group_by": "shot_type", "shot_type": null, "metric": "unforced_errors"}}
- "Forehand errors vs backhand errors" → {{"group_by": "shot_type", "shot_type": null, "metric": "errors"}}
- "Forced errors on forehand vs backhand" → {{"group_by": "shot_type", "shot_type": null, "metric": "forced_errors"}}
- "Crosscourt vs Down the Line" → {{"group_by": "shot_direction", "direction": null}}
- "1st serve vs 2nd serve win %" → {{"group_by": "serve_number", "serve_number": null, "metric": "win_percentage"}}
- "Shallow vs Deep vs Very Deep returns" → {{"group_by": "return_depth", "depth": null}}
- "Ad Court compared to Deuce Court" → {{"group_by": "court_side", "court_side": null}}
- "Points by rally length" → {{"group_by": "rally_length_category"}}
- "Stats in service games won vs lost" → {{"group_by": "game_outcome", "role": "server"}}
- "Which player hit more aces?" → {{"player": "both", "group_by": "player", "metric": "aces"}}
- "Who used body serves more?" → {{"player": "both", "group_by": "player", "serve_target": "body", "metric": "count"}}

SET COMPARISON:
- "Errors in Set 1 vs Set 3" → {{"set_comparison": {{"set_a": [1], "set_b": [3]}}}}
- "In the sets X won vs the sets X lost" → Use the MATCH CONTEXT to determine which specific sets X won/lost, then set set_a and set_b accordingly
  Example: If Player A won sets [2, 3, 5] and lost sets [1, 4], then:
  - "Player A's stats in sets he won vs sets he lost" → {{"player": "Player A", "set_comparison": {{"set_a": [2, 3, 5], "set_b": [1, 4]}}}}

SITUATION COMPARISON:
- "Net points in tiebreaks compared to rest of match" → {{"court_zone": "net", "metric": "net_points_won", "group_by": "situation", "situation_comparison": {{"situation_a": "tiebreak", "situation_b": "non_tiebreak"}}}}
- "Break points vs non-break points" → {{"group_by": "situation", "situation_comparison": {{"situation_a": "break_point", "situation_b": "non_break_point"}}}}

MULTI-METRIC QUERIES (N metrics in one question - GENERIC FOR ALL METRIC TYPES):
**CRITICAL DISTINCTION:**
- Use "metrics_parsed" for DIFFERENT metrics or UNRELATED filters (e.g., "aces AND double faults")
- Use "group_by" for SAME metric with different values of ONE dimension (e.g., "forehand VS backhand winners")
- Keywords: "vs"/"compared to"/"versus" → group_by | "and"/"plus"/"also" → metrics_parsed

- "First serve % and first serve win %" → {{
    "metrics_parsed": [
      {{"metric": "first_serve_pct", "filters": {{"role": "server"}}, "context": "serve"}},
      {{"metric": "first_serve_win_pct", "filters": {{"role": "server", "serve_number": 1}}, "context": "serve"}}
    ]
  }}
  **CRITICAL RULE FOR first_serve_pct:**
  - first_serve_pct = (first serves IN) / (ALL serve attempts)
  - It needs ALL serves (both serve_number=1 AND serve_number=2) to calculate the denominator
  - DO NOT set serve_number filter for first_serve_pct - it must be null/omitted
  - first_serve_win_pct DOES need serve_number=1 because it's win % ON first serves that went in
- "Aces and double faults" → {{
    "metrics_parsed": [
      {{"metric": "aces", "filters": {{"role": "server"}}, "context": "serve"}},
      {{"metric": "double_faults", "filters": {{"role": "server"}}, "context": "serve"}}
    ]
  }}
- "Break point save % and conversion %" → {{
    "metrics_parsed": [
      {{"metric": "win_percentage", "filters": {{"situation": "break_point", "role": "server"}}, "context": "situation"}},
      {{"metric": "win_percentage", "filters": {{"situation": "break_point", "role": "returner"}}, "context": "situation"}}
    ]
  }}
- "Net points won and baseline winners" → {{
    "metrics_parsed": [
      {{"metric": "points_won", "filters": {{"court_zone": "net"}}, "context": "net"}},
      {{"metric": "winners", "filters": {{"court_zone": "baseline"}}, "context": "rally"}}
    ]
  }}
- "Set 1 aces plus Set 3 aces" → {{
    "metrics_parsed": [
      {{"metric": "aces", "filters": {{"set": 1}}, "context": "serve"}},
      {{"metric": "aces", "filters": {{"set": 3}}, "context": "serve"}}
    ]
  }}
- "Game point winners and break point winners" → {{
    "metrics_parsed": [
      {{"metric": "winners", "filters": {{"situation": "game_point"}}, "context": "situation"}},
      {{"metric": "winners", "filters": {{"situation": "break_point"}}, "context": "situation"}}
    ]
  }}
- GENERIC: Each metric has its OWN complete filter set - works for ANY filter type (serve_number, situation, shot_type, direction, court_zone, court_side, set, depth, serve_target, role, etc.)
- Code doesn't know about specific metrics - LLM decides what filters each metric needs
- Related metrics (same context) will be synthesized together in the answer

RATIO ANALYSIS:
- "Winners to errors ratio" → {{"metric": "winners", "secondary_metric": "errors", "analysis_type": "ratio"}}
- "Winners to unforced errors ratio" → {{"metric": "winners", "secondary_metric": "unforced_errors", "analysis_type": "ratio"}}

TREND ANALYSIS:
- "How did serve % change across sets?" → {{"metric": "first_serve_pct", "analysis_type": "trend"}}

2D CROSS-TAB:
- "IO vs DTL ratio in sets won vs lost" → {{"group_by": "shot_direction", "secondary_group_by": "set_groups", "analysis_type": "2d_cross_tab"}}

ROLE-BASED:
- "When serving, break point saves" → {{"role": "server", "situation": "break_point"}}
- "As returner, deep returns" → {{"role": "returner", "group_by": "return_depth"}}
- **CRITICAL - SERVE EFFECTIVENESS vs SERVE SHOTS:**
  - "Serve effectiveness" / "serve win %" / "points won on serve" → {{"role": "server", "metric": "win_percentage"}} (NO shot_type!)
  - "How many aces?" → {{"metric": "aces"}} (NO shot_type needed - aces are detected by outcome)
  - "Forehand winners" → {{"shot_type": "forehand", "metric": "winners"}} (shot_type IS the winning shot)
  - Do NOT set shot_type: "serve" for serve effectiveness - that filters to only aces/double faults!
  
- **CRITICAL - SERVE TARGET FILTER (DO NOT HALLUCINATE):**
  - "First serve percentage" / "Second serve won percentage" → {{"serve_target": null}} (NO serve_target filter!)
  - "Serve effectiveness" / "Serve win %" → {{"serve_target": null}} (NO serve_target filter!)
  - ONLY set serve_target if question EXPLICITLY mentions: "wide", "body", "to T", "down the T", "to the middle"
  - Examples that SHOULD have serve_target:
    * "First serve percentage to T" → {{"serve_target": "t"}}
    * "Wide serve win percentage" → {{"serve_target": "wide"}}
  - Examples that should NOT have serve_target:
    * "First serve percentage" → {{"serve_target": null}}
    * "Second serve won percentage" → {{"serve_target": null}}
    * "Serve effectiveness" → {{"serve_target": null}}
  - DO NOT add serve_target for general serve questions! The system will block it anyway, but don't waste tokens.

CHAIN LOGIC (A → B):
- "Backhand slice led to unforced error" → {{"chain_logic": {{"shot_a": "backhand slice", "shot_b": "unforced error"}}, "analysis_type": "chain"}}
- "Approach shot followed by winner" → {{"chain_logic": {{"shot_a": "approach shot", "shot_b": "winner"}}, "analysis_type": "chain"}}
- "Drop shot directly led to winner" → {{"chain_logic": {{"shot_a": "drop shot", "shot_b": "winner"}}, "analysis_type": "chain"}}

NEW TAXONOMY EXAMPLES:
- "Forehand slice winners" → {{"shot_type": "forehand", "spin": "slice", "metric": "winners"}}
- "Volley winners at net" → {{"contact_type": "volley", "location": "net", "metric": "winners"}}
- "Approach shot effectiveness" → {{"intent": "approach", "metric": "win_percentage"}}
- "Drop shot winners" → {{"intent": "drop_shot", "metric": "winners"}}
- "Passing shot success rate" → {{"intent": "passing_shot", "metric": "win_percentage"}}
- "Topspin forehand crosscourt" → {{"shot_type": "forehand", "spin": "topspin", "direction": "crosscourt"}}
- "Slice backhand down the line" → {{"shot_type": "backhand", "spin": "slice", "direction": "down_the_line"}}
- "Net play by contact type" → {{"location": "net", "group_by": "contact_type"}}
- "Groundstroke vs volley winners" → {{"group_by": "contact_type", "metric": "winners"}}

MOMENTUM ANALYSIS:
- "Momentum after break points" → {{"analysis_type": "momentum", "situation": "break_point"}}
- "Did aggression increase after breaks?" → {{"analysis_type": "momentum"}}
- "Carry-over effect after winning break" → {{"analysis_type": "momentum"}}

QUERY_TYPE CLASSIFICATION:
- **analytical**: Questions asking for specific counts, percentages, or metrics that can be directly calculated
  Examples: 
  - "How many winners?"
  - "What was the ace count?" 
  - "Break point conversion %"
  - "Serve % in Set 1 vs Set 3" (has clear metric: serve %)
  - "Winners in sets won vs lost" (has clear metric: winners)
  
- **narrative**: Questions about strategy, tactics, patterns, behavior, "change", or questions with vague/unclear metrics
  Examples:
  - "What was the tactical approach?"
  - "Did they play more aggressively after winning a break point?" (vague metric: "aggressive")
  - "How did momentum shift?"
  - "Tell the story of Set 3"
  - "Did X change after Y?" (vague: change in what?)
  - "Performance on break points" (vague: performance = win %? aggression? shot selection?)
  
KEY DISTINCTION:
- **Clear, calculable metric** → analytical (e.g., "ace count", "first serve %", "winner count")
- **Vague concept or strategic question** → narrative (e.g., "aggression", "momentum", "effectiveness", "performance")
- When in doubt: if the metric isn't a direct count/percentage → narrative

METRIC CLARITY CHECK:
- **clear_metric**: The question specifies EXACTLY what to count/measure
  Examples: "first serve win %", "ace count", "break point conversion", "forehand winners"
- **vague_metric**: The question asks about something but doesn't specify what metric
  Examples: "How did first serves change?", "Did serving improve?", "Forehand effectiveness", "Performance on break points"
  → If vague_metric → default to query_type: "narrative"

N-DIMENSIONAL (complex multi-filter + multi-group):
- "On break points, serving to T, Ad court, in sets won - 1st vs 2nd serve win %" → {{
    "situation": "break_point",
    "serve_target": "t", 
    "court_side": "ad",
    "set_comparison": {{"set_a": [1, 3], "set_b": [2]}},
    "group_by": "serve_number",
    "n_dimensional": true
  }}
- "In tiebreaks, on 2nd serves, compare forehand vs backhand return effectiveness by court side" → {{
    "situation": "tiebreak",
    "serve_number": 2,
    "group_by": "shot_type",
    "secondary_group_by": "court_side",
    "n_dimensional": true
  }}
- "How many net points in tiebreaks compared to rest of match?" → {{
    "player": "Roger Federer",
    "court_zone": "net",
    "metric": "net_points_won",
    "group_by": "situation",
    "situation_comparison": {{"situation_a": "tiebreak", "situation_b": "non_tiebreak"}}
  }}
- "On break points, T vs Wide vs Body" → {{
    "situation": "break_point",
    "group_by": "serve_direction",
    "serve_target": null
  }}
- "In Set 5, Ad Court vs Deuce Court win %" → {{
    "set_filter": 5,
    "group_by": "court_side",
    "court_side": null,
    "metric": "win_percentage"
  }}

Return ONLY the JSON:"""

        try:
            # ALWAYS use gemini-2.5-flash for query parsing
            import google.generativeai as genai
            model = genai.GenerativeModel('gemini-2.5-flash')
            response = model.generate_content(parse_prompt)
            response_text = response.text.strip()
            
            # Clean up response - remove markdown code blocks if present
            if response_text.startswith("```"):
                response_text = response_text.split("```")[1]
                if response_text.startswith("json"):
                    response_text = response_text[4:]
                response_text = response_text.strip()
            
            # Parse JSON
            parsed = json.loads(response_text)
            print(f"[LLM-PARSE] Parsed query: {json.dumps(parsed, indent=2)}")
            return parsed
            
        except Exception as e:
            print(f"[LLM-PARSE] Error parsing query: {e}")
            return None
    
    def _apply_llm_parse_to_classification(self, classification: Dict, llm_parse: Dict, original_question: str = None) -> Dict:
        """Apply LLM parsing results to the classification."""
        if not llm_parse:
            return classification
        
        # CRITICAL: Sanitize string "null" values to actual None
        # LLM sometimes returns "null" as a string instead of JSON null
        def sanitize_null(value):
            if isinstance(value, str) and value.lower() == 'null':
                return None
            return value
        
        # Sanitize all values in llm_parse
        for key in list(llm_parse.keys()):
            llm_parse[key] = sanitize_null(llm_parse[key])
        
        # CRITICAL: Detect which dimensions are being used for grouping
        # If a dimension is in group_by, it should NOT be in filters
        grouped_dimensions = set()
        group_by_to_filter_map = {
            'court_side': 'court_side',
            'serve_direction': 'serve_target',
            'shot_direction': 'direction',
            'shot_type': 'shot_type',
            'serve_number': 'serve_number',
            'return_depth': 'depth',
            'rally_length_category': None,  # No corresponding filter
            'player': None,  # Special handling
            'game_outcome': None,  # No corresponding filter
            'sets': None,  # No corresponding filter
        }
        
        if llm_parse.get('group_by'):
            group_by = llm_parse['group_by']
            filter_key = group_by_to_filter_map.get(group_by)
            if filter_key:
                grouped_dimensions.add(filter_key)
        
        # Also check secondary and tertiary group_by
        if llm_parse.get('secondary_group_by'):
            filter_key = group_by_to_filter_map.get(llm_parse['secondary_group_by'])
            if filter_key:
                grouped_dimensions.add(filter_key)
        
        if llm_parse.get('tertiary_group_by'):
            filter_key = group_by_to_filter_map.get(llm_parse['tertiary_group_by'])
            if filter_key:
                grouped_dimensions.add(filter_key)
        
        # Update filters from LLM parse
        filters = classification.get('filters', {})
        
        # CRITICAL: Remove any dimensions from filters that are being grouped
        # (These may have been added by _classify_query before LLM parse)
        for dim in grouped_dimensions:
            if dim in filters:
                del filters[dim]
                print(f"[LLM-PARSE] Removed '{dim}' from filters because it's being grouped for comparison")
        
        # Check if this is a chain logic query
        is_chain_query = llm_parse.get('analysis_type') == 'chain' or llm_parse.get('chain_logic')
        
        # For chain queries, remove shot characteristics from filters (they're in chain_logic)
        if is_chain_query:
            chain_related_filters = ['shot_type', 'shot_modifier', 'shot_base', 'shot_number', 'direction']
            for f in chain_related_filters:
                if f in filters:
                    del filters[f]
                    print(f"[LLM-PARSE] Removed '{f}' from filters because it's a chain query (characteristics are in chain_logic)")
        
        if llm_parse.get('player'):
            filters['player'] = llm_parse['player']
        
        # Skip shot_type/shot_modifier for chain queries (they're in chain_logic structure)
        # Skip shot_type if it's being grouped (e.g., "Forehand vs Backhand")
        if llm_parse.get('shot_type') and 'shot_type' not in grouped_dimensions and not is_chain_query:
            filters['shot_type'] = llm_parse['shot_type']
            # Also set shot_base for compatibility
            shot_type = llm_parse['shot_type']
            if shot_type in ['forehand', 'backhand']:
                filters['shot_base'] = shot_type
        
        if llm_parse.get('shot_modifier') and not is_chain_query:
            filters['shot_modifier'] = llm_parse['shot_modifier']
        
        # CRITICAL: Only add/update situation if LLM actually detected one AND NOT doing situation comparison
        # When doing situation_comparison (tiebreak vs rest), situation is used for GROUPING, not filtering
        # DON'T overwrite existing situation detection from _detect_filters_mcp with null/None
        if llm_parse.get('situation') and not llm_parse.get('situation_comparison'):
            print(f"[LLM-PARSE] Updating situation filter from taxonomy '{filters.get('situation')}' to LLM '{llm_parse['situation']}'")
            filters['situation'] = llm_parse['situation']
        elif filters.get('situation'):
            print(f"[LLM-PARSE] Keeping taxonomy-detected situation '{filters['situation']}' (LLM returned: {llm_parse.get('situation')})")
        # If LLM returned null but we already detected one, keep it
        # (Don't let LLM null overwrite good taxonomy detection)
        
        if llm_parse.get('set_filter'):
            filters['set'] = llm_parse['set_filter']
        
        # Skip direction if it's being grouped (e.g., "Crosscourt vs Down the Line")
        if llm_parse.get('direction') and 'direction' not in grouped_dimensions:
            filters['direction'] = llm_parse['direction']
        
        # Handle serve_number (1st serve vs 2nd serve)
        # Skip if it's being grouped (e.g., "1st serve vs 2nd serve win %")
        if llm_parse.get('serve_number') and 'serve_number' not in grouped_dimensions:
            filters['serve_number'] = llm_parse['serve_number']
        
        classification['filters'] = filters
        
        # === GENERIC N-METRIC SUPPORT ===
        # Each metric has its OWN COMPLETE filter set - code doesn't know about specific metrics
        # LLM decides what filters each metric needs
        metrics_parsed = llm_parse.get('metrics_parsed', [])
        
        if metrics_parsed:
            # GENERIC: Each metric has its own complete filter set from LLM
            classification['metrics'] = []
            classification['metric_filters'] = {}  # Store COMPLETE per-metric filters
            
            for i, mp in enumerate(metrics_parsed):
                metric_name = mp.get('metric')
                if not metric_name:
                    continue
                
                # CRITICAL: Map invalid metric names to correct base metrics FIRST
                # LLM might return "ace_percentage" instead of "aces", etc.
                # ALSO map "shots" → "shot_count" (shots = individual shots in rallies, not points)
                metric_name_map = {
                    'shots': 'shot_count',  # CRITICAL: "shots" means count individual shots, not points
                    'shots_hit': 'shot_count',  # LLM sometimes returns this variant
                    'shots_count': 'shot_count',  # LLM sometimes returns this variant (with 's')
                    'total_shots': 'shot_count',  # LLM sometimes returns this variant
                    'shot': 'shot_count',  # Singular form
                    'ace_percentage': 'aces',
                    'ace_pct': 'aces',
                    'winner_percentage': 'winners',
                    'winner_pct': 'winners',
                    'error_percentage': 'unforced_errors',
                    'error_pct': 'unforced_errors',
                    'double_fault_percentage': 'double_faults',
                    'double_fault_pct': 'double_faults',
                    'game_win_percentage': 'service_games_held',
                    'service_game_percentage': 'service_games_held',
                    'service_game_win_percentage': 'service_games_held',
                }
                # CRITICAL: "count" with context="rally" means count individual shots
                # Also: "count" with shot_type filter means count individual shots (even if context is missing)
                context = mp.get('context', '')
                metric_filters_check = mp.get('filters', {})
                if metric_name == 'count':
                    if context == 'rally':
                        print(f"[LLM-PARSE] Mapping 'count' with context='rally' -> 'shot_count' (count individual shots)")
                        metric_name = 'shot_count'
                    elif 'shot_type' in metric_filters_check:
                        # Fallback: if counting by shot_type, it's clearly a shot-level query
                        print(f"[LLM-PARSE] Mapping 'count' with shot_type filter -> 'shot_count' (count individual shots by type)")
                        metric_name = 'shot_count'
                elif metric_name in metric_name_map:
                    print(f"[LLM-PARSE] Mapping '{metric_name}' -> '{metric_name_map[metric_name]}' (use base metric names)")
                    metric_name = metric_name_map[metric_name]
                
                # Generate unique key if same metric appears multiple times with different filters
                # e.g., win_percentage for server vs win_percentage for returner
                metric_key = metric_name
                if metric_key in classification['metric_filters']:
                    metric_key = f"{metric_name}_{i}"
                
                classification['metrics'].append(metric_key)
                
                # Store COMPLETE filter set for this metric (LLM decides everything)
                metric_filters = mp.get('filters', {})
                
                # CRITICAL: Merge top-level filters into metric-specific filters
                # LLM sometimes puts player/role/set at top level but not in metric filters
                # Merge global filters if not already present in metric-specific filters
                top_level_filters = ['player', 'role', 'set', 'situation']
                for filter_key in top_level_filters:
                    top_value = llm_parse.get(filter_key)
                    if top_value and filter_key not in metric_filters:
                        metric_filters[filter_key] = top_value
                        print(f"[LLM-PARSE] Merging top-level '{filter_key}={top_value}' into metric filters")
                
                # CRITICAL: Type coercion for serve_number (LLM might return string)
                if 'serve_number' in metric_filters and metric_filters['serve_number'] is not None:
                    try:
                        metric_filters['serve_number'] = int(metric_filters['serve_number'])
                    except (ValueError, TypeError):
                        pass
                
                # CRITICAL: first_serve_pct should NOT have serve_number filter
                # It needs ALL serve attempts (1st and 2nd) to calculate percentage
                if metric_name == 'first_serve_pct' and 'serve_number' in metric_filters:
                    print(f"[LLM-PARSE] WARNING: Removing serve_number filter from first_serve_pct (needs ALL serves)")
                    del metric_filters['serve_number']
                
                classification['metric_filters'][metric_key] = {
                    'metric': metric_name,  # Original metric name
                    'filters': metric_filters,  # Complete filter set for THIS metric
                    'context': mp.get('context'),  # For synthesis grouping
                }
                
                # Log what filters this metric has
                filter_str = ', '.join(f"{k}={v}" for k, v in metric_filters.items() if v is not None)
                print(f"[LLM-PARSE] Metric '{metric_key}' with filters: {{{filter_str}}}")
            
            # CRITICAL: If metrics_parsed has different shot_type filters, remove global shot_type filter
            # Global filter would conflict with per-metric filters (e.g., one metric for forehand, one for backhand)
            shot_types_in_metrics = set()
            for mp in metrics_parsed:
                metric_filters = mp.get('filters', {})
                if 'shot_type' in metric_filters:
                    shot_types_in_metrics.add(metric_filters['shot_type'])
            
            if len(shot_types_in_metrics) > 1:
                # Multiple different shot_type filters - remove global filter
                if 'shot_type' in filters:
                    removed_shot_type = filters.pop('shot_type')
                    print(f"[LLM-PARSE] Removed global shot_type='{removed_shot_type}' filter (metrics_parsed has multiple shot_type filters: {shot_types_in_metrics})")
                if 'shot_base' in filters:
                    removed_shot_base = filters.pop('shot_base')
                    print(f"[LLM-PARSE] Removed global shot_base='{removed_shot_base}' filter (metrics_parsed has multiple shot_type filters)")
                # Update classification filters after removal
                classification['filters'] = filters
            
            # Check if metrics are related (same context) for narrative synthesis
            contexts = set(mp.get('context') for mp in metrics_parsed if mp.get('context'))
            if len(contexts) == 1 and len(metrics_parsed) > 1:
                classification['synthesize_related_metrics'] = True
                classification['metric_context_type'] = list(contexts)[0]
                print(f"[LLM-PARSE] Related metrics detected (context: {list(contexts)[0]}) - will synthesize in narrative")
        else:
            # UNIFIED: Convert single metric to metrics_parsed format for consistent processing
            # This eliminates duplication and ensures all metrics go through the same logic
            if llm_parse.get('metric') or llm_parse.get('secondary_metric'):
                print(f"[LLM-PARSE] Converting single metric to metrics_parsed format for unified processing")
                metrics_to_add = []
                
                # Primary metric
                if llm_parse.get('metric'):
                    llm_metric = llm_parse['metric']
                    print(f"[LLM-PARSE-DEBUG] Raw metric from LLM: '{llm_metric}' (type: {type(llm_metric).__name__}, repr: {repr(llm_metric)})")
                    
                    # CRITICAL: If metric='count' AND group_by='shot_type', it means count individual shots
                    if llm_metric == 'count' and llm_parse.get('group_by') == 'shot_type':
                        print(f"[LLM-PARSE] Detected 'count' with group_by='shot_type' -> treating as shot_count (count individual shots)")
                        llm_metric = 'shot_count'
                    
                    metrics_to_add.append({
                        'metric': llm_metric,
                        'filters': {},
                        'context': llm_parse.get('context')
                    })
                
                # Secondary metric (if any)
                if llm_parse.get('secondary_metric'):
                    secondary = llm_parse['secondary_metric']
                    metrics_to_add.append({
                        'metric': secondary,
                        'filters': {},
                        'context': llm_parse.get('context')
                    })
                    print(f"[LLM-PARSE] Added secondary metric: {secondary}")
                
                # Convert to metrics_parsed and reprocess through unified path
                llm_parse['metrics_parsed'] = metrics_to_add
                # Recursive call to process through unified metrics_parsed path
                # This ensures all mappings happen in one place
                return self._apply_llm_parse_to_classification(classification, llm_parse, original_question)
        
        # === GENERIC: Transform metrics based on action verbs (create/cause/induce) ===
        # When asking "how many errors did X create/cause/induce", we want the INDUCED version
        # The player mentioned CAUSED the error (opponent made it), not made the error themselves
        if original_question:
            q_lower = original_question.lower()
            # Note: 'force/forced/forcing' removed - too ambiguous with 'forced error'
            action_verbs = ['create', 'created', 'creating', 'cause', 'caused', 'causing',  
                           'induce', 'induced', 'inducing', 'generate', 'generated', 
                           'draw', 'drew', 'drawing', 'elicit', 'elicited']
            matched_verbs = [v for v in action_verbs if v in q_lower]
            has_action_verb = len(matched_verbs) > 0
            
            if has_action_verb:
                # GENERIC: Map error metrics to their induced counterparts
                # The pattern: X_errors → induced_X_errors (player caused opponent's error)
                metric_transforms = {
                    'forced_errors': 'induced_forced_errors',
                    # Add more transforms as needed (e.g., if we track 'induced_unforced_errors' someday)
                }
                
                current_metrics = classification.get('metrics', [])
                transformed = False
                for i, metric in enumerate(current_metrics):
                    if metric in metric_transforms:
                        new_metric = metric_transforms[metric]
                        current_metrics[i] = new_metric
                        transformed = True
                        print(f"[LLM-PARSE] Action verb detected {matched_verbs} - Transforming metric '{metric}' to '{new_metric}'")
                
                # Also transform in metric_filters if using metrics_parsed
                if 'metric_filters' in classification and transformed:
                    for key, mf in classification['metric_filters'].items():
                        old_metric = mf.get('metric')
                        if old_metric in metric_transforms:
                            new_metric = metric_transforms[old_metric]
                            mf['metric'] = new_metric
                            print(f"[LLM-PARSE] Also transformed metric_filter '{key}': '{old_metric}' to '{new_metric}'")
        
        # === GENERIC: Add shot_count for shot-level queries ===
        # When asking about individual shots (not points), need shot_count as denominator
        # Matches the same patterns as rule-based detection in _detect_metrics
        if original_question:
            q_lower = original_question.lower()
            
            # Check for shot-level query patterns (consistent with _detect_metrics line 7849)
            shot_level_patterns = ['how many shot', 'total shot', 'shot count', 
                                  'number of shot', 'percentage of shot', 
                                  'percent of shot', '% of shot']
            is_shot_query = any(phrase in q_lower for phrase in shot_level_patterns)
            
            # Also check for "percentage...shots" pattern (with words in between)
            is_shot_percentage = (('percentage' in q_lower or 'percent' in q_lower or '%' in q_lower) and 
                                 ('shots' in q_lower or 'shot' in q_lower))
            
            if is_shot_query or is_shot_percentage:
                current_metrics = classification.get('metrics', [])
                if 'shot_count' not in current_metrics:
                    current_metrics.append('shot_count')
                    print(f"[LLM-PARSE] Detected shot-level query -> Adding 'shot_count' for denominator")
        
        # Update query category
        if llm_parse.get('query_type'):
            classification['query_category'] = llm_parse['query_type']
        
        # CRITICAL: Override to narrative if metric is vague
        metric_clarity = llm_parse.get('metric_clarity')
        if metric_clarity == 'vague':
            print(f"[LLM-PARSE] Metric clarity is VAGUE -> Overriding to narrative route")
            classification['query_category'] = 'narrative'
        
        # === GENERIC: Detect role from keywords for ANY situation ===
        # This applies to break points, game points, set points, match points, deuce, etc.
        # - save/saved/face/faced/defend = role=server (defending the point/situation)
        # - convert/converted/conversion/create/created/opportunity = role=returner (attacking/capitalizing)
        situation = classification.get('filters', {}).get('situation')
        if situation and not classification.get('filters', {}).get('role'):
            # Get question text for keyword detection
            question_text = original_question or llm_parse.get('actual_question', '') or classification.get('raw_query', '')
            question_lower = question_text.lower() if question_text else ''
            
            # GENERIC: Check for role-indicating keywords in the question
            has_defensive_kw = any(kw in question_lower for kw in ['save', 'saved', 'saving', 'face', 'faced', 'facing', 'defend', 'defended', 'defending'])
            has_offensive_kw = any(kw in question_lower for kw in ['convert', 'converted', 'conversion', 'create', 'created', 'opportunity', 'opportunities', 'capitalize'])
            
            if has_defensive_kw and has_offensive_kw:
                # Both perspectives mentioned - don't set role, show both
                print(f"[LLM-PARSE] Situation '{situation}' with BOTH defensive and offensive keywords - leaving role=None (will show both perspectives)")
            elif has_defensive_kw:
                classification['filters']['role'] = 'server'
                print(f"[LLM-PARSE] Situation '{situation}' with defensive keywords → role='server'")
            elif has_offensive_kw:
                classification['filters']['role'] = 'returner'
                print(f"[LLM-PARSE] Situation '{situation}' with offensive keywords → role='returner'")
            else:
                # No specific keywords - leave role unset (will show the situation regardless of role)
                print(f"[LLM-PARSE] Situation '{situation}' without role keywords - leaving role=None")
        
        # CRITICAL: Questions about "returnable" serves must always go to narrative
        if original_question and 'returnable' in original_question.lower():
            print(f"[LLM-PARSE] Question contains 'returnable' -> Overriding to narrative route")
            classification['query_category'] = 'narrative'
        
        # CRITICAL: Questions asking about "shots" descriptively must go to narrative
        # But quantitative shot queries (ratio, count, percentage) should be analytical
        if original_question:
            q_lower = original_question.lower()
            if (' shot' in q_lower or q_lower.startswith('shot')):
                # Allow analytical if:
                # 1. About winners/errors/outcomes
                # 2. About shot counts/ratios/percentages/rates
                is_quantitative = any(kw in q_lower for kw in [
                    'winner', 'winners', 'error', 'errors', 'winning shot',
                    'ratio', 'percentage', 'percent', 'how many', 'count', 
                    'total', 'number of', 'shot count', 'rate', 'success'
                ])
                if not is_quantitative:
                    print(f"[LLM-PARSE] Question asks about 'shots' descriptively (not quantitative) -> Overriding to narrative route")
                    classification['query_category'] = 'narrative'
        
        # Handle group_by from LLM (e.g., 'sets' for per-set breakdown)
        # CRITICAL: Do NOT apply group_by='player' for overall win% queries
        # When asking "overall win percentage for both players", we want:
        # - Sinner: 142 / 282 total points = 50.4%
        # - Medvedev: 140 / 282 total points = 49.6%
        # NOT per-player branches where each player wins 100% of "their" points
        if llm_parse.get('group_by'):
            llm_group_by = llm_parse['group_by']
            
            # Check if this is an overall percentage query that should NOT be grouped by player
            player_filter = classification.get('filters', {}).get('player', '')
            is_both_players = player_filter and str(player_filter).lower() == 'both'
            metrics = classification.get('metrics', [])
            role_filter = classification.get('filters', {}).get('role')
            
            # Special case: Don't apply group_by='player' for overall win_percentage/points_won queries
            # These queries want match totals, not per-player branches
            overall_pct_metrics = ['win_percentage', 'points_won']
            is_overall_pct_query = is_both_players and any(m in metrics for m in overall_pct_metrics) and not role_filter
            
            if llm_group_by == 'player' and is_overall_pct_query:
                print(f"[LLM-PARSE] Ignoring group_by='player' for overall win% query (want match totals, not per-player branches)")
            else:
                classification['group_by'] = llm_group_by
        
        # Handle secondary_group_by for 2D analysis
        if llm_parse.get('secondary_group_by'):
            classification['secondary_group_by'] = llm_parse['secondary_group_by']
        
        # Handle set comparison
        if llm_parse.get('set_comparison'):
            classification['group_by'] = 'set_groups'
            classification['filters']['set_group_a'] = llm_parse['set_comparison'].get('set_a', [])
            classification['filters']['set_group_b'] = llm_parse['set_comparison'].get('set_b', [])
        
        # Handle situation comparison (tiebreak vs rest of match)
        if llm_parse.get('situation_comparison'):
            classification['group_by'] = 'situation'
            situation_a = llm_parse['situation_comparison'].get('situation_a')
            situation_b = llm_parse['situation_comparison'].get('situation_b')
            # Store for later use in grouping logic
            classification['filters']['situation_group_a'] = situation_a
            classification['filters']['situation_group_b'] = situation_b
            # CRITICAL: Remove any situation filter that was set by _classify_query
            # When doing comparison, situation is for GROUPING, not filtering!
            if 'situation' in classification['filters']:
                del classification['filters']['situation']
                print(f"[LLM-PARSE] Removed 'situation' filter - using for grouping instead")
            print(f"[LLM-PARSE] Set situation comparison: {situation_a} vs {situation_b}")
        
        # Handle role filter (server/returner)
        if llm_parse.get('role'):
            classification['filters']['role'] = llm_parse['role']
        
        # Handle depth filter
        # Skip if it's being grouped (e.g., "Shallow vs Deep returns")
        if llm_parse.get('depth') and 'depth' not in grouped_dimensions:
            classification['filters']['depth'] = llm_parse['depth']
        
        # Handle analysis_type for specialized routing
        if llm_parse.get('analysis_type'):
            classification['analysis_type'] = llm_parse['analysis_type']
        
        # Handle ratio_metrics for ratio analysis
        if llm_parse.get('analysis_type') == 'ratio' and llm_parse.get('metric') and llm_parse.get('secondary_metric'):
            classification['ratio_metrics'] = [llm_parse['metric'], llm_parse['secondary_metric']]
        
        # CRITICAL: Add court_zone filter for net queries
        # Priority: 1) Explicit court_zone from LLM, 2) Infer from net_points_won metric, 3) Infer from domain
        if llm_parse.get('court_zone'):
            classification['filters']['court_zone'] = llm_parse['court_zone']
            print(f"[LLM-PARSE] Set 'court_zone: {llm_parse['court_zone']}' from LLM parse")
            # Remove conflicting shot_type if it's volley (net zone is broader)
            if classification['filters'].get('shot_type') == 'volley':
                del classification['filters']['shot_type']
                print(f"[LLM-PARSE] Removed 'shot_type: volley' because court_zone is set")
        elif llm_parse.get('metric') == 'net_points_won' or classification.get('domain') == 'net':
            classification['filters']['court_zone'] = 'net'
            print(f"[LLM-PARSE] Added 'court_zone: net' filter for net points query")
        
        # Handle chain logic for "Shot A led to Shot B" queries
        if llm_parse.get('chain_logic'):
            classification['filters']['chain_logic'] = llm_parse['chain_logic']
            classification['analysis_type'] = 'chain'
        
        # Handle tertiary_group_by for 3D analysis
        if llm_parse.get('tertiary_group_by'):
            classification['tertiary_group_by'] = llm_parse['tertiary_group_by']
        
        # Handle n_dimensional flag
        if llm_parse.get('n_dimensional'):
            classification['n_dimensional'] = llm_parse['n_dimensional']
        
        # Handle serve_target filter (from LLM)
        # BUT: skip if serve_target is being grouped (for comparisons like "T vs Wide")
        # CRITICAL: Only add serve_target if explicitly mentioned in the question
        # The LLM frequently hallucinates serve targets for general serve/return questions
        # AGGRESSIVE SAFEGUARD: Block serve_target unless explicitly mentioned
        if llm_parse.get('serve_target') and 'serve_target' not in grouped_dimensions:
            # Check if question explicitly mentions serve direction/target
            if original_question:
                q_lower = original_question.lower()
                
                # STRICT CHECK: Only allow serve_target if question EXPLICITLY mentions direction/target
                # Must be clear terms like "to T", "wide", "body", etc.
                serve_target_keywords = [
                    'wide', 'body', 
                    'down the t', 'to the t', 't serve', 'serve t', 'serves to t',
                    'down the middle', 'to the middle', 'to middle',
                    'serve wide', 'serve body', 'serves wide', 'serves body',
                    'served wide', 'served to', 'served to the',
                    'targeting', 'targeted',
                    'center', 'middle'  # Only if clearly about serves
                ]
                
                has_explicit_target = any(kw in q_lower for kw in serve_target_keywords)
                
                # Apply filter ONLY if explicit target is mentioned
                if has_explicit_target:
                    classification['filters']['serve_target'] = llm_parse['serve_target']
                    print(f"[LLM-PARSE] [ALLOWED] Applying serve_target='{llm_parse['serve_target']}' - explicitly mentioned")
                else:
                    print(f"[LLM-PARSE] [BLOCKED] Ignoring LLM's serve_target='{llm_parse['serve_target']}' - "
                          f"NOT explicitly mentioned in question: '{original_question}'")
                    # Explicitly remove if somehow already set
                    classification['filters'].pop('serve_target', None)
            else:
                # No original question to check - be conservative, don't trust LLM
                print(f"[LLM-PARSE] [BLOCKED] Ignoring LLM's serve_target='{llm_parse['serve_target']}' - "
                      f"no original question to validate")
                classification['filters'].pop('serve_target', None)
        
        # Handle court_side filter (from LLM)
        # BUT: skip if court_side is being grouped (for comparisons like "Ad Court vs Deuce Court")
        if llm_parse.get('court_side') and 'court_side' not in grouped_dimensions:
            classification['filters']['court_side'] = llm_parse['court_side']
        
        # Store actual question for answer formatting
        if llm_parse.get('actual_question'):
            classification['actual_question'] = llm_parse['actual_question']
        
        # === POST-PROCESSING: Fix metric hallucinations ===
        # If asking about break points, remove incorrect metrics like 'aces' or 'games_lost'
        if classification['filters'].get('situation') == 'break_point':
            metrics = classification.get('metrics', [])
            # Remove inappropriate metrics that LLM might have hallucinated
            inappropriate_for_bp = ['aces', 'games_lost', 'games_won']
            metrics = [m for m in metrics if m not in inappropriate_for_bp]
            # Default to points_won if we removed everything
            classification['metrics'] = metrics if metrics else ['points_won']
            print(f"[LLM-PARSE] Cleaned metrics for break_point situation: {classification['metrics']}")
        
        # === POST-PROCESSING: Fix first_serve_pct calculation ===
        # First serve percentage = (first serves IN) / (total serve attempts)
        # CRITICAL: We need ALL serve attempts, NOT just serve_number=1 points
        # serve_number=1 = points where first serve went IN
        # serve_number=2 = points where first serve was a FAULT (had to use 2nd serve)
        # So total = serve_number=1 + serve_number=2, count = serve_number=1
        metrics = classification.get('metrics', [])
        
        # CRITICAL: For secondary metrics, preserve serve_number context
        # If asking about "first serve percentage and first serve win percentage",
        # the serve_number filter should be removed for first_serve_pct but KEPT for win_percentage
        # Solution: Store metric-specific filters instead of global filter removal
        classification.setdefault('metric_specific_filters', {})
        
        if 'first_serve_pct' in metrics:
            # Remove serve_target filter (first serve % is global across all targets)
            if classification['filters'].get('serve_target'):
                print(f"[LLM-PARSE] Removing serve_target filter for first_serve_pct (global metric)")
                del classification['filters']['serve_target']
            
            # Remove shot_number if it was incorrectly set (shot_number is rally position, not serve attempt)
            if classification['filters'].get('shot_number'):
                print(f"[LLM-PARSE] Removing shot_number filter for first_serve_pct")
                del classification['filters']['shot_number']
            
            # CRITICAL: Store the serve_number filter before removing it
            # Other metrics (like win_percentage) might need it
            serve_number_filter = classification['filters'].get('serve_number')
            if serve_number_filter:
                print(f"[LLM-PARSE] Storing serve_number={serve_number_filter} for non-first_serve_pct metrics")
                classification['metric_specific_filters']['serve_number'] = serve_number_filter
            
            # Remove serve_number filter for first_serve_pct
            # We need ALL serve attempts (both 1st and 2nd serve points) to calculate the percentage correctly
            # The tracking logic will count serve_number=1 as "in" and everything as "total"
            if classification['filters'].get('serve_number'):
                print(f"[LLM-PARSE] Removing serve_number filter for first_serve_pct (need ALL serve attempts)")
                del classification['filters']['serve_number']
            
            print(f"[LLM-PARSE] first_serve_pct: Will count serve_number=1 as IN / all serves as total")
        
        # === POST-PROCESSING: Fix "break serve" vs "break point" confusion ===
        # CRITICAL: "break points" (situation) vs "breaks of serve" (games) are DIFFERENT!
        # - "break points" = points in break point situation (situation filter)
        # - "breaks", "break serve", "games broken" = games won on opponent's serve (games_lost metric)
        
        # Use original question if available, otherwise fall back to LLM's rephrased version
        question_lower = (original_question or llm_parse.get('actual_question') or '').lower()
        
        # FIRST: Check if this is clearly about break POINTS (situation), not games
        is_break_point_query = 'break point' in question_lower or 'breakpoint' in question_lower or 'break points' in question_lower
        
        # SECOND: Only check for break serve patterns if NOT a break point query
        is_break_serve_query = False
        if not is_break_point_query:
            # These patterns indicate break of serve (games), not break points (situation)
            break_serve_patterns = [
                'break serve', 'break of serve', 'breaks of serve',
                'games broken', 'break.*game', 'game.*break',
                'resulted in break', 'resulted in breaks'
            ]
            # Use regex matching for patterns
            import re
            for pattern in break_serve_patterns:
                if re.search(pattern, question_lower):
                    is_break_serve_query = True
                    print(f"[LLM-PARSE] Detected 'break serve' (games) query: pattern='{pattern}'")
                    break
        
        if is_break_point_query:
            # This is about break POINTS (situation), ensure filters are correct
            print(f"[LLM-PARSE] Detected 'break point' (situation) query")
            # Ensure situation is set correctly if LLM missed it
            if not classification['filters'].get('situation'):
                classification['filters']['situation'] = 'break_point'
                print(f"[LLM-PARSE] Set situation='break_point' (was missing)")
            
            # Ensure metric is appropriate for break points
            metrics = classification.get('metrics', [])
            if 'games_lost' in metrics or 'breaks' in metrics:
                print(f"[LLM-PARSE] Removing game metrics {metrics} for break_point situation")
                metrics = [m for m in metrics if m not in ['games_lost', 'breaks', 'games_won']]
                classification['metrics'] = metrics if metrics else ['points_won']
        elif is_break_serve_query:
            # This is about breaks of serve (games), NOT break points
            # Ensure situation is NOT set to break_point
            if classification['filters'].get('situation') == 'break_point':
                print(f"[LLM-PARSE] Fixing 'break serve' query: removing incorrect situation=break_point")
                classification['filters']['situation'] = None
            # Fix incorrect metric like "breaks_of_serve"
            if 'breaks_of_serve' in metrics:
                metrics.remove('breaks_of_serve')
            if 'games_lost' not in metrics:
                metrics.append('games_lost')
            # Remove points_won/win_percentage if they were incorrectly added
            if 'points_won' in metrics:
                metrics.remove('points_won')
            if 'win_percentage' in metrics and 'games_lost' in metrics:
                # Keep win_percentage only if it's asking for percentage
                if 'percentage' not in question_lower:
                    metrics.remove('win_percentage')
            classification['metrics'] = metrics
            print(f"[LLM-PARSE] Fixed break serve query - using games_lost metric with role=returner")
        
        return classification
    
    def ask_question(self, question: str, top_k: int = None) -> str:
        """
        Main method to ask a question and get an answer.
        
        INTELLIGENT ROUTING:
        1. LLM parses query → structured understanding
        2. Classification uses LLM output + keyword detection
        3. Route by category:
           - 'analytical' → Taxonomy/PBP parsing
           - 'comparative' → Taxonomy + LLM synthesis
           - 'narrative' → NL retrieval + LLM
        """
        print(f"Processing question: {question}")
        
        # STEP 1: LLM PARSES THE QUERY FIRST
        print("[LLM-PARSE] Using LLM to understand query structure...")
        llm_parse = self._llm_parse_query(question)
        
        # STEP 2: TAXONOMY CLASSIFICATION (enhanced by LLM parse)
        classification = self._classify_query(question)
        
        # STEP 3: APPLY LLM PARSE TO CLASSIFICATION
        if llm_parse:
            classification = self._apply_llm_parse_to_classification(classification, llm_parse, original_question=question)
        
        # STEP 3.1: POST-PROCESS PLAYER + ROLE DETECTION
        # Fix cases like "Sinner's return games" where LLM sets player='both' but should be 'Jannik Sinner'
        classification = self._fix_player_role_detection(question, classification)
        
        # STEP 3.25: RESOLVE VAGUE TERMS TO METRICS
        # Convert terms like "effective", "aggressive", "momentum" to concrete metric bundles
        classification = self._resolve_vague_terms(question, classification)
        
        # STEP 3.4: GAME-LEVEL QUERIES NOW USE UNIFIED TREE
        # Games should aggregate naturally from point data through score parsing
        # TODO CRITICAL: Add game/set info to point metadata for proper hierarchical aggregation:
        #   - Parse score from each point header (set-game-point)
        #   - Add 'game_number' and 'set_number' to point metadata
        #   - Track unique (set, game) tuples won by each player during tree traversal
        #   - Aggregate games → sets → match naturally through the tree
        # For now, games_won metric temporarily falls back to game_winners dict
        
        # STEP 3.5: CLASSIFY QUERY COMPLEXITY FOR MODEL SELECTION
        complexity = self._classify_query_complexity(question, classification)
        model_config = self._get_model_config(complexity)
        classification['_complexity'] = complexity  # Store for later use
        classification['_model_config'] = model_config  # Store model config
        
        complexity_labels = {1: "SIMPLE (2.5 Flash)", 2: "MODERATE (3 Flash)", 3: "COMPLEX (3 Flash)"}
        print(f"[MODEL-TIER] Complexity: {complexity_labels.get(complexity, 'UNKNOWN')} | Model: {model_config['model_name']} | Temp: {model_config.get('temperature', 0.7)}")
        
        group_by = classification.get('group_by')
        secondary_group_by = classification.get('secondary_group_by')
        tertiary_group_by = classification.get('tertiary_group_by')
        analysis_type = classification.get('analysis_type', 'count')
        query_category = classification.get('query_category', 'analytical')
        is_n_dimensional = classification.get('n_dimensional', False)
        
        # Count total dimensions (filters with values + groups)
        filters = classification.get('filters', {})
        # Exclude non-restrictive filters: player='both', handedness (default), None values
        active_filters = sum(1 for k, v in filters.items() 
                           if v is not None 
                           and not (k == 'player' and v and v.lower() == 'both')
                           and not (k == 'handedness'))
        group_count = sum(1 for g in [group_by, secondary_group_by, tertiary_group_by] if g)
        total_dimensions = active_filters + group_count
        
        print(f"[ROUTING] Category: {query_category}, Domain: {classification['domain']}, Group: {group_by}")
        print(f"[ROUTING] Analysis Type: {analysis_type}, Secondary Group: {secondary_group_by}")
        print(f"[ROUTING] Filters: {filters}")
        print(f"[ROUTING] Metrics: {classification.get('metrics', [])}")
        print(f"[ROUTING] Total Dimensions: {total_dimensions} (filters: {active_filters}, groups: {group_count})")
        
        # =====================================================================
        # INTELLIGENT ROUTING (LLM-Driven)
        # =====================================================================
        # 1. NARRATIVE → LLM identified as narrative question → Use NL file
        # 2. CHAIN LOGIC → "Shot A → Shot B" patterns → Use chain analysis
        # 3. ANALYTICAL/COMPARATIVE → Taxonomy/PBP data with N-DIM for complex
        # =====================================================================
        
        question_lower = question.lower()
        
        # === 0. NARRATIVE ROUTE → LLM identified as narrative ===
        # Questions about strategy, momentum, patterns, "did X change?", etc.
        # Narrative has access to BOTH NL file AND point-by-point data
        if query_category == 'narrative':
            print("[NARRATIVE] LLM classified as narrative question -> Using NL file + PBP data context")
            answer = self._handle_narrative_query(question, classification, top_k)
            self.last_answer = answer
            self.last_analysis = None  # Narrative queries don't have structured analysis
            return answer
        
        # === 0.5. GAME QUERY ROUTE → "How many games won?" ===
        # Games are aggregated from score transitions, not point counts
        # Route game queries to narrative instead of dedicated game handler
        if self._is_game_query(question):
            print("[GAME-QUERY] Detected game-level query -> Routing to narrative")
            answer = self._handle_narrative_query(question, classification, top_k)
            self.last_answer = answer
            self.last_analysis = None  # Narrative queries don't have structured analysis
            return answer
        
        # === 1. CHAIN LOGIC ANALYSIS → Shot A → Shot B patterns ===
        if analysis_type == 'chain' or filters.get('chain_logic') or 'led to' in question_lower or 'lead to' in question_lower or 'followed by' in question_lower:
            print("[CHAIN] Routing to chain logic analysis (Shot A -> Shot B)")
            try:
                analysis = self._analyze_chain_logic(classification)
                if 'error' not in analysis and analysis.get('total_shot_a', 0) > 0:
                    # Store analysis for external access
                    self.last_analysis = analysis
                    data_response = self._format_chain_logic_analysis(analysis)
                    answer = self._synthesize_with_narrative(question, data_response, classification)
                    self.last_answer = answer
                    return answer
                elif 'error' in analysis:
                    print(f"[CHAIN] Error: {analysis.get('error')}, falling through to taxonomy")
                else:
                    print(f"[CHAIN] No matches found, falling through to taxonomy")
            except Exception as e:
                print(f"[CHAIN] Exception: {e}, falling through to taxonomy")
        
        # === 2. UNIFIED TREE ANALYZER → ALL analytical queries ===
        # ONE PATH for all queries - complexity just affects tree depth
        # Simple query = shallow tree (0-1 filters), Complex = deep tree (3+ filters)
        # NOTE: "TAXONOMY" and "N-DIM" are the SAME system - just different log labels
        print(f"[ANALYSIS] Unified tree analyzer (depth={total_dimensions})")
        try:
            analysis = self._analyze_n_dimensional(classification)
            if 'error' not in analysis:
                # Store analysis for external access
                self.last_analysis = analysis
                data_response = self._format_n_dimensional_results(analysis)
                answer = self._synthesize_with_narrative(question, data_response, classification)
                self.last_answer = answer
                return answer
            else:
                print(f"[TAXONOMY] Analysis error: {analysis.get('error')}, falling through to narrative")
        except Exception as e:
            import traceback
            print(f"[TAXONOMY] Exception: {e}")
            traceback.print_exc()
        
        # === 3. NARRATIVE FALLBACK → Pure summary/story questions ===
        # Also handles any queries that taxonomy couldn't process
        print("[NARRATIVE] Routing to NL retrieval + LLM for narrative synthesis")
        answer = self._handle_narrative_query(question, classification, top_k)
        self.last_answer = answer
        self.last_analysis = None  # Narrative queries don't have structured analysis
        return answer
    
    def get_chunk_info(self) -> Dict:
        """
        Get information about the loaded chunks.
        """
        if not self.chunks:
            return {"error": "No chunks loaded"}
        
        # Count chunks by type and section
        type_counts = {}
        section_counts = {}
        
        for chunk in self.chunks:
            chunk_type = chunk["metadata"]["type"]
            section = chunk["metadata"]["section"]
            
            type_counts[chunk_type] = type_counts.get(chunk_type, 0) + 1
            section_counts[section] = section_counts.get(section, 0) + 1
        
        return {
            "total_chunks": len(self.chunks),
            "chunks_by_type": type_counts,
            "chunks_by_section": section_counts,
            "match_id": self.match_id,
            "llm_provider": self.llm_provider
        }

    def convert_json_to_natural_language(self, match_data: Dict[str, Any]) -> str:
        """
        Convert all JSON data to natural language text that the LLM can easily read and analyze.
        This includes all tables, player names, data descriptions, and context.
        """
        if not match_data:
            return "No match data available."
            
        natural_language = []
        natural_language.append("TENNIS MATCH DATA - NATURAL LANGUAGE FORMAT")
        natural_language.append("=" * 60)
        natural_language.append("")
        natural_language.append("IMPORTANT INSTRUCTIONS FOR DATA ANALYSIS:")
        natural_language.append("")
        natural_language.append("CRITICAL RULE FOR PER-SET / PER-GAME QUESTIONS:")
        natural_language.append("- If asked for PER-SET or PER-GAME breakdowns (e.g., 'unforced errors in each set', 'aces per set', 'serve % across sets'):")
        natural_language.append("  1. Check if the summary tables contain this per-set breakdown")
        natural_language.append("  2. If NOT in tables, you MUST count from the point-by-point narrative")
        natural_language.append("  3. Do NOT say 'data not available' - the point-by-point data contains everything")
        natural_language.append("")
        natural_language.append("GENERAL RULES FOR AGGREGATE TOTALS:")
        natural_language.append("- When answering about MATCH TOTALS (aces, double faults, points won), use only the AUTHORITATIVE TOTALS as the single source of truth")
        natural_language.append("- Use detailed breakdowns only for distributions and patterns, never for recalculating totals")
        natural_language.append("- Breakdowns sum to the authoritative totals - do not add them again")
        natural_language.append("- Summary statistics take precedence over detailed breakdowns for aggregate numbers")
        natural_language.append("")
        
        # Handle the actual JSON structure with matches array
        if 'matches' in match_data and match_data['matches']:
            match = match_data['matches'][0]  # Get the first match
        else:
            # Direct match object passed
            match = match_data
            
        # Get player names from match data first
        self.player1 = match.get('basic', {}).get('player1', 'Player 1')
        self.player2 = match.get('basic', {}).get('player2', 'Player 2')
        player1 = self.player1
        player2 = self.player2
        
        # Add match overview information
        natural_language.extend(self._get_match_overview_text(match))
        natural_language.append("")
        
        # Add all detailed statistics in natural language
        if 'details_tables' in match:
            natural_language.extend(self._convert_details_tables_to_text(match['details_tables'], player1, player2))
        
        # Add details_flat data for shots, shotdir, and netpts (these are not in details_tables)
        if 'details_flat' in match:
            natural_language.extend(self._convert_details_flat_to_text(match['details_flat'], player1, player2))
        
        # Add point-by-point data if available
        if 'point_log' in match:
            natural_language.extend(self._convert_point_log_to_text(match['point_log'], player1, player2))
        elif 'pointlog_rows' in match:
            natural_language.extend(self._convert_point_log_to_text(match['pointlog_rows'], player1, player2))
            
        # Post-process to move rally outcomes to the end for optimal embedding order
        final_text = "\n".join(natural_language)
        final_text = self._move_rally_outcomes_to_end(final_text)
        
        return final_text

    def _move_rally_outcomes_to_end(self, content: str) -> str:
        """Move RALLY OUTCOMES STATISTICS section to the very end for optimal embedding order"""
        
        lines = content.split('\n')
        
        # Find the rally outcomes section
        rally_start = None
        rally_end = None
        
        for i, line in enumerate(lines):
            if "RALLY OUTCOMES STATISTICS:" in line:
                rally_start = i
            elif rally_start is not None and line.strip() and any(keyword in line for keyword in ["STATISTICS:", "NARRATIVE:"]) and "RALLY OUTCOMES" not in line:
                rally_end = i
                break
        
        if rally_start is None:
            # No rally outcomes section found, return as-is
            return content
        
        if rally_end is None:
            rally_end = len(lines)  # If it's the last section
        
        # Extract the rally outcomes section
        rally_section = lines[rally_start:rally_end]
        
        # Remove rally outcomes from its current position
        lines_without_rally = lines[:rally_start] + lines[rally_end:]
        
        # Add rally outcomes at the very end
        lines_without_rally.extend([''] + rally_section)
        
        return '\n'.join(lines_without_rally)

    def _get_match_overview_text(self, match: Dict[str, Any]) -> List[str]:
        """Convert match overview data to natural language"""
        text = []
        text.append("MATCH OVERVIEW:")
        text.append("-" * 20)
        
        # Extract basic match information
        if 'basic' in match:
            basic = match['basic']
            text.append(f"The match was played on {basic.get('date', 'Unknown')} at the {basic.get('tournament', 'Unknown')} tournament.")
            text.append(f"The players were {basic.get('player1', 'Unknown')} and {basic.get('player2', 'Unknown')}.")
            text.append(f"This was a {basic.get('tour', 'Unknown')} match.")
            
            # Try to get match result from multiple possible locations
            match_result = None
            
            # First try: basic["match_result"]
            if 'match_result' in basic and basic['match_result']:
                match_result = basic['match_result']
            # Second try: details_flat["Match Result"]
            elif 'details_flat' in match and 'Match Result' in match['details_flat']:
                match_result = match['details_flat']['Match Result']
                # Clean up the result (remove extra player name prefix like "PegulaJessica Pegula")
                if match_result:
                    # Remove last name prefix (e.g., "PegulaJessica Pegula d. ..." -> "Jessica Pegula d. ...")
                    for player in [basic.get('player1', ''), basic.get('player2', '')]:
                        if player:
                            # Get last name
                            last_name = player.split()[-1] if ' ' in player else player
                            # Check if result starts with last name + full name
                            if match_result.startswith(last_name):
                                # Remove the last name prefix
                                match_result = match_result[len(last_name):]
                                break
            
            if match_result and match_result != "Unknown":
                text.append(f"Final Score: {match_result}")
            else:
                final_score = self._extract_final_score(match)
                if final_score:
                    text.append(f"Final Score: {final_score['winner']} defeated {final_score['loser']} {final_score['score']}")
                else:
                    text.append("Final Score: Unknown")
        
        return text

    def _extract_final_score(self, match: Dict[str, Any]) -> Optional[Dict[str, str]]:
        """Extract final score from point-by-point data"""
        try:
            if 'pointlog_rows' not in match:
                return None
            
            pointlog = match['pointlog_rows']
            if not pointlog:
                return None
            
            # Get the last point to find final score
            last_point = pointlog[-1]
            
            # Extract final sets and games from the last point
            final_sets = last_point.get('sets', '0-0')
            final_games = last_point.get('games', '0-0')
            
            # Parse sets score to determine winner
            sets_parts = final_sets.split('-')
            if len(sets_parts) == 2:
                player1_sets = int(sets_parts[0])  # Player 1's sets
                player2_sets = int(sets_parts[1])  # Player 2's sets
                
                # Get player names
                player1 = match.get('basic', {}).get('player1', 'Player 1')
                player2 = match.get('basic', {}).get('player2', 'Player 2')
                
                if player2_sets > player1_sets:
                    winner = player2
                    loser = player1
                    score = f"{player2_sets}-{player1_sets} in sets ({final_games} in final set)"
                else:
                    winner = player1
                    loser = player2  
                    score = f"{player1_sets}-{player2_sets} in sets ({final_games} in final set)"
                
                return {
                    'winner': winner,
                    'loser': loser,
                    'score': score
                }
            
        except Exception as e:
            print(f"Error extracting final score: {e}")
        
        return None

    def _determine_match_winner(self, match: Dict[str, Any]) -> Optional[str]:
        """Determine match winner from available data sources"""
        try:
            # Method 1: Check for explicit match result in details_tables
            if 'details_tables' in match:
                for table in match['details_tables']:
                    if table.get('name', '').lower() in ['other data', 'match result', 'result']:
                        for row in table.get('rows', []):
                            label = row.get('label', '').lower()
                            if 'match result' in label or 'result' in label:
                                values = row.get('values', [])
                                if values and values[0]:
                                    result_text = values[0]
                                    # Parse format like "Player 2 d. Player 1 6-4 7-5"
                                    if ' d. ' in result_text:
                                        winner = result_text.split(' d. ')[0].strip()
                                        return winner
            
            # Method 2: Check details_flat for match result
            if 'details_flat' in match:
                flat_data = match['details_flat']
                for key, value in flat_data.items():
                    if 'result' in key.lower() and isinstance(value, str) and ' d. ' in value:
                        winner = value.split(' d. ')[0].strip()
                        return winner
            
            return None
        except Exception:
            return None

    def _extract_match_result_with_score(self, match: Dict[str, Any]) -> Optional[str]:
        """Extract match result with score from available data"""
        try:
            # Check details_flat for match result
            if 'details_flat' in match:
                flat_data = match['details_flat']
                for key, value in flat_data.items():
                    if 'result' in key.lower() and isinstance(value, str):
                        # Clean up malformed player names
                        result = value
                        # Fix duplicate name patterns dynamically
                        if self.player1 and f"{self.player1.split()[-1]}{self.player1}" in result:
                            result = result.replace(f"{self.player1.split()[-1]}{self.player1}", self.player1)
                        if self.player2 and f"{self.player2.split()[-1]}{self.player2}" in result:
                            result = result.replace(f"{self.player2.split()[-1]}{self.player2}", self.player2)
                        return result
            
            return None
        except Exception:
            return None

    def _convert_details_tables_to_text(self, details_tables: List[Dict[str, Any]], player1: str, player2: str) -> List[str]:
        """Convert all details tables to natural language text"""
        text = []
        
        for table in details_tables:
            table_name = table.get('name', 'Unknown Table')
            rows = table.get('rows', [])
            
            # Skip shots, shotdir, netpts, serve, return, and keypoints tables since they will be handled by _convert_details_flat_to_text
            if any(keyword in table_name.lower() for keyword in ['shots', 'shotdir', 'netpts', 'serve', 'return', 'keypoints']):
                continue
            
            # Handle special cases
            # Skip 'other data' table since match result is already in overview
            if table_name.lower() == 'other data':
                continue
            elif 'serve' in table_name.lower():
                text.extend(self._convert_serve_table(table_name, rows))
            elif 'return' in table_name.lower():
                text.extend(self._convert_return_table(table_name, rows))
            elif 'keypoints' in table_name.lower():
                text.extend(self._convert_keypoints_table(rows))
            elif 'serveneut' in table_name.lower():
                text.extend(self._convert_serveneut_table(rows))
            elif 'rallyoutcomes' in table_name.lower():
                text.extend(self._convert_rallyoutcomes_table(rows, player1, player2))
            elif 'overview' in table_name.lower():
                text.extend(self._convert_overview_table(rows, player1, player2))
            else:
                # Generic table conversion
                text.extend(self._convert_generic_table(table_name, rows))
            
            text.append("")  # Add spacing between tables
            
        return text

    def _convert_table_row_to_text(self, row: Dict[str, Any], table_name: str, column_headers: List[str]) -> List[str]:
        """Convert a single table row to natural language sentences"""
        text = []
        
        row_label = row.get('label', 'Unknown')
        values = row.get('values', [])
        
        # Determine player from table name or row label
        player = self._get_player_from_table_or_row(table_name, row_label)
        
        # Determine table type (table1 vs table2) based on column headers
        table_type = self._determine_table_type(column_headers)
        
        # Handle different table types
        if 'serveneut' in table_name.lower():
            text.extend(self._convert_serveneut_row_to_sentences(row_label, values, column_headers, player))
        elif 'serve' in table_name.lower():
            text.extend(self._convert_serve_row_to_sentences(row_label, values, column_headers, player, table_type))
        elif 'return' in table_name.lower():
            text.extend(self._convert_return_row_to_sentences(row_label, values, column_headers, player, table_type))
        elif 'keypoints' in table_name.lower():
            text.extend(self._convert_keypoints_row_to_sentences(row_label, values, column_headers, player))
        elif 'shots' in table_name.lower():
            text.extend(self._convert_shots_row_to_sentences(row_label, values, column_headers, player))
        elif 'shotdir' in table_name.lower():
            text.extend(self._convert_shotdir_row_to_sentences(row_label, values, column_headers, player, table_type))
        elif 'netpts' in table_name.lower():
            text.extend(self._convert_netpts_row_to_sentences(row_label, values, column_headers, player))
        elif 'rallyoutcomes' in table_name.lower():
            text.extend(self._convert_rallyoutcomes_row_to_sentences(row_label, values, column_headers))
        elif 'overview' in table_name.lower():
            text.extend(self._convert_overview_row_to_sentences(row_label, values, column_headers))
        else:
            # Generic conversion for unknown table types
            text.extend(self._convert_generic_row_to_sentences(row_label, values, column_headers, table_name))
            
        return text

    def _get_player_from_table_or_row(self, table_name: str, row_label: str) -> str:
        """Determine player name from table name or row label"""
        if 'serve1' in table_name or 'return1' in table_name or 'shots1' in table_name or 'shotdir1' in table_name or 'netpts1' in table_name:
            return self.player1 if self.player1 else "Player 1"
        elif 'serve2' in table_name or 'return2' in table_name or 'shots2' in table_name or 'shotdir2' in table_name or 'netpts2' in table_name:
            return self.player2 if self.player2 else "Player 2"
        else:
            # Try to extract player initials from row_label dynamically
            if self.player1 and self.player2:
                player1_initials = ''.join([word[0] for word in self.player1.split()]).upper()
                player2_initials = ''.join([word[0] for word in self.player2.split()]).upper()
                if player1_initials in row_label:
                    return self.player1
                elif player2_initials in row_label:
                    return self.player2
            return "Unknown Player"

    def _determine_table_type(self, column_headers: List[str]) -> str:
        """Determine if this is table1 or table2 based on column headers"""
        # For serves: table1 has "Total: Pts", table2 has "1st: Pts" and "2nd: Pts"
        if "Total: Pts" in column_headers:
            return "table1"
        elif "1st: Pts" in column_headers and "2nd: Pts" in column_headers:
            return "table2"
        
        # For returns: table1 has outcome columns, table2 has depth columns
        return_table1_specific = ["Pts", "Total: Pts", "PtsW----%", "RtbleW--%", "inPlay--%", "inPlayW-%", "Wnr-----%", "AvgRally"]
        return_table2_specific = ["Shlw----%", "Deep----%", "V Deep--%", "UFE-----%", "net-----%", "deep----%", "wide----%", "wide&deep"]
        
        # Check for return table2 first (more specific columns)
        if any(col in column_headers for col in return_table2_specific):
            return "table2"
        elif any(col in column_headers for col in return_table1_specific):
            return "table1"
        
        # Default to table1
        return "table1"

    def _convert_shot_abbreviations(self, shot_type: str) -> str:
        """Convert shot type abbreviations to proper descriptions"""
        shot_type = shot_type.lower()
        
        # Replace common abbreviations
        if shot_type.startswith("fh "):
            shot_type = shot_type.replace("fh ", "forehand ")
        elif shot_type.startswith("bh "):
            shot_type = shot_type.replace("bh ", "backhand ")
        
        # Handle specific shot types
        if "gs (top/flt/slc)" in shot_type:
            shot_type = shot_type.replace("gs (top/flt/slc)", "groundstrokes with topspin, flat, or slice")
        elif "(top/flt)" in shot_type:
            shot_type = shot_type.replace("(top/flt)", "with topspin or flat")
        elif "gs" in shot_type:
            shot_type = shot_type.replace("gs", "groundstrokes")
        elif "lob" in shot_type:
            shot_type = shot_type.replace("lob", "lobs")
        elif "drop shot" in shot_type:
            shot_type = shot_type.replace("drop shot", "drop shots")
        elif "slice/chip" in shot_type:
            shot_type = shot_type.replace("slice/chip", "slice or chip shots")
        elif "swinging volley" in shot_type:
            shot_type = shot_type.replace("swinging volley", "swinging volleys")
        elif "volley" in shot_type:
            shot_type = shot_type.replace("volley", "volleys")
        
        return shot_type

    def _convert_shots_row_to_sentences(self, row_label: str, values: List[str], column_headers: List[str], player: str) -> List[str]:
        """Convert shot statistics row to natural language sentences"""
        sentences = []
        
        # Handle different shot row types
        if "Total" in row_label:
            context = f"{player} hit shots"
        elif "Forehand side" in row_label:
            context = f"{player} hit forehand shots"
        elif "Backhand side" in row_label:
            context = f"{player} hit backhand shots"
        elif "FH GS (top/flt/slc)" in row_label:
            context = f"{player} hit forehand groundstrokes with topspin or flat shots or slice shots"
        elif "BH GS (top/flt/slc)" in row_label:
            context = f"{player} hit backhand groundstrokes with topspin or flat shots or slice shots"
        elif "Groundstrokes (top/flt)" in row_label:
            context = f"{player} hit groundstrokes with topspin or flat shots"
        elif "Baseline shots" in row_label:
            context = f"{player} hit baseline shots"
        elif "Net shots" in row_label:
            context = f"{player} hit shots at the net"
        elif "Dropshots" in row_label:
            context = f"{player} hit dropshots"
        elif "Lobs" in row_label:
            context = f"{player} hit lobs"
        elif "Volleys" in row_label:
            context = f"{player} hit volleys"
        elif "Swinging volleys" in row_label:
            context = f"{player} hit swinging volleys"
        elif "Forehands (top/flt)" in row_label:
            context = f"{player} hit forehand topspin or flat shots"
        elif "Backhands (top/flt)" in row_label:
            context = f"{player} hit backhand topspin or flat shots"
        elif "FH slice/chip" in row_label:
            context = f"{player} hit forehand slice or chip shots"
        elif "BH slice/chip" in row_label:
            context = f"{player} hit backhand slice or chip shots"
        elif "BH drop shot" in row_label:
            context = f"{player} hit backhand drop shots"
        elif "BH lob" in row_label:
            context = f"{player} hit backhand lobs"
        elif "FH volley" in row_label:
            context = f"{player} hit forehand volleys"
        elif "FH swinging volley" in row_label:
            context = f"{player} hit forehand swinging volleys"
        else:
            context = f"{player} hit shots"
        
        # Convert each value to a sentence with better formatting
        for i, value in enumerate(values):
            if i < len(column_headers) and value and value != "0":
                header = column_headers[i]
                
                if header == "Total":
                    sentences.append(f"{context} {value} times.")
                elif header == "Winner--%":
                     # Extract the number and percentage
                     if "(" in value and ")" in value:
                         number = value.split("(")[0].strip()
                         percentage = value.split("(")[1].split(")")[0].replace("%", "")
                         if "Total" in row_label:
                             sentences.append(f"{player} hit {number} winners, which represents {percentage}% of all shots hit by {player}.")
                         elif "Forehand side" in row_label:
                             sentences.append(f"{player} hit {number} forehand winners, which represents {percentage}% of all forehand shots hit by {player}.")
                         elif "Backhand side" in row_label:
                             sentences.append(f"{player} hit {number} backhand winners, which represents {percentage}% of all backhand shots hit by {player}.")
                         else:
                             # Use the actual row label instead of generic "this shot type"
                             shot_type = self._convert_shot_abbreviations(row_label)
                             sentences.append(f"{player} hit {number} winners with {shot_type}, which represents {percentage}% of all {shot_type} hit by {player}.")
                     else:
                         sentences.append(f"{player} hit {value} winners.")
                elif header == "UnfErr--%":
                     # Extract the number and percentage
                     if "(" in value and ")" in value:
                         number = value.split("(")[0].strip()
                         percentage = value.split("(")[1].split(")")[0].replace("%", "")
                         if "Total" in row_label:
                             sentences.append(f"{player} made {number} unforced errors, which represents {percentage}% of all shots hit by {player}.")
                         elif "Forehand side" in row_label:
                             sentences.append(f"{player} made {number} forehand unforced errors, which represents {percentage}% of all forehand shots hit by {player}.")
                         elif "Backhand side" in row_label:
                             sentences.append(f"{player} made {number} backhand unforced errors, which represents {percentage}% of all backhand shots hit by {player}.")
                         else:
                             # Use the actual row label instead of generic "this shot type"
                             shot_type = self._convert_shot_abbreviations(row_label)
                             sentences.append(f"{player} made {number} unforced errors with {shot_type}, which represents {percentage}% of all {shot_type} hit by {player}.")
                     else:
                         sentences.append(f"{player} made {value} unforced errors.")
                elif header == "IndFcd--%":
                     # Extract the number and percentage
                     if "(" in value and ")" in value:
                         number = value.split("(")[0].strip()
                         percentage = value.split("(")[1].split(")")[0].replace("%", "")
                         if "Total" in row_label:
                             sentences.append(f"{player} made {number} induced forced errors, which represents {percentage}% of all shots hit by {player}.")
                         elif "Forehand side" in row_label:
                             sentences.append(f"{player} made {number} induced forced errors with forehand shots, which represents {percentage}% of all forehand shots hit by {player}.")
                         elif "Backhand side" in row_label:
                             sentences.append(f"{player} made {number} induced forced errors with backhand shots, which represents {percentage}% of all backhand shots hit by {player}.")
                         else:
                             # Use the actual row label instead of generic "this shot type"
                             shot_type = self._convert_shot_abbreviations(row_label)
                             sentences.append(f"{player} made {number} induced forced errors with {shot_type}, which represents {percentage}% of all {shot_type} hit by {player}.")
                     else:
                         sentences.append(f"{player} made {value} induced forced errors.")
                elif header == "PtEnd---%":
                     # Extract the number and percentage
                     if "(" in value and ")" in value:
                         number = value.split("(")[0].strip()
                         percentage = value.split("(")[1].split(")")[0].replace("%", "")
                         if "Total" in row_label:
                             sentences.append(f"{player} ended {number} points with shots, which represents {percentage}% of all shots hit by {player}.")
                         elif "Forehand side" in row_label:
                             sentences.append(f"{player} ended {number} points with forehand shots, which represents {percentage}% of all forehand shots hit by {player}.")
                         elif "Backhand side" in row_label:
                             sentences.append(f"{player} ended {number} points with backhand shots, which represents {percentage}% of all backhand shots hit by {player}.")
                         else:
                             # Use the actual row label instead of generic "this shot type"
                             shot_type = self._convert_shot_abbreviations(row_label)
                             sentences.append(f"{player} ended {number} points with {shot_type}, which represents {percentage}% of all {shot_type} hit by {player}.")
                     else:
                         sentences.append(f"{player} ended {value} points with shots.")
                elif header == "SvReturn":
                     # Extract the number and percentage
                     if "(" in value and ")" in value:
                         number = value.split("(")[0].strip()
                         percentage = value.split("(")[1].split(")")[0].replace("%", "")
                         if "Total" in row_label:
                             sentences.append(f"{player} hit {number} serve returns, which represents {percentage}% of all shots hit by {player}.")
                         elif "Forehand side" in row_label:
                             sentences.append(f"{player} hit {number} forehand serve returns, which represents {percentage}% of all forehand shots hit by {player}.")
                         elif "Backhand side" in row_label:
                             sentences.append(f"{player} hit {number} backhand serve returns, which represents {percentage}% of all backhand shots hit by {player}.")
                         else:
                             # Use the actual row label instead of generic "this shot type"
                             shot_type = self._convert_shot_abbreviations(row_label)
                             sentences.append(f"{player} hit {number} serve returns with {shot_type}, which represents {percentage}% of all {shot_type} hit by {player}.")
                     else:
                         sentences.append(f"{player} hit {value} serve returns.")
                elif header == "inPtsW--%":
                     # Extract the number and percentage
                     if "(" in value and ")" in value:
                         number = value.split("(")[0].strip()
                         percentage = value.split("(")[1].split(")")[0].replace("%", "")
                         if "Total" in row_label:
                             sentences.append(f"{player} won {number} points with shots, which represents {percentage}% of all shots hit by {player}.")
                         elif "Forehand side" in row_label:
                             sentences.append(f"{player} won {number} points with forehand shots, which represents {percentage}% of all forehand shots hit by {player}.")
                         elif "Backhand side" in row_label:
                             sentences.append(f"{player} won {number} points with backhand shots, which represents {percentage}% of all backhand shots hit by {player}.")
                         else:
                             # Use the actual row label instead of generic "this shot type"
                             shot_type = self._convert_shot_abbreviations(row_label)
                             sentences.append(f"{player} won {number} points with {shot_type}, which represents {percentage}% of all {shot_type} hit by {player}.")
                     else:
                         sentences.append(f"{player} won {value} points with shots.")
                elif header == "inPtsL--%":
                     # Extract the number and percentage
                     if "(" in value and ")" in value:
                         number = value.split("(")[0].strip()
                         percentage = value.split("(")[1].split(")")[0].replace("%", "")
                         if "Total" in row_label:
                             sentences.append(f"{player} lost {number} points with shots, which represents {percentage}% of all shots hit by {player}.")
                         elif "Forehand side" in row_label:
                             sentences.append(f"{player} lost {number} points with forehand shots, which represents {percentage}% of all forehand shots hit by {player}.")
                         elif "Backhand side" in row_label:
                             sentences.append(f"{player} lost {number} points with backhand shots, which represents {percentage}% of all backhand shots hit by {player}.")
                         else:
                             # Use the actual row label instead of generic "this shot type"
                             shot_type = self._convert_shot_abbreviations(row_label)
                             sentences.append(f"{player} lost {number} points with {shot_type}, which represents {percentage}% of all {shot_type} hit by {player}.")
                     else:
                         sentences.append(f"{player} lost {value} points with shots.")
                else:
                    # Generic fallback for any other headers
                    sentences.append(f"{context} and {header}: {value}.")
        
        return sentences

    def _convert_shotdir_row_to_sentences(self, row_label: str, values: List[str], column_headers: List[str], player: str, table_type: str = "table1") -> List[str]:
        """Convert shot direction statistics row to natural language sentences"""
        sentences = []
        
        # Handle different shot direction row types
        if "Total" in row_label:
            context = f"{player} hit shots in different directions"
        elif "Forehand" in row_label:
            context = f"{player} hit forehand shots"
        elif "Backhand" in row_label:
            context = f"{player} hit backhand shots"
        elif "BH slice" in row_label:
            context = f"{player} hit backhand slice shots"
        else:
            context = f"{player} hit shots in different directions"
        
        # Convert each value to a sentence with better formatting
        for i, value in enumerate(values):
            if i < len(column_headers) and value and value != "0":
                header = column_headers[i]
                
                # Handle table1 structure (direction breakdowns)
                if table_type == "table1":
                    if "Total" in row_label:
                        # Handle Total row - process each column as direction breakdown
                        if header == "Crosscourt":
                            # Extract just the number from percentage format
                            if "(" in value and ")" in value:
                                number = value.split("(")[0].strip()
                                sentences.append(f"{player} hit {number} crosscourt shots.")
                            else:
                                sentences.append(f"{player} hit {value} crosscourt shots.")
                        elif header == "Down middle":
                            # Extract just the number from percentage format
                            if "(" in value and ")" in value:
                                number = value.split("(")[0].strip()
                                sentences.append(f"{player} hit {number} down-the-middle shots.")
                            else:
                                sentences.append(f"{player} hit {value} down-the-middle shots.")
                        elif header == "Down the line":
                            # Extract just the number from percentage format
                            if "(" in value and ")" in value:
                                number = value.split("(")[0].strip()
                                sentences.append(f"{player} hit {number} down-the-line shots.")
                            else:
                                sentences.append(f"{player} hit {value} down-the-line shots.")
                        elif header == "Inside-out":
                            # Extract just the number from percentage format
                            if "(" in value and ")" in value:
                                number = value.split("(")[0].strip()
                                sentences.append(f"{player} hit {number} inside-out shots.")
                            else:
                                sentences.append(f"{player} hit {value} inside-out shots.")
                        elif header == "Inside-in":
                            # Extract just the number from percentage format
                            if "(" in value and ")" in value:
                                number = value.split("(")[0].strip()
                                sentences.append(f"{player} hit {number} inside-in shots.")
                            else:
                                sentences.append(f"{player} hit {value} inside-in shots.")
                        else:
                            # Generic fallback for table1 Total row
                            sentences.append(f"{context} and {header}: {value}.")
                    else:
                        # Handle other table1 rows (Forehand, Backhand, BH slice) - sum up the values
                        if "(" in value and ")" in value:
                            number = value.split("(")[0].strip()
                            if "Forehand" in row_label:
                                sentences.append(f"{player} hit {number} forehand shots.")
                            elif "Backhand" in row_label:
                                sentences.append(f"{player} hit {number} backhand shots.")
                            elif "BH slice" in row_label:
                                sentences.append(f"{player} hit {number} backhand slice shots.")
                            else:
                                sentences.append(f"{context} and {header}: {number}.")
                        else:
                            if "Forehand" in row_label:
                                sentences.append(f"{player} hit {value} forehand shots.")
                            elif "Backhand" in row_label:
                                sentences.append(f"{player} hit {value} backhand shots.")
                            elif "BH slice" in row_label:
                                sentences.append(f"{player} hit {value} backhand slice shots.")
                            else:
                                sentences.append(f"{context} and {header}: {value}.")
                    continue  # Skip the table2 processing for table1
                
                # Handle table2 structure (outcome breakdowns)
                if table_type == "table2":
                    if header == "Total":
                        if "FH crosscourt" in row_label:
                            sentences.append(f"{player} hit {value} forehand crosscourt shots.")
                        elif "FH down middle" in row_label:
                            sentences.append(f"{player} hit {value} forehand down-the-middle shots.")
                        elif "FH down the line" in row_label:
                            sentences.append(f"{player} hit {value} forehand down-the-line shots.")
                        elif "FH inside-out" in row_label:
                            sentences.append(f"{player} hit {value} forehand inside-out shots.")
                        elif "BH crosscourt" in row_label:
                            sentences.append(f"{player} hit {value} backhand crosscourt shots.")
                        elif "BH down middle" in row_label:
                            sentences.append(f"{player} hit {value} backhand down-the-middle shots.")
                        elif "BH down the line" in row_label:
                            sentences.append(f"{player} hit {value} backhand down-the-line shots.")
                        elif "BH inside-out" in row_label:
                            sentences.append(f"{player} hit {value} backhand inside-out shots.")
                        else:
                            sentences.append(f"{player} hit {value} {row_label.lower().replace('down the line', 'down-the-line')} shots.")
                    elif header == "PtEnding":
                        if "(" in value and ")" in value:
                            number = value.split("(")[0].strip()
                            percentage = value.split("(")[1].split(")")[0]
                            sentences.append(f"{player} ended {number} points with {row_label.lower().replace('down the line', 'down-the-line')} shots, or {percentage} of {row_label.lower().replace('down the line', 'down-the-line')} shots ended points.")
                        else:
                            sentences.append(f"{player} ended {value} points with {row_label.lower()} shots.")
                    elif header == "Winner":
                        if "(" in value and ")" in value:
                            number = value.split("(")[0].strip()
                            percentage = value.split("(")[1].split(")")[0]
                            sentences.append(f"{player} hit {number} {row_label.lower().replace('down the line', 'down-the-line')} winners, or {percentage} of {row_label.lower().replace('down the line', 'down-the-line')} shots were winners.")
                        else:
                            sentences.append(f"{player} hit {value} {row_label.lower()} winners.")
                    elif header == "InduceFcd":
                        if "(" in value and ")" in value:
                            number = value.split("(")[0].strip()
                            percentage = value.split("(")[1].split(")")[0]
                            sentences.append(f"{player} induced {number} forced errors with {row_label.lower().replace('down the line', 'down-the-line')} shots, or {percentage} of {row_label.lower().replace('down the line', 'down-the-line')} shots induced forced errors.")
                        else:
                            sentences.append(f"{player} induced {value} forced errors with {row_label.lower()} shots.")
                    elif header == "UnfErr":
                        if "(" in value and ")" in value:
                            number = value.split("(")[0].strip()
                            percentage = value.split("(")[1].split(")")[0]
                            sentences.append(f"{player} had {number} unforced errors with {row_label.lower().replace('down the line', 'down-the-line')} shots, or {percentage} of {row_label.lower().replace('down the line', 'down-the-line')} shots were unforced errors.")
                        else:
                            sentences.append(f"{player} had {value} unforced errors with {row_label.lower()} shots.")
                    elif header == "inPtsWon":
                        if "(" in value and ")" in value:
                            number = value.split("(")[0].strip()
                            percentage = value.split("(")[1].split(")")[0]
                            sentences.append(f"{player} won {number} points when hitting {row_label.lower().replace('down the line', 'down-the-line')} shots, or {percentage} success rate with {row_label.lower().replace('down the line', 'down-the-line')} shots.")
                        else:
                            sentences.append(f"{player} won {value} points when hitting {row_label.lower()} shots.")
                    elif header == "inPtsLost":
                        if "(" in value and ")" in value:
                            number = value.split("(")[0].strip()
                            percentage = value.split("(")[1].split(")")[0]
                            sentences.append(f"{player} lost {number} points when hitting {row_label.lower().replace('down the line', 'down-the-line')} shots, or {percentage} failure rate with {row_label.lower().replace('down the line', 'down-the-line')} shots.")
                        else:
                            sentences.append(f"{player} lost {value} points when hitting {row_label.lower()} shots.")
                    else:
                        # Generic fallback for table2
                        sentences.append(f"{context} and {header}: {value}.")
                    continue  # Skip the existing table2 processing
                
                # Generic fallback for any other cases
                sentences.append(f"{context} and {header}: {value}.")
        
        return sentences

    def _convert_serve_row_to_sentences(self, row_label: str, values: List[str], column_headers: List[str], player: str, table_type: str) -> List[str]:
        """Convert serve statistics row to natural language sentences"""
        sentences = []
        
        # Handle different serve row types
        if "Total" in row_label:
            context = f"{player} served"
        elif "1st Serve" in row_label:
            context = f"{player} hit first serves"
        elif "2nd Serve" in row_label:
            context = f"{player} hit second serves"
        else:
            context = f"{player} served"
        
        # Convert each value to a sentence
        for i, value in enumerate(values):
            if i < len(column_headers) and value and value != "0":
                header = column_headers[i]
                
                if header == "Total":
                    sentences.append(f"{context} {value} times.")
                elif header == "Pts":
                    sentences.append(f"{context} and won {value} points.")
                elif header == "PtsW----%":
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0]
                        sentences.append(f"{context} and won {number} points, or {percentage} of serves were won.")
                    else:
                        sentences.append(f"{context} and won {value} points.")
                elif header == "ACE":
                    sentences.append(f"{context} and hit {value} aces.")
                elif header == "DF":
                    sentences.append(f"{context} and made {value} double faults.")
                else:
                    sentences.append(f"{context} and {header}: {value}.")
        
        return sentences

    def _convert_return_row_to_sentences(self, row_label: str, values: List[str], column_headers: List[str], player: str, table_type: str) -> List[str]:
        """Convert return statistics row to natural language sentences"""
        sentences = []
        
        # Handle different return row types
        if "Total" in row_label:
            context = f"{player} returned"
        elif "1st Serve Return" in row_label:
            context = f"{player} returned first serves"
        elif "2nd Serve Return" in row_label:
            context = f"{player} returned second serves"
        else:
            context = f"{player} returned"
        
        # Convert each value to a sentence
        for i, value in enumerate(values):
            if i < len(column_headers) and value and value != "0":
                header = column_headers[i]
                
                if header == "Total":
                    sentences.append(f"{context} {value} times.")
                elif header == "Pts":
                    sentences.append(f"{context} and won {value} points.")
                elif header == "PtsW----%":
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0]
                        sentences.append(f"{context} and won {number} points, or {percentage} of returns were won.")
                    else:
                        sentences.append(f"{context} and won {value} points.")
                else:
                    sentences.append(f"{context} and {header}: {value}.")
        
        return sentences

    def _convert_keypoints_row_to_sentences(self, row_label: str, values: List[str], column_headers: List[str], player: str) -> List[str]:
        """Convert key points statistics row to natural language sentences"""
        sentences = []
        
        # Handle different key points row types
        if "Break Points" in row_label:
            context = f"{player} faced break points"
        elif "Set Points" in row_label:
            context = f"{player} faced set points"
        elif "Match Points" in row_label:
            context = f"{player} faced match points"
        else:
            context = f"{player} played key points"
        
        # Convert each value to a sentence
        for i, value in enumerate(values):
            if i < len(column_headers) and value and value != "0":
                header = column_headers[i]
                
                if header == "OPP":
                    sentences.append(f"{context} {value} times.")
                elif header == "CONV":
                    sentences.append(f"{context} and converted {value}.")
                elif header == "CONV--%":
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{context} and converted {number}, or {percentage} conversion rate.")
                    else:
                        sentences.append(f"{context} and converted {value}.")
                else:
                    sentences.append(f"{context} and {header}: {value}.")
        
        return sentences

    def _convert_serveneut_row_to_sentences(self, row_label: str, values: List[str], column_headers: List[str], player: str) -> List[str]:
        """Convert serve neutral rally distribution row to natural language sentences"""
        sentences = []
        
        # Use the player parameter that's already passed in
        # If we need to determine player from row_label, do it here
        if self.player1 and self.player2:
            player1_initials = ''.join([word[0] for word in self.player1.split()]).upper()
            player2_initials = ''.join([word[0] for word in self.player2.split()]).upper()
            if player1_initials in row_label:
                player = self.player1
            elif player2_initials in row_label:
                player = self.player2
        
        # Determine serve type context
        if "1st Serve" in row_label:
            serve_type = "first serve"
        elif "2nd Serve" in row_label:
            serve_type = "second serve"
        else:
            serve_type = "serve"
        
        for i, value in enumerate(values):
            if i < len(column_headers) and value and value != "0" and value != "-":
                header = column_headers[i]
                
                if header == "Pts":
                    sentences.append(f"{player} served {value} {serve_type}s.")
                elif header == "1+ shots":
                    if "%" in value:
                        percentage = value.replace("%", "")
                        sentences.append(f"{player} won {percentage}% of {serve_type} points overall.")
                    else:
                        sentences.append(f"{player} won {value} {serve_type} points overall.")
                elif header == "2+":
                    if "%" in value:
                        percentage = value.replace("%", "")
                        sentences.append(f"{player} won {percentage}% of {serve_type} points when rallies reached 2 or more shots.")
                    else:
                        sentences.append(f"{player} won {value} {serve_type} points when rallies reached 2 or more shots.")
                elif header == "3+":
                    if "%" in value:
                        percentage = value.replace("%", "")
                        sentences.append(f"{player} won {percentage}% of {serve_type} points when rallies reached 3 or more shots.")
                    else:
                        sentences.append(f"{player} won {value} {serve_type} points when rallies reached 3 or more shots.")
                elif header == "4+":
                    if "%" in value:
                        percentage = value.replace("%", "")
                        sentences.append(f"{player} won {percentage}% of {serve_type} points when rallies reached 4 or more shots.")
                    else:
                        sentences.append(f"{player} won {value} {serve_type} points when rallies reached 4 or more shots.")
                elif header == "5+":
                    if "%" in value:
                        percentage = value.replace("%", "")
                        sentences.append(f"{player} won {percentage}% of {serve_type} points when rallies reached 5 or more shots.")
                    else:
                        sentences.append(f"{player} won {value} {serve_type} points when rallies reached 5 or more shots.")
                elif header == "6+":
                    if "%" in value:
                        percentage = value.replace("%", "")
                        sentences.append(f"{player} won {percentage}% of {serve_type} points when rallies reached 6 or more shots.")
                    else:
                        sentences.append(f"{player} won {value} {serve_type} points when rallies reached 6 or more shots.")
                elif header == "7+":
                    if "%" in value:
                        percentage = value.replace("%", "")
                        sentences.append(f"{player} won {percentage}% of {serve_type} points when rallies reached 7 or more shots.")
                    else:
                        sentences.append(f"{player} won {value} {serve_type} points when rallies reached 7 or more shots.")
                elif header == "8+":
                    if "%" in value:
                        percentage = value.replace("%", "")
                        sentences.append(f"{player} won {percentage}% of {serve_type} points when rallies reached 8 or more shots.")
                    else:
                        sentences.append(f"{player} won {value} {serve_type} points when rallies reached 8 or more shots.")
                elif header == "9+":
                    if "%" in value:
                        percentage = value.replace("%", "")
                        sentences.append(f"{player} won {percentage}% of {serve_type} points when rallies reached 9 or more shots.")
                    else:
                        sentences.append(f"{player} won {value} {serve_type} points when rallies reached 9 or more shots.")
                elif header == "10+":
                    if "%" in value:
                        percentage = value.replace("%", "")
                        sentences.append(f"{player} won {percentage}% of {serve_type} points when rallies reached 10 or more shots.")
                    else:
                        sentences.append(f"{player} won {value} {serve_type} points when rallies reached 10 or more shots.")
        
        return sentences

    def _convert_rallyoutcomes_row_to_sentences(self, row_label: str, values: List[str], column_headers: List[str]) -> List[str]:
        """Convert rally outcomes statistics row to natural language sentences"""
        sentences = []
        
        # Handle different rally outcome row types
        if "Total" in row_label:
            context = "Rally outcomes"
        elif "Short" in row_label:
            context = "Short rallies (1-3 shots)"
        elif "Medium" in row_label:
            context = "Medium rallies (4-6 shots)"
        elif "Long" in row_label:
            context = "Long rallies (7+ shots)"
        else:
            context = "Rally outcomes"
        
        # Convert each value to a sentence
        for i, value in enumerate(values):
            if i < len(column_headers) and value and value != "0":
                header = column_headers[i]
                
                if header == "Total":
                    sentences.append(f"{context} occurred {value} times.")
                elif header == "Pts":
                    sentences.append(f"{context} and {value} points were played.")
                else:
                    sentences.append(f"{context} and {header}: {value}.")
        
        return sentences

    def _convert_overview_row_to_sentences(self, row_label: str, values: List[str], column_headers: List[str]) -> List[str]:
        """Convert overview statistics row to natural language sentences"""
        sentences = []
        
        # Handle different overview row types
        if "A%" in row_label:
            context = "Ace percentage"
        elif "DF%" in row_label:
            context = "Double fault percentage"
        elif "1stIn" in row_label:
            context = "First serve in percentage"
        elif "1st%" in row_label:
            context = "First serve won percentage"
        elif "2nd%" in row_label:
            context = "Second serve won percentage"
        elif "BPSaved" in row_label:
            context = "Break points saved"
        elif "RPW%" in row_label:
            context = "Return points won percentage"
        elif "Winners" in row_label:
            context = "Winners"
        elif "UFE" in row_label:
            context = "Unforced errors"
        else:
            context = "Overview statistic"
        
        # Convert each value to a sentence
        for i, value in enumerate(values):
            if i < len(column_headers) and value and value != "0":
                header = column_headers[i]
                
                if header == "A%":
                    sentences.append(f"{context} was {value}.")
                elif header == "DF%":
                    sentences.append(f"{context} was {value}.")
                elif header == "1stIn":
                    sentences.append(f"{context} was {value}.")
                elif header == "1st%":
                    sentences.append(f"{context} was {value}.")
                elif header == "2nd%":
                    sentences.append(f"{context} was {value}.")
                elif header == "BPSaved":
                    sentences.append(f"{context} were {value}.")
                elif header == "RPW%":
                    sentences.append(f"{context} was {value}.")
                elif header == "Winners":
                    sentences.append(f"{context} were {value}.")
                elif header == "UFE":
                    sentences.append(f"{context} were {value}.")
                else:
                    sentences.append(f"{context} and {header}: {value}.")
        
        return sentences

    def _convert_generic_row_to_sentences(self, row_label: str, values: List[str], column_headers: List[str], table_name: str) -> List[str]:
        """Convert generic row to natural language sentences"""
        sentences = []
        
        context = f"In the {table_name} category"
        
        # Convert each value to a sentence
        for i, value in enumerate(values):
            if i < len(column_headers) and value and value != "0":
                header = column_headers[i]
                sentences.append(f"{context}, {row_label}: {header} = {value}.")
        
        return sentences

    def _convert_netpts_row_to_sentences(self, row_label: str, values: List[str], column_headers: List[str], player: str) -> List[str]:
        """Convert net points statistics row to natural language sentences"""
        sentences = []
        
        # Handle different net row types
        if "All Net Points" in row_label:
            context = f"{player} played"
        elif "All Net Approaches" in row_label:
            context = f"{player} made"
        elif "Net Points (excl S-and-V)" in row_label:
            context = f"{player} played"
        elif "Net Approaches (excl S-and-V)" in row_label:
            context = f"{player} made"
        else:
            context = f"{player} played"
        
        # Convert each value to a sentence with better formatting
        for i, value in enumerate(values):
            if i < len(column_headers) and value and value != "0":
                header = column_headers[i]
                
                if header == "Pts":
                    if "All Net Points" in row_label:
                        sentences.append(f"{player} played {value} net points.")
                    elif "Net Points (excl S-and-V)" in row_label:
                        sentences.append(f"{player} played {value} net points excluding serve and volleys.")
                    elif "All Net Approaches" in row_label:
                        sentences.append(f"{player} made {value} net approaches.")
                    elif "Net Approaches (excl S-and-V)" in row_label:
                        sentences.append(f"{player} made {value} net approaches excluding serve and volleys.")
                    else:
                        sentences.append(f"{context} {value} times.")
                elif header == "Won-----%":
                    # Extract the number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        if "All Net Points" in row_label:
                            sentences.append(f"{player} won {number} net points, or {percentage}% of total net points for {player}.")
                        elif "All Net Approaches" in row_label:
                            sentences.append(f"{player} won {number} net approaches, or {percentage}% of total net approaches for {player}.")
                        elif "Net Points (excl S-and-V)" in row_label:
                            sentences.append(f"{player} won {number} net points excluding serve and volleys, or {percentage}% of total net points excluding serve and volleys for {player}.")
                        elif "Net Approaches (excl S-and-V)" in row_label:
                            sentences.append(f"{player} won {number} net approaches excluding serve and volleys, or {percentage}% of total net approaches excluding serve and volleys for {player}.")
                        else:
                            sentences.append(f"{context} and won {number} points, or {percentage}% of total net points for {player}.")
                    else:
                        sentences.append(f"{context} and won {value} points.")
                elif header == "Wnr at Net":
                    # Extract number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        if "All Net Points" in row_label:
                            sentences.append(f"{player} hit {number} winners at the net, which represents {percentage}% of net points for {player}.")
                        elif "All Net Approaches" in row_label:
                            sentences.append(f"{player} hit {number} winners on net approaches, which represents {percentage}% of net approaches for {player}.")
                        elif "Net Points (excl S-and-V)" in row_label:
                            sentences.append(f"{player} hit {number} winners at the net excluding serve and volleys, which represents {percentage}% of net points for {player}.")
                        elif "Net Approaches (excl S-and-V)" in row_label:
                            sentences.append(f"{player} hit {number} winners on net approaches excluding serve and volleys, which represents {percentage}% of net approaches for {player}.")
                        else:
                            sentences.append(f"{player} hit {number} winners at the net, which represents {percentage}% of net points for {player}.")
                    else:
                        if "All Net Points" in row_label:
                            sentences.append(f"{player} hit {value} winners at the net.")
                        elif "All Net Approaches" in row_label:
                            sentences.append(f"{player} hit {value} winners on net approaches.")
                        else:
                            sentences.append(f"{player} hit {value} winners at the net.")
                elif header == "indFcd at Net":
                    # Extract number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        if "All Net Points" in row_label:
                            sentences.append(f"{player} induced {number} forced errors at the net, which represents {percentage}% of net points for {player}.")
                        elif "All Net Approaches" in row_label:
                            sentences.append(f"{player} induced {number} forced errors on net approaches, which represents {percentage}% of net approaches for {player}.")
                        elif "Net Points (excl S-and-V)" in row_label:
                            sentences.append(f"{player} induced {number} forced errors at the net excluding serve and volleys, which represents {percentage}% of net points for {player}.")
                        elif "Net Approaches (excl S-and-V)" in row_label:
                            sentences.append(f"{player} induced {number} forced errors on net approaches excluding serve and volleys, which represents {percentage}% of net approaches for {player}.")
                        else:
                            sentences.append(f"{player} induced {number} forced errors at the net, which represents {percentage}% of net points for {player}.")
                    else:
                        if "All Net Points" in row_label:
                            sentences.append(f"{player} induced {value} forced errors at the net.")
                        elif "All Net Approaches" in row_label:
                            sentences.append(f"{player} induced {value} forced errors on net approaches.")
                        else:
                            sentences.append(f"{player} induced {value} forced errors at the net.")
                elif header == "UFE at Net":
                    # Extract number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        if "All Net Points" in row_label:
                            sentences.append(f"{player} made {number} unforced errors at the net, which represents {percentage}% of net points for {player}.")
                        elif "All Net Approaches" in row_label:
                            sentences.append(f"{player} made {number} unforced errors on net approaches, which represents {percentage}% of net approaches for {player}.")
                        elif "Net Points (excl S-and-V)" in row_label:
                            sentences.append(f"{player} made {number} unforced errors at the net excluding serve and volleys, which represents {percentage}% of net points for {player}.")
                        elif "Net Approaches (excl S-and-V)" in row_label:
                            sentences.append(f"{player} made {number} unforced errors on net approaches excluding serve and volleys, which represents {percentage}% of net approaches for {player}.")
                        else:
                            sentences.append(f"{player} made {number} unforced errors at the net, which represents {percentage}% of net points for {player}.")
                    else:
                        if "All Net Points" in row_label:
                            sentences.append(f"{player} made {value} unforced errors at the net.")
                        elif "All Net Approaches" in row_label:
                            sentences.append(f"{player} made {value} unforced errors on net approaches.")
                        else:
                            sentences.append(f"{player} made {value} unforced errors at the net.")
                elif header == "Passed at Net":
                    # Extract number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        if "All Net Points" in row_label:
                            sentences.append(f"{player} was passed {number} times at the net, which represents {percentage}% of net points for {player}.")
                        elif "All Net Approaches" in row_label:
                            sentences.append(f"{player} was passed {number} times on net approaches, which represents {percentage}% of net approaches for {player}.")
                        elif "Net Points (excl S-and-V)" in row_label:
                            sentences.append(f"{player} was passed {number} times at the net excluding serve and volleys, which represents {percentage}% of net points for {player}.")
                        elif "Net Approaches (excl S-and-V)" in row_label:
                            sentences.append(f"{player} was passed {number} times on net approaches excluding serve and volleys, which represents {percentage}% of net approaches for {player}.")
                        else:
                            sentences.append(f"{player} was passed {number} times at the net, which represents {percentage}% of net points for {player}.")
                    else:
                        if "All Net Points" in row_label:
                            sentences.append(f"{player} was passed {value} times at the net.")
                        elif "All Net Approaches" in row_label:
                            sentences.append(f"{player} was passed {value} times on net approaches.")
                        else:
                            sentences.append(f"{player} was passed {value} times at the net.")
                elif header == "PsgSht indFcd":
                    # Extract number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        if "All Net Points" in row_label:
                            sentences.append(f"{player} induced {number} forced errors with passing shots at the net, which represents {percentage}% of net points.")
                        elif "All Net Approaches" in row_label:
                            sentences.append(f"{player} induced {number} forced errors with passing shots on net approaches, which represents {percentage}% of net approaches.")
                        elif "Net Points (excl S-and-V)" in row_label:
                            sentences.append(f"{player} induced {number} forced errors with passing shots at the net excluding serve and volleys, which represents {percentage}% of net points.")
                        elif "Net Approaches (excl S-and-V)" in row_label:
                            sentences.append(f"{player} induced {number} forced errors with passing shots on net approaches excluding serve and volleys, which represents {percentage}% of net approaches.")
                        else:
                            sentences.append(f"{player} induced {number} forced errors with passing shots at the net, which represents {percentage}% of net points.")
                    else:
                        if "All Net Points" in row_label:
                            sentences.append(f"{player} induced {value} forced errors with passing shots at the net.")
                        elif "All Net Approaches" in row_label:
                            sentences.append(f"{player} induced {value} forced errors with passing shots on net approaches.")
                        else:
                            sentences.append(f"{player} induced {value} forced errors with passing shots at the net.")
                elif header == "rallyLen":
                    if "All Net Points" in row_label:
                        sentences.append(f"{player} played at the net and the average rally length was {value} strokes.")
                    elif "All Net Approaches" in row_label:
                        sentences.append(f"{player} approached the net and the average rally length was {value} strokes.")
                    elif "Net Points (excl S-and-V)" in row_label:
                        sentences.append(f"{player} played at the net excluding serve and volleys and the average rally length was {value} strokes.")
                    elif "Net Approaches (excl S-and-V)" in row_label:
                        sentences.append(f"{player} approached the net excluding serve and volleys and the average rally length was {value} strokes.")
                    else:
                        sentences.append(f"{context} and the average rally length was {value} strokes.")
                else:
                    # Generic fallback
                    sentences.append(f"{context} and {header}: {value}.")
        
        return sentences

    def _convert_details_flat_to_text(self, details_flat: Dict[str, Any], player1: str, player2: str) -> List[str]:
        """Convert details_flat data to natural language text"""
        text = []
        
        # Group the flat data by table type
        shots_data = {}
        shotdir_data = {}
        netpts_data = {}
        serve_data = {}
        return_data = {}
        keypoints_data = {}
        overview_data = {}
        
        for key, value in details_flat.items():
            if key.startswith('shots1') or key.startswith('shots2'):
                shots_data[key] = value
            elif key.startswith('shotdir1') or key.startswith('shotdir2'):
                shotdir_data[key] = value
            elif key.startswith('netpts1') or key.startswith('netpts2'):
                netpts_data[key] = value
            elif key.startswith('serve1') or key.startswith('serve2'):
                serve_data[key] = value
            elif key.startswith('return1') or key.startswith('return2'):
                return_data[key] = value
            elif key.startswith('keypoints'):
                keypoints_data[key] = value
            elif key.startswith('overview'):
                overview_data[key] = value
        
        # Convert serve data (most important - comes first)
        if serve_data:
            text.extend(self._convert_flat_serve_to_text(serve_data, player1, player2))
        
        # Convert return data (second most important)
        if return_data:
            text.extend(self._convert_flat_return_to_text(return_data, player1, player2))
        
        # Convert overview data (summary statistics)
        if overview_data:
            text.extend(self._convert_flat_overview_to_text(overview_data, player1, player2))
        
        # Convert key points data
        if keypoints_data:
            text.extend(self._convert_flat_keypoints_to_text(keypoints_data, player1, player2))
        
        # Convert shots data
        if shots_data:
            text.extend(self._convert_flat_shots_to_text(shots_data, player1, player2))
        
        # Convert shotdir data
        if shotdir_data:
            text.extend(self._convert_flat_shotdir_to_text(shotdir_data, player1, player2))
        
        # Convert netpts data
        if netpts_data:
            text.extend(self._convert_flat_netpts_to_text(netpts_data, player1, player2))
        
        return text

    def _convert_flat_shots_to_text(self, shots_data: Dict[str, Any], player1: str, player2: str) -> List[str]:
        """Convert flat shots data to natural language text"""
        text = []
        
        # Group by player
        shots1_data = {k: v for k, v in shots_data.items() if k.startswith('shots1')}
        shots2_data = {k: v for k, v in shots_data.items() if k.startswith('shots2')}
        
        if shots1_data:
            text.append("SHOTS1 STATISTICS:")
            text.append("-" * 20)
            text.extend(self._convert_flat_shots_player_to_text(shots1_data, player1))
            text.append("")
        
        if shots2_data:
            text.append("SHOTS2 STATISTICS:")
            text.append("-" * 20)
            text.extend(self._convert_flat_shots_player_to_text(shots2_data, player2))
            text.append("")
        
        return text

    def _convert_flat_shots_player_to_text(self, shots_data: Dict[str, Any], player: str) -> List[str]:
        """Convert flat shots data for one player to natural language text"""
        text = []
        
        # TIER 1 (AUTHORITATIVE): Extract all columns from TOTAL, FOREHAND, and BACKHAND rows
        total_row_values = None
        forehand_row_values = None
        backhand_row_values = None
        row_headers = None
        
        # Find the header row
        header_key = None
        for key in shots_data.keys():
            if 'SHOT TYPES' in key:
                header_key = key
                break
        
        if header_key:
            headers = [h.strip() for h in shots_data[header_key].split(' | ')]
            
            # Extract all columns from TOTAL, FOREHAND, and BACKHAND rows (all are authoritative)
            for key, value in shots_data.items():
                if key != header_key and 'SHOT TYPES' not in key:
                    # Extract the row label (remove the prefix like "shots1 - ")
                    row_label = key.split(' - ', 1)[1] if ' - ' in key else key
                    
                    # Skip if this looks like a header row
                    if any(header_word in row_label for header_word in ['SHOT TYPES', 'PtEnd', 'Winner', 'IndFcd', 'UnfErr', 'SvReturn', 'inPtsW', 'inPtsL']):
                        continue
                    
                    # Split the value by | to get individual values
                    values = [v.strip() for v in value.split(' | ')]
                    
                    # Extract all columns from the authoritative rows
                    if len(values) == len(headers) and any(v != '' and v != '0' for v in values):
                        if 'Total' in row_label:
                            total_row_values = values
                            row_headers = headers
                        elif 'Forehand side' in row_label:
                            forehand_row_values = values
                            row_headers = headers
                        elif 'Backhand side' in row_label:
                            backhand_row_values = values
                            row_headers = headers
        
        # Add all authoritative totals from TOTAL, FOREHAND, and BACKHAND rows
        if row_headers:
            text.append(f"AUTHORITATIVE TOTALS FOR {player.upper()} SHOT STATISTICS:")
            
            # Add TOTAL row data
            if total_row_values:
                text.append("TOTAL SHOTS AUTHORITATIVE DATA:")
                for i, (header, value) in enumerate(zip(row_headers, total_row_values)):
                    if value and value != "0":
                        if header == "Total":
                            text.append(f"{player} hit {value} total shots.")
                        elif header == "PtEnd---%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} ended {number} total points with shots.")
                        elif header == "Winner--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} hit {number} total winners.")
                        elif header == "IndFcd--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} was induced into making {number} total forced errors.")
                        elif header == "UnfErr--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} made {number} total unforced errors.")
                        elif header == "SvReturn":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} hit {number} total serve returns.")
                        elif header == "inPtsW--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} won {number} total points with shots.")
                        elif header == "inPtsL--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} lost {number} total points with shots.")
            
            # Add FOREHAND row data
            if forehand_row_values:
                text.append("FOREHAND SHOTS AUTHORITATIVE DATA:")
                for i, (header, value) in enumerate(zip(row_headers, forehand_row_values)):
                    if value and value != "0":
                        if header == "Total":
                            text.append(f"{player} hit {value} forehand shots.")
                        elif header == "PtEnd---%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} ended {number} points with forehand shots.")
                        elif header == "Winner--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} hit {number} forehand winners.")
                        elif header == "IndFcd--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} was induced into making {number} forced errors with forehand shots.")
                        elif header == "UnfErr--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} made {number} forehand unforced errors.")
                        elif header == "SvReturn":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} hit {number} forehand serve returns.")
                        elif header == "inPtsW--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} won {number} points with forehand shots.")
                        elif header == "inPtsL--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} lost {number} points with forehand shots.")
            
            # Add BACKHAND row data
            if backhand_row_values:
                text.append("BACKHAND SHOTS AUTHORITATIVE DATA:")
                for i, (header, value) in enumerate(zip(row_headers, backhand_row_values)):
                    if value and value != "0":
                        if header == "Total":
                            text.append(f"{player} hit {value} backhand shots.")
                        elif header == "PtEnd---%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} ended {number} points with backhand shots.")
                        elif header == "Winner--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} hit {number} backhand winners.")
                        elif header == "IndFcd--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} was induced into making {number} forced errors with backhand shots.")
                        elif header == "UnfErr--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} made {number} backhand unforced errors.")
                        elif header == "SvReturn":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} hit {number} backhand serve returns.")
                        elif header == "inPtsW--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} won {number} points with backhand shots.")
                        elif header == "inPtsL--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} lost {number} points with backhand shots.")
            
            text.append("")
            text.append("DETAILED BREAKDOWN (these are contextual details, not for recalculating totals):")
            text.append("")
        
        # Second pass: process all rows for detailed breakdown
        if header_key:
            headers = [h.strip() for h in shots_data[header_key].split(' | ')]
            
            # Process each data row (skip the header row)
            for key, value in shots_data.items():
                if key != header_key and 'SHOT TYPES' not in key:
                    # Extract the row label (remove the prefix like "shots1 - ")
                    row_label = key.split(' - ', 1)[1] if ' - ' in key else key
                    
                    # Skip if this looks like a header row
                    if any(header_word in row_label for header_word in ['SHOT TYPES', 'Total', 'PtEnd', 'Winner', 'IndFcd', 'UnfErr', 'SvReturn', 'inPtsW', 'inPtsL']):
                        continue
                    
                    # Split the value by | to get individual values
                    values = [v.strip() for v in value.split(' | ')]
                    
                    # Only process if we have valid data (not just headers)
                    if len(values) == len(headers) and any(v != '' and v != '0' for v in values):
                        # Convert to sentences using the existing method
                        sentences = self._convert_shots_row_to_sentences(row_label, values, headers, player)
                        text.extend(sentences)
        
        return text

    def _convert_flat_shotdir_to_text(self, shotdir_data: Dict[str, Any], player1: str, player2: str) -> List[str]:
        """Convert flat shotdir data to natural language text"""
        text = []
        
        # Group by player
        shotdir1_data = {k: v for k, v in shotdir_data.items() if k.startswith('shotdir1')}
        shotdir2_data = {k: v for k, v in shotdir_data.items() if k.startswith('shotdir2')}
        
        if shotdir1_data:
            text.append("SHOTDIR1 STATISTICS:")
            text.append("-" * 22)
            text.extend(self._convert_flat_shotdir_player_to_text(shotdir1_data, player1))
            text.append("")
        
        if shotdir2_data:
            text.append("SHOTDIR2 STATISTICS:")
            text.append("-" * 22)
            text.extend(self._convert_flat_shotdir_player_to_text(shotdir2_data, player2))
            text.append("")
        
        # Add explicit totals for complex shot direction + outcome combinations
        # These help the LLM anchor on correct totals for complex questions
        text.append("")
        text.append("EXPLICIT TOTALS FOR SHOT DIRECTION + OUTCOME COMBINATIONS:")
        text.append("-" * 50)
        
        # Calculate explicit totals from the natural language sentences we just generated
        directions = ['crosscourt', 'down middle', 'down the line', 'inside-out', 'inside-in']
        outcomes = ['winners', 'induced forced errors', 'unforced errors', 'points won', 'points lost']
        
        # Create a nested dictionary to store all combinations for both players
        player_totals = {player1: {}, player2: {}}
        for player in player_totals:
            player_totals[player] = {}
            for direction in directions:
                player_totals[player][direction] = {}
                for outcome in outcomes:
                    player_totals[player][direction][outcome] = {'forehand': 0, 'backhand': 0, 'slice': 0}
        
        # Parse the natural language sentences to extract numbers
        for line in text:
            # Extract the number from the beginning of the line
            import re
            number_match = re.search(r'(\d+)', line)
            if not number_match:
                continue
            number = int(number_match.group(1))
            
            # Determine which player this line is for
            current_player = None
            if player1 in line:
                current_player = player1
            elif player2 in line:
                current_player = player2
            else:
                continue
            
            # Look for lines like "hit X winners with [shot type] [direction] shots"
            if 'hit' in line and 'winners' in line and 'shots' in line:
                for direction in directions:
                    if direction in line:
                        if 'forehand' in line:
                            player_totals[current_player][direction]['winners']['forehand'] = number
                        elif 'backhand' in line and 'slice' not in line:
                            player_totals[current_player][direction]['winners']['backhand'] = number
                        elif 'slice' in line:
                            player_totals[current_player][direction]['winners']['slice'] = number
                        break
            
            elif 'made' in line and 'induced forced errors' in line and 'shots' in line:
                for direction in directions:
                    if direction in line:
                        if 'forehand' in line:
                            player_totals[current_player][direction]['induced forced errors']['forehand'] = number
                        elif 'backhand' in line and 'slice' not in line:
                            player_totals[current_player][direction]['induced forced errors']['backhand'] = number
                        elif 'slice' in line:
                            player_totals[current_player][direction]['induced forced errors']['slice'] = number
                        break
            
            elif 'made' in line and 'unforced errors' in line and 'shots' in line:
                for direction in directions:
                    if direction in line:
                        if 'forehand' in line:
                            player_totals[current_player][direction]['unforced errors']['forehand'] = number
                        elif 'backhand' in line and 'slice' not in line:
                            player_totals[current_player][direction]['unforced errors']['backhand'] = number
                        elif 'slice' in line:
                            player_totals[current_player][direction]['unforced errors']['slice'] = number
                        break
            
            elif 'won' in line and 'points' in line and 'shots' in line:
                for direction in directions:
                    if direction in line:
                        if 'forehand' in line:
                            player_totals[current_player][direction]['points won']['forehand'] = number
                        elif 'backhand' in line and 'slice' not in line:
                            player_totals[current_player][direction]['points won']['backhand'] = number
                        elif 'slice' in line:
                            player_totals[current_player][direction]['points won']['slice'] = number
                        break
            
            elif 'lost' in line and 'points' in line and 'shots' in line:
                for direction in directions:
                    if direction in line:
                        if 'forehand' in line:
                            player_totals[current_player][direction]['points lost']['forehand'] = number
                        elif 'backhand' in line and 'slice' not in line:
                            player_totals[current_player][direction]['points lost']['backhand'] = number
                        elif 'slice' in line:
                            player_totals[current_player][direction]['points lost']['slice'] = number
                        break
        
        # Generate explicit totals for ALL combinations (including zeros) for both players
        for player in [self.player1, self.player2] if self.player1 and self.player2 else ['Player 1', 'Player 2']:
            for direction in directions:
                for outcome in outcomes:
                    total = sum(player_totals[player][direction][outcome].values())
                    fh, bh, sl = player_totals[player][direction][outcome].values()
                    if outcome == 'winners':
                        text.append(f"{player} hit {total} {direction} {outcome} total, including {fh} forehand {direction} {outcome}, {bh} backhand {direction} {outcome}, and {sl} slice {direction} {outcome}")
                    elif outcome == 'induced forced errors':
                        text.append(f"{player} made {total} {direction} {outcome} total, including {fh} forehand {direction} {outcome}, {bh} backhand {direction} {outcome}, and {sl} slice {direction} {outcome}")
                    elif outcome == 'unforced errors':
                        text.append(f"{player} made {total} {direction} {outcome} total, including {fh} forehand {direction} {outcome}, {bh} backhand {direction} {outcome}, and {sl} slice {direction} {outcome}")
                    elif outcome == 'points won':
                        text.append(f"{player} won {total} {direction} {outcome} total, including {fh} forehand {direction} {outcome}, {bh} backhand {direction} {outcome}, and {sl} slice {direction} {outcome}")
                    elif outcome == 'points lost':
                        text.append(f"{player} lost {total} {direction} {outcome} total, including {fh} forehand {direction} {outcome}, {bh} backhand {direction} {outcome}, and {sl} slice {direction} {outcome}")
        
        text.append("")
        
        return text

    def _convert_flat_shotdir_player_to_text(self, shotdir_data: Dict[str, Any], player: str) -> List[str]:
        """Convert flat shotdir data for one player to natural language text"""
        text = []
        
        # Group by table type
        table1_data = {k: v for k, v in shotdir_data.items() if '_table1' in k}
        table2_data = {k: v for k, v in shotdir_data.items() if '_table2' in k}
        
        # TIER 1 (AUTHORITATIVE): Extract totals from "Total" row as single source of truth
        total_shots_all_directions = 0
        total_forehand_shots = 0
        total_backhand_shots = 0
        total_backhand_slice_shots = 0
        
        # Directional totals
        total_crosscourt_shots = 0
        total_down_the_line_shots = 0
        total_down_the_middle_shots = 0
        total_inside_out_shots = 0
        total_inside_in_shots = 0
        
        # Extract authoritative totals from table1 rows
        if table1_data:
            header_key = None
            for key in table1_data.keys():
                if 'SHOT DIRECTION' in key:
                    header_key = key
                    break
            
            if header_key:
                headers = [h.strip() for h in table1_data[header_key].split(' | ')]
                
                for key, value in table1_data.items():
                    if key != header_key and 'SHOT DIRECTION' not in key:
                        row_label = key.split(' - ', 1)[1] if ' - ' in key else key
                        
                        # Skip header rows except Total
                        if any(header_word in row_label for header_word in ['SHOT DIRECTION', 'PtEnding', 'Winner', 'InduceFcd', 'UnfErr', 'inPtsWon', 'inPtsLost']):
                            continue
                        
                        values = [v.strip() for v in value.split(' | ')]
                        
                        # Extract totals from each row
                        if len(values) == len(headers) and any(v != '' and v != '0' for v in values):
                            try:
                                # Sum up all direction values for this shot type
                                shot_total = sum(int(v.split('(')[0].strip()) for v in values if v and '(' in v and v.split('(')[0].strip().isdigit())
                                
                                if 'Total' in row_label:
                                    total_shots_all_directions = shot_total  # AUTHORITATIVE
                                    
                                    # Extract directional totals from the Total row
                                    for i, header in enumerate(headers):
                                        if i < len(values) and values[i] and '(' in values[i]:
                                            direction_value = int(values[i].split('(')[0].strip())
                                            if 'Crosscourt' in header:
                                                total_crosscourt_shots = direction_value
                                            elif 'Down the line' in header:
                                                total_down_the_line_shots = direction_value
                                            elif 'Down middle' in header:
                                                total_down_the_middle_shots = direction_value
                                            elif 'Inside-out' in header:
                                                total_inside_out_shots = direction_value
                                            elif 'Inside-in' in header:
                                                total_inside_in_shots = direction_value
                                
                                elif 'Forehand' in row_label:
                                    total_forehand_shots = shot_total
                                elif 'BH slice' in row_label:
                                    total_backhand_slice_shots = shot_total
                                elif 'Backhand' in row_label:
                                    total_backhand_shots = shot_total
                            except (ValueError, IndexError):
                                continue
        
        # Add authoritative summary (TIER 1)
        if total_shots_all_directions > 0:
            text.append(f"AUTHORITATIVE TOTALS FOR {player.upper()} SHOT DIRECTIONS:")
            text.append(f"{player} hit {total_shots_all_directions} total shots in all directions including crosscourt, down the middle, down the line, inside-out, and inside-in.")
            text.append("")
            text.append("SHOT TYPE BREAKDOWN (these sum to total above, do not add again):")
            if total_forehand_shots > 0:
                text.append(f"{player} hit {total_forehand_shots} forehand shots in all directions including crosscourt, down the middle, down the line, inside-out, and inside-in.")
            if total_backhand_shots > 0:
                text.append(f"{player} hit {total_backhand_shots} backhand shots in all directions including crosscourt, down the middle, down the line, inside-out, and inside-in.")
            if total_backhand_slice_shots > 0:
                text.append(f"{player} hit {total_backhand_slice_shots} backhand slice shots in all directions including crosscourt, down the middle, down the line, inside-out, and inside-in.")
            text.append("")
            text.append("AUTHORITATIVE TOTALS BY DIRECTION (these sum to total above, do not add again):")
            text.append(f"{player} hit {total_crosscourt_shots} total crosscourt shots.")
            text.append(f"{player} hit {total_inside_out_shots} total inside-out shots.")
            text.append(f"{player} hit {total_down_the_line_shots} total down the line shots.")
            text.append(f"{player} hit {total_down_the_middle_shots} total down the middle shots.")
            text.append(f"{player} hit {total_inside_in_shots} total inside-in shots.")
            text.append("")
        
        # Process table1 (direction breakdowns)
        if table1_data:
            text.append("SHOT DIRECTION BREAKDOWN:")
            text.append("-" * 25)
            
            # Find the header row for table1
            header_key = None
            for key in table1_data.keys():
                if 'SHOT DIRECTION' in key:
                    header_key = key
                    break
            
            if header_key:
                headers = [h.strip() for h in table1_data[header_key].split(' | ')]
                
                # Process each data row in table1
                for key, value in table1_data.items():
                    if key != header_key and 'SHOT DIRECTION' not in key:
                        # Extract the row label
                        row_label = key.split(' - ', 1)[1] if ' - ' in key else key
                        
                        # Skip if this looks like a header row
                        if any(header_word in row_label for header_word in ['SHOT DIRECTION', 'Total', 'PtEnding', 'Winner', 'InduceFcd', 'UnfErr', 'inPtsWon', 'inPtsLost']):
                            continue
                        
                        # Split the value by | to get individual values
                        values = [v.strip() for v in value.split(' | ')]
                        
                        # Only process if we have valid data
                        if len(values) == len(headers) and any(v != '' and v != '0' for v in values):
                            # Convert to sentences for table1
                            sentences = self._convert_shotdir_table1_row_to_sentences(row_label, values, headers, player)
                            text.extend(sentences)
            
            text.append("")
        
        # Process table2 (detailed breakdowns by shot type and direction)
        if table2_data:
            text.append("SHOT DIRECTION DETAILED BREAKDOWN:")
            text.append("-" * 35)
            
            # Find the header row for table2
            header_key = None
            for key in table2_data.keys():
                if 'SHOT DIRECTION' in key:
                    header_key = key
                    break
            
            if header_key:
                headers = [h.strip() for h in table2_data[header_key].split(' | ')]
                
                # Process each data row in table2
                for key, value in table2_data.items():
                    if key != header_key and 'SHOT DIRECTION' not in key:
                        # Extract the row label
                        row_label = key.split(' - ', 1)[1] if ' - ' in key else key
                        
                        # Skip if this looks like a header row
                        if any(header_word in row_label for header_word in ['SHOT DIRECTION', 'Total', 'PtEnding', 'Winner', 'InduceFcd', 'UnfErr', 'inPtsWon', 'inPtsLost']):
                            continue
                        
                        # Split the value by | to get individual values
                        values = [v.strip() for v in value.split(' | ')]
                        
                        # Only process if we have valid data
                        if len(values) == len(headers) and any(v != '' and v != '0' for v in values):
                            # Convert to sentences for table2
                            sentences = self._convert_shotdir_table2_row_to_sentences(row_label, values, headers, player)
                            text.extend(sentences)
        

        
        return text

    def _convert_shotdir_table1_row_to_sentences(self, row_label: str, values: List[str], headers: List[str], player: str) -> List[str]:
        """Convert shot direction table1 row to natural language sentences"""
        sentences = []
        
        # Handle different row types
        if "Total" in row_label:
            # Total row shows breakdown by direction
            for i, value in enumerate(values):
                if i < len(headers) and value and value != "0":
                    header = headers[i]
                    
                    # Extract number and percentage from format like "57  (48%)"
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        
                        if header == "Crosscourt":
                            sentences.append(f"{player} hit {number} crosscourt shots, which represents {percentage}% of all shots hit by {player}.")
                        elif header == "Down middle":
                            sentences.append(f"{player} hit {number} down-the-middle shots, which represents {percentage}% of all shots hit by {player}.")
                        elif header == "Down the line":
                            sentences.append(f"{player} hit {number} down-the-line shots, which represents {percentage}% of all shots hit by {player}.")
                        elif header == "Inside-out":
                            sentences.append(f"{player} hit {number} inside-out shots, which represents {percentage}% of all shots hit by {player}.")
                        elif header == "Inside-in":
                            sentences.append(f"{player} hit {number} inside-in shots, which represents {percentage}% of all shots hit by {player}.")
                        else:
                            sentences.append(f"{player} hit {number} {header.lower()} shots, which represents {percentage}% of all shots hit by {player}.")
                    else:
                        sentences.append(f"{player} hit {value} {header.lower()} shots.")
        else:
            # Other rows (Forehand, Backhand, BH slice) show breakdown by direction for that shot type
            for i, value in enumerate(values):
                if i < len(headers) and value and value != "0":
                    header = headers[i]
                    
                    # Extract number and percentage from format like "57  (48%)"
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        
                        if "Forehand" in row_label:
                            if header == "Crosscourt":
                                sentences.append(f"{player} hit {number} forehand crosscourt shots, which represents {percentage}% of all forehand shots hit by {player}.")
                            elif header == "Down middle":
                                sentences.append(f"{player} hit {number} forehand down-the-middle shots, which represents {percentage}% of all forehand shots hit by {player}.")
                            elif header == "Down the line":
                                sentences.append(f"{player} hit {number} forehand down-the-line shots, which represents {percentage}% of all forehand shots hit by {player}.")
                            elif header == "Inside-out":
                                sentences.append(f"{player} hit {number} forehand inside-out shots, which represents {percentage}% of all forehand shots hit by {player}.")
                            elif header == "Inside-in":
                                sentences.append(f"{player} hit {number} forehand inside-in shots, which represents {percentage}% of all forehand shots hit by {player}.")
                        elif "Backhand" in row_label:
                            if header == "Crosscourt":
                                sentences.append(f"{player} hit {number} backhand crosscourt shots, which represents {percentage}% of all backhand shots hit by {player}.")
                            elif header == "Down middle":
                                sentences.append(f"{player} hit {number} backhand down-the-middle shots, which represents {percentage}% of all backhand shots hit by {player}.")
                            elif header == "Down the line":
                                sentences.append(f"{player} hit {number} backhand down-the-line shots, which represents {percentage}% of all backhand shots hit by {player}.")
                            elif header == "Inside-out":
                                sentences.append(f"{player} hit {number} backhand inside-out shots, which represents {percentage}% of all backhand shots hit by {player}.")
                            elif header == "Inside-in":
                                sentences.append(f"{player} hit {number} backhand inside-in shots, which represents {percentage}% of all backhand shots hit by {player}.")
                        elif "BH slice" in row_label:
                            if header == "Crosscourt":
                                sentences.append(f"{player} hit {number} backhand slice crosscourt shots, which represents {percentage}% of all backhand slice shots hit by {player}.")
                            elif header == "Down middle":
                                sentences.append(f"{player} hit {number} backhand slice down-the-middle shots, which represents {percentage}% of all backhand slice shots hit by {player}.")
                            elif header == "Down the line":
                                sentences.append(f"{player} hit {number} backhand slice down-the-line shots, which represents {percentage}% of all backhand slice shots hit by {player}.")
                            elif header == "Inside-out":
                                sentences.append(f"{player} hit {number} backhand slice inside-out shots, which represents {percentage}% of all backhand slice shots hit by {player}.")
                            elif header == "Inside-in":
                                sentences.append(f"{player} hit {number} backhand slice inside-in shots, which represents {percentage}% of all backhand slice shots hit by {player}.")
                    else:
                        if "Forehand" in row_label:
                            sentences.append(f"{player} hit {value} forehand {header.lower()} shots.")
                        elif "Backhand" in row_label:
                            sentences.append(f"{player} hit {value} backhand {header.lower()} shots.")
                        elif "BH slice" in row_label:
                            sentences.append(f"{player} hit {value} backhand slice {header.lower()} shots.")
        
        return sentences

    def _convert_shotdir_table2_row_to_sentences(self, row_label: str, values: List[str], headers: List[str], player: str) -> List[str]:
        """Convert shot direction table2 row to natural language sentences"""
        sentences = []
        
        # Extract shot type and direction from row label (e.g., "FH crosscourt_table2" -> "forehand crosscourt")
        shot_type = row_label.lower()
        
        # Remove table suffix if present
        if "_table" in shot_type:
            shot_type = shot_type.split("_table")[0]
        
        # Convert abbreviations
        if "FH" in shot_type:
            shot_type = shot_type.replace("FH", "forehand")
        if "BH" in shot_type:
            shot_type = shot_type.replace("BH", "backhand")
        if "fh" in shot_type:
            shot_type = shot_type.replace("fh", "forehand")
        if "bh" in shot_type:
            shot_type = shot_type.replace("bh", "backhand")
        
        # Convert each value to a sentence
        for i, value in enumerate(values):
            if i < len(headers) and value and value != "0":
                header = headers[i]
                
                if header == "Total":
                    sentences.append(f"{player} hit {value} {shot_type} shots.")
                elif header == "PtEnding":
                    # Extract number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} ended {number} points with {shot_type} shots, which represents {percentage}% of all {shot_type} shots hit by {player}.")
                    else:
                        sentences.append(f"{player} ended {value} points with {shot_type} shots.")
                elif header == "Winner":
                    # Extract number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} hit {number} winners with {shot_type} shots, which represents {percentage}% of all {shot_type} shots hit by {player}.")
                    else:
                        sentences.append(f"{player} hit {value} winners with {shot_type} shots.")
                elif header == "InduceFcd":
                    # Extract number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} made {number} induced forced errors with {shot_type} shots, which represents {percentage}% of all {shot_type} shots hit by {player}.")
                    else:
                        sentences.append(f"{player} made {value} induced forced errors with {shot_type} shots.")
                elif header == "UnfErr":
                    # Extract number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} made {number} unforced errors with {shot_type} shots, which represents {percentage}% of all {shot_type} shots hit by {player}.")
                    else:
                        sentences.append(f"{player} made {value} unforced errors with {shot_type} shots.")
                elif header == "inPtsWon":
                    # Extract number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} won {number} points with {shot_type} shots, which represents {percentage}% of all {shot_type} shots hit by {player}.")
                    else:
                        sentences.append(f"{player} won {value} points with {shot_type} shots.")
                elif header == "inPtsLost":
                    # Extract number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} lost {number} points with {shot_type} shots, which represents {percentage}% of all {shot_type} shots hit by {player}.")
                    else:
                        sentences.append(f"{player} lost {value} points with {shot_type} shots.")
                else:
                    sentences.append(f"{player} had {header}: {value} with {shot_type} shots.")
        
        return sentences

    def _convert_flat_netpts_to_text(self, netpts_data: Dict[str, Any], player1: str, player2: str) -> List[str]:
        """Convert flat netpts data to natural language text"""
        text = []
        
        # Group by player
        netpts1_data = {k: v for k, v in netpts_data.items() if k.startswith('netpts1')}
        netpts2_data = {k: v for k, v in netpts_data.items() if k.startswith('netpts2')}
        
        if netpts1_data:
            text.append("NETPTS1 STATISTICS:")
            text.append("-" * 21)
            text.extend(self._convert_flat_netpts_player_to_text(netpts1_data, player1))
            text.append("")
        
        if netpts2_data:
            text.append("NETPTS2 STATISTICS:")
            text.append("-" * 21)
            text.extend(self._convert_flat_netpts_player_to_text(netpts2_data, player2))
            text.append("")
        
        return text

    def _convert_flat_netpts_player_to_text(self, netpts_data: Dict[str, Any], player: str) -> List[str]:
        """Convert flat netpts data for one player to natural language text"""
        text = []
        
        # Find the header row
        header_key = None
        for key in netpts_data.keys():
            if 'NET POINTS' in key:
                header_key = key
                break
        
        if header_key:
            headers = netpts_data[header_key].split(' | ')
            
            # Process each data row
            for key, value in netpts_data.items():
                if key != header_key and 'NET POINTS' not in key:
                    # Extract the row label
                    row_label = key.split(' - ', 1)[1] if ' - ' in key else key
                    
                    # Split the value by | to get individual values
                    values = [v.strip() for v in value.split(' | ')]
                    
                    # Convert to sentences using the existing method
                    sentences = self._convert_netpts_row_to_sentences(row_label, values, headers, player)
                    text.extend(sentences)
        
        return text

    def _convert_flat_serve_to_text(self, serve_data: Dict[str, Any], player1: str, player2: str) -> List[str]:
        """Convert flat serve data to natural language text"""
        text = []
        
        # Group by player
        serve1_data = {k: v for k, v in serve_data.items() if k.startswith('serve1')}
        serve2_data = {k: v for k, v in serve_data.items() if k.startswith('serve2')}
        
        # Serve1 Table 1 (Summary)
        if serve1_data:
            text.append("SERVE1 STATISTICS (SUMMARY):")
            text.append("-" * 28)
            text.extend(self._convert_flat_serve_player_table1_to_text(serve1_data, player1))
            text.append("")
        
        # Serve1 Table 2 (Detailed)
        if serve1_data:
            text.append("SERVE1 STATISTICS (DETAILED):")
            text.append("-" * 30)
            text.extend(self._convert_flat_serve_player_table2_to_text(serve1_data, player1))
            text.append("")
        
        # Serve2 Table 1 (Summary)
        if serve2_data:
            text.append("SERVE2 STATISTICS (SUMMARY):")
            text.append("-" * 28)
            text.extend(self._convert_flat_serve_player_table1_to_text(serve2_data, player2))
            text.append("")
        
        # Serve2 Table 2 (Detailed)
        if serve2_data:
            text.append("SERVE2 STATISTICS (DETAILED):")
            text.append("-" * 30)
            text.extend(self._convert_flat_serve_player_table2_to_text(serve2_data, player2))
            text.append("")
        
        return text

    def _convert_flat_serve_player_table1_to_text(self, serve_data: Dict[str, Any], player: str) -> List[str]:
        """Convert flat serve data table1 (summary) for one player to natural language text"""
        text = []
        
        # TIER 1 (AUTHORITATIVE): Calculate summary totals first
        total_aces = 0
        total_double_faults = 0
        total_points_served = 0
        total_points_won = 0
        
        # Extract authoritative totals ONLY from Deuce Court and Ad Court (non-overlapping categories)
        for key, value in serve_data.items():
            if '_table1' in key and ' - ' in key:
                location_part = key.split(' - ')[1].split('_table1')[0]
                # Only use Deuce Court and Ad Court as authoritative sources (they don't overlap)
                if location_part in ['Deuce Court', 'Ad Court']:
                    values = [v.strip() for v in value.split(' | ')]
                    if len(values) >= 8:
                        try:
                            total_points_served += int(values[0]) if values[0] and values[0] != "0" else 0
                            if "(" in values[1]:
                                total_points_won += int(values[1].split('(')[0].strip()) if values[1].split('(')[0].strip() else 0
                            total_aces += int(values[2].split('(')[0].strip()) if values[2] and "(" in values[2] else (int(values[2]) if values[2] and values[2] != "0" else 0)
                            total_double_faults += int(values[7].split('(')[0].strip()) if values[7] and "(" in values[7] else (int(values[7]) if values[7] and values[7] != "0" else 0)
                        except (ValueError, IndexError):
                            continue
        
        # Add authoritative summary (TIER 1)
        text.append(f"AUTHORITATIVE TOTALS FOR {player.upper()}:")
        text.append(f"{player} served {total_points_served} total points.")
        text.append(f"{player} won {total_points_won} total serve points.")
        text.append(f"{player} hit {total_aces} total aces.")
        text.append(f"{player} made {total_double_faults} total double faults.")
        text.append("")
        text.append("BREAKDOWN BY COURT LOCATION (these sum to totals above, do not add again):")
        text.append("")
        
        # Process each serve breakdown for table1 (summary)
        for key, value in serve_data.items():
            # Only process table1 data
            if '_table1' not in key:
                continue
                
            # Extract the location from the key
            # Format: "serve1 - Deuce Court_table1"
            if ' - ' in key and '_table1' in key:
                location_part = key.split(' - ')[1].split('_table1')[0]
                
                # Skip header rows
                if 'BREAKDOWN' in location_part:
                    continue
                
                # Split the value by | to get individual values
                values = [v.strip() for v in value.split(' | ')]
                
                # Convert location to proper description
                if 'Deuce Court' in location_part:
                    location_desc = "to the Deuce court"
                elif 'Ad Court' in location_part:
                    location_desc = "to the Ad court"
                else:
                    location_desc = location_part.lower()
                
                # Extract stats for table1 (summary)
                if len(values) >= 8:
                    total_pts = values[0]
                    won_pts = values[1]
                    aces = values[2]
                    unreturned = values[3]
                    forced_errors = values[4]
                    won_3_or_less = values[5]
                    first_serves_in = values[6]
                    double_faults = values[7]
                    
                    # Create detailed descriptions
                    if total_pts and total_pts != "0":
                        text.append(f"{player} served {location_desc} {total_pts} times.")
                        
                        # Points won
                        if won_pts and won_pts != "0":
                            if "(" in won_pts and ")" in won_pts:
                                percentage = won_pts.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} served {location_desc} and won {won_pts.split('(')[0].strip()} points, or {percentage}% of total points served {location_desc} by {player}.")
                            else:
                                text.append(f"{player} served {location_desc} and won {won_pts} points, or {won_pts}% of total points served {location_desc} by {player}.")
                        
                        # Aces
                        if aces and aces != "0":
                            if "(" in aces and ")" in aces:
                                percentage = aces.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} hit {aces.split('(')[0].strip()} aces served {location_desc}, or {percentage}% of total points served {location_desc} by {player}.")
                            else:
                                text.append(f"{player} hit {aces} aces served {location_desc}, or {aces}% of total points served {location_desc} by {player}.")
                        
                        # Unreturned serves
                        if unreturned and unreturned != "0":
                            if "(" in unreturned and ")" in unreturned:
                                percentage = unreturned.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} had {unreturned.split('(')[0].strip()} unreturned serves served {location_desc}, or {percentage}% of total points served {location_desc} by {player}.")
                            else:
                                text.append(f"{player} had {unreturned} unreturned serves served {location_desc}, or {unreturned}% of total points served {location_desc} by {player}.")
                        
                        # Forced errors
                        if forced_errors and forced_errors != "0":
                            if "(" in forced_errors and ")" in forced_errors:
                                percentage = forced_errors.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} forced {forced_errors.split('(')[0].strip()} errors from her opponent on serves {location_desc}, or {percentage}% of total points served {location_desc} by {player}.")
                            else:
                                text.append(f"{player} forced {forced_errors} errors from her opponent on serves {location_desc}, or {forced_errors}% of total points served {location_desc} by {player}.")
                        
                        # Won in 3 shots or less
                        if won_3_or_less and won_3_or_less != "0":
                            if "(" in won_3_or_less and ")" in won_3_or_less:
                                percentage = won_3_or_less.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} won {won_3_or_less.split('(')[0].strip()} points in 3 shots or less on serves {location_desc}, or {percentage}% of total points served {location_desc} by {player}.")
                            else:
                                text.append(f"{player} won {won_3_or_less} points in 3 shots or less on serves {location_desc}, or {won_3_or_less}% of total points served {location_desc} by {player}.")
                        
                        # First serves in
                        if first_serves_in and first_serves_in != "0":
                            if "(" in first_serves_in and ")" in first_serves_in:
                                percentage = first_serves_in.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} hit in {first_serves_in.split('(')[0].strip()} first serves served {location_desc}, or {percentage}% of first serves served {location_desc} by {player}.")
                            else:
                                text.append(f"{player} hit in {first_serves_in} first serves served {location_desc}, or {first_serves_in}% of first serves served {location_desc} by {player}.")
                        
                        # Double faults
                        if double_faults and double_faults != "0":
                            if "(" in double_faults and ")" in double_faults:
                                percentage = double_faults.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} served {location_desc} and had {double_faults.split('(')[0].strip()} double faults, or {percentage}% of serves {location_desc} by {player}.")
                            else:
                                text.append(f"{player} served {location_desc} and had {double_faults} double faults, or {double_faults}% of serves {location_desc} by {player}.")
        
        return text

    def _convert_flat_serve_player_table2_to_text(self, serve_data: Dict[str, Any], player: str) -> List[str]:
        """Convert flat serve data table2 (detailed) for one player to natural language text"""
        text = []
        
        # Process each serve breakdown for table2 (detailed)
        for key, value in serve_data.items():
            # Only process table2 data
            if '_table2' not in key:
                continue
                
            # Extract the location from the key
            # Format: "serve1 - Deuce Court_table2"
            if ' - ' in key and '_table2' in key:
                location_part = key.split(' - ')[1].split('_table2')[0]
                
                # Skip header rows
                if 'BREAKDOWN' in location_part:
                    continue
                
                # Split the value by | to get individual values
                values = [v.strip() for v in value.split(' | ')]
                
                # Convert location to proper description
                if 'Deuce Court' in location_part:
                    location_desc = "to the Deuce court"
                elif 'Ad Court' in location_part:
                    location_desc = "to the Ad court"
                else:
                    location_desc = location_part.lower()
                
                # Extract stats for table2 (detailed - separates first and second serves)
                if len(values) >= 12:
                    # First serve stats
                    first_pts = values[0]
                    first_won = values[1]
                    first_aces = values[2]
                    first_unreturned = values[3]
                    first_forced_errors = values[4]
                    first_won_3_or_less = values[5]
                    
                    # Second serve stats
                    second_pts = values[6]
                    second_won = values[7]
                    second_aces = values[8]
                    second_unreturned = values[9]
                    second_forced_errors = values[10]
                    second_won_3_or_less = values[11]
                    
                    # First serve details
                    if first_pts and first_pts != "0":
                        text.append(f"{player} served {location_desc} {first_pts} first serves.")
                        
                        if first_won and first_won != "0":
                            if "(" in first_won and ")" in first_won:
                                percentage = first_won.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} won {first_won.split('(')[0].strip()} first serve points {location_desc}, or {percentage}% of first serves {location_desc} by {player}.")
                            else:
                                text.append(f"{player} won {first_won} first serve points {location_desc}, or {first_won}% of first serves {location_desc} by {player}.")
                        
                        if first_aces and first_aces != "0":
                            if "(" in first_aces and ")" in first_aces:
                                percentage = first_aces.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} hit {first_aces.split('(')[0].strip()} aces on first serves {location_desc}, or {percentage}% of first serves {location_desc} by {player}.")
                            else:
                                text.append(f"{player} hit {first_aces} aces on first serves {location_desc}, or {first_aces}% of first serves {location_desc} by {player}.")
                        
                        if first_won_3_or_less and first_won_3_or_less != "0":
                            if "(" in first_won_3_or_less and ")" in first_won_3_or_less:
                                percentage = first_won_3_or_less.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} won {first_won_3_or_less.split('(')[0].strip()} first serve points in 3 shots or less {location_desc}, or {percentage}% of first serves {location_desc} by {player}.")
                            else:
                                text.append(f"{player} won {first_won_3_or_less} first serve points in 3 shots or less {location_desc}, or {first_won_3_or_less}% of first serves {location_desc} by {player}.")
                    
                    # Second serve details
                    if second_pts and second_pts != "0":
                        text.append(f"{player} served {location_desc} {second_pts} second serves.")
                        
                        if second_won and second_won != "0":
                            if "(" in second_won and ")" in second_won:
                                percentage = second_won.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} won {second_won.split('(')[0].strip()} second serve points {location_desc}, or {percentage}% of second serves {location_desc} by {player}.")
                            else:
                                text.append(f"{player} won {second_won} second serve points {location_desc}, or {second_won}% of second serves {location_desc} by {player}.")
                        
                        if second_aces and second_aces != "0":
                            if "(" in second_aces and ")" in second_aces:
                                percentage = second_aces.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} hit {second_aces.split('(')[0].strip()} aces on second serves {location_desc}, or {percentage}% of second serves {location_desc} by {player}.")
                            else:
                                text.append(f"{player} hit {second_aces} aces on second serves {location_desc}, or {second_aces}% of second serves {location_desc} by {player}.")
                        
                        if second_won_3_or_less and second_won_3_or_less != "0":
                            if "(" in second_won_3_or_less and ")" in second_won_3_or_less:
                                percentage = second_won_3_or_less.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} won {second_won_3_or_less.split('(')[0].strip()} second serve points in 3 shots or less {location_desc}, or {percentage}% of second serves {location_desc} by {player}.")
                            else:
                                text.append(f"{player} won {second_won_3_or_less} second serve points in 3 shots or less {location_desc}, or {second_won_3_or_less}% of second serves {location_desc} by {player}.")
        
        return text

    def _convert_flat_serve_player_to_text(self, serve_data: Dict[str, Any], player: str) -> List[str]:
        """Convert flat serve data for one player to natural language text"""
        text = []
        
        # Process each serve breakdown
        for key, value in serve_data.items():
            # Extract the location and table type from the key
            # Format: "serve1 - Deuce Court_table1" or "serve1 - Ad Court_table2"
            if ' - ' in key and '_table' in key:
                location_part = key.split(' - ')[1].split('_table')[0]
                table_type = key.split('_table')[1]
                
                # Skip header rows
                if 'BREAKDOWN' in location_part:
                    continue
                
                # Split the value by | to get individual values
                values = [v.strip() for v in value.split(' | ')]
                
                # Determine serve type based on table type
                if table_type == '1':
                    serve_type = "first serves"
                elif table_type == '2':
                    serve_type = "second serves"
                else:
                    serve_type = "serves"
                
                # Convert location to proper description
                if 'Deuce Court' in location_part:
                    location_desc = "to the Deuce court"
                elif 'Ad Court' in location_part:
                    location_desc = "to the Ad court"
                else:
                    location_desc = location_part.lower()
                
                # Extract stats (similar to the serve table conversion)
                if len(values) >= 8:
                    total_pts = values[0]
                    won_pts = values[1]
                    aces = values[2]
                    unreturned = values[3]
                    forced_errors = values[4]
                    won_3_or_less = values[5]
                    first_serves_in = values[6]
                    double_faults = values[7]
                    
                    # Create detailed descriptions
                    if total_pts and total_pts != "0":
                        text.append(f"{player} served {location_desc} {total_pts} times ({serve_type}).")
                        
                        # Points won
                        if won_pts and won_pts != "0":
                            if "(" in won_pts and ")" in won_pts:
                                percentage = won_pts.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} served {location_desc} and won {won_pts.split('(')[0].strip()} points, or {percentage}% of total points served {location_desc} by {player}.")
                            else:
                                text.append(f"{player} served {location_desc} and won {won_pts} points, or {won_pts}% of total points served {location_desc} by {player}.")
                        
                        # Aces
                        if aces and aces != "0":
                            if "(" in aces and ")" in aces:
                                percentage = aces.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} hit {aces.split('(')[0].strip()} aces served {location_desc}, or {percentage}% of total points served {location_desc} by {player}.")
                            else:
                                text.append(f"{player} hit {aces} aces served {location_desc}, or {aces}% of total points served {location_desc} by {player}.")
                        
                        # Unreturned serves
                        if unreturned and unreturned != "0":
                            if "(" in unreturned and ")" in unreturned:
                                percentage = unreturned.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} had {unreturned.split('(')[0].strip()} unreturned serves served {location_desc}, or {percentage}% of total points served {location_desc} by {player}.")
                            else:
                                text.append(f"{player} had {unreturned} unreturned serves served {location_desc}, or {unreturned}% of total points served {location_desc} by {player}.")
                        
                        # Forced errors
                        if forced_errors and forced_errors != "0":
                            if "(" in forced_errors and ")" in forced_errors:
                                percentage = forced_errors.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} forced {forced_errors.split('(')[0].strip()} errors from her opponent on serves {location_desc}, or {percentage}% of total points served {location_desc} by {player}.")
                            else:
                                text.append(f"{player} forced {forced_errors} errors from her opponent on serves {location_desc}, or {forced_errors}% of total points served {location_desc} by {player}.")
                        
                        # Points won in 3 shots or less
                        if won_3_or_less and won_3_or_less != "0":
                            if "(" in won_3_or_less and ")" in won_3_or_less:
                                percentage = won_3_or_less.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} won {won_3_or_less.split('(')[0].strip()} points in 3 shots or less on serves {location_desc}, or {percentage}% of total points served {location_desc} by {player}.")
                            else:
                                text.append(f"{player} won {won_3_or_less} points in 3 shots or less on serves {location_desc}, or {won_3_or_less}% of total points served {location_desc} by {player}.")
                        
                        # First serves in
                        if first_serves_in and first_serves_in != "0":
                            if "(" in first_serves_in and ")" in first_serves_in:
                                percentage = first_serves_in.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} hit in {first_serves_in.split('(')[0].strip()} first serves served {location_desc}, or {percentage}% of first serves served {location_desc} by {player}.")
                            else:
                                text.append(f"{player} hit in {first_serves_in} first serves served {location_desc}, or {first_serves_in}% of first serves served {location_desc} by {player}.")
                        
                        # Double faults
                        if double_faults and double_faults != "0":
                            if "(" in double_faults and ")" in double_faults:
                                percentage = double_faults.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} served {location_desc} and had {double_faults.split('(')[0].strip()} double faults, or {percentage}% of serves {location_desc} by {player}.")
                            else:
                                text.append(f"{player} served {location_desc} and had {double_faults} double faults, or {double_faults}% of serves {location_desc} by {player}.")
        
        return text

    def _convert_flat_return_to_text(self, return_data: Dict[str, Any], player1: str, player2: str) -> List[str]:
        """Convert flat return data to natural language text"""
        text = []
        
        # Group by player
        return1_data = {k: v for k, v in return_data.items() if k.startswith('return1')}
        return2_data = {k: v for k, v in return_data.items() if k.startswith('return2')}
        
        if return1_data:
            text.append("RETURN1 STATISTICS (DETAILED):")
            text.append("-" * 32)
            text.extend(self._convert_flat_return_player_to_text(return1_data, player1))
            text.append("")
        
        if return2_data:
            text.append("RETURN2 STATISTICS (DETAILED):")
            text.append("-" * 32)
            text.extend(self._convert_flat_return_player_to_text(return2_data, player2))
            text.append("")
        
        return text

    def _convert_flat_return_player_to_text(self, return_data: Dict[str, Any], player: str) -> List[str]:
        """Convert flat return data for one player to natural language text"""
        text = []
        
        # TIER 1 (AUTHORITATIVE): Extract totals from "Total" row first
        total_returns = 0
        total_points_won = 0
        total_returnable = 0
        total_returnable_won = 0
        total_in_play = 0
        total_in_play_won = 0
        total_winners = 0
        
        # Find and process the "Total" row as authoritative source
        for key, value in return_data.items():
            if ' - ' in key and '_table' in key:
                return_type_part = key.split(' - ')[1].split('_table')[0]
                table_type = key.split('_table')[1]
                
                # Only process table1 (outcomes) and only the "Total" row
                if table_type == '1' and return_type_part.lower() == 'total':
                    values = [v.strip() for v in value.split(' | ')]
                    if len(values) >= 8:
                        try:
                            total_returns = int(values[0]) if values[0] and values[0] != "0" else 0
                            if "(" in values[1]:
                                total_points_won = int(values[1].split('(')[0].strip()) if values[1].split('(')[0].strip() else 0
                            if "(" in values[2]:
                                total_returnable = int(values[2].split('(')[0].strip()) if values[2].split('(')[0].strip() else 0
                            if "(" in values[3]:
                                total_returnable_won = int(values[3].split('(')[0].strip()) if values[3].split('(')[0].strip() else 0
                            if "(" in values[4]:
                                total_in_play = int(values[4].split('(')[0].strip()) if values[4].split('(')[0].strip() else 0
                            if "(" in values[5]:
                                total_in_play_won = int(values[5].split('(')[0].strip()) if values[5].split('(')[0].strip() else 0
                            if "(" in values[6]:
                                total_winners = int(values[6].split('(')[0].strip()) if values[6].split('(')[0].strip() else 0
                        except (ValueError, IndexError):
                            continue
                    break
        
        # Add authoritative summary (TIER 1)
        if total_returns > 0:
            text.append(f"AUTHORITATIVE TOTALS FOR {player.upper()} RETURNS:")
            text.append(f"{player} returned {total_returns} total serves.")
            text.append(f"{player} won {total_points_won} total return points.")
            text.append(f"{player} faced {total_returnable} total returnable serves (non-aces).")
            text.append(f"{player} won {total_returnable_won} total points on returnable serves.")
            text.append(f"{player} got {total_in_play} total returns in play.")
            text.append(f"{player} won {total_in_play_won} total points when returns were in play.")
            text.append(f"{player} hit {total_winners} total return winners.")
            text.append("")
            text.append("BREAKDOWN BY SERVE TYPE (these sum to totals above, do not add again):")
            text.append("")
        
        # Process each return breakdown
        for key, value in return_data.items():
            # Extract the return type and table type from the key
            # Format: "return1 - vs 1st Svs_table1" or "return1 - Deuce Court_table2"
            if ' - ' in key and '_table' in key:
                return_type_part = key.split(' - ')[1].split('_table')[0]
                table_type = key.split('_table')[1]
                
                # Skip header rows
                if 'OUTCOMES' in return_type_part or 'DEPTH' in return_type_part:
                    continue
                
                # Split the value by | to get individual values
                values = [v.strip() for v in value.split(' | ')]
                
                # Determine return type based on the return_type_part
                if 'vs 1st Svs' in return_type_part:
                    return_desc = "first serves"
                elif 'vs 2nd Svs' in return_type_part:
                    return_desc = "second serves"
                elif 'Deuce Court' in return_type_part:
                    return_desc = "serves from the Deuce court"
                elif 'Ad Court' in return_type_part:
                    return_desc = "serves from the Ad court"
                elif 'Wide serves' in return_type_part:
                    return_desc = "wide serves"
                elif 'Body serves' in return_type_part:
                    return_desc = "body serves"
                elif 'T serves' in return_type_part:
                    return_desc = "T serves"
                elif 'Deuce-Wide' in return_type_part:
                    return_desc = "wide serves from the Deuce court"
                elif 'Ad-Wide' in return_type_part:
                    return_desc = "wide serves from the Ad court"
                elif 'Deuce-Body' in return_type_part:
                    return_desc = "body serves from the Deuce court"
                elif 'Ad-Body' in return_type_part:
                    return_desc = "body serves from the Ad court"
                elif 'Deuce-T' in return_type_part:
                    return_desc = "T serves from the Deuce court"
                elif 'Ad-T' in return_type_part:
                    return_desc = "T serves from the Ad court"
                elif 'Forehand side' in return_type_part:
                    return_desc = "serves to the forehand side"
                elif 'Backhand side' in return_type_part:
                    return_desc = "serves to the backhand side"
                elif 'Flat/Topspin' in return_type_part:
                    return_desc = "flat or topspin serves"
                elif 'Slice/Chip' in return_type_part:
                    return_desc = "slice or chip serves"
                elif 'Svc Box' in return_type_part:
                    return_desc = "serves into the service box"
                elif 'Beh Svc Ln' in return_type_part:
                    return_desc = "serves behind the service line"
                elif 'Back qtr' in return_type_part:
                    return_desc = "serves to the back quarter"
                else:
                    return_desc = return_type_part.lower()
                
                # Handle table1 (outcomes) and table2 (depth) differently
                if table_type == '1':
                    # Table1: Outcomes data
                    if len(values) >= 8:
                        total_pts = values[0]
                        won_pts = values[1]
                        returnable = values[2]
                        returnable_won = values[3]
                        in_play = values[4]
                        in_play_won = values[5]
                        winners = values[6]
                        avg_rally = values[7]
                        
                        # Create detailed descriptions for outcomes
                        if total_pts and total_pts != "0":
                            # Remove "total" from the description when return_desc is "total"
                            if return_desc.lower() == "total":
                                text.append(f"{player} returned {total_pts} times.")
                            else:
                                text.append(f"{player} returned {return_desc} {total_pts} times.")
                            
                            # Points won
                            if won_pts and won_pts != "0":
                                if "(" in won_pts and ")" in won_pts:
                                    percentage = won_pts.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} returned {return_desc} and won {won_pts.split('(')[0].strip()} points, or {percentage}% of returns when {player} was returning.")
                                else:
                                    text.append(f"{player} returned {return_desc} and won {won_pts} points, or {won_pts}% of returns when {player} was returning.")
                            
                            # Returnable serves
                            if returnable and returnable != "0":
                                if "(" in returnable and ")" in returnable:
                                    percentage = returnable.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} got {returnable.split('(')[0].strip()} returnable serves when returning {return_desc}, or {percentage}% of serves when {player} was returning.")
                                else:
                                    text.append(f"{player} got {returnable} returnable serves when returning {return_desc}, or {returnable}% of serves when {player} was returning.")
                            
                            # Points won on returnable serves
                            if returnable_won and returnable_won != "0":
                                if "(" in returnable_won and ")" in returnable_won:
                                    percentage = returnable_won.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} won {returnable_won.split('(')[0].strip()} points on returnable serves when returning {return_desc}, or {percentage}% of returnable serves when {player} was returning.")
                                else:
                                    text.append(f"{player} won {returnable_won} points on returnable serves when returning {return_desc}, or {returnable_won}% of returnable serves when {player} was returning.")
                            
                            # Returns in play
                            if in_play and in_play != "0":
                                if "(" in in_play and ")" in in_play:
                                    percentage = in_play.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} got {in_play.split('(')[0].strip()} returns in play when returning {return_desc}, or {percentage}% of returns when {player} was returning.")
                                else:
                                    text.append(f"{player} got {in_play} returns in play when returning {return_desc}, or {in_play}% of returns when {player} was returning.")
                            
                            # Points won on returns in play
                            if in_play_won and in_play_won != "0":
                                if "(" in in_play_won and ")" in in_play_won:
                                    percentage = in_play_won.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} won {in_play_won.split('(')[0].strip()} points on returns in play when returning {return_desc}, or {percentage}% of returns in play when {player} was returning.")
                                else:
                                    text.append(f"{player} won {in_play_won} points on returns in play when returning {return_desc}, or {in_play_won}% of returns in play when {player} was returning.")
                            
                            # Winners
                            if winners and winners != "0":
                                if "(" in winners and ")" in winners:
                                    percentage = winners.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} hit {winners.split('(')[0].strip()} winners when returning {return_desc}, or {percentage}% of returns when {player} was returning.")
                                else:
                                    text.append(f"{player} hit {winners} winners when returning {return_desc}, or {winners}% of returns when {player} was returning.")
                            
                            # Average rally length
                            if avg_rally and avg_rally != "0":
                                text.append(f"{player} had an average rally length of {avg_rally} shots when returning {return_desc}.")
                
                elif table_type == '2':
                    # Table2: Depth data
                    if len(values) >= 9:
                        returnable = values[0]
                        shallow = values[1]
                        deep = values[2]
                        very_deep = values[3]
                        unforced_errors = values[4]
                        net_approaches = values[5]
                        deep_returns = values[6]
                        wide_returns = values[7]
                        wide_and_deep = values[8]
                        
                        # Create detailed descriptions for depth
                        if returnable and returnable != "0":
                            # Remove "returning {return_desc}" when return_desc is "total"
                            if return_desc.lower() == "total":
                                text.append(f"{player} had {returnable} returnable serves.")
                            else:
                                text.append(f"{player} had {returnable} returnable serves when returning {return_desc}.")
                            
                            # Shallow returns
                            if shallow and shallow != "0":
                                if "(" in shallow and ")" in shallow:
                                    percentage = shallow.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} hit {shallow.split('(')[0].strip()} shallow returns when returning {return_desc}, or {percentage}% of returnable serves when {player} was returning.")
                                else:
                                    text.append(f"{player} hit {shallow} shallow returns when returning {return_desc}.")
                            
                            # Deep returns
                            if deep and deep != "0":
                                if "(" in deep and ")" in deep:
                                    percentage = deep.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} hit {deep.split('(')[0].strip()} deep returns when returning {return_desc}, or {percentage}% of returnable serves when {player} was returning.")
                                else:
                                    text.append(f"{player} hit {deep} deep returns when returning {return_desc}.")
                            
                            # Very deep returns
                            if very_deep and very_deep != "0":
                                if "(" in very_deep and ")" in very_deep:
                                    percentage = very_deep.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} hit {very_deep.split('(')[0].strip()} very deep returns when returning {return_desc}, or {percentage}% of returnable serves when {player} was returning.")
                                else:
                                    text.append(f"{player} hit {very_deep} very deep returns when returning {return_desc}.")
                            
                            # Unforced errors
                            if unforced_errors and unforced_errors != "0":
                                if "(" in unforced_errors and ")" in unforced_errors:
                                    percentage = unforced_errors.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} made {unforced_errors.split('(')[0].strip()} unforced errors when returning {return_desc}, or {percentage}% of returnable serves when {player} was returning.")
                                else:
                                    text.append(f"{player} made {unforced_errors} unforced errors when returning {return_desc}.")
                            
                            # Net approaches
                            if net_approaches and net_approaches != "0":
                                if "(" in net_approaches and ")" in net_approaches:
                                    percentage = net_approaches.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} made {net_approaches.split('(')[0].strip()} net approaches when returning {return_desc}, or {percentage}% of returnable serves when {player} was returning.")
                                else:
                                    text.append(f"{player} made {net_approaches} net approaches when returning {return_desc}.")
                            
                            # Deep returns (from depth column)
                            if deep_returns and deep_returns != "0":
                                if "(" in deep_returns and ")" in deep_returns:
                                    percentage = deep_returns.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} hit {deep_returns.split('(')[0].strip()} deep returns when returning {return_desc}, or {percentage}% of returnable serves when {player} was returning.")
                                else:
                                    text.append(f"{player} hit {deep_returns} deep returns when returning {return_desc}.")
                            
                            # Wide returns
                            if wide_returns and wide_returns != "0":
                                if "(" in wide_returns and ")" in wide_returns:
                                    percentage = wide_returns.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} hit {wide_returns.split('(')[0].strip()} wide returns when returning {return_desc}, or {percentage}% of returnable serves when {player} was returning.")
                                else:
                                    text.append(f"{player} hit {wide_returns} wide returns when returning {return_desc}.")
                            
                            # Wide and deep returns
                            if wide_and_deep and wide_and_deep != "0":
                                if "(" in wide_and_deep and ")" in wide_and_deep:
                                    percentage = wide_and_deep.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} hit {wide_and_deep.split('(')[0].strip()} wide and deep returns when returning {return_desc}, or {percentage}% of returnable serves when {player} was returning.")
                                else:
                                    text.append(f"{player} hit {wide_and_deep} wide and deep returns when returning {return_desc}.")
        
        return text

    def _convert_flat_keypoints_to_text(self, keypoints_data: Dict[str, Any], player1: str, player2: str) -> List[str]:
        """Convert flat key points data to natural language text with hierarchy"""
        text = []
        
        # TIER 1 (AUTHORITATIVE): Extract key point totals as single source of truth
        player1_keypoints = {}
        player2_keypoints = {}
        
        # Group by table type
        table1_data = {k: v for k, v in keypoints_data.items() if '_table1' in k}
        table2_data = {k: v for k, v in keypoints_data.items() if '_table2' in k}
        
        # Extract authoritative totals from both tables
        if table1_data:
            player1_keypoints.update(self._extract_keypoints_totals(table1_data, player1))
        if table2_data:
            player1_keypoints.update(self._extract_keypoints_totals(table2_data, player1))
            
        if table1_data:
            player2_keypoints.update(self._extract_keypoints_totals(table1_data, player2))
        if table2_data:
            player2_keypoints.update(self._extract_keypoints_totals(table2_data, player2))
        
        # Add comprehensive authoritative summary (TIER 1)
        text.append("AUTHORITATIVE TOTALS FOR KEY POINTS:")
        text.append("-" * 35)
        
        # Extract comprehensive totals for both players
        player1_comprehensive = self._extract_comprehensive_keypoints_totals(table1_data, table2_data, player1)
        player2_comprehensive = self._extract_comprehensive_keypoints_totals(table1_data, table2_data, player2)
        
        if player1_comprehensive:
            text.append(f"{player1.upper()} KEY POINTS AUTHORITATIVE TOTALS:")
            text.append(f"{player1} faced {player1_comprehensive['total_break_points_faced']} break points total.")
            text.append(f"{player1} faced {player1_comprehensive['total_game_points_faced']} game points total.")
            text.append(f"{player1} faced {player1_comprehensive['break_points_faced_serving']} break points while serving and won {player1_comprehensive['break_points_won_serving']} of them.")
            text.append(f"{player1} faced {player1_comprehensive['break_points_faced_returning']} break points while returning and won {player1_comprehensive['break_points_won_returning']} of them.")
            text.append(f"{player1} faced {player1_comprehensive['game_points_faced_serving']} game points while serving and won {player1_comprehensive['game_points_won_serving']} of them.")
            text.append(f"{player1} faced {player1_comprehensive['game_points_faced_returning']} game points while returning and won {player1_comprehensive['game_points_won_returning']} of them.")
            text.append(f"{player1} played {player1_comprehensive['deuce_points_serving']} deuce points while serving and won {player1_comprehensive['deuce_points_won_serving']} of them.")
            text.append(f"{player1} played {player1_comprehensive['deuce_points_returning']} deuce points while returning and won {player1_comprehensive['deuce_points_won_returning']} of them.")
            text.append("")
        
        if player2_comprehensive:
            text.append(f"{player2.upper()} KEY POINTS AUTHORITATIVE TOTALS:")
            text.append(f"{player2} faced {player2_comprehensive['total_break_points_faced']} break points total.")
            text.append(f"{player2} faced {player2_comprehensive['total_game_points_faced']} game points total.")
            text.append(f"{player2} faced {player2_comprehensive['break_points_faced_serving']} break points while serving and won {player2_comprehensive['break_points_won_serving']} of them.")
            text.append(f"{player2} faced {player2_comprehensive['break_points_faced_returning']} break points while returning and won {player2_comprehensive['break_points_won_returning']} of them.")
            text.append(f"{player2} faced {player2_comprehensive['game_points_faced_serving']} game points while serving and won {player2_comprehensive['game_points_won_serving']} of them.")
            text.append(f"{player2} faced {player2_comprehensive['game_points_faced_returning']} game points while returning and won {player2_comprehensive['game_points_won_returning']} of them.")
            text.append(f"{player2} played {player2_comprehensive['deuce_points_serving']} deuce points while serving and won {player2_comprehensive['deuce_points_won_serving']} of them.")
            text.append(f"{player2} played {player2_comprehensive['deuce_points_returning']} deuce points while returning and won {player2_comprehensive['deuce_points_won_returning']} of them.")
            text.append("")
        
        text.append("DETAILED KEY POINTS BREAKDOWN (these are contextual details, not for recalculating totals):")
        text.append("")
        
        # Process detailed breakdowns (TIER 2)
        if table1_data:
            text.append("KEY POINTS STATISTICS (SERVES):")
            text.append("-" * 32)
            # Include authoritative totals at the beginning of serves section
            text.append("AUTHORITATIVE TOTALS FOR KEY POINTS:")
            text.append("-" * 35)
            if player1_comprehensive:
                text.append(f"{player1.upper()} KEY POINTS AUTHORITATIVE TOTALS:")
                text.append(f"{player1} faced {player1_comprehensive['total_break_points_faced']} break points total.")
                text.append(f"{player1} faced {player1_comprehensive['total_game_points_faced']} game points total.")
                text.append(f"{player1} faced {player1_comprehensive['break_points_faced_serving']} break points while serving and won {player1_comprehensive['break_points_won_serving']} of them.")
                text.append(f"{player1} faced {player1_comprehensive['break_points_faced_returning']} break points while returning and won {player1_comprehensive['break_points_won_returning']} of them.")
                text.append(f"{player1} faced {player1_comprehensive['game_points_faced_serving']} game points while serving and won {player1_comprehensive['game_points_won_serving']} of them.")
                text.append(f"{player1} faced {player1_comprehensive['game_points_faced_returning']} game points while returning and won {player1_comprehensive['game_points_won_returning']} of them.")
                text.append(f"{player1} played {player1_comprehensive['deuce_points_serving']} deuce points while serving and won {player1_comprehensive['deuce_points_won_serving']} of them.")
                text.append(f"{player1} played {player1_comprehensive['deuce_points_returning']} deuce points while returning and won {player1_comprehensive['deuce_points_won_returning']} of them.")
                text.append("")
            if player2_comprehensive:
                text.append(f"{player2.upper()} KEY POINTS AUTHORITATIVE TOTALS:")
                text.append(f"{player2} faced {player2_comprehensive['total_break_points_faced']} break points total.")
                text.append(f"{player2} faced {player2_comprehensive['total_game_points_faced']} game points total.")
                text.append(f"{player2} faced {player2_comprehensive['break_points_faced_serving']} break points while serving and won {player2_comprehensive['break_points_won_serving']} of them.")
                text.append(f"{player2} faced {player2_comprehensive['break_points_faced_returning']} break points while returning and won {player2_comprehensive['break_points_won_returning']} of them.")
                text.append(f"{player2} faced {player2_comprehensive['game_points_faced_serving']} game points while serving and won {player2_comprehensive['game_points_won_serving']} of them.")
                text.append(f"{player2} faced {player2_comprehensive['game_points_faced_returning']} game points while returning and won {player2_comprehensive['game_points_won_returning']} of them.")
                text.append(f"{player2} played {player2_comprehensive['deuce_points_serving']} deuce points while serving and won {player2_comprehensive['deuce_points_won_serving']} of them.")
                text.append(f"{player2} played {player2_comprehensive['deuce_points_returning']} deuce points while returning and won {player2_comprehensive['deuce_points_won_returning']} of them.")
                text.append("")
            text.append("DETAILED KEY POINTS BREAKDOWN (these are contextual details, not for recalculating totals):")
            text.append("")
            text.extend(self._convert_flat_keypoints_table_to_text(table1_data, "serves"))
            text.append("")
        
        if table2_data:
            text.append("KEY POINTS STATISTICS (RETURNS):")
            text.append("-" * 33)
            # Include authoritative totals at the beginning of returns section
            text.append("AUTHORITATIVE TOTALS FOR KEY POINTS:")
            text.append("-" * 35)
            if player1_comprehensive:
                text.append(f"{player1.upper()} KEY POINTS AUTHORITATIVE TOTALS:")
                text.append(f"{player1} faced {player1_comprehensive['total_break_points_faced']} break points total.")
                text.append(f"{player1} faced {player1_comprehensive['total_game_points_faced']} game points total.")
                text.append(f"{player1} faced {player1_comprehensive['break_points_faced_serving']} break points while serving and won {player1_comprehensive['break_points_won_serving']} of them.")
                text.append(f"{player1} faced {player1_comprehensive['break_points_faced_returning']} break points while returning and won {player1_comprehensive['break_points_won_returning']} of them.")
                text.append(f"{player1} faced {player1_comprehensive['game_points_faced_serving']} game points while serving and won {player1_comprehensive['game_points_won_serving']} of them.")
                text.append(f"{player1} faced {player1_comprehensive['game_points_faced_returning']} game points while returning and won {player1_comprehensive['game_points_won_returning']} of them.")
                text.append(f"{player1} played {player1_comprehensive['deuce_points_serving']} deuce points while serving and won {player1_comprehensive['deuce_points_won_serving']} of them.")
                text.append(f"{player1} played {player1_comprehensive['deuce_points_returning']} deuce points while returning and won {player1_comprehensive['deuce_points_won_returning']} of them.")
                text.append("")
            if player2_comprehensive:
                text.append(f"{player2.upper()} KEY POINTS AUTHORITATIVE TOTALS:")
                text.append(f"{player2} faced {player2_comprehensive['total_break_points_faced']} break points total.")
                text.append(f"{player2} faced {player2_comprehensive['total_game_points_faced']} game points total.")
                text.append(f"{player2} faced {player2_comprehensive['break_points_faced_serving']} break points while serving and won {player2_comprehensive['break_points_won_serving']} of them.")
                text.append(f"{player2} faced {player2_comprehensive['break_points_faced_returning']} break points while returning and won {player2_comprehensive['break_points_won_returning']} of them.")
                text.append(f"{player2} faced {player2_comprehensive['game_points_faced_serving']} game points while serving and won {player2_comprehensive['game_points_won_serving']} of them.")
                text.append(f"{player2} faced {player2_comprehensive['game_points_faced_returning']} game points while returning and won {player2_comprehensive['game_points_won_returning']} of them.")
                text.append(f"{player2} played {player2_comprehensive['deuce_points_serving']} deuce points while serving and won {player2_comprehensive['deuce_points_won_serving']} of them.")
                text.append(f"{player2} played {player2_comprehensive['deuce_points_returning']} deuce points while returning and won {player2_comprehensive['deuce_points_won_returning']} of them.")
                text.append("")
            text.append("DETAILED KEY POINTS BREAKDOWN (these are contextual details, not for recalculating totals):")
            text.append("")
            text.extend(self._convert_flat_keypoints_table_to_text(table2_data, "returns"))
            text.append("")
        
        return text

    def _generate_player_initials(self, player_name: str) -> str:
        """Generate player initials from full name"""
        if not player_name:
            return ""
        words = player_name.split()
        if len(words) >= 2:
            return words[0][0].upper() + words[1][0].upper()
        elif len(words) == 1:
            return words[0][:2].upper()
        return ""

    def _extract_keypoints_totals(self, keypoints_data: Dict[str, Any], player: str) -> Dict[str, str]:
        """Extract authoritative totals from key points statistics"""
        totals = {}
        
        # Generate player initials dynamically
        player_initials = self._generate_player_initials(player)
        
        # Find the header row
        header_key = None
        for key in keypoints_data.keys():
            if 'KEY POINTS:' in key:
                header_key = key
                break
        
        if header_key:
            headers = [h.strip() for h in keypoints_data[header_key].split(' | ')]
            
            # Process each data row to find player-specific totals
            for key, value in keypoints_data.items():
                if key != header_key and 'KEY POINTS:' not in key:
                    # Extract the row label
                    row_label = key.split(' - ', 1)[1] if ' - ' in key else key
                    
                    # Check if this row belongs to the target player using dynamic initials
                    if (player_initials in row_label) or (player in row_label):
                        
                        values = [v.strip() for v in value.split(' | ')]
                        
                        # Extract totals based on row type
                        if 'BP Faced' in row_label or 'Break Points' in row_label:
                            if len(values) >= 1:
                                totals['break_points_faced'] = values[0]
                            if len(values) >= 2:
                                totals['break_points_converted'] = values[1]
                        elif 'Game Pts' in row_label or 'Game Points' in row_label:
                            if len(values) >= 1:
                                totals['game_points'] = values[0]
                        elif 'Set Points' in row_label:
                            if len(values) >= 1:
                                totals['set_points'] = values[0]
                        elif 'Match Points' in row_label:
                            if len(values) >= 1:
                                totals['match_points'] = values[0]
        
        return totals
    
    def _extract_comprehensive_keypoints_totals(self, serves_data: Dict[str, Any], returns_data: Dict[str, Any], player: str) -> Dict[str, str]:
        """Extract comprehensive key points totals from both serves and returns tables"""
        comprehensive = {
            'total_break_points_faced': '0',
            'total_game_points_faced': '0',
            'break_points_faced_serving': '0',
            'break_points_won_serving': '0',
            'break_points_faced_returning': '0',
            'break_points_won_returning': '0',
            'game_points_faced_serving': '0',
            'game_points_won_serving': '0',
            'game_points_faced_returning': '0',
            'game_points_won_returning': '0',
            'deuce_points_serving': '0',
            'deuce_points_won_serving': '0',
            'deuce_points_returning': '0',
            'deuce_points_won_returning': '0'
        }
        
        # Extract from serves table (when player is serving)
        if serves_data:
            serves_totals = self._extract_keypoints_from_table(serves_data, player, "serves")
            comprehensive.update(serves_totals)
        
        # Extract from returns table (when player is returning)
        if returns_data:
            returns_totals = self._extract_keypoints_from_table(returns_data, player, "returns")
            comprehensive.update(returns_totals)
        
        # Calculate totals
        try:
            bp_serving_faced = int(comprehensive['break_points_faced_serving'])
            bp_returning_faced = int(comprehensive['break_points_faced_returning'])
            comprehensive['total_break_points_faced'] = str(bp_serving_faced + bp_returning_faced)
            
            gp_serving_faced = int(comprehensive['game_points_faced_serving'])
            gp_returning_faced = int(comprehensive['game_points_faced_returning'])
            comprehensive['total_game_points_faced'] = str(gp_serving_faced + gp_returning_faced)
            
            # Deuce points should be extracted from the data above
        except (ValueError, TypeError):
            pass
        
        return comprehensive
    
    def _extract_keypoints_from_table(self, table_data: Dict[str, Any], player: str, table_type: str) -> Dict[str, str]:
        """Extract key points data from a specific table (serves or returns)"""
        totals = {}
        
        # Generate player initials dynamically
        player_initials = self._generate_player_initials(player)
        
        # Find the header row
        header_key = None
        for key in table_data.keys():
            if 'KEY POINTS:' in key:
                header_key = key
                break
        
        if not header_key:
            return totals
        
        headers = [h.strip() for h in table_data[header_key].split(' | ')]
        
        # Process each data row to find player-specific data
        for key, value in table_data.items():
            if key != header_key and 'KEY POINTS:' not in key:
                # Extract the row label
                row_label = key.split(' - ', 1)[1] if ' - ' in key else key
                
                # Check if this row belongs to the target player using dynamic initials
                if player_initials in row_label:
                    
                    values = [v.strip() for v in value.split(' | ')]
                    
                    # Extract data based on row type and table type
                    if 'BP Faced' in row_label or 'BP Opps' in row_label:
                        if len(values) >= 1:
                            if table_type == "serves":
                                totals['break_points_faced_serving'] = values[0]
                            else:  # returns
                                totals['break_points_faced_returning'] = values[0]
                        if len(values) >= 2:
                            if table_type == "serves":
                                totals['break_points_won_serving'] = values[1].split('(')[0].strip()
                            else:  # returns
                                totals['break_points_won_returning'] = values[1].split('(')[0].strip()
                    
                    elif 'Game Pts' in row_label or 'GP Faced' in row_label:
                        if len(values) >= 1:
                            if table_type == "serves":
                                totals['game_points_faced_serving'] = values[0]
                            else:  # returns
                                totals['game_points_faced_returning'] = values[0]
                        if len(values) >= 2:
                            if table_type == "serves":
                                totals['game_points_won_serving'] = values[1].split('(')[0].strip()
                            else:  # returns
                                totals['game_points_won_returning'] = values[1].split('(')[0].strip()
                    
                    elif 'Svg Deuce' in row_label or 'Ret Deuce' in row_label:
                        if len(values) >= 1:
                            if table_type == "serves":
                                totals['deuce_points_serving'] = values[0]
                            else:  # returns
                                totals['deuce_points_returning'] = values[0]
                        if len(values) >= 2:
                            if table_type == "serves":
                                totals['deuce_points_won_serving'] = values[1].split('(')[0].strip()
                            else:  # returns
                                totals['deuce_points_won_returning'] = values[1].split('(')[0].strip()
        
        return totals

    def _convert_flat_keypoints_table_to_text(self, keypoints_data: Dict[str, Any], table_type: str) -> List[str]:
        """Convert flat key points table data to natural language text"""
        text = []
        
        # Find the header row
        header_key = None
        for key in keypoints_data.keys():
            if 'KEY POINTS:' in key:
                header_key = key
                break
        
        if header_key:
            headers = keypoints_data[header_key].split(' | ')
            
            # Process each data row
            for key, value in keypoints_data.items():
                if key != header_key and 'KEY POINTS:' not in key:
                    # Extract the row label (remove the prefix like "keypoints - ")
                    row_label = key.split(' - ', 1)[1].split('_table')[0]
                    
                    # Split the value by | to get individual values
                    values = [v.strip() for v in value.split(' | ')]
                    
                    # Convert to sentences using the existing method
                    sentences = self._convert_keypoints_row_to_sentences(row_label, values, headers, table_type)
                    text.extend(sentences)
        
        return text

    def _convert_keypoints_row_to_sentences(self, row_label: str, values: List[str], headers: List[str], table_type: str) -> List[str]:
        """Convert key points row to natural language sentences"""
        sentences = []
        
        # Determine player from row label dynamically
        player = "Unknown Player"
        if self.player1 and self.player2:
            player1_initials = ''.join([word[0] for word in self.player1.split()]).upper()
            player2_initials = ''.join([word[0] for word in self.player2.split()]).upper()
            if player1_initials in row_label:
                player = self.player1
            elif player2_initials in row_label:
                player = self.player2
        
        # Determine key point type from row label and table type
        if table_type == "serves":
            # When table_type is "serves", the player is serving
            if 'BP Faced' in row_label:
                key_point_type = "break points faced when serving"
            elif 'BP Opps' in row_label:
                key_point_type = "break point opportunities when serving"
            elif 'Game Pts' in row_label:
                key_point_type = "game points when serving"
            elif 'GP Faced' in row_label:
                key_point_type = "game points faced when serving"
            elif 'Svg Deuce' in row_label:
                key_point_type = "deuce points when serving"
            elif 'Ret Deuce' in row_label:
                key_point_type = "deuce points when returning serves"
            elif 'Total' in row_label:
                key_point_type = f"total key points ({table_type})"
            else:
                key_point_type = "key points"
        else:
            # When table_type is "returns", the player is returning
            if 'BP Faced' in row_label:
                key_point_type = "break points faced when returning serves"
            elif 'BP Opps' in row_label:
                key_point_type = "break point opportunities when returning serves"
            elif 'Game Pts' in row_label:
                key_point_type = "game points when returning serves"
            elif 'GP Faced' in row_label:
                key_point_type = "game points faced when returning serves"
            elif 'Svg Deuce' in row_label:
                key_point_type = "deuce points when serving"
            elif 'Ret Deuce' in row_label:
                key_point_type = "deuce points when returning serves"
            elif 'Total' in row_label:
                key_point_type = f"total key points ({table_type})"
            else:
                key_point_type = "key points"
        
        # Convert each value to a sentence
        for i, value in enumerate(values):
            if i < len(headers) and value and value != "0":
                header = headers[i]
                
                if header == "Pts":
                    sentences.append(f"{player} played {value} {key_point_type}.")
                elif header == "PtsW----%":
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} won {number} {key_point_type}, or {percentage}% of {key_point_type} for {player}.")
                    else:
                        sentences.append(f"{player} won {value} {key_point_type}.")
                elif header == "1stIn---%":
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} made {number} first serves in on {key_point_type}, or {percentage}% of {key_point_type} for {player}.")
                    else:
                        sentences.append(f"{player} made {value} first serves in on {key_point_type}.")
                elif header == "A-------%":
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} hit {number} aces on {key_point_type}, or {percentage}% of {key_point_type} for {player}.")
                    else:
                        sentences.append(f"{player} hit {value} aces on {key_point_type}.")
                elif header == "SvWnr---%":
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} hit {number} serve winners on {key_point_type}, or {percentage}% of {key_point_type} for {player}.")
                    else:
                        sentences.append(f"{player} hit {value} serve winners on {key_point_type}.")
                elif header == "RlyWnr--%":
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} hit {number} rally winners on {key_point_type}, or {percentage}% of {key_point_type} for {player}.")
                    else:
                        sentences.append(f"{player} hit {value} rally winners on {key_point_type}.")
                elif header == "RlyFcd--%":
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} forced {number} errors on {key_point_type}, or {percentage}% of {key_point_type} for {player}.")
                    else:
                        sentences.append(f"{player} forced {value} errors on {key_point_type}.")
                elif header == "UFE-----%":
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} made {number} unforced errors on {key_point_type}, or {percentage}% of {key_point_type} for {player}.")
                    else:
                        sentences.append(f"{player} made {value} unforced errors on {key_point_type}.")
                elif header == "DF------%":
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} made {number} double faults on {key_point_type}, or {percentage}% of {key_point_type} for {player}.")
                    else:
                        sentences.append(f"{player} made {value} double faults on {key_point_type}.")
        
        return sentences

    def _convert_flat_overview_to_text(self, overview_data: Dict[str, Any], player1: str, player2: str) -> List[str]:
        """Convert flat overview data to natural language text with hierarchy"""
        text = []
        
        # TIER 1 (AUTHORITATIVE): Extract key totals from Overview as single source of truth
        player1_serve_stats = {}
        player2_serve_stats = {}
        
        # Generate player initials dynamically
        player1_initials = self._generate_player_initials(player1)
        player2_initials = self._generate_player_initials(player2)
        
        # Find the header row
        header_key = None
        for key in overview_data.keys():
            if 'STATS OVERVIEW' in key:
                header_key = key
                break
        
        if header_key:
            headers = [h.strip() for h in overview_data[header_key].split(' | ')]
            
            # Process each player's data to extract authoritative totals
            for key, value in overview_data.items():
                if key != header_key and 'STATS OVERVIEW' not in key:
                    # Extract the player name
                    player = key.split(' - ', 1)[1] if ' - ' in key else key
                    
                    # Split the value by | to get individual values
                    values = [v.strip() for v in value.split(' | ')]
                    
                    # Store authoritative totals using dynamic player detection
                    if player1 in player or player1_initials in player:
                        player1_serve_stats = self._extract_overview_totals(values, headers)
                    elif player2 in player or player2_initials in player:
                        player2_serve_stats = self._extract_overview_totals(values, headers)
        
        # Add authoritative summary (TIER 1)
        text.append("AUTHORITATIVE TOTALS FROM OVERVIEW STATISTICS:")
        text.append("-" * 45)
        
        if player1_serve_stats:
            text.append(f"{player1.upper()} AUTHORITATIVE TOTALS:")
            text.append(f"First serve percentage: {player1_serve_stats.get('first_serve_pct', 'N/A')}")
            text.append(f"Second serve won percentage: {player1_serve_stats.get('second_serve_won_pct', 'N/A')}")
            text.append(f"Ace percentage: {player1_serve_stats.get('ace_pct', 'N/A')}")
            text.append(f"Double fault percentage: {player1_serve_stats.get('df_pct', 'N/A')}")
            text.append(f"Break points saved: {player1_serve_stats.get('bp_saved', 'N/A')}")
            text.append(f"Return points won percentage: {player1_serve_stats.get('return_pct', 'N/A')}")
            text.append(f"Total winners: {player1_serve_stats.get('winners', 'N/A')}")
            text.append(f"Total unforced errors: {player1_serve_stats.get('ufe', 'N/A')}")
            text.append("")
        
        if player2_serve_stats:
            text.append(f"{player2.upper()} AUTHORITATIVE TOTALS:")
            text.append(f"First serve percentage: {player2_serve_stats.get('first_serve_pct', 'N/A')}")
            text.append(f"Second serve won percentage: {player2_serve_stats.get('second_serve_won_pct', 'N/A')}")
            text.append(f"Ace percentage: {player2_serve_stats.get('ace_pct', 'N/A')}")
            text.append(f"Double fault percentage: {player2_serve_stats.get('df_pct', 'N/A')}")
            text.append(f"Break points saved: {player2_serve_stats.get('bp_saved', 'N/A')}")
            text.append(f"Return points won percentage: {player2_serve_stats.get('return_pct', 'N/A')}")
            text.append(f"Total winners: {player2_serve_stats.get('winners', 'N/A')}")
            text.append(f"Total unforced errors: {player2_serve_stats.get('ufe', 'N/A')}")
            text.append("")
        
        text.append("DETAILED BREAKDOWN (these are contextual details, not for recalculating totals):")
        text.append("")
        
        # Process detailed breakdowns (TIER 2)
        if header_key:
            headers = [h.strip() for h in overview_data[header_key].split(' | ')]
            
            for key, value in overview_data.items():
                if key != header_key and 'STATS OVERVIEW' not in key:
                    # Extract the player name
                    player = key.split(' - ', 1)[1] if ' - ' in key else key
                    
                    # Split the value by | to get individual values
                    values = [v.strip() for v in value.split(' | ')]
                    
                    # Convert to sentences
                    sentences = self._convert_overview_row_to_sentences(player, values, headers)
                    text.extend(sentences)
        
        return text

    def _extract_overview_totals(self, values: List[str], headers: List[str]) -> Dict[str, str]:
        """Extract authoritative totals from overview statistics"""
        totals = {}
        
        for i, value in enumerate(values):
            if i < len(headers) and value and value != "0":
                header = headers[i]
                
                if header == "1stIn":
                    totals['first_serve_pct'] = value
                elif header == "2nd%":
                    totals['second_serve_won_pct'] = value
                elif header == "A%":
                    totals['ace_pct'] = value
                elif header == "DF%":
                    totals['df_pct'] = value
                elif header == "BPSaved":
                    totals['bp_saved'] = value
                elif header == "RPW%":
                    totals['return_pct'] = value
                elif header == "Winners (FH/BH)":
                    totals['winners'] = value
                elif header == "UFE (FH/BH)":
                    totals['ufe'] = value
        
        return totals

    def _convert_overview_row_to_sentences(self, player: str, values: List[str], headers: List[str]) -> List[str]:
        """Convert overview statistics row to natural language sentences"""
        sentences = []
        
        # Convert each value to a sentence
        for i, value in enumerate(values):
            if i < len(headers) and value and value != "0":
                header = headers[i]
                
                if header == "A%":
                    sentences.append(f"{player} had an ace percentage of {value}.")
                elif header == "DF%":
                    sentences.append(f"{player} had a double fault percentage of {value}.")
                elif header == "1stIn":
                    sentences.append(f"{player} had a first serve percentage of {value}.")
                elif header == "1st%":
                    sentences.append(f"{player} won {value} of first serves.")
                elif header == "2nd%":
                    sentences.append(f"{player} won {value} of second serves.")
                elif header == "BPSaved":
                    sentences.append(f"{player} saved {value} break points.")
                elif header == "RPW%":
                    sentences.append(f"{player} won {value} of return points.")
                elif header == "Winners (FH/BH)":
                    sentences.append(f"{player} hit {value} winners (forehand/backhand).")
                elif header == "UFE (FH/BH)":
                    sentences.append(f"{player} made {value} unforced errors (forehand/backhand).")
                else:
                    sentences.append(f"{player} had {header}: {value}.")
        
        return sentences

    def _convert_point_log_to_text(self, point_log: List[Dict[str, Any]], player1: str, player2: str) -> List[str]:
        """Convert point-by-point data to natural language text with shot attribution and point winner"""
        text = []
        text.append("POINT-BY-POINT NARRATIVE:")
        text.append("-" * 30)
        text.append("")
        
        for i, point in enumerate(point_log, 1):
            # Extract point information
            point_num = point.get('point_number') or point.get('point') or i
            server = point.get('server', '').strip()
            sets = point.get('sets', '')
            games = point.get('games', '')
            points_score = point.get('points', '')
            description = point.get('description', '')
            
            if not description:
                continue
            
            # Determine the returner dynamically
            returner = self._determine_returner(server, player1, player2)
            
            # Parse rally and add shot attribution
            rally_shots = self._parse_rally_sequence(description, server, returner)
            
            # Determine point winner
            point_winner = self._determine_point_winner(rally_shots, server, returner)
            
            # Build formatted point text with attribution
            header = f"Point {point_num} [Server: {server} | Returner: {returner} | Score: {sets} {games} {points_score}]:"
            
            # Format rally with player attribution after each shot
            rally_parts = []
            for shot in rally_shots:
                shot_desc = shot.get('description', '')
                shot_player = shot.get('player', '')
                if shot_desc:
                    rally_parts.append(f"{shot_desc} [{shot_player}]")
            
            rally_text = "; ".join(rally_parts) + "." if rally_parts else description
            
            # Add point winner
            winner_text = f" [Point won by: {point_winner}]" if point_winner else ""
            
            text.append(f"{header}")
            text.append(f"{rally_text}{winner_text}")
            text.append("")
        
        return text
    
    def _determine_returner(self, server: str, player1: str, player2: str) -> str:
        """Determine the returner based on server and player names"""
        if not server:
            return player2
        
        server_lower = server.lower()
        p1_lower = player1.lower()
        p2_lower = player2.lower()
        
        # Exact match
        if server_lower == p1_lower:
            return player2
        elif server_lower == p2_lower:
            return player1
        
        # Partial matching (first name, last name, etc.)
        if any(part in server_lower for part in p1_lower.split()) or any(part in p1_lower for part in server_lower.split()):
            return player2
        elif any(part in server_lower for part in p2_lower.split()) or any(part in p2_lower for part in server_lower.split()):
            return player1
        
        return player2  # Default fallback
    
    def _determine_point_winner(self, rally_shots: List[Dict], server: str, returner: str, 
                                  return_details: bool = False) -> str:
        """
        UNIFIED point winner determination - use this everywhere.
        
        Args:
            rally_shots: List of parsed shot dictionaries
            server: Server name
            returner: Returner name
            return_details: If True, returns (winner, shot_type, error_player) tuple
            
        Returns:
            If return_details=False: winner name (str) or None
            If return_details=True: (winner, shot_type, error_player) tuple
        """
        if not rally_shots:
            return (None, None, None) if return_details else None
        
        winner = None
        shot_type = None
        error_player = None
        
        # Check for double fault first
        for shot in rally_shots:
            outcome = shot.get('outcome', '')
            desc_lower = shot.get('description', '').lower()
            
            # Check for double fault (generic)
            if 'double fault' in desc_lower or (outcome and 'DOUBLE' in outcome.upper()):
                winner = returner
                shot_type = 'double_fault'
                error_player = server
                return (winner, shot_type, error_player) if return_details else winner
            if '2nd serve' in desc_lower and 'fault' in desc_lower and 'fault (' not in desc_lower:
                winner = returner
                shot_type = 'double_fault'
                error_player = server
                return (winner, shot_type, error_player) if return_details else winner
        
        # Find the last shot with a decisive outcome - GENERIC using OUTCOME_CONFIG
        for shot in reversed(rally_shots):
            outcome = shot.get('outcome', '')
            shot_player = shot.get('player', '')
            desc_lower = shot.get('description', '').lower()
            
            if outcome == 'FAULT':
                continue  # Skip serve faults, look for actual outcome
            
            # GENERIC outcome handling using OUTCOME_CONFIG
            outcome_config = self._get_outcome_config(outcome)
            if outcome_config:
                winning_shot_type = outcome_config.get('winning_shot_type', '')
                player_attribution = outcome_config.get('player_attribution', '')
                is_positive = outcome_config.get('is_positive', True)
                
                if winning_shot_type:
                    shot_type = winning_shot_type
                    
                    if player_attribution == 'server':
                        winner = server if is_positive else returner
                        error_player = server if not is_positive else None
                    elif player_attribution == 'winner':
                        winner = shot_player
                        error_player = None
                    elif player_attribution == 'error':
                        # Error player loses - opponent wins
                        winner = returner if shot_player == server else server
                        error_player = shot_player
                    else:
                        winner = shot_player
                        error_player = None
                    
                    return (winner, shot_type, error_player) if return_details else winner
            
            # FALLBACK: Check description for winner/error keywords
            if 'ace' in desc_lower:
                winner = shot_player
                shot_type = 'ace'
                return (winner, shot_type, None) if return_details else winner
            elif 'winner' in desc_lower:
                winner = shot_player
                shot_type = 'winner'
                return (winner, shot_type, None) if return_details else winner
            elif 'forced error' in desc_lower:
                winner = returner if shot_player == server else server
                shot_type = 'forced_error'
                error_player = shot_player
                return (winner, shot_type, error_player) if return_details else winner
            elif 'unforced error' in desc_lower or 'error' in desc_lower:
                winner = returner if shot_player == server else server
                shot_type = 'unforced_error'
                error_player = shot_player
                return (winner, shot_type, error_player) if return_details else winner
        
        return (None, None, None) if return_details else None

    def _convert_other_data_table(self, rows: List[Dict[str, Any]]) -> List[str]:
        """Convert other data table to natural language text"""
        text = []
        text.append("OTHER DATA STATISTICS:")
        text.append("-" * 20)
        
        for row in rows:
            label = row.get('label', '')
            values = row.get('values', [])
            
            if label == 'Match Result' and values:
                text.append(f"Match result: {values[0]}")
        
        return text

    def _convert_serve_table(self, table_name: str, rows: List[Dict[str, Any]]) -> List[str]:
        """Convert serve table to natural language text"""
        text = []
        
        # Determine player
        if 'serve1' in table_name.lower():
            player = self.player1 if self.player1 else "Player 1"
            text.append("SERVE1 STATISTICS:")
        elif 'serve2' in table_name.lower():
            player = self.player2 if self.player2 else "Player 2"
            text.append("SERVE2 STATISTICS:")
        else:
            player = "Unknown Player"
            text.append(f"{table_name.upper()} STATISTICS:")
        
        text.append("-" * len(text[-1]))
        
        # Find header row
        headers = []
        data_rows = []
        
        for row in rows:
            label = row.get('label', '')
            if 'BREAKDOWN' in label:
                headers = row.get('values', [])
            else:
                data_rows.append(row)
        
        # Convert data rows
        for row in data_rows:
            label = row.get('label', '')
            values = row.get('values', [])
            
            if label and values:
                # Determine serve location and type from the row label
                serve_location = label.lower()
                
                # Convert serve location to proper description
                if 'deuce court' in serve_location:
                    location_desc = "to the Deuce court"
                elif 'ad court' in serve_location:
                    location_desc = "to the Ad court"
                elif 'wide serves' in serve_location:
                    location_desc = "wide"
                elif 'body serves' in serve_location:
                    location_desc = "into the body"
                elif 't serves' in serve_location:
                    location_desc = "down the T"
                else:
                    location_desc = serve_location
                
                # Extract all available stats
                total_pts = values[0] if len(values) > 0 else "0"
                won_pts = values[1] if len(values) > 1 else "0"
                aces = values[2] if len(values) > 2 else "0"
                unreturned = values[3] if len(values) > 3 else "0"
                forced_errors = values[4] if len(values) > 4 else "0"
                won_3_or_less = values[5] if len(values) > 5 else "0"
                first_serves_in = values[6] if len(values) > 6 else "0"
                double_faults = values[7] if len(values) > 7 else "0"
                
                # Create detailed descriptions for each serve location
                if total_pts and total_pts != "0":
                    # Total serves
                    text.append(f"{player} served {location_desc} {total_pts} times.")
                    
                    # Points won
                    if won_pts and won_pts != "0":
                        if "(" in won_pts and ")" in won_pts:
                            percentage = won_pts.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} served {location_desc} and won {won_pts.split('(')[0].strip()} points, or {percentage}% of total points served {location_desc} by {player}.")
                        else:
                            text.append(f"{player} served {location_desc} and won {won_pts} points, or {won_pts}% of total points served {location_desc} by {player}.")
                    
                    # Aces
                    if aces and aces != "0":
                        if "(" in aces and ")" in aces:
                            percentage = aces.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} hit {aces.split('(')[0].strip()} aces served {location_desc}, or {percentage}% of total points served {location_desc} by {player}.")
                        else:
                            text.append(f"{player} hit {aces} aces served {location_desc}, or {aces}% of total points served {location_desc} by {player}.")
                    
                    # Unreturned serves
                    if unreturned and unreturned != "0":
                        if "(" in unreturned and ")" in unreturned:
                            percentage = unreturned.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} had {unreturned.split('(')[0].strip()} unreturned serves served {location_desc}, or {percentage}% of total points served {location_desc} by {player}.")
                        else:
                            text.append(f"{player} had {unreturned} unreturned serves served {location_desc}, or {unreturned}% of total points served {location_desc} by {player}.")
                    
                    # Forced errors
                    if forced_errors and forced_errors != "0":
                        if "(" in forced_errors and ")" in forced_errors:
                            percentage = forced_errors.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} forced {forced_errors.split('(')[0].strip()} errors from her opponent on serves {location_desc}, or {percentage}% of total points served {location_desc} by {player}.")
                        else:
                            text.append(f"{player} forced {forced_errors} errors from her opponent on serves {location_desc}, or {forced_errors}% of total points served {location_desc} by {player}.")
                    
                    # Points won in 3 shots or less
                    if won_3_or_less and won_3_or_less != "0":
                        if "(" in won_3_or_less and ")" in won_3_or_less:
                            percentage = won_3_or_less.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} won {won_3_or_less.split('(')[0].strip()} points in 3 shots or less on serves {location_desc}, or {percentage}% of total points served {location_desc} by {player}.")
                        else:
                            text.append(f"{player} won {won_3_or_less} points in 3 shots or less on serves {location_desc}, or {won_3_or_less}% of total points served {location_desc} by {player}.")
                    
                    # First serves in
                    if first_serves_in and first_serves_in != "0":
                        if "(" in first_serves_in and ")" in first_serves_in:
                            percentage = first_serves_in.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} hit in {first_serves_in.split('(')[0].strip()} first serves served {location_desc}, or {percentage}% of first serves served {location_desc} by {player}.")
                        else:
                            text.append(f"{player} hit in {first_serves_in} first serves served {location_desc}, or {first_serves_in}% of first serves served {location_desc} by {player}.")
                    
                    # Double faults
                    if double_faults and double_faults != "0":
                        if "(" in double_faults and ")" in double_faults:
                            percentage = double_faults.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} served {location_desc} and had {double_faults.split('(')[0].strip()} double faults, or {percentage}% of serves {location_desc} by {player}.")
                        else:
                            text.append(f"{player} served {location_desc} and had {double_faults} double faults, or {double_faults}% of serves {location_desc} by {player}.")
        
        return text

    def _convert_return_table(self, table_name: str, rows: List[Dict[str, Any]]) -> List[str]:
        """Convert return table to natural language text"""
        text = []
        
        # Determine player
        if 'return1' in table_name.lower():
            player = self.player1 if self.player1 else "Player 1"
            text.append("RETURN1 STATISTICS:")
        elif 'return2' in table_name.lower():
            player = self.player2 if self.player2 else "Player 2"
            text.append("RETURN2 STATISTICS:")
        else:
            player = "Unknown Player"
            text.append(f"{table_name.upper()} STATISTICS:")
        
        text.append("-" * len(text[-1]))
        
        # Find header row
        headers = []
        data_rows = []
        
        for row in rows:
            label = row.get('label', '')
            if 'BREAKDOWN' in label:
                headers = row.get('values', [])
            else:
                data_rows.append(row)
        
        # Convert data rows
        for row in data_rows:
            label = row.get('label', '')
            values = row.get('values', [])
            
            if label and values:
                # Determine return type
                return_type = label.lower()
                if '1st serve return' in return_type:
                    return_desc = "first serves"
                elif '2nd serve return' in return_type:
                    return_desc = "second serves"
                else:
                    return_desc = return_type
                
                # Extract all available stats
                total_pts = values[0] if len(values) > 0 else "0"
                won_pts = values[1] if len(values) > 1 else "0"
                in_play = values[2] if len(values) > 2 else "0"
                in_play_won = values[3] if len(values) > 3 else "0"
                winners = values[4] if len(values) > 4 else "0"
                forced_errors = values[5] if len(values) > 5 else "0"
                unforced_errors = values[6] if len(values) > 6 else "0"
                avg_rally = values[7] if len(values) > 7 else "0"
                
                # Create detailed descriptions for each return type
                if total_pts and total_pts != "0":
                    # Total returns
                    # Remove "total" from the description when return_desc is "total"
                    if return_desc.lower() == "total":
                        text.append(f"{player} returned {total_pts} times.")
                    else:
                        text.append(f"{player} returned {return_desc} {total_pts} times.")
                    
                    # Points won
                    if won_pts and won_pts != "0":
                        if "(" in won_pts and ")" in won_pts:
                            percentage = won_pts.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} returned {return_desc} and won {won_pts.split('(')[0].strip()} points, or {percentage}% of returns for {return_desc}.")
                        else:
                            text.append(f"{player} returned {return_desc} and won {won_pts} points, or {won_pts}% of returns for {return_desc}.")
                    
                    # Returns in play
                    if in_play and in_play != "0":
                        if "(" in in_play and ")" in in_play:
                            percentage = in_play.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} got {in_play.split('(')[0].strip()} returns in play, or {percentage}% of returns when {player} was returning.")
                        else:
                            text.append(f"{player} got {in_play} returns in play, or {in_play}% of returns when {player} was returning.")
                    
                    # Points won on returns in play
                    if in_play_won and in_play_won != "0":
                        if "(" in in_play_won and ")" in in_play_won:
                            percentage = in_play_won.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} won {in_play_won.split('(')[0].strip()} points on returns in play, or {percentage}% of returns in play when {player} was returning.")
                        else:
                            text.append(f"{player} won {in_play_won} points on returns in play, or {in_play_won}% of returns in play when {player} was returning.")
                    
                    # Winners
                    if winners and winners != "0":
                        if "(" in winners and ")" in winners:
                            percentage = winners.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} hit {winners.split('(')[0].strip()} winners on returns, or {percentage}% of returns when {player} was returning.")
                        else:
                            text.append(f"{player} hit {winners} winners on returns, or {winners}% of returns when {player} was returning.")
                    
                    # Forced errors
                    if forced_errors and forced_errors != "0":
                        if "(" in forced_errors and ")" in forced_errors:
                            percentage = forced_errors.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} forced {forced_errors.split('(')[0].strip()} errors on returns, or {percentage}% of returns when {player} was returning.")
                        else:
                            text.append(f"{player} forced {forced_errors} errors on returns, or {forced_errors}% of returns when {player} was returning.")
                    
                    # Unforced errors
                    if unforced_errors and unforced_errors != "0":
                        if "(" in unforced_errors and ")" in unforced_errors:
                            percentage = unforced_errors.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} made {unforced_errors.split('(')[0].strip()} unforced errors on returns, or {percentage}% of returns when {player} was returning.")
                        else:
                            text.append(f"{player} made {unforced_errors} unforced errors on returns, or {unforced_errors}% of returns when {player} was returning.")
                    
                    # Average rally length
                    if avg_rally and avg_rally != "0":
                        text.append(f"{player} had an average rally length of {avg_rally} shots when returning {return_desc}.")
        
        return text

    def _convert_keypoints_table(self, rows: List[Dict[str, Any]]) -> List[str]:
        """Convert key points table to natural language text"""
        text = []
        text.append("KEY POINTS STATISTICS:")
        text.append("-" * 22)
        
        # Find header row
        headers = []
        data_rows = []
        
        for row in rows:
            label = row.get('label', '')
            if 'KEY POINTS:' in label:
                headers = row.get('values', [])
            else:
                data_rows.append(row)
        
        # Convert data rows
        for row in data_rows:
            label = row.get('label', '')
            values = row.get('values', [])
            
            if label and values:
                # Determine player dynamically from initials
                player = "Unknown Player"
                if self.player1 and self.player2:
                    player1_initials = ''.join([word[0] for word in self.player1.split()]).upper()
                    player2_initials = ''.join([word[0] for word in self.player2.split()]).upper()
                    if player1_initials in label:
                        player = self.player1
                    elif player2_initials in label:
                        player = self.player2
                
                # Extract key stats
                total_pts = values[0] if len(values) > 0 else "0"
                won_pct = values[1] if len(values) > 1 else "0%"
                
                text.append(f"{player} played {total_pts} key points and won {won_pct} of them.")
        
        return text

    def _convert_serveneut_table(self, rows: List[Dict[str, Any]]) -> List[str]:
        """Convert serve neutral table to natural language text"""
        text = []
        text.append("SERVENEUT STATISTICS:")
        text.append("-" * 20)
        
        # Find header row
        headers = []
        data_rows = []
        
        for row in rows:
            label = row.get('label', '')
            if 'SERVE INFLUENCE' in label:
                headers = row.get('values', [])
            else:
                data_rows.append(row)
        
        # Convert data rows
        for row in data_rows:
            label = row.get('label', '')
            values = row.get('values', [])
            
            if label and values:
                # Determine player dynamically from initials
                player = "Unknown Player"
                if self.player1 and self.player2:
                    player1_initials = ''.join([word[0] for word in self.player1.split()]).upper()
                    player2_initials = ''.join([word[0] for word in self.player2.split()]).upper()
                    if player1_initials in label:
                        player = self.player1
                    elif player2_initials in label:
                        player = self.player2
                
                # Determine serve type
                if '1st Serve' in label:
                    serve_type = "first serves"
                elif '2nd Serve' in label:
                    serve_type = "second serves"
                else:
                    serve_type = "serves"
                
                # Extract key stats
                total_pts = values[0] if len(values) > 0 else "0"
                overall_pct = values[1] if len(values) > 1 else "0%"
                
                text.append(f"{player} served {total_pts} {serve_type} and won {overall_pct} of points overall.")
        
        return text

    def _convert_rallyoutcomes_table(self, rows: List[Dict[str, Any]], player1: str, player2: str) -> List[str]:
        """Convert rally outcomes table to natural language text"""
        text = []
        text.append("RALLY OUTCOMES STATISTICS:")
        text.append("-" * 26)
        
        # Generate player initials dynamically
        player1_initials = self._generate_player_initials(player1)
        player2_initials = self._generate_player_initials(player2)
        
        # Find header row
        headers = []
        data_rows = []
        
        for row in rows:
            label = row.get('label', '')
            if 'OUTCOMES' in label:
                headers = row.get('values', [])
            else:
                data_rows.append(row)
        
        # Convert data rows
        for row in data_rows:
            label = row.get('label', '')
            values = row.get('values', [])
            
            if label and values and len(values) >= 9:
                # Determine rally type and player context
                rally_type = label
                if 'Total' in label:
                    rally_type = "total rallies"
                elif 'All: 1-3' in label:
                    rally_type = "1-3 shot rallies"
                elif 'All: 4-6' in label:
                    rally_type = "4-6 shot rallies"
                elif 'All: 7-9' in label:
                    rally_type = "7-9 shot rallies"
                elif 'All: 10+' in label:
                    rally_type = "10+ shot rallies"
                elif f'{player1_initials} Sv:' in label:
                    rally_type = f"1-3 shot rallies on {player1} serves" if "1-3" in label else \
                               f"4-6 shot rallies on {player1} serves" if "4-6" in label else \
                               f"7-9 shot rallies on {player1} serves" if "7-9" in label else \
                               f"10+ shot rallies on {player1} serves" if "10+" in label else \
                               f"rallies on {player1} serves"
                elif f'{player2_initials} Sv:' in label:
                    rally_type = f"1-3 shot rallies on {player2} serves" if "1-3" in label else \
                               f"4-6 shot rallies on {player2} serves" if "4-6" in label else \
                               f"7-9 shot rallies on {player2} serves" if "7-9" in label else \
                               f"10+ shot rallies on {player2} serves" if "10+" in label else \
                               f"rallies on {player2} serves"
                
                # Extract stats for both players
                total_pts = values[0] if len(values) > 0 else "0"
                
                # Player 1 stats (columns 1-4) - strip percentages
                player1_wins = values[1].split('(')[0].strip() if len(values) > 1 and values[1] else "0"
                player1_winners = values[2].split('(')[0].strip() if len(values) > 2 and values[2] else "0"
                player1_forced_errors = values[3].split('(')[0].strip() if len(values) > 3 and values[3] else "0"
                player1_unforced_errors = values[4].split('(')[0].strip() if len(values) > 4 and values[4] else "0"
                
                # Player 2 stats (columns 5-8) - strip percentages
                player2_wins = values[5].split('(')[0].strip() if len(values) > 5 and values[5] else "0"
                player2_winners = values[6].split('(')[0].strip() if len(values) > 6 and values[6] else "0"
                player2_forced_errors = values[7].split('(')[0].strip() if len(values) > 7 and values[7] else "0"
                player2_unforced_errors = values[8].split('(')[0].strip() if len(values) > 8 and values[8] else "0"
                
                # Create sentences
                text.append(f"There were {total_pts} {rally_type} in the match.")
                
                # Add player-specific statistics
                if f'{player1_initials} Sv:' in label or f'{player2_initials} Sv:' in label:
                    # For player-specific rows, focus on that player's stats
                    if f'{player1_initials} Sv:' in label:
                        text.append(f"{player1} won {player1_wins} points and hit {player1_winners} winners on {rally_type}.")
                        text.append(f"{player1} had {player1_forced_errors} forced errors and made {player1_unforced_errors} unforced errors on {rally_type}.")
                    else:  # Player 2 Sv
                        text.append(f"{player2} won {player2_wins} points and hit {player2_winners} winners on {rally_type}.")
                        text.append(f"{player2} had {player2_forced_errors} forced errors and made {player2_unforced_errors} unforced errors on {rally_type}.")
                else:
                    # For total/all rows, show both players' stats
                    text.append(f"{player1} won {player1_wins} points and hit {player1_winners} winners on {rally_type}.")
                    text.append(f"{player1} had {player1_forced_errors} forced errors and made {player1_unforced_errors} unforced errors on {rally_type}.")
                    text.append(f"{player2} won {player2_wins} points and hit {player2_winners} winners on {rally_type}.")
                    text.append(f"{player2} had {player2_forced_errors} forced errors and made {player2_unforced_errors} unforced errors on {rally_type}.")
                
                text.append("")  # Add spacing between sections
        
        return text

    def _convert_overview_table(self, rows: List[Dict[str, Any]], player1: str, player2: str) -> List[str]:
        """Convert overview table to natural language text"""
        text = []
        text.append("OVERVIEW STATISTICS:")
        text.append("-" * 20)
        
        # Find header row
        headers = []
        data_rows = []
        
        for row in rows:
            label = row.get('label', '')
            if 'STATS OVERVIEW' in label:
                headers = row.get('values', [])
            else:
                data_rows.append(row)
        
        # Convert data rows
        for row in data_rows:
            label = row.get('label', '')
            values = row.get('values', [])
            
            if label and values:
                # Determine player
                if self.player1 and self.player1 in label:
                    player = self.player1
                elif self.player2 and self.player2 in label:
                    player = self.player2
                else:
                    # Try dynamic initials extraction as fallback
                    player = "Unknown Player"
                    if self.player1 and self.player2:
                        player1_initials = ''.join([word[0] for word in self.player1.split()]).upper()
                        player2_initials = ''.join([word[0] for word in self.player2.split()]).upper()
                        if player1_initials in label:
                            player = self.player1
                        elif player2_initials in label:
                            player = self.player2
                
                # Extract key stats
                ace_pct = values[0] if len(values) > 0 else "0%"
                df_pct = values[1] if len(values) > 1 else "0%"
                first_serve_pct = values[2] if len(values) > 2 else "0%"
                first_serve_won_pct = values[3] if len(values) > 3 else "0%"
                second_serve_won_pct = values[4] if len(values) > 4 else "0%"
                break_points_saved = values[5] if len(values) > 5 else "0"
                return_points_won_pct = values[6] if len(values) > 6 else "0%"
                winners = values[7] if len(values) > 7 else "0"
                unforced_errors = values[8] if len(values) > 8 else "0"
                
                text.append(f"{player} had {ace_pct} aces.")
                text.append(f"{player} had {df_pct} double faults.")
                text.append(f"{player} made {first_serve_pct} of first serves.")
                text.append(f"{player} won {first_serve_won_pct} of first serve points.")
                text.append(f"{player} won {second_serve_won_pct} of second serve points.")
                text.append(f"{player} saved {break_points_saved} break points.")
                text.append(f"{player} won {return_points_won_pct} of return points.")
                # Parse the winners and unforced errors to extract forehand/backhand breakdowns
                winners_total = winners.split(" (")[0] if " (" in winners else winners
                winners_fh_bh = winners.split("(")[1].split(")")[0] if "(" in winners else "0/0"
                winners_fh, winners_bh = winners_fh_bh.split("/") if "/" in winners_fh_bh else ("0", "0")
                
                ufe_total = unforced_errors.split(" (")[0] if " (" in unforced_errors else unforced_errors
                ufe_fh_bh = unforced_errors.split("(")[1].split(")")[0] if "(" in unforced_errors else "0/0"
                ufe_fh, ufe_bh = ufe_fh_bh.split("/") if "/" in ufe_fh_bh else ("0", "0")
                
                text.append(f"{player} hit {winners_total} winners, {winners_fh} forehand and {winners_bh} backhand.")
                text.append(f"{player} made {ufe_total} unforced errors, including {ufe_fh} on the forehand and {ufe_bh} on the backhand.")
        
        return text



    def _convert_generic_table(self, table_name: str, rows: List[Dict[str, Any]]) -> List[str]:
        """Convert generic table to natural language text"""
        text = []
        text.append(f"{table_name.upper()} STATISTICS:")
        text.append("-" * len(table_name + " STATISTICS"))
        
        for row in rows:
            label = row.get('label', '')
            values = row.get('values', [])
            
            if label and values:
                text.append(f"{label}: {', '.join(values)}")
        
        return text


