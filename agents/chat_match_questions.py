#!/usr/bin/env python3

import json
import os
import re
import numpy as np
import faiss
import pickle
from typing import Dict, List, Any, Optional
import tiktoken
import time
import pickle

class TennisChatAgentEmbeddingQALocal:
    """
    Tennis Chat Agent using LOCAL embedding model (sentence-transformers) and LLM for answering.
    Uses FREE local embeddings with sophisticated retrieval logic.
    Supports Gemini for answering questions.
    """
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # VAGUE TERM -> METRIC MAPPING SYSTEM
    # Converts "vague" analytical terms into computable metric bundles
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    # Step 1: Normalize synonyms to canonical tokens
    TERM_NORMALIZATION = {
        # Performance variants
        "perform": "performance", "performed": "performance", "performing": "performance",
        # Effectiveness variants
        "effective": "effectiveness", "ineffective": "effectiveness",
        # Efficiency variants
        "efficient": "efficiency", "inefficient": "efficiency",
        # Aggression variants
        "aggressive": "aggression", "aggressively": "aggression", "aggressor": "aggression",
        # Control variants
        "control": "control", "controlled": "control", "controlling": "control", "dictate": "control", "dictated": "control",
        # Consistency variants
        "consistent": "consistency", "consistently": "consistency", "inconsistent": "consistency",
        # Pressure variants
        "pressure": "pressure", "clutch": "pressure", "tight": "pressure",
        # Risk variants
        "risky": "risk", "risk-taking": "risk", "risks": "risk",
        # Momentum variants
        "momentum": "momentum", "shift": "momentum", "shifted": "momentum", "turning point": "momentum",
        # Dominance variants
        "dominant": "dominance", "dominated": "dominance", "dominate": "dominance", "dominating": "dominance",
    }
    
    # Step 2: Map canonical terms to metric bundles
    # Each term maps to context-specific metric bundles
    VAGUE_TERM_MAP = {
        "performance": {
            "description": "How well did outcomes align with opportunity?",
            "default": ["win_percentage", "winners", "unforced_errors"],
            "serve": ["first_serve_pct", "first_serve_win_pct", "second_serve_win_pct", "aces", "double_faults"],
            "return": ["return_points_won_pct", "return_winners", "break_point_conversion"],
            "rally": ["win_percentage", "winners", "forced_errors"],
        },
        "effectiveness": {
            "description": "Did an action produce the intended advantage?",
            "default": ["win_percentage", "forced_errors", "winners"],
            "serve": ["first_serve_win_pct", "second_serve_win_pct", "service_winners"],
            "return": ["return_points_won_pct", "return_winners"],
            "net": ["net_points_won_pct", "volley_winners"],
        },
        "efficiency": {
            "description": "How much value per unit effort?",
            "default": ["win_percentage", "avg_rally_length", "winners"],
            "serve": ["first_serve_pct", "aces", "service_winners"],
            "rally": ["win_percentage", "avg_rally_length", "short_rally_win_pct"],
        },
        "aggression": {
            "description": "Intent to shorten points and take risk.",
            "default": ["winners", "unforced_errors", "avg_rally_length"],
            "serve": ["aces", "first_serve_pct", "service_winners"],
            "rally": ["winners", "avg_rally_length", "net_approaches"],
            "net": ["net_points_won", "volley_winners"],
        },
        "control": {
            "description": "Who imposed structure on rallies?",
            "default": ["win_percentage", "long_rally_win_pct", "forced_errors"],
            "rally": ["win_percentage", "avg_rally_length", "forced_errors"],
            "serve": ["first_serve_pct", "first_serve_win_pct"],
        },
        "consistency": {
            "description": "Stability of execution over time.",
            "default": ["unforced_errors", "first_serve_pct", "win_percentage"],
            "serve": ["first_serve_pct", "double_faults", "first_serve_win_pct"],
            "rally": ["unforced_errors", "avg_rally_length"],
        },
        "pressure": {
            "description": "Performance under elevated leverage. 'Under pressure' includes all critical situations: break_point (0-40, 15-40, 30-40, AD-OUT), game_point (40-0, 40-15, 40-30, AD-IN), set_point, match_point, and deuce (40-40).",
            "default": ["win_percentage", "unforced_errors"],  # Applied to pressure situations
            "break_point": ["break_point_conversion", "break_point_saves", "win_percentage"],
            "game_point": ["win_percentage", "game_point_conversion"],
            "set_point": ["win_percentage", "set_point_conversion"],
            "match_point": ["win_percentage", "match_point_conversion"],
            "deuce": ["win_percentage", "deuce_points_won"],
            "serve": ["break_point_saves", "game_point_saves", "win_percentage"],
            "return": ["break_point_conversion", "game_point_conversion", "win_percentage"],
        },
        "risk": {
            "description": "Volatility vs payoff.",
            "default": ["winners", "unforced_errors"],
            "rally": ["winners", "unforced_errors", "avg_rally_length"],
        },
        "momentum": {
            "description": "Short-term outcome correlation.",
            "default": ["win_percentage"],  # Applied across sets/games
            "group_by": "sets",  # Force grouping by sets to show progression
        },
        "dominance": {
            "description": "Sustained advantage across contexts.",
            "default": ["win_percentage", "winners", "unforced_errors"],
            "serve": ["serve_points_won_pct", "aces"],
            "return": ["return_points_won_pct", "break_point_conversion"],
        },
    }
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # GLOBAL CONSTANTS - Used throughout the codebase
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    # All winner outcome types (referenced in multiple places)
    WINNER_TYPES = {
        'winner',           # Generic winner (groundstroke)
        'volley_winner',    # Winner at net via volley
        'specialty_winner', # Drop shot, lob, etc.
        'net_winner',       # Generic net winner
        'overhead_winner',  # Smash/overhead winner
        'drop_shot_winner', # Drop shot winner
    }
    
    # Metrics where "win rate" doesn't make sense (self-evident outcomes)
    SELF_EVIDENT_OUTCOME_METRICS = {
        'winners', 'groundstroke_winners', 'baseline_winners', 'rally_winners',
        'aces', 'service_winners',
        'unforced_errors', 'forced_errors', 'induced_forced_errors',
        'double_faults',
    }
    
    # Terms indicating "both players" (not a specific player filter)
    BOTH_PLAYER_INDICATORS = {
        'both', 'each', 'both players', 'each player', 'either player',
        'both player', 'which player', 'who', 'compare players', 
        'player comparison', 'players compared', 'each of the players',
        'all players', 'every player', 'per player', 'by player',
        'the players', 'comparison', 'compare',
    }
    
    # When grouping by X, exclude these filters (they're dimensions, not filters)
    GROUP_TO_FILTER_EXCLUSIONS = {
        'rally_length_category': ['rally_length'],
        'player': ['player'],
        'sets': ['set'],
        'set_groups': ['set'],
        'court_side': ['court_side'],
        'serve_number': ['serve_number'],
        'shot_type': ['shot_type', 'shot_base'],
        'serve_direction': ['serve_target'],
        'situation': ['situation'],
    }
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # OUTCOME CONFIGURATION - Maps outcome strings to their properties
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    OUTCOME_CONFIG = {
        'WINNER': {
            'winning_shot_type': 'winner',
            'point_ends_match': True,
            'player_attribution': 'winner',  # Who hit the shot
            'is_positive': True,  # Good for the player who hit it
        },
        'ACE': {
            'winning_shot_type': 'ace',
            'point_ends_match': True,
            'player_attribution': 'server',
            'is_positive': True,
        },
        'SERVICE_WINNER': {
            'winning_shot_type': 'service_winner',
            'point_ends_match': True,
            'player_attribution': 'server',
            'is_positive': True,
        },
        'DOUBLE_FAULT': {
            'winning_shot_type': 'double_fault',
            'point_ends_match': True,
            'player_attribution': 'server',
            'is_positive': False,  # Bad for server
        },
        'UNFORCED ERROR': {
            'winning_shot_type': 'unforced_error',
            'point_ends_match': True,
            'player_attribution': 'error',
            'is_positive': False,
        },
        'FORCED ERROR': {
            'winning_shot_type': 'forced_error',
            'point_ends_match': True,
            'player_attribution': 'error',
            'is_positive': False,
        },
    }
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ONE-SHOT-PER-POINT TYPES - Shot types that occur exactly once per point
    # These use point metadata and don't require rally parsing
    #
    # NOTE: METRIC_CONFIG['player_role'] indicates which shot type a metric uses:
    #   player_role='server' → metric about THE SERVE (uses serve_info metadata)
    #   player_role='returner' → metric about THE RETURN (uses return_info metadata)
    #   player_role='winner' → metric about THE WINNING SHOT (uses winning_shot metadata)
    #   player_role='error' → metric about THE ERROR SHOT (uses winning_shot metadata)
    #   player_role='performer' or 'both' → rally analysis (requires parsing multiple shots)
    #
    # "player_role" is a misnomer - it actually indicates DATA SOURCE (which shot type)
    ONE_SHOT_TYPES = {
        'server',    # SERVE shot - one per point
        'returner',  # RETURN shot - one per point
        'winner',    # WINNING shot - one per point
        'error'      # ERROR shot - one per point (also uses winning_shot metadata)
    }
    
    # TREE-LEVEL DIMENSIONS - Filters handled by tree (point-level metadata)
    # Used for: tree traversal, hybrid routing detection, filter promotion
    # Add new dimensions here to automatically support them throughout
    TREE_LEVEL_DIMENSIONS = {
        'situation',      # break_point, game_point, deuce, etc.
        'set',            # set number
        'point_score',    # 30-30, 15-40, etc.
        'serve_number',   # 1st or 2nd serve
        'serve_target',   # wide, body, T (serve that was in play)
        'serve_direction', # same as serve_target
        'return_depth',   # shallow, deep, very_deep (ONE per return point - in metadata)
        'court_side',     # deuce, ad
        'court_zone',     # net, baseline
        'rally_length',   # number of shots in rally
        'prev_rally_length',  # rally length of PREVIOUS point (for "after X" queries)
        'role',           # server, returner
        'game_number',    # game number overall
        'game_number_in_set',  # game number within set
        'point_number_range',  # (min, max) tuple for temporal/segment analysis
        'player',         # specific player (when not "both")
        'winning_shot_type',  # forehand, backhand, volley (shot that ended point - in metadata)
        'winning_shot_direction',  # crosscourt, DTL (direction of winning shot - in metadata)
        'winning_shot_outcome',  # winner, unforced_error, forced_error, ace, double_fault
        'serve_plus_one_type',  # forehand, backhand, none (shot after serve - in metadata)
    }
    
    # SHOT-LEVEL ATTRIBUTES - These are NOT tree dimensions, must NOT be in filters
    # These are attributes of individual shots within rallies, not point-level metadata
    SHOT_LEVEL_FIELDS = {
        'direction',      # crosscourt, down_the_line, inside_out, inside_in
        'shot_type',      # forehand, backhand (when used as filter, not grouping)
        'shot_modifier',  # slice, topspin, approach, volley
        'depth',          # shallow, deep, very_deep
        'shot_number',    # position in rally (1st shot, 2nd shot, etc.)
        'error_location', # where error was hit
        # New taxonomy fields (not yet used by tree)
        'shot_phase',     # serve, return, rally, net
        'contact_type',   # groundstroke, volley, half_volley, overhead
        'spin',           # slice, flat, topspin
        'intent',         # approach, drop_shot, lob, passing_shot, winner_attempt
        'location',       # baseline, mid_court, net, service_line
    }
    
    # GROUPING FIELDS - Top-level only, never in filters
    GROUPING_FIELDS = {
        'group_by',
        'secondary_group_by',
        'tertiary_group_by',
        'n_dimensional',
    }
    
    # COMPARISON STRUCTURES - Top-level only
    COMPARISON_FIELDS = {
        'set_comparison',
        'situation_comparison',
        'set_group_a',
        'set_group_b',
        'situation_group_a',
        'situation_group_b',
        'situation_group',
    }
    
    # TREE-SUPPORTED METRICS - What the tree can compute
    # Planner should only route to tree for these metrics
    TREE_SUPPORTED_METRICS = {
        # Basic point outcomes
        'points_won',
        'points_count',         # Total count of filtered points (denominator)
        'points_played',        # Alias for points_count (LLM sometimes generates this)
        'win_percentage',
        # Serve metrics
        'first_serve_pct',
        'first_serve_win_pct', 
        'second_serve_win_pct',
        'aces',
        'double_faults',
        'service_winners',      # Winners on serve (ace or service winner)
        'serve_points_won_pct', # Alias for first_serve_win_pct + second_serve_win_pct combined
        # Return metrics
        'return_points_won',
        'return_win_pct',
        'return_points_won_pct',  # Alias for return_win_pct
        'return_winners',       # Winners hit by returner
        # Situation metrics
        'break_points_won',
        'break_points_saved',
        'break_point_conversion',
        'break_point_saves',    # Alias for break_points_saved
        'game_point_conversion',
        'game_point_saves',
        'set_point_conversion',
        'match_point_conversion',
        'deuce_points_won',
        # Rally metrics
        'avg_rally_length',
        'short_rally_win_pct',  # Win% on rallies 0-4 shots
        'long_rally_win_pct',   # Win% on rallies 7+ shots
        # Net metrics
        'net_points_won',
        'net_points_won_pct',
        'net_approaches',
        'volley_winners',
        # Shot outcomes (point-ending)
        'winners',
        'unforced_errors',
        'forced_errors',
    }
    
    # REQUIRED_POINT_FIELDS - Fields that MUST be stored on each point during enrichment
    # These enable Query Plan to work WITHOUT re-parsing point text every time
    # If a field is missing, filtering/counting will fail silently (return 0)
    REQUIRED_POINT_FIELDS = {
        # Identity
        'point_number',         # Unique point identifier
        'server',               # Who served
        'returner',             # Who returned
        # Result
        'point_winner',         # Who won the point (CRITICAL for points_won metric)
        'error_player',         # Who made the error (for error metrics)
        # Game context
        'score',                # Point score (e.g., "1-0 3-2 30-15")
        'set_number',           # Current set number
        'game_number_in_set',   # Game number within current set
        # Serve info
        'serve_number',         # 1 or 2 (CRITICAL for 2nd serve queries)
        # Rally info  
        'rally_length',         # Number of shots in rally (excluding serve)
        # Winning shot info (stored as dict)
        'winning_shot',         # {shot_type, direction, outcome, at_net, shot_modifier}
    }
    
    # OPERATION TYPES - For planner to specify precise intent
    OPERATION_TYPES = {
        # Tree operations
        'tree_filter_only',      # Just filter points, return subset
        'tree_aggregate',        # Filter + compute metrics
        'tree_compare',          # Compare two filtered subsets
        # Narrative operations  
        'narrative_describe',    # Describe tactics/patterns
        'narrative_explain',     # Explain "why" something happened
        'narrative_timeline',    # Describe flow/momentum shifts
        # Meta operations
        'clarify',               # Ask user for clarification
        'combine_results',       # Synthesize multiple operation results
    }
    
    # DEBUG MODE - Toggle point details in output
    # Set to False for production/public output
    DEBUG_SHOW_POINTS = True
    
    # ═══════════════════════════════════════════════════════════════════════════
    # TERM MAPPINGS - Normalize user language to tree filters
    # ═══════════════════════════════════════════════════════════════════════════
    # These map common user terms to actual filter values
    # Used by LLM parse to expand/normalize user queries
    TERM_MAPPINGS = {
        # Rally length shortcuts
        'short rally': {'rally_length': '<=3'},
        'short rallies': {'rally_length': '<=3'},
        'long rally': {'rally_length': '>=7'},
        'long rallies': {'rally_length': '>=7'},
        'extended rally': {'rally_length': '>=10'},
        'extended rallies': {'rally_length': '>=10'},
        # Match phase shortcuts
        'late match': {'set': [3, 4, 5]},
        'early match': {'set': [1, 2]},
        # NOTE: "late" and "early" alone are too ambiguous - removed
        # NOTE: serve_number handled by LLM parse, not TERM_MAPPINGS
        # "first serve" could mean serve_number=1 OR the serve shot itself
    }
    
    # Situation synonyms - map user terms to situation filter values
    # These expand to multiple situations when user asks about "pressure" etc
    SITUATION_SYNONYMS = {
        'clutch': ['break_point', 'deuce', 'set_point', 'match_point'],
        'clutch points': ['break_point', 'deuce', 'set_point', 'match_point'],
        'pressure': ['break_point', 'game_point', 'set_point', 'match_point'],
        'pressure points': ['break_point', 'game_point', 'set_point', 'match_point'],
        'high leverage': ['break_point', 'set_point', 'match_point'],
        'big points': ['break_point', 'game_point', 'set_point', 'match_point'],
    }
    
    # ═══════════════════════════════════════════════════════════════════════════
    # METRIC REQUIREMENTS CONTRACT
    # ═══════════════════════════════════════════════════════════════════════════
    # Each metric specifies what point-level data it requires
    # If requirements aren't met: downgrade confidence or route to narrative
    METRIC_REQUIREMENTS = {
        'points_won': {
            'required_fields': ['point_winner'],
            'numerator': 'point_winner == player',
            'denominator': 'all_points',
            'perspective': 'both',  # Can be computed for either player
        },
        'win_percentage': {
            'required_fields': ['point_winner'],
            'numerator': 'point_winner == player',
            'denominator': 'all_points_in_filter',
            'perspective': 'both',
        },
        'first_serve_pct': {
            'required_fields': ['serve_number', 'server'],
            'numerator': 'serve_number == 1 AND serve_in',  # First serves that went in
            'denominator': 'all_first_serve_attempts',  # Total first serves (in + fault)
            'perspective': 'server',
        },
        'first_serve_win_pct': {
            'required_fields': ['serve_number', 'point_winner', 'server'],
            'numerator': 'serve_number == 1 AND point_winner == server',
            'denominator': 'first_serves_in_play',  # NOT total service points!
            'perspective': 'server',
        },
        'second_serve_win_pct': {
            'required_fields': ['serve_number', 'point_winner', 'server'],
            'numerator': 'serve_number == 2 AND point_winner == server',
            'denominator': 'second_serves_in_play',
            'perspective': 'server',
        },
        'aces': {
            'required_fields': ['winning_shot', 'server'],
            'numerator': 'winning_shot == ace OR outcome contains ace',
            'denominator': None,  # Count metric, no denominator
            'perspective': 'server',
        },
        'double_faults': {
            'required_fields': ['outcome', 'server'],
            'numerator': 'outcome == double_fault',
            'denominator': None,  # Count metric
            'perspective': 'server',
        },
        'return_points_won': {
            'required_fields': ['point_winner', 'returner'],
            'numerator': 'point_winner == returner',
            'denominator': 'all_return_points',
            'perspective': 'returner',
        },
        'return_win_pct': {
            'required_fields': ['point_winner', 'returner'],
            'numerator': 'point_winner == returner',
            'denominator': 'all_return_points',
            'perspective': 'returner',
        },
        'break_points_won': {
            'required_fields': ['situation', 'point_winner', 'returner'],
            'numerator': 'situation == break_point AND point_winner == returner',
            'denominator': 'all_break_points',
            'perspective': 'returner',  # Returner wins break points
        },
        'break_points_saved': {
            'required_fields': ['situation', 'point_winner', 'server'],
            'numerator': 'situation == break_point AND point_winner == server',
            'denominator': 'all_break_points',
            'perspective': 'server',  # Server saves break points
        },
        'break_point_conversion': {
            'required_fields': ['situation', 'point_winner', 'returner'],
            'numerator': 'situation == break_point AND point_winner == returner',
            'denominator': 'break_points_faced',  # NOT return points!
            'perspective': 'returner',
        },
        'winners': {
            'required_fields': ['outcome', 'point_winner'],
            'numerator': 'outcome == winner',
            'denominator': None,  # Count metric
            'perspective': 'point_winner',
            'fallback': 'narrative',  # Route to narrative if not reliably tracked
        },
        'unforced_errors': {
            'required_fields': ['outcome', 'error_player'],
            'numerator': 'outcome == unforced_error',
            'denominator': None,
            'perspective': 'error_player',
            'fallback': 'narrative',
        },
        'forced_errors': {
            'required_fields': ['outcome'],
            'numerator': 'outcome == forced_error',
            'denominator': None,
            'perspective': 'point_winner',  # Winner forced the error
            'fallback': 'narrative',
        },
        # Added metrics from VAGUE_TERM_MAP
        'points_count': {
            'required_fields': [],
            'numerator': 'all_filtered_points',
            'denominator': None,  # Count metric
            'perspective': 'both',
        },
        'service_winners': {
            'required_fields': ['outcome', 'server', 'winning_shot'],
            'numerator': '(outcome == ace OR winning_shot == service_winner) AND role == server',
            'denominator': None,
            'perspective': 'server',
        },
        'serve_points_won_pct': {
            'required_fields': ['point_winner', 'server'],
            'numerator': 'point_winner == server',
            'denominator': 'all_service_points',
            'perspective': 'server',
        },
        'return_points_won_pct': {
            'required_fields': ['point_winner', 'returner'],
            'numerator': 'point_winner == returner',
            'denominator': 'all_return_points',
            'perspective': 'returner',
            'alias_for': 'return_win_pct',
        },
        'return_winners': {
            'required_fields': ['outcome', 'returner', 'point_winner'],
            'numerator': 'outcome == winner AND point_winner == returner',
            'denominator': None,
            'perspective': 'returner',
        },
        'break_point_saves': {
            'required_fields': ['situation', 'point_winner', 'server'],
            'numerator': 'situation == break_point AND point_winner == server',
            'denominator': 'all_break_points',
            'perspective': 'server',
            'alias_for': 'break_points_saved',
        },
        'game_point_conversion': {
            'required_fields': ['situation', 'point_winner', 'server'],
            'numerator': 'situation == game_point AND point_winner == server',
            'denominator': 'all_game_points',
            'perspective': 'server',
        },
        'game_point_saves': {
            'required_fields': ['situation', 'point_winner', 'returner'],
            'numerator': 'situation == game_point AND point_winner == returner',
            'denominator': 'all_game_points',
            'perspective': 'returner',
        },
        'set_point_conversion': {
            'required_fields': ['situation', 'point_winner'],
            'numerator': 'situation == set_point AND point_winner == player_with_set_point',
            'denominator': 'all_set_points',
            'perspective': 'both',
        },
        'match_point_conversion': {
            'required_fields': ['situation', 'point_winner'],
            'numerator': 'situation == match_point AND point_winner == player_with_match_point',
            'denominator': 'all_match_points',
            'perspective': 'both',
        },
        'deuce_points_won': {
            'required_fields': ['situation', 'point_winner'],
            'numerator': 'situation == deuce AND point_winner == player',
            'denominator': 'all_deuce_points',
            'perspective': 'both',
        },
        'avg_rally_length': {
            'required_fields': ['rally_length'],
            'numerator': 'sum(rally_length)',
            'denominator': 'count(points)',
            'perspective': 'both',
        },
        'short_rally_win_pct': {
            'required_fields': ['rally_length', 'point_winner'],
            'numerator': 'rally_length <= 4 AND point_winner == player',
            'denominator': 'rally_length <= 4',
            'perspective': 'both',
        },
        'long_rally_win_pct': {
            'required_fields': ['rally_length', 'point_winner'],
            'numerator': 'rally_length >= 7 AND point_winner == player',
            'denominator': 'rally_length >= 7',
            'perspective': 'both',
        },
        'net_points_won': {
            'required_fields': ['at_net', 'point_winner'],
            'numerator': 'at_net == True AND point_winner == player',
            'denominator': None,
            'perspective': 'both',
            'fallback': 'narrative',  # at_net detection may be unreliable
        },
        'net_points_won_pct': {
            'required_fields': ['at_net', 'point_winner'],
            'numerator': 'at_net == True AND point_winner == player',
            'denominator': 'at_net == True',
            'perspective': 'both',
            'fallback': 'narrative',
        },
        'net_approaches': {
            'required_fields': ['at_net'],
            'numerator': 'at_net == True',
            'denominator': None,
            'perspective': 'both',
            'fallback': 'narrative',
        },
        'volley_winners': {
            'required_fields': ['winning_shot', 'outcome'],
            'numerator': 'winning_shot contains volley AND outcome == winner',
            'denominator': None,
            'perspective': 'point_winner',
            'fallback': 'narrative',
        },
    }
    
    # ═══════════════════════════════════════════════════════════════════════════
    # SMALL-N THRESHOLDS
    # ═══════════════════════════════════════════════════════════════════════════
    # Confidence thresholds based on sample size
    SAMPLE_SIZE_THRESHOLDS = {
        'high_confidence': 15,    # >= 15 points for high confidence
        'medium_confidence': 5,   # >= 5 points for medium confidence  
        'low_confidence': 1,      # >= 1 point for low confidence
        'no_tactical_claims': 7,  # Don't make tactical claims below this
        'suggest_widening': 3,    # Suggest widening scope below this
    }
    
    # NOTE: Synonym/alias handling already exists in:
    # - TERM_NORMALIZATION (vague terms like "effective" -> "effectiveness")
    # - POINT_SCORE_CONFIG['aliases'] (DEUCE -> 40-40)
    # - COURT_SIDE_CONFIG['aliases'] (ad court -> ad)
    # - GROUP_CONFIG['aliases'] for each dimension
    
    # SITUATION CONFIGURATION - Maps situations to their detection logic
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    SITUATION_CONFIG = {
        'break_point': {
            'detection_method': '_is_break_point_score',
            'score_patterns': ['0-40', '15-40', '30-40', '40-AD', 'AD-OUT'],  # AD-OUT normalized to AD-40, but keep for reference
            'role_context': 'returner_advantage',
        },
        'game_point': {
            'detection_method': '_is_game_point_score',
            'score_patterns': ['40-0', '40-15', '40-30', 'AD-40', 'AD-IN'],  # AD-IN normalized to 40-AD, but keep for reference
            'role_context': 'server_advantage',
        },
        'set_point': {
            'detection_method': '_is_set_point_score',
            'score_patterns': [],  # Complex logic
            'role_context': 'varies',
        },
        'match_point': {
            'detection_method': '_is_match_point_score',
            'score_patterns': [],  # Complex logic
            'role_context': 'varies',
        },
        'deuce': {
            'detection_method': '_is_deuce_score',
            'score_patterns': ['40-40', 'DEUCE'],
            'role_context': 'neutral',
        },
        'tiebreak': {
            'detection_method': '_is_tiebreak',
            'score_patterns': [],
            'role_context': 'neutral',
        },
    }
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # POINT SCORE CONFIGURATION - Valid point scores and normalization
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    POINT_SCORE_CONFIG = {
        'valid_values': ['0', '15', '30', '40', 'AD'],  # Valid tennis point scores
        'aliases': {
            # Common alternative representations
            'DEUCE': '40-40',
            'ALL': None,  # Special marker: "30-all" â†' use first value repeated
            'ADVANTAGE': 'AD',
            'ADV': 'AD',
            'A': 'AD',
            # Handle AD-OUT and AD-IN formats (tennis terminology)
            'AD-OUT': 'AD-40',  # Advantage server (game point) = AD-40
            'AD_OUT': 'AD-40',
            'ADOUT': 'AD-40',
            'AD-IN': '40-AD',   # Advantage returner (break point) = 40-AD
            'AD_IN': '40-AD',
            'ADIN': '40-AD',
            # Handle OUT and IN as individual values (for parsing)
            'OUT': '40',  # When used with AD: "AD-OUT" means server at AD, returner at 40
            'IN': 'AD',   # When used with 40: "40-AD" means server at 40, returner at AD
        },
        'patterns': {
            # Regex patterns for detecting point scores in queries
            # Use \u2013 for en dash to support both hyphen and en dash in user input
            # Added OUT and IN to support AD-OUT and AD-IN formats
            'standard': r'(?:at\s+|when\s+)?(\d{1,2}|AD)[-\u2013](\d{1,2}|AD|all|OUT|IN)',
            'with_context': r'(?:at\s+|when\s+)?(\d{1,2}|AD)[-\u2013](\d{1,2}|AD|all|OUT|IN)(?:\s+(?:points?|score))?',
        },
        'normalization_rules': {
            # How to normalize point scores for comparison
            'uppercase': True,
            'deuce_to_40_40': True,
            'handle_en_dash': True,  # Convert en dash to hyphen (-)
            'handle_ad_out_in': True,  # Convert AD-OUT/AD-IN to AD-40/40-AD
        }
    }
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ROLE CONFIGURATION - Maps roles to player resolution
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    ROLE_CONFIG = {
        'server': {
            'player_field': 'server',
            'opposite_role': 'returner',
            'domain': 'serve',
        },
        'returner': {
            'player_field': 'returner',
            'opposite_role': 'server',
            'domain': 'return',
        },
        'winner': {
            'player_field': 'point_winner',
            'opposite_role': 'loser',
            'domain': None,
        },
        'error': {
            'player_field': 'error_player',
            'opposite_role': 'winner',
            'domain': None,
        },
    }
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # DOMAIN CONFIGURATION - Maps domains to their properties
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # SHOT-LEVEL CONFIGURATION - For advanced shot sequence handlers
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    DOMAIN_CONFIG = {
        'serve': {
            'role': 'server',
            'default_metrics': ['first_serve_pct', 'first_serve_win_pct', 'aces', 'double_faults'],
            'player_field': 'server',
        },
        'return': {
            'role': 'returner',
            'default_metrics': ['return_points_won_pct', 'return_winners'],
            'player_field': 'returner',
        },
        'rally': {
            'role': None,
            'default_metrics': ['win_percentage', 'winners', 'unforced_errors'],
            'player_field': None,
        },
        'net': {
            'role': None,
            'default_metrics': ['net_points_won', 'volley_winners'],
            'player_field': None,
        },
    }
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # COURT SIDE CONFIGURATION - Maps court sides to their properties
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    COURT_SIDE_CONFIG = {
        'deuce': {
            'game_score_patterns': ['0-', '30-', 'deuce'],
            'aliases': ['deuce', 'right'],
        },
        'ad': {
            'game_score_patterns': ['15-', '40-', 'AD'],
            'aliases': ['ad', 'advantage', 'left'],
        },
    }
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # COURT ZONE CONFIGURATION - Maps court zones to their properties
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    COURT_ZONE_CONFIG = {
        'net': {
            'detection_fields': ['at_net', 'court_position'],
            'detection_value': True,
            'shot_modifiers': ['volley', 'half_volley', 'overhead', 'swinging_volley', 'drop_volley'],
        },
        'baseline': {
            'detection_fields': ['at_net'],
            'detection_value': False,
            'shot_modifiers': [],
        },
    }
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # GROUP BY CONFIGURATION - Maps group_by values to their grouping logic
    # FULLY VARIABLE-DRIVEN: Add new groupings here, no code changes needed!
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    GROUP_CONFIG = {
        'player': {
            'extraction_method': 'metric_aware',  # Uses METRIC_CONFIG to determine player_field
            'metadata_path': None,  # Determined dynamically
            'normalize': None,
            'display_source': 'custom',  # Special: uses player1/player2 names
            'custom_display': 'get_player_display',  # String identifier
            'display_type': 'player',  # Each group IS a player
        },
        'serve_number': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['serve_info', 'serve_number'],
            'normalize': lambda v: '2nd' if v == 2 else '1st',
            'fallback': lambda point_lower: '2nd' if '2nd serve' in point_lower or 'fault' in point_lower[:50] else '1st',
            'display_source': 'inventory',
            'inventory_key': 'serve_numbers',
            'default_branches': ['1st', '2nd'],
            'display_labels': {'1st': '1st Serve', '2nd': '2nd Serve', '1': '1st Serve', '2': '2nd Serve'},
        },
        'serve_direction': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['serve_info', 'target'],
            'normalize': None,
            'display_source': 'inventory',
            'inventory_key': 'serve_targets',
            'default_branches': ['wide', 'body', 't'],
            'display_labels': {'wide': 'Wide', 'body': 'Body', 't': 'T (Down the Middle)'},
            'display_type': 'role_based',  # Shows returner perspective
        },
        'shot_type': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['winning_shot', 'shot_type'],
            'normalize': None,
            'display_source': 'inventory',
            'inventory_key': 'shot_types',
            'default_branches': ['forehand', 'backhand'],
            'display_labels': {'forehand': 'Forehand', 'backhand': 'Backhand', 'volley': 'Volley', 'overhead': 'Overhead/Smash', 'drop_shot': 'Drop Shot', 'serve': 'Serve'},
            'include_modifiers': True,  # Also include shot_modifiers from inventory
        },
        'shot_direction': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['winning_shot', 'direction'],
            'normalize': None,
            'display_source': 'inventory',
            'inventory_key': 'directions',
            'default_branches': ['crosscourt', 'down_the_line', 'inside_out', 'inside_in', 'down_the_middle'],
            'display_labels': {'crosscourt': 'Crosscourt', 'down_the_line': 'Down the Line', 'inside_out': 'Inside-Out', 'inside_in': 'Inside-In', 'down_the_middle': 'Down the Middle'},
        },
        'shot_modifier': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['winning_shot', 'shot_modifier'],
            'normalize': None,
            'display_source': 'inventory',
            'inventory_key': 'shot_modifiers',
            'default_branches': ['slice', 'volley', 'drop_shot', 'approach'],
        },
        'depth': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['winning_shot', 'depth'],
            'normalize': None,
            'display_source': 'inventory',
            'inventory_key': 'depths',
            'default_branches': ['shallow', 'deep', 'very_deep'],
            'display_labels': {'shallow': 'Shallow', 'deep': 'Deep', 'very_deep': 'Very Deep'},
        },
        'court_zone': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['winning_shot', 'court_position'],
            'normalize': None,
            'display_source': 'inventory',
            'inventory_key': 'court_positions',
            'default_branches': ['baseline', 'net', 'approach'],
        },
        'court_position': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['winning_shot', 'court_position'],
            'normalize': None,
            'display_source': 'inventory',
            'inventory_key': 'court_positions',
            'default_branches': ['baseline', 'net', 'approach'],
            'display_labels': {'baseline': 'Baseline', 'net': 'Net', 'approach': 'Approach'},
        },
        'spin': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['winning_shot', 'spin'],
            'normalize': None,
            'display_source': 'inventory',
            'inventory_key': 'spin_types',
            'default_branches': ['topspin', 'slice', 'flat'],
            'display_labels': {'topspin': 'Topspin', 'slice': 'Slice', 'flat': 'Flat'},
        },
        'return_depth': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['return_info', 'return_depth'],
            'normalize': lambda v: v or 'unspecified',
            'display_source': 'inventory',
            'inventory_key': 'depths',
            'default_branches': ['shallow', 'deep', 'very_deep'],
            'display_labels': {'shallow': 'Shallow', 'deep': 'Deep', 'very_deep': 'Very Deep', 'unspecified': 'Unspecified'},
            'always_include': ['unspecified'],  # Always include this branch
        },
        'sets': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['set_number'],
            'normalize': lambda v: str(v) if v else None,
            'fallback': 'extract_current_set',  # Special fallback identifier
            'display_source': 'inventory',
            'inventory_key': 'sets_played',
            'default_branches': [1, 2, 3, 4, 5],
            'display_labels': lambda v: f'Set {v}',  # Function to format
        },
        'set': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['set_number'],
            'normalize': lambda v: f"Set {v}" if v else None,
            'display_source': 'inventory',
            'inventory_key': 'sets_played',
            'default_branches': [1, 2, 3, 4, 5],
            'display_labels': lambda v: f'Set {v}',
        },
        'set_groups': {
            'extraction_method': 'custom',
            'custom_func': 'get_set_group',  # String identifier - handled in _extract_group_key
            'display_source': 'custom',
            'custom_display': 'get_set_groups_display',  # String identifier
        },
        'situation': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['situation', 'type'],
            'normalize': None,
            'display_source': 'inventory',
            'inventory_key': 'situations',
            'default_branches': ['break_point', 'game_point', 'deuce', 'set_point', 'match_point', 'tiebreak'],
        },
        'outcome': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['winning_shot', 'outcome'],
            'normalize': 'normalize_outcome',  # String identifier - handled in _extract_group_key
            'display_source': 'inventory',
            'inventory_key': 'outcomes',
            'default_branches': ['winner', 'ace', 'forced_error', 'unforced_error', 'double_fault'],
            'display_labels': {'winner': 'Winner', 'ace': 'Ace', 'forced_error': 'Forced Error (Induced)', 'unforced_error': 'Unforced Error', 'double_fault': 'Double Fault'},
        },
        'shot_number': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['rally_length'],
            'normalize': lambda v: '1' if v == 1 else '2' if v == 2 else '3' if v == 3 else '4+' if v >= 4 else None,
            'display_source': 'predefined',
            'default_branches': ['1', '2', '3', '4+'],
            'display_labels': {'1': 'Serve (1st shot)', '2': 'Return (2nd shot)', '3': 'Serve+1 (3rd shot)', '4+': 'Rally (4+ shots)'},
        },
        'rally_length_category': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['rally_category'],
            'normalize': None,
            'fallback': lambda rally_length: '1-3' if 1 <= rally_length <= 3 else '4-6' if 4 <= rally_length <= 6 else '7-9' if 7 <= rally_length <= 9 else '10+' if rally_length >= 10 else None,
            'display_source': 'inventory',
            'inventory_key': 'rally_categories',
            'default_branches': ['1-3', '4-6', '7-9', '10+'],
            'display_labels': {'1-3': 'Short (1-3 shots)', '4-6': 'Medium (4-6 shots)', '7-9': 'Extended (7-9 shots)', '10+': 'Long (10+ shots)'},
        },
        'rally_length': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['rally_length'],
            'normalize': None,
            'display_source': 'dynamic',  # Values discovered during traversal
        },
        'court_side': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['situation', 'court_side'],
            'normalize': None,
            'fallback': lambda score: 'deuce',  # Default
            'display_source': 'inventory',
            'inventory_key': 'court_sides',
            'default_branches': ['deuce', 'ad'],
            'display_labels': {'deuce': 'Deuce Court', 'ad': 'Ad Court'},
        },
        'pressure_level': {
            'extraction_method': 'filter',
            'filter_key': '_pressure_tightness',
            'normalize': lambda v: 'low' if 0 <= v <= 3 else 'medium' if 4 <= v <= 6 else 'high' if 7 <= v <= 10 else None,
            'display_source': 'inventory',
            'inventory_key': 'pressure_levels',
            'default_branches': ['low', 'medium', 'high'],
            'display_labels': {'low': 'Low Pressure (0-3)', 'medium': 'Medium Pressure (4-6)', 'high': 'High Pressure (7-10)'},
        },
        'serve_plus_one_type': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['serve_plus_one', 'shot_type'],
            'normalize': lambda v: v or 'none',
            'display_source': 'inventory',
            'inventory_key': 'serve_plus_one_shot_types',
            'default_branches': ['forehand', 'backhand', 'volley'],
            'display_labels': {'forehand': 'Serve+1 Forehand', 'backhand': 'Serve+1 Backhand', 'volley': 'Serve+1 Volley', 'none': 'No Serve+1 (ended on serve/return)'},
            'always_include': ['none'],  # Always include this branch
        },
        'after_rally_length': {
            'extraction_method': 'filter',
            'filter_key': '_prev_rally_length',
            'normalize': lambda v: 'first_point' if v == 0 else 'after_short' if 1 <= v <= 4 else 'after_medium' if 5 <= v <= 9 else 'after_long' if v >= 10 else None,
            'display_source': 'predefined',
            'default_branches': ['after_short', 'after_medium', 'after_long', 'first_point'],
            'display_labels': {'after_short': 'After Short Rally (1-4 shots)', 'after_medium': 'After Medium Rally (5-9 shots)', 'after_long': 'After Long Rally (10+ shots)', 'first_point': 'First Point (no previous rally)'},
        },
        'net_play_type': {
            'extraction_method': 'custom',
            'custom_func': 'get_net_play_type',  # String identifier - handled in _extract_group_key
            'display_source': 'inventory',
            'inventory_key': 'net_play_types',
            'default_branches': [],
        },
        'game': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['game_number_in_set'],
            'normalize': lambda v: f"Game {v}" if v else None,
            'display_source': 'dynamic',  # Values discovered during traversal
        },
        'game_overall': {
            'extraction_method': 'metadata_path',
            'metadata_path': ['game_number_overall'],
            'normalize': lambda v: f"Game {v}" if v else None,
            'display_source': 'dynamic',  # Values discovered during traversal
        },
    }
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # METRIC CONFIGURATION - SINGLE SOURCE OF TRUTH
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 
    # This config defines EVERYTHING about how metrics behave:
    #   - player_role: whose metric (server/returner/winner/error/both/performer)
    #   - total_filter: what counts toward denominator
    #   - count_filter: what counts toward numerator  
    #   - display_type: how to format in output
    #       - 'per_player_pct': Show each player's X% (count/total) separately
    #       - 'aggregate_pct': Show combined X% (count/total)
    #       - 'count': Show raw count
    #       - 'points_won': Show win/loss distribution
    #   - keywords: for keyword-based counting (on_match filter)
    #
    # The tree handles ALL filtering (situation, set, role, point_score).
    # METRIC_CONFIG ONLY defines what counts for numerator/denominator.
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    METRIC_CONFIG = {
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # SERVE PERCENTAGE METRICS - Per-player percentages (each player's own stats)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        'first_serve_pct': {
            'player_role': 'server',
            'total_filter': 'always',       # Denominator: all serve attempts by this player
            'count_filter': 'first_serve_in',  # Numerator: first serves in
            'display_type': 'per_player_pct',
            'label': 'First Serve %'
        },
        'first_serve_win_pct': {
            'player_role': 'server',
            'total_filter': 'first_serve',   # Denominator: first serves only
            'count_filter': 'won',           # Numerator: points won on first serve
            'display_type': 'per_player_pct',
            'label': 'First Serve Win %'
        },
        'second_serve_pct': {
            'player_role': 'server',
            'total_filter': 'second_serve',
            'count_filter': 'second_serve_in',
            'display_type': 'per_player_pct',
            'label': 'Second Serve %'
        },
        'second_serve_win_pct': {
            'player_role': 'server',
            'total_filter': 'second_serve',
            'count_filter': 'won',
            'display_type': 'per_player_pct',
            'label': 'Second Serve Win %'
        },
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # POINT OUTCOME METRICS - Shows who won how many points
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        'points_won': {
            'player_role': 'both',
            'total_filter': 'always',
            'count_filter': 'won',
            'display_type': 'points_won',
            'label': 'Points Won'
        },
        'win_percentage': {
            'player_role': 'both',
            'total_filter': 'always',
            'count_filter': 'won',
            'display_type': 'points_won',
            'label': 'Win Percentage'
        },
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # COUNT METRICS - Raw counts per player
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        'winners': {
            'player_role': 'winner',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['winner'],
            'display_type': 'count',
            'label': 'Winners'
        },
        'aces': {
            'player_role': 'server',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['ace'],
            'display_type': 'count',
            'label': 'Aces'
        },
        'double_faults': {
            'player_role': 'server',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['double fault'],
            'display_type': 'count',
            'label': 'Double Faults'
        },
        'forced_errors': {
            'player_role': 'winner',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['forced error'],
            'exclude_keywords': ['unforced'],  # CRITICAL: Don't match "unforced error"!
            'display_type': 'count',
            'label': 'Forced Errors (Induced)'
        },
        'unforced_errors': {
            'player_role': 'error',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['unforced error'],
            'display_type': 'count',
            'label': 'Unforced Errors'
        },
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # NET PLAY METRICS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        'net_points_won': {
            'player_role': 'performer',
            'total_filter': 'on_match',
            'count_filter': 'won',
            'keywords': ['volley', 'at net', 'approach'],
            'display_type': 'per_player_pct',
            'label': 'Net Points Won %'
        },
        'net_approaches': {
            'player_role': 'performer',
            'total_filter': 'on_match',
            'count_filter': 'always',
            'keywords': ['approach', 'net approach'],
            'display_type': 'count',
            'label': 'Net Approaches'
        },
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # RETURN METRICS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        'return_winners': {
            'player_role': 'returner',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['return', 'winner'],
            'display_type': 'count',
            'label': 'Return Winners'
        },
        'return_errors': {
            'player_role': 'returner',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['return', 'error'],
            'display_type': 'count',
            'label': 'Return Errors'
        },
        'returns_in_play': {
            'player_role': 'returner',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['return'],
            'display_type': 'count',
            'label': 'Returns In Play'
        },
        'return_points_won_pct': {
            'player_role': 'returner',
            'total_filter': 'always',
            'count_filter': 'won',
            'display_type': 'per_player_pct',
            'label': 'Return Points Won %'
        },
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # SHOT-BASED OUTCOME METRICS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        'forehand_winners': {
            'player_role': 'winner',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['forehand', 'winner'],
            'display_type': 'count',
            'label': 'Forehand Winners'
        },
        'backhand_winners': {
            'player_role': 'winner',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['backhand', 'winner'],
            'display_type': 'count',
            'label': 'Backhand Winners'
        },
        'forehand_errors': {
            'player_role': 'error',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['forehand', 'error'],
            'display_type': 'count',
            'label': 'Forehand Errors'
        },
        'backhand_errors': {
            'player_role': 'error',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['backhand', 'error'],
            'display_type': 'count',
            'label': 'Backhand Errors'
        },
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # RALLY-BASED METRICS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        'rally_winners': {
            'player_role': 'winner',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['winner'],
            'min_rally_length': 2,
            'display_type': 'count',
            'label': 'Rally Winners'
        },
        'groundstroke_winners': {
            'player_role': 'winner',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['winner'],
            'min_rally_length': 2,
            'display_type': 'count',
            'label': 'Groundstroke Winners'
        },
        'baseline_winners': {
            'player_role': 'winner',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['winner'],
            'exclude_modifiers': ['volley', 'overhead'],
            'display_type': 'count',
            'label': 'Baseline Winners'
        },
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # SERVICE-BASED METRICS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        'service_winners': {
            'player_role': 'server',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['winner'],
            'max_rally_length': 1,
            'display_type': 'count',
            'label': 'Service Winners'
        },
        'first_serve_in': {
            'player_role': 'server',
            'total_filter': 'always',
            'count_filter': 'first_serve_in',
            'display_type': 'count',
            'label': 'First Serves In'
        },
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # GENERIC OUTCOME METRICS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        'errors': {
            'player_role': 'error',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['error'],
            'display_type': 'count',
            'label': 'Errors'
        },
        'points_lost': {
            'player_role': 'loser',
            'total_filter': 'always',
            'count_filter': 'lost',
            'display_type': 'count',
            'label': 'Points Lost'
        },
        'induced_forced_errors': {
            'player_role': 'winner',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['forced error'],
            'exclude_keywords': ['unforced'],
            'display_type': 'count',
            'label': 'Induced Forced Errors'
        },
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # BREAK POINT METRICS - Per-player percentages
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        'break_point_conversion': {
            'player_role': 'returner',
            'total_filter': 'always',  # Tree already filters to break points
            'count_filter': 'won',
            'display_type': 'per_player_pct',
            'label': 'Break Point Conversion %'
        },
        'break_point_saves': {
            'player_role': 'server',
            'total_filter': 'always',  # Tree already filters to break points
            'count_filter': 'won',
            'display_type': 'per_player_pct',
            'label': 'Break Points Saved %'
        },
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # GAME-LEVEL METRICS (aggregated from points)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        'games_won': {
            'player_role': 'game_winner',
            'total_filter': 'games',
            'count_filter': 'game_won',
            'aggregate_level': 'game',
            'display_type': 'count',
            'label': 'Games Won'
        },
        'games_lost': {
            'player_role': 'game_loser',
            'total_filter': 'games',
            'count_filter': 'game_lost',
            'aggregate_level': 'game',
            'display_type': 'count',
            'label': 'Games Lost'
        },
        'service_games_held': {
            'player_role': 'server',
            'total_filter': 'service_games',
            'count_filter': 'game_won',
            'aggregate_level': 'game',
            'display_type': 'per_player_pct',
            'label': 'Service Games Held %'
        },
        'breaks': {
            'player_role': 'returner',
            'total_filter': 'return_games',
            'count_filter': 'game_won',
            'aggregate_level': 'game',
            'display_type': 'count',
            'label': 'Breaks'
        },
        'sets_won': {
            'player_role': 'set_winner',
            'total_filter': 'sets',
            'count_filter': 'set_won',
            'aggregate_level': 'set',
            'display_type': 'count',
            'label': 'Sets Won'
        },
        
        # ═══════════════════════════════════════════════════════════════════════
        # NEWLY ADDED METRICS (from VAGUE_TERM_MAP audit)
        # ═══════════════════════════════════════════════════════════════════════
        'points_count': {
            'player_role': 'both',
            'total_filter': 'always',
            'count_filter': 'always',
            'display_type': 'count',
            'label': 'Total Points'
        },
        'serve_points_won_pct': {
            'player_role': 'server',
            'total_filter': 'always',
            'count_filter': 'won',
            'display_type': 'per_player_pct',
            'label': 'Serve Points Won %'
        },
        'return_points_won': {
            'player_role': 'returner',
            'total_filter': 'always',
            'count_filter': 'won',
            'display_type': 'points_won',
            'label': 'Return Points Won'
        },
        'return_win_pct': {
            'player_role': 'returner',
            'total_filter': 'always',
            'count_filter': 'won',
            'display_type': 'per_player_pct',
            'label': 'Return Win %'
        },
        'break_points_won': {
            'player_role': 'returner',
            'total_filter': 'always',  # Tree already filters to break points
            'count_filter': 'won',
            'display_type': 'points_won',
            'label': 'Break Points Won'
        },
        'break_points_saved': {
            'player_role': 'server',
            'total_filter': 'always',  # Tree already filters to break points
            'count_filter': 'won',
            'display_type': 'points_won',
            'label': 'Break Points Saved'
        },
        'game_point_conversion': {
            'player_role': 'server',
            'total_filter': 'always',  # Tree filters to game_point situation
            'count_filter': 'won',
            'display_type': 'per_player_pct',
            'label': 'Game Point Conversion %'
        },
        'game_point_saves': {
            'player_role': 'returner',
            'total_filter': 'always',  # Tree filters to game_point situation
            'count_filter': 'won',
            'display_type': 'per_player_pct',
            'label': 'Game Point Saves %'
        },
        'set_point_conversion': {
            'player_role': 'both',
            'total_filter': 'always',  # Tree filters to set_point situation
            'count_filter': 'won',
            'display_type': 'per_player_pct',
            'label': 'Set Point Conversion %'
        },
        'match_point_conversion': {
            'player_role': 'both',
            'total_filter': 'always',  # Tree filters to match_point situation
            'count_filter': 'won',
            'display_type': 'per_player_pct',
            'label': 'Match Point Conversion %'
        },
        'deuce_points_won': {
            'player_role': 'both',
            'total_filter': 'always',  # Tree filters to deuce situation
            'count_filter': 'won',
            'display_type': 'points_won',
            'label': 'Deuce Points Won'
        },
        'avg_rally_length': {
            'player_role': 'both',
            'total_filter': 'always',
            'count_filter': 'average',
            'display_type': 'average',
            'label': 'Avg Rally Length'
        },
        'short_rally_win_pct': {
            'player_role': 'both',
            'total_filter': 'short_rally',  # rally_length <= 4
            'count_filter': 'won',
            'display_type': 'per_player_pct',
            'label': 'Short Rally Win % (0-4 shots)'
        },
        'long_rally_win_pct': {
            'player_role': 'both',
            'total_filter': 'long_rally',  # rally_length >= 7
            'count_filter': 'won',
            'display_type': 'per_player_pct',
            'label': 'Long Rally Win % (7+ shots)'
        },
        'net_points_won_pct': {
            'player_role': 'performer',
            'total_filter': 'at_net',
            'count_filter': 'won',
            'keywords': ['volley', 'at net', 'approach'],
            'display_type': 'per_player_pct',
            'label': 'Net Points Won %'
        },
        'volley_winners': {
            'player_role': 'winner',
            'total_filter': 'always',
            'count_filter': 'on_match',
            'keywords': ['volley', 'winner'],
            'display_type': 'count',
            'label': 'Volley Winners'
        },
    }
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # DISPLAY TYPE REFERENCE (for understanding the config above)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 
    # 'per_player_pct': Each player gets their own percentage
    #   -> "Sinner: 58% (7/12), Medvedev: 33% (3/9)"
    #   Used for: first_serve_pct, serve_win_pct, return_pct, net_points_won
    #
    # 'aggregate_pct': Combined percentage across both players
    #   -> "Overall: 47% (10/21)"
    #   Used for: rare, mostly when explicitly combining
    #
    # 'count': Raw count per player
    #   -> "Sinner: 15, Medvedev: 12"
    #   Used for: aces, winners, errors, double_faults
    #
    # 'points_won': Win/loss distribution with percentages
    #   -> "Sinner: 142 (50%), Medvedev: 141 (50%)"
    #   Used for: points_won, win_percentage
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def __init__(self, llm_provider: str = "gemini", api_key: str = None, model: str = None):
        """
        Initialize with specified LLM provider and LOCAL embeddings.
        
        Args:
            llm_provider: "openai", "claude", or "gemini" (for answering questions, default: gemini)
            api_key: API key for the provider (optional, will use env vars)
        """
        self.llm_provider = llm_provider.lower()
        self.api_key = api_key
        self.custom_model = model  # Allow custom model override
        self.chunks = []
        self.index = None
        self.metadata_store = []
        self.match_id = "match_data"  # Generic default, overwritten when loading match
        self.player1 = None
        self.player2 = None
        self.tournament = None  # Tournament name (for Grand Slam detection)
        self.point_by_point = []  # Structured point-by-point data for analysis
        
        # === MATCH FILTER INVENTORY ===
        # Built once at load time - contains ALL available filter values from this match
        # LLM uses this to map queries to KNOWN filters (no guessing)
        self.match_filter_inventory = {}
        self.match_stats_summary = {}
        
        # Store last analysis result for external access
        self.last_analysis = None
        self.last_answer = None
        
        # Rate limiting
        self.last_api_call = 0
        self.min_delay = 2.0  # Minimum 2 seconds between API calls
        
        # Initialize local embedding model (FREE!)
        print("Loading LOCAL embedding model (sentence-transformers)...")
        try:
            from sentence_transformers import SentenceTransformer
            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
            self.embedding_dim = 384
            print("Local embedding model loaded (FREE)!")
        except ImportError:
            raise ImportError("Please install sentence-transformers: pip install sentence-transformers")
        
        # Initialize the appropriate LLM client
        self._init_llm_client()
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # GENERIC CONFIG-DRIVEN HELPER METHODS
    # These replace ALL hardcoded if/elif chains with config lookups
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _get_outcome_config(self, outcome: str) -> Dict:
        """Get config for an outcome - NEVER hardcode outcome checks!"""
        return self.OUTCOME_CONFIG.get(outcome.upper() if outcome else '', {})
    
    def _get_winning_shot_type(self, outcome: str) -> str:
        """Get winning shot type from outcome - GENERIC lookup."""
        config = self._get_outcome_config(outcome)
        return config.get('winning_shot_type', '')
    
    def _get_player_for_outcome(self, outcome: str, server: str, returner: str, 
                                 point_winner: str, error_player: str) -> str:
        """Get which player is attributed to an outcome - GENERIC lookup."""
        config = self._get_outcome_config(outcome)
        attribution = config.get('player_attribution', '')
        
        # Use ROLE_CONFIG to resolve the actual player
        if attribution in self.ROLE_CONFIG:
            field = self.ROLE_CONFIG[attribution].get('player_field', '')
            players = {'server': server, 'returner': returner, 
                      'point_winner': point_winner, 'error_player': error_player}
            return players.get(field, '')
        return ''
    
    def _get_situation_config(self, situation: str) -> Dict:
        """Get config for a situation - NEVER hardcode situation checks!"""
        return self.SITUATION_CONFIG.get(situation.lower() if situation else '', {})
    
    def _normalize_point_score(self, point_score: str) -> str:
        """
        Normalize a point score using POINT_SCORE_CONFIG rules.
        
        Examples:
            "30-30" -> "30-30"
            "DEUCE" -> "40-40"
            "30-30" (en dash) -> "30-30"
            "40-AD" -> "40-AD"
            "AD-OUT" -> "AD-40"
            "AD-IN" -> "40-AD"
        """
        if not point_score:
            return ''
        
        # Apply normalization rules from config
        normalized = str(point_score)
        
        # Handle en dash -> hyphen (en dash is U+2013)
        if self.POINT_SCORE_CONFIG['normalization_rules']['handle_en_dash']:
            normalized = normalized.replace('\u2013', '-')
        
        # Uppercase
        if self.POINT_SCORE_CONFIG['normalization_rules']['uppercase']:
            normalized = normalized.upper()
        
        # Handle AD-OUT and AD-IN formats first (before individual value replacement)
        if self.POINT_SCORE_CONFIG['normalization_rules'].get('handle_ad_out_in', False):
            # Check for full score patterns first
            if 'AD-OUT' in normalized or 'AD_OUT' in normalized or 'ADOUT' in normalized:
                normalized = normalized.replace('AD-OUT', 'AD-40').replace('AD_OUT', 'AD-40').replace('ADOUT', 'AD-40')
            elif 'AD-IN' in normalized or 'AD_IN' in normalized or 'ADIN' in normalized:
                normalized = normalized.replace('AD-IN', '40-AD').replace('AD_IN', '40-AD').replace('ADIN', '40-AD')
            else:
                # Handle individual OUT/IN values in score format (e.g., "AD-OUT" parsed as "AD" and "OUT")
                # This handles cases where regex extracts them separately
                import re
                score_match = re.match(r'(\d+|AD)[-\u2013](OUT|IN)', normalized)
                if score_match:
                    p1, p2 = score_match.groups()
                    if p1 == 'AD' and p2 == 'OUT':
                        normalized = 'AD-40'
                    elif p1 == 'AD' and p2 == 'IN':
                        normalized = '40-AD'
                    elif p1.isdigit() and p2 == 'OUT':
                        # e.g., "40-OUT" -> "40-40" (not valid, but handle gracefully)
                        normalized = f"{p1}-40"
                    elif p1.isdigit() and p2 == 'IN':
                        # e.g., "40-IN" -> "40-AD"
                        normalized = f"{p1}-AD"
        
        # Apply aliases (e.g., DEUCE -> 40-40)
        if self.POINT_SCORE_CONFIG['normalization_rules']['deuce_to_40_40']:
            for alias, replacement in self.POINT_SCORE_CONFIG['aliases'].items():
                if replacement and alias in normalized:
                    normalized = normalized.replace(alias, replacement)
        
        return normalized
    
    def _is_valid_point_score(self, point_score: str) -> bool:
        """Check if a string looks like a valid point score using POINT_SCORE_CONFIG."""
        import re
        if not point_score:
            return False
        
        # Check against standard pattern
        pattern = self.POINT_SCORE_CONFIG['patterns']['standard']
        return bool(re.match(pattern, point_score, re.IGNORECASE))
    
    def _check_situation(self, situation: str, score: str, game_score: str = None) -> bool:
        """Check if a score matches a situation - GENERIC lookup."""
        config = self._get_situation_config(situation)
        if not config:
            return False
        
        method_name = config.get('detection_method')
        if method_name and hasattr(self, method_name):
            return getattr(self, method_name)(score)
        
        # Fallback to pattern matching
        patterns = config.get('score_patterns', [])
        return score in patterns if patterns else False
    
    def _get_role_config(self, role: str) -> Dict:
        """Get config for a role - NEVER hardcode role checks!"""
        return self.ROLE_CONFIG.get(role.lower() if role else '', {})
    
    def _filter_matches(self, actual_value, filter_value) -> bool:
        """
        UNIVERSAL filter matching - handles single values, lists, tuples, and ranges.
        
        Use this EVERYWHERE instead of direct equality checks!
        
        Args:
            actual_value: The actual value from the point data (e.g., set_number=1)
            filter_value: The filter to match against (e.g., 1, [1,2], (1,2), ">=5")
            
        Returns:
            True if actual_value matches filter_value
        """
        if filter_value is None:
            return True  # No filter = all pass
            
        # Handle list/tuple: check if actual is IN the collection
        if isinstance(filter_value, (list, tuple)):
            # If it's a 2-element numeric collection, could be a range
            if len(filter_value) == 2:
                try:
                    min_val, max_val = filter_value
                    if isinstance(min_val, (int, float)) and isinstance(max_val, (int, float)):
                        # Looks like a range - but only if actual is numeric too
                        if isinstance(actual_value, (int, float)):
                            # Ambiguous: could be range (min, max) or list [val1, val2]
                            # Use heuristic: if actual_value is in the list, it's a list match
                            if actual_value in filter_value:
                                return True
                            # Otherwise treat as range
                            return min_val <= actual_value <= max_val
                except (TypeError, ValueError):
                    pass
            # Default list behavior: check membership
            return actual_value in filter_value
            
        # Handle string comparisons: ">=5", "<=3", ">7", "<10"
        if isinstance(filter_value, str):
            try:
                if filter_value.startswith('>='):
                    return actual_value >= int(filter_value[2:])
                elif filter_value.startswith('<='):
                    return actual_value <= int(filter_value[2:])
                elif filter_value.startswith('>'):
                    return actual_value > int(filter_value[1:])
                elif filter_value.startswith('<'):
                    return actual_value < int(filter_value[1:])
                elif filter_value.isdigit():
                    return actual_value == int(filter_value)
            except (TypeError, ValueError):
                pass
            # Fall back to string equality
            return str(actual_value).lower() == filter_value.lower()
        
        # Default: exact match
        return actual_value == filter_value
    
    def _get_player_for_role(self, role: str, server: str, returner: str,
                              point_winner: str = '', error_player: str = '') -> str:
        """Get the player for a given role - GENERIC lookup."""
        config = self._get_role_config(role)
        field = config.get('player_field', '')
        players = {'server': server, 'returner': returner,
                  'point_winner': point_winner, 'error_player': error_player}
        return players.get(field, '')
    
    def _get_domain_config(self, domain: str) -> Dict:
        """Get config for a domain - NEVER hardcode domain checks!"""
        return self.DOMAIN_CONFIG.get(domain.lower() if domain else '', {})
    
    def _get_role_for_domain(self, domain: str) -> str:
        """Get the role associated with a domain - GENERIC lookup."""
        config = self._get_domain_config(domain)
        return config.get('role', '')
    
    def _get_player_for_domain(self, domain: str, server: str, returner: str) -> str:
        """Get the player field for a domain - GENERIC lookup."""
        config = self._get_domain_config(domain)
        field = config.get('player_field', '')
        if field == 'server':
            return server
        elif field == 'returner':
            return returner
        return ''
    
    def _get_court_zone_config(self, zone: str) -> Dict:
        """Get config for a court zone - NEVER hardcode zone checks!"""
        return self.COURT_ZONE_CONFIG.get(zone.lower() if zone else '', {})
    
    def _check_court_zone(self, zone: str, point_metadata: Dict) -> bool:
        """Check if a point matches a court zone - GENERIC lookup."""
        config = self._get_court_zone_config(zone)
        if not config:
            return True  # No filter
        
        # Check detection fields
        for field in config.get('detection_fields', []):
            if point_metadata.get(field) == config.get('detection_value'):
                return True
        
        # Check shot modifiers
        shot_modifier = point_metadata.get('winning_shot', {}).get('shot_modifier', '')
        shot_modifiers = point_metadata.get('winning_shot', {}).get('shot_modifiers', [])
        zone_modifiers = config.get('shot_modifiers', [])
        
        if shot_modifier in zone_modifiers or any(m in zone_modifiers for m in shot_modifiers):
            return zone == 'net'  # These modifiers indicate net play
        
        return zone == 'baseline'  # Default to baseline if no net indicators
    
    def _get_group_config(self, group_by: str) -> Dict:
        """Get config for a group_by value - NEVER hardcode group_by checks!"""
        return self.GROUP_CONFIG.get(group_by.lower() if group_by else '', {})
    
    def _extract_group_key(self, group_by: str, point_data: Dict, metadata: Dict, 
                           filters: Dict, score: str, point_lower: str, 
                           rally_length: int = 0) -> str:
        """
        GENERIC group key extraction using GROUP_CONFIG.
        This replaces ALL hardcoded if/elif chains for group_by routing.
        """
        config = self._get_group_config(group_by)
        if not config:
            return None
        
        extraction_method = config.get('extraction_method', 'metadata_path')
        normalize = config.get('normalize')
        fallback = config.get('fallback')
        
        value = None
        
        if extraction_method == 'metadata_path':
            path = config.get('metadata_path', [])
            if path:
                # SPECIAL CASE: For shot_type grouping with error metrics, use error_shot_type instead of winning_shot.shot_type
                if group_by == 'shot_type' and path == ['winning_shot', 'shot_type']:
                    current_metric = filters.get('_current_metric', '')
                    error_metrics = ['unforced_errors', 'forced_errors', 'errors']
                    if current_metric in error_metrics:
                        # Use error_shot_type for error metrics (stored in error_info)
                        error_info = metadata.get('error_info', {})
                        error_shot_type = error_info.get('error_shot_type')
                        if error_shot_type:
                            value = error_shot_type
                            # DEBUG: Show that we're using error_shot_type
                            if not hasattr(self, '_error_shot_debug_count'):
                                self._error_shot_debug_count = 0
                            if self._error_shot_debug_count < 3:
                                self._error_shot_debug_count += 1
                                print(f"[GROUP-DEBUG] Using error_shot_type='{error_shot_type}' for error metric '{current_metric}' (not winning_shot)")
                        else:
                            # Fallback to winning_shot path if error_shot_type not available
                            value = metadata
                            for key in path:
                                value = value.get(key, {}) if isinstance(value, dict) else None
                                if value is None:
                                    break
                    else:
                        # Normal path for non-error metrics
                        value = metadata
                        for key in path:
                            value = value.get(key, {}) if isinstance(value, dict) else None
                            if value is None:
                                break
                else:
                    # Normal metadata_path extraction
                    value = metadata
                    for key in path:
                        value = value.get(key, {}) if isinstance(value, dict) else None
                        if value is None:
                            break
                if value and isinstance(value, dict):
                    value = None  # Don't return dicts
        
        elif extraction_method == 'filter':
            filter_key = config.get('filter_key', '')
            value = filters.get(filter_key)
        
        elif extraction_method == 'custom':
            custom_func = config.get('custom_func')
            if custom_func:
                # Handle string identifiers for custom functions that need self
                if isinstance(custom_func, str):
                    if custom_func == 'get_set_group':
                        value = self._get_set_group(filters, score)
                    elif custom_func == 'get_net_play_type':
                        value = self._get_net_play_type(metadata)
                    # Add more custom function handlers here as needed
                else:
                    # Callable - pass parameters directly
                    value = custom_func(filters, metadata, score)
        
        elif extraction_method == 'metric_aware':
            # Special handling for player grouping - uses metric context
            value = self._get_player_group_key(filters, metadata)
        
        # Apply normalization if provided
        if value is not None and normalize:
            try:
                # Handle string identifiers for normalizers that need self
                if isinstance(normalize, str):
                    if normalize == 'normalize_outcome':
                        value = self._normalize_outcome_for_grouping(value)
                    # Add more normalizer handlers here as needed
                else:
                    # Callable
                    value = normalize(value)
            except:
                pass
        
        # Use fallback if value is None
        if value is None and fallback:
            try:
                # Handle string identifiers for special fallbacks
                if isinstance(fallback, str):
                    if fallback == 'extract_current_set':
                        value = str(self._extract_current_set(score)) if score else None
                    # Add more special fallback handlers here as needed
                # Handle callable fallbacks
                elif callable(fallback):
                    if 'point_lower' in fallback.__code__.co_varnames:
                        value = fallback(point_lower)
                    elif 'score' in fallback.__code__.co_varnames:
                        value = fallback(score)
                    elif 'rally_length' in fallback.__code__.co_varnames:
                        value = fallback(rally_length)
                    else:
                        value = fallback()
            except:
                pass
        
        return str(value) if value is not None else None
    
    def _get_player_group_key(self, filters: Dict, metadata: Dict) -> str:
        """Get player group key based on metric context - uses METRIC_CONFIG."""
        current_metric = filters.get('_current_metric')
        
        # Use METRIC_CONFIG to determine player_role
        metric_config = self.METRIC_CONFIG.get(current_metric, {}) if current_metric else {}
        player_role = metric_config.get('player_role', 'server')  # Default to server
        
        # CRITICAL: For 'both' role (like points_won), group by POINT_WINNER not server
        # This ensures "who won more points at X" groups by who WON, not who served
        if player_role == 'both':
            player_field = 'point_winner'
        else:
            # Get player field from ROLE_CONFIG
            role_config = self.ROLE_CONFIG.get(player_role, {})
            player_field = role_config.get('player_field', 'server')
        
        # Map to filter/metadata keys
        field_to_key = {
            'server': '_server',
            'returner': '_returner',
            'point_winner': '_point_winner',
            'error_player': '_error_player'
        }
        filter_key = field_to_key.get(player_field, '_server')
        target_player = filters.get(filter_key, '') or metadata.get(player_field, '')
        
        # Match to player1 or player2
        if target_player and self._names_match_robust(self.player1, target_player):
            return 'player1'
        elif target_player and self._names_match_robust(self.player2, target_player):
            return 'player2'
        else:
            # Fallback to server
            server = filters.get('_server', '') or metadata.get('server', '')
            if self._names_match_robust(self.player1, server):
                return 'player1'
            else:
                return 'player2'
    
    def _normalize_outcome_for_grouping(self, outcome: str) -> str:
        """Normalize outcome string for grouping - uses OUTCOME_CONFIG."""
        outcome_config = self._get_outcome_config(outcome)
        winning_shot_type = outcome_config.get('winning_shot_type', '')
        if winning_shot_type:
            return winning_shot_type
        
        # Fallback normalization
        outcome_lower = outcome.lower().replace(' ', '_')
        if 'unforced' in outcome_lower:
            return 'unforced_error'
        elif 'forced' in outcome_lower:
            return 'forced_error'
        return outcome_lower
    
    def _get_set_group(self, filters: Dict, score: str) -> str:
        """Get set group (group_a/group_b) for a point."""
        current_set = self._extract_current_set(score)
        set_group_a = filters.get('set_group_a', [])
        set_group_b = filters.get('set_group_b', [])
        if current_set in set_group_a:
            return 'group_a'
        elif current_set in set_group_b:
            return 'group_b'
        return None
    
    def _get_net_play_type(self, metadata: Dict) -> str:
        """Get net play type from metadata."""
        winning_shot = metadata.get('winning_shot', {})
        shot_type = winning_shot.get('shot_type')
        at_net = winning_shot.get('at_net', False)
        shot_modifiers = winning_shot.get('shot_modifiers', [])
        shot_modifier = winning_shot.get('shot_modifier')
        
        if 'volley' in shot_modifiers or shot_modifier == 'volley':
            return f"{shot_type}_volley" if shot_type else "volley"
        elif at_net or winning_shot.get('court_position') == 'net':
            return f"{shot_type}_at_net" if shot_type else "net_play"
        return None
    
    def _get_player_display(self, classification: Dict) -> Dict:
        """Get player display groups - GENERIC."""
        return {
            'player1': {'label': self.player1, 'total': 0, 'player1_wins': 0, 'player2_wins': 0, 'player1_metric': 0, 'player2_metric': 0},
            'player2': {'label': self.player2, 'total': 0, 'player1_wins': 0, 'player2_wins': 0, 'player1_metric': 0, 'player2_metric': 0}
        }
    
    def _get_set_groups_display(self, classification: Dict) -> Dict:
        """Get set groups display - GENERIC."""
        filters = classification.get('filters', {})
        set_a = filters.get('set_group_a', [])
        set_b = filters.get('set_group_b', [])
        set_a_label = f"Set{'s' if len(set_a) > 1 else ''} {', '.join(map(str, set_a))}" if set_a else "Group A"
        set_b_label = f"Set{'s' if len(set_b) > 1 else ''} {', '.join(map(str, set_b))}" if set_b else "Group B"
        
        def make_group(label):
            return {'label': label, 'total': 0, 'player1_wins': 0, 'player2_wins': 0, 'player1_metric': 0, 'player2_metric': 0}
        
        return {
            'group_a': {'label': set_a_label, 'sets': set_a, **make_group(set_a_label)},
            'group_b': {'label': set_b_label, 'sets': set_b, **make_group(set_b_label)}
        }
    
    def _get_display_label(self, group_by: str, value: Any, classification: Dict = None) -> str:
        """
        GENERIC display label getter using GROUP_CONFIG.
        Returns the display label for a given group_by value.
        """
        config = self._get_group_config(group_by)
        if not config:
            # Fallback: format value as title case
            if isinstance(value, str):
                return value.replace('_', ' ').title()
            return str(value)
        
        display_source = config.get('display_source', 'default')
        display_labels = config.get('display_labels', {})
        
        # Handle custom display functions
        if display_source == 'custom':
            custom_display = config.get('custom_display')
            if custom_display == 'get_player_display':
                # Special case: player grouping uses player names
                if value == 'player1':
                    return self.player1 or 'Player 1'
                elif value == 'player2':
                    return self.player2 or 'Player 2'
                return str(value)
            elif custom_display == 'get_set_groups_display':
                # Special case: set groups handled separately
                if value == 'group_a':
                    if classification:
                        filters = classification.get('filters', {})
                        set_a = filters.get('set_group_a', [])
                        if set_a:
                            return f"Set{'s' if len(set_a) > 1 else ''} {', '.join(map(str, set_a))}"
                    return "Group A"
                elif value == 'group_b':
                    if classification:
                        filters = classification.get('filters', {})
                        set_b = filters.get('set_group_b', [])
                        if set_b:
                            return f"Set{'s' if len(set_b) > 1 else ''} {', '.join(map(str, set_b))}"
                    return "Group B"
                return str(value)
        
        # Handle function-based display_labels (e.g., sets)
        if callable(display_labels):
            try:
                return display_labels(value)
            except:
                pass
        
        # Handle dictionary-based display_labels
        if isinstance(display_labels, dict):
            # Try exact match first
            if value in display_labels:
                return display_labels[value]
            # Try string conversion
            str_value = str(value)
            if str_value in display_labels:
                return display_labels[str_value]
        
        # Handle inventory-based display (with labels)
        if display_source == 'inventory':
            inventory = getattr(self, 'match_filter_inventory', {})
            inventory_key = config.get('inventory_key')
            if inventory_key and isinstance(display_labels, dict):
                # Use display_labels if available
                if value in display_labels:
                    return display_labels[value]
                str_value = str(value)
                if str_value in display_labels:
                    return display_labels[str_value]
        
        # Fallback: format value nicely
        if isinstance(value, str):
            return value.replace('_', ' ').title()
        return str(value)
    
    def _get_all_group_values(self, group_by: str, classification: Dict = None) -> Dict[str, str]:
        """
        GENERIC method to get all possible group values and their display labels.
        Uses GROUP_CONFIG as single source of truth.
        """
        config = self._get_group_config(group_by)
        if not config:
            return {}
        
        display_source = config.get('display_source', 'default')
        display_labels = config.get('display_labels', {})
        inventory = getattr(self, 'match_filter_inventory', {})
        
        result = {}
        
        # Handle custom display
        if display_source == 'custom':
            custom_display = config.get('custom_display')
            if custom_display == 'get_player_display':
                result['player1'] = self.player1 or 'Player 1'
                result['player2'] = self.player2 or 'Player 2'
                return result
            elif custom_display == 'get_set_groups_display':
                if classification:
                    filters = classification.get('filters', {})
                    set_a = filters.get('set_group_a', [])
                    set_b = filters.get('set_group_b', [])
                    set_a_label = f"Set{'s' if len(set_a) > 1 else ''} {', '.join(map(str, set_a))}" if set_a else "Group A"
                    set_b_label = f"Set{'s' if len(set_b) > 1 else ''} {', '.join(map(str, set_b))}" if set_b else "Group B"
                    result['group_a'] = set_a_label
                    result['group_b'] = set_b_label
                else:
                    result['group_a'] = 'Group A'
                    result['group_b'] = 'Group B'
                return result
        
        # Handle inventory-based (most common)
        if display_source == 'inventory':
            inventory_key = config.get('inventory_key')
            if inventory_key:
                values = inventory.get(inventory_key, config.get('default_branches', []))
                for val in values:
                    label = self._get_display_label(group_by, val, classification)
                    result[str(val)] = label
                # Add always_include values
                always_include = config.get('always_include', [])
                for val in always_include:
                    label = self._get_display_label(group_by, val, classification)
                    result[str(val)] = label
            else:
                # No inventory key, use default_branches
                default_branches = config.get('default_branches', [])
                for val in default_branches:
                    label = self._get_display_label(group_by, val, classification)
                    result[str(val)] = label
        
        # Handle predefined
        elif display_source == 'predefined':
            default_branches = config.get('default_branches', [])
            for val in default_branches:
                label = self._get_display_label(group_by, val, classification)
                result[str(val)] = label
        
        # Handle dynamic (values discovered during traversal)
        elif display_source == 'dynamic':
            # For dynamic, we can't pre-populate - return empty
            # Caller will discover values during traversal
            pass
        
        # Default: use display_labels if available
        else:
            if isinstance(display_labels, dict):
                result = {k: v for k, v in display_labels.items()}
            elif config.get('default_branches'):
                for val in config.get('default_branches', []):
                    label = self._get_display_label(group_by, val, classification)
                    result[str(val)] = label
        
        return result
    
    def _metric_matches_outcome(self, metric: str, outcome: str) -> bool:
        """Check if a metric matches an outcome - GENERIC using METRIC_CONFIG."""
        metric_config = self.METRIC_CONFIG.get(metric, {})
        keywords = metric_config.get('keywords', [])
        
        if not keywords:
            # No keywords means this metric doesn't filter by outcome
            return True
        
        outcome_lower = outcome.lower() if outcome else ''
        # Check if ANY keyword matches the outcome
        return any(kw.lower() in outcome_lower for kw in keywords)
    
    def _outcome_matches_metric(self, outcome: str, metric: str) -> bool:
        """Check if an outcome matches a metric - GENERIC using configs."""
        outcome_config = self._get_outcome_config(outcome)
        winning_shot_type = outcome_config.get('winning_shot_type', '')
        
        metric_config = self.METRIC_CONFIG.get(metric, {})
        keywords = metric_config.get('keywords', [])
        
        if not keywords:
            return True  # No keywords = matches all
        
        # Check if winning shot type matches any keyword
        return any(kw.lower() in winning_shot_type for kw in keywords)
        
    def _get_model_config(self, complexity: int) -> Dict:
        """
        Get model name and generation config based on complexity tier.
        
        Returns dict with:
            - model_name: str
            - temperature: float
        """
        if self.llm_provider != "gemini":
            # For non-Gemini, just return default model
            return {
                "model_name": self.model,
                "temperature": 0.1
            }
        
        if complexity == 1:
            # Tier 1: Simple - Fast & cheap (2.5 Flash)
            return {
                "model_name": self.model_25_flash,
                "temperature": 0.1
            }
        elif complexity == 2:
            # Tier 2: Moderate - 3 Flash with medium temperature
            # Note: 3 Flash has built-in reasoning capabilities
            return {
                "model_name": self.model_30_flash,
                "temperature": 0.7
            }
        else:  # complexity == 3
            # Tier 3: Complex - 3 Flash with lower temperature for precision
            # Note: 3 Flash has built-in deep reasoning capabilities
            return {
                "model_name": self.model_30_flash,
                "temperature": 0.3
            }
    
    def _fix_player_role_detection(self, question: str, classification: Dict) -> Dict:
        """
        Fix player detection for "[Player]'s return/service games" patterns.
        
        When a query says "Sinner's return games", the player should be Sinner,
        not "both". This overrides incorrect LLM parsing.
        """
        import re
        # Normalize ALL apostrophe variants to ASCII apostrophe
        # U+2019 = ' (right single quote - most common smart quote)
        # U+2018 = ' (left single quote)
        # U+0060 = ` (grave accent/backtick)
        # U+00B4 = Â´ (acute accent)
        # U+2032 = â€² (prime)
        question_normalized = question
        for char in ['\u2019', '\u2018', '\u0060', '\u00b4', '\u2032', ''', ''', '`', 'Â´']:
            question_normalized = question_normalized.replace(char, "'")
        question_lower = question_normalized.lower()
        filters = classification.get('filters', {})
        
        # Debug: print bytes of apostrophe area to see exactly what character is there
        if "sinner" in question_lower:
            idx = question_lower.find("sinner")
            snippet = question_lower[idx:idx+15]
        
        # Pattern: "[Player]'s return/service games"
        # This indicates the player is the RETURNER/SERVER, not just a filter
        # NOTE: Patterns are ordered from most specific to least specific
        # After normalization, all apostrophes are converted to straight quote '
        patterns = [
            # "On Sinner's return games" -> player=Sinner, role=returner (most specific)
            (r"(?:on\s+)?(\w+)'s\s+return\s+(?:games?|points?)", 'returner'),
            # "On Sinner's service/serve games" -> player=Sinner, role=server
            (r"(?:on\s+)?(\w+)'s\s+(?:service|serve)\s+(?:games?|points?)", 'server'),
            # "On Sinner's return" (without games/points) -> player=Sinner, role=returner
            (r"on\s+(\w+)'s\s+return(?:\s|$|,)", 'returner'),
            # "On Sinner's serve" (without games/points) -> player=Sinner, role=server
            (r"on\s+(\w+)'s\s+(?:service|serve)(?:\s|$|,)", 'server'),
            # "When Sinner returns" -> player=Sinner, role=returner
            (r"when\s+(\w+)\s+returns?", 'returner'),
            # "When Sinner serves" -> player=Sinner, role=server
            (r"when\s+(\w+)\s+serves?", 'server'),
            # "Sinner returning" or "Sinner on return" -> player=Sinner, role=returner
            (r"(\w+)\s+(?:returning|on\s+return)", 'returner'),
            # "Sinner serving" or "Sinner on serve" -> player=Sinner, role=server
            (r"(\w+)\s+(?:serving|on\s+serve)", 'server'),
        ]
        
        # Debug: Test first pattern explicitly
        test_pattern = r"(?:on\s+)?(\w+)'s\s+return\s+(?:games?|points?)"
        test_match = re.search(test_pattern, question_lower)
        
        for i, (pattern, role) in enumerate(patterns):
            match = re.search(pattern, question_lower)
            if match:
                player_name_raw = match.group(1).strip()
                
                # Try to match against known player names
                player1 = self.player1 if hasattr(self, 'player1') else None
                player2 = self.player2 if hasattr(self, 'player2') else None
                
                matched_player = None
                if player1 and player_name_raw.lower() in player1.lower():
                    matched_player = player1
                elif player2 and player_name_raw.lower() in player2.lower():
                    matched_player = player2
                elif player1 and player1.lower().split()[-1] == player_name_raw.lower():
                    # Last name match
                    matched_player = player1
                elif player2 and player2.lower().split()[-1] == player_name_raw.lower():
                    matched_player = player2
                
                if matched_player:
                    # Only override if current player is 'both' or unset
                    current_player = filters.get('player', '')
                    if not current_player or (current_player and current_player.lower() == 'both'):
                        filters['player'] = matched_player
                        filters['role'] = role
                    # else: Player already set, skip
                else:
                    # Pattern matched but couldn't resolve player - continue to next pattern
                    continue
                break
        
        classification['filters'] = filters
        return classification
    
    def _resolve_vague_terms(self, question: str, classification: Dict) -> Dict:
        """
        Detect vague analytical terms and resolve them to concrete metric bundles.
        
        This converts questions like "How effective was Sinner's serve?" into
        computable metrics like [first_serve_win_pct, second_serve_win_pct, service_winners].
        
        Returns:
            Updated classification with:
            - _vague_term: The detected term (if any)
            - _vague_interpretation: Description of what we're measuring
            - metrics: Updated with resolved metric bundle
            - query_category: Changed to 'analytical' if we can compute
        """
        question_lower = question.lower()
        
        # Step A: Detect vague terms using keyword match
        detected_term = None
        for raw_term, canonical in self.TERM_NORMALIZATION.items():
            # Word boundary check to avoid partial matches
            if f' {raw_term}' in f' {question_lower} ' or question_lower.startswith(raw_term):
                detected_term = canonical
                break
        
        # Also check canonical terms directly
        if not detected_term:
            for canonical in self.VAGUE_TERM_MAP.keys():
                if f' {canonical}' in f' {question_lower} ' or question_lower.startswith(canonical):
                    detected_term = canonical
                    break
        
        if not detected_term:
            return classification  # No vague term detected, return as-is
        
        # Step B: Infer context from query
        context = "default"
        filters = classification.get('filters', {})
        domain = classification.get('domain', 'all')
        
        # Check for context based on domain or role - GENERIC using configs
        role = filters.get('role')
        if domain in self.DOMAIN_CONFIG:
            context = domain
        elif role in self.ROLE_CONFIG:
            # Map role to context using DOMAIN_CONFIG
            for d, cfg in self.DOMAIN_CONFIG.items():
                if cfg.get('role') == role:
                    context = d
                    break
        elif 'serve' in question_lower:
            context = 'serve'
        elif 'return' in question_lower:
            context = 'return'
        # Check for rally context
        elif 'rally' in question_lower or 'baseline' in question_lower:
            context = "rally"
        # Check for net context
        elif 'net' in question_lower and 'internet' not in question_lower:
            context = "net"
        # Check for break point context
        elif 'break point' in question_lower or filters.get('situation') == 'break_point':
            context = "break_point"
        
        # Step C: Bind to metric bundle
        term_config = self.VAGUE_TERM_MAP.get(detected_term, {})
        metric_bundle = term_config.get(context, term_config.get("default", ["win_percentage"]))
        interpretation = term_config.get("description", f"Analyzing {detected_term}")
        
        # Step D: Update classification
        print(f"[VAGUE-RESOLVE] Detected '{detected_term}' in context '{context}'")
        print(f"[VAGUE-RESOLVE] Interpretation: {interpretation}")
        print(f"[VAGUE-RESOLVE] Metric bundle: {metric_bundle}")
        
        # Store vague term info for disclosure
        classification['_vague_term'] = detected_term
        classification['_vague_context'] = context
        classification['_vague_interpretation'] = interpretation
        classification['_vague_metrics'] = metric_bundle
        
        # Update metrics (add to existing, don't replace)
        existing_metrics = classification.get('metrics', [])
        for m in metric_bundle:
            if m not in existing_metrics:
                existing_metrics.append(m)
        classification['metrics'] = existing_metrics
        
        # CRITICAL: Preserve/create metric_filters for vague-resolved metrics
        # If LLM provided top-level filters (shot_type, direction, etc.) but metrics_parsed was empty (vague),
        # we need to apply those filters to the vague-resolved metrics
        if 'metric_filters' not in classification:
            classification['metric_filters'] = {}
        
        # Check if LLM provided top-level shot filters
        top_level_shot_filters = {}
        for filter_key in ['shot_type', 'direction', 'shot_modifier', 'player', 'role', 'situation', 'set']:
            filter_value = filters.get(filter_key)
            if filter_value:
                top_level_shot_filters[filter_key] = filter_value
        
        # Apply these filters to all vague-resolved metrics
        if top_level_shot_filters:
            for m in metric_bundle:
                if m not in classification['metric_filters']:
                    classification['metric_filters'][m] = {
                        'metric': m,
                        'filters': top_level_shot_filters.copy(),
                        'context': context
                    }
        
        # Force group_by if term has special grouping (e.g., momentum -> by sets)
        if 'group_by' in term_config and not classification.get('group_by'):
            classification['group_by'] = term_config['group_by']
            print(f"[VAGUE-RESOLVE] Forcing group_by: {term_config['group_by']}")
        
        # CRITICAL: If we can compute metrics, change to analytical (not narrative)
        if metric_bundle:
            classification['query_category'] = 'analytical'
            print(f"[VAGUE-RESOLVE] Converting to ANALYTICAL route (computable metrics found)")
        
        return classification
    
    def _classify_query_complexity(self, question: str, classification: Dict) -> int:
        """
        Classify query complexity for model selection.
        
        Returns:
            1 = Simple (2.5 Flash, no thinking) - Retrieval, counts, basic stats
            2 = Moderate (3.0 Flash, medium thinking) - Comparisons, multi-step, cross-tab
            3 = Complex (3.0 Flash, high thinking) - Deep tactical, causation, strategy analysis
        """
        question_lower = question.lower()
        query_category = classification.get('query_category', 'analytical')
        analysis_type = classification.get('analysis_type', 'count')
        metrics = classification.get('metrics', [])
        filters = classification.get('filters', {})
        group_by = classification.get('group_by')
        secondary_group_by = classification.get('secondary_group_by')
        
        # === TIER 3: COMPLEX (3.0 Flash, High Thinking) ===
        # Deep tactical analysis, causation, multi-layered strategic questions
        if query_category == 'narrative':
            # Narrative questions need strategic thinking
            if any(kw in question_lower for kw in ['why', 'how did', 'what caused', 'momentum', 'tactical', 'strategy', 'aggressive', 'pattern']):
                return 3  # Deep tactical analysis
            return 2  # Simple narrative lookup
        
        # Multi-dimensional or chained analysis
        if analysis_type in ['chain', 'momentum', '2d_cross_tab']:
            return 3
        
        # Questions about causation or correlation
        if any(kw in question_lower for kw in ['why', 'because', 'lead to', 'caused', 'result in', 'due to']):
            return 3
        
        # === TIER 2: MODERATE (3.0 Flash, Medium Thinking) ===
        # Comparisons, grouping, cross-sectional analysis
        if secondary_group_by or analysis_type in ['comparison', 'ratio', 'trend']:
            return 2
        
        # Comparing across dimensions (grouping requires coordination)
        if group_by:  # Any grouping adds complexity
            return 2
        
        # Multiple filters (needs coordination)
        active_filters = sum(1 for v in filters.values() if v is not None and v != '')
        if active_filters >= 3:
            return 2
        
        # Comparison keywords
        if any(kw in question_lower for kw in ['vs', 'versus', 'compared to', 'difference', 'change', 'across sets']):
            return 2
        
        # === TIER 1: SIMPLE (2.5 Flash, No Thinking) ===
        # Direct retrieval, simple counts, basic aggregation
        if analysis_type == 'count' and not group_by and active_filters <= 1:
            return 1  # "How many aces?" - simple count
        
        # Simple lookup questions
        if any(question_lower.startswith(kw) for kw in ['how many', 'what was', 'who won', 'show me', 'list']):
            if not group_by and active_filters <= 1:
                return 1
        
        # Default to moderate for anything not clearly simple or complex
        return 2
    
    def _init_llm_client(self):
        """Initialize the LLM client based on provider."""
        if self.llm_provider == "claude":
            try:
                import anthropic
                api_key = self.api_key or os.getenv("ANTHROPIC_API_KEY")
                if not api_key:
                    raise ValueError("ANTHROPIC_API_KEY environment variable required for Claude")
                self.client = anthropic.Anthropic(api_key=api_key)
                self.model = "claude-3-5-sonnet-20241022"
            except ImportError:
                raise ImportError("Please install anthropic: pip install anthropic")
                
        elif self.llm_provider == "gemini":
            try:
                import google.generativeai as genai
                api_key = self.api_key or os.getenv("GOOGLE_API_KEY")
                if not api_key:
                    raise ValueError("GOOGLE_API_KEY environment variable required for Gemini")
                genai.configure(api_key=api_key)
                self.client = genai
                # Default to 2.5 Flash (fast & cheap) - will be overridden dynamically based on query complexity
                self.model = self.custom_model or "gemini-2.5-flash"
                self.model_25_flash = "gemini-2.5-flash"  # For simple queries
                self.model_30_flash = "gemini-3-flash-preview"  # For complex queries
            except ImportError:
                raise ImportError("Please install google-generativeai: pip install google-generativeai")
                
        elif self.llm_provider == "openai":
            try:
                from openai import OpenAI
                api_key = self.api_key or os.getenv("OPENAI_API_KEY")
                if not api_key:
                    raise ValueError("OPENAI_API_KEY environment variable required for OpenAI")
                self.client = OpenAI(api_key=api_key)
                self.model = self.custom_model or "gpt-4o-mini"  # Allow custom model
            except ImportError:
                raise ImportError("Please install openai: pip install openai")
        else:
            raise ValueError("llm_provider must be 'claude', 'gemini', or 'openai'")
        
    def _parse_match_score(self, content: str) -> None:
        """
        Parse the match score from the markdown content and build set mapping.
        Example: "Carlos Alcaraz d. Jannik Sinner 4-6 6-7(4) 6-4 7-6(3)"
        Format: "Winner d. Loser winner_score-loser_score ..."
        """
        import re
        
        # Initialize
        self.match_score = None
        self.set_mapping = {}  # Maps set number to set score (e.g., {1: "0-0", 2: "0-1", 3: "0-2", 4: "1-2"})
        self.total_sets = 0
        self.set_winners = {}  # Maps set number to winner (player1 or player2)
        self.match_winner = None
        self.match_loser = None
        self.game_winners = {}  # Maps (set_num, game_num) -> winner (player1 or player2)
        self.game_servers = {}  # Maps (set_num, game_num) -> server (player1 or player2)
        
        # Find the Final Score line
        score_match = re.search(r'Final Score:\s*(.+?)(?:\n|$)', content)
        if not score_match:
            print("[WARN] Could not find Final Score in markdown")
            return
        
        score_line = score_match.group(1).strip()
        self.match_score = score_line
        
        # Parse the format: "Winner d. Loser score score score"
        match_result = re.match(r'(.+?)\s+d\.\s+(.+?)\s+([\d\-\(\)\s]+)$', score_line)
        if not match_result:
            print("[WARN] Could not parse match result format:", score_line)
            return
        
        winner_name = match_result.group(1).strip()
        loser_name = match_result.group(2).strip()
        scores_str = match_result.group(3).strip()
        
        self.match_winner = winner_name
        self.match_loser = loser_name
        
        # Extract the set scores
        set_scores = re.findall(r'(\d+)-(\d+)(?:\(\d+\))?', scores_str)
        
        if not set_scores:
            print("[WARN] Could not parse set scores from:", score_line)
            return
        
        self.total_sets = len(set_scores)
        
        # Determine which player is player1 and which is player2
        # (based on who is mentioned first in self.player1/player2)
        winner_is_player1 = (hasattr(self, 'player1') and 
                            self.player1 and 
                            winner_name.lower().replace(' ', '') == self.player1.lower().replace(' ', ''))
        
        # Build cumulative set score and track set winners
        # Scores in the format are: winner_score-loser_score for each set
        player1_sets = 0
        player2_sets = 0
        
        for i, (score1, score2) in enumerate(set_scores, 1):
            # Record the set score BEFORE this set starts
            self.set_mapping[i] = f"{player1_sets}-{player2_sets}"
            
            # Determine who won this set
            # score1 is winner's score, score2 is loser's score
            if int(score1) > int(score2):
                # Winner won this set
                if winner_is_player1:
                    self.set_winners[i] = 'player1'
                    player1_sets += 1
                else:
                    self.set_winners[i] = 'player2'
                    player2_sets += 1
            else:
                # Loser won this set
                if winner_is_player1:
                    self.set_winners[i] = 'player2'
                    player2_sets += 1
                else:
                    self.set_winners[i] = 'player1'
                    player1_sets += 1
        
        print(f"[MATCH] Final Score: {self.match_score}")
        print(f"[MATCH] Winner: {winner_name} | Loser: {loser_name}")
        print(f"[MATCH] Winner is Player1: {winner_is_player1}")
        print(f"[MATCH] Set Mapping: {self.set_mapping}")
        print(f"[MATCH] Set Winners: {self.set_winners}")
    
    def _get_sets_won_by_player(self, player_name: str) -> list:
        """
        Get the list of set numbers won by a specific player.
        Returns empty list if player not found or no sets tracked.
        """
        if not hasattr(self, 'set_winners') or not self.set_winners:
            return []
        
        if not player_name:
            return []
        
        # Normalize player name for comparison
        player_normalized = player_name.lower().replace(' ', '')
        player1_normalized = (self.player1 or '').lower().replace(' ', '')
        player2_normalized = (self.player2 or '').lower().replace(' ', '')
        
        # Determine if this is player1 or player2
        is_player1 = player_normalized == player1_normalized
        is_player2 = player_normalized == player2_normalized
        
        if not is_player1 and not is_player2:
            return []
        
        # Get sets won by this player
        sets_won = []
        for set_num, winner in self.set_winners.items():
            if (is_player1 and winner == 'player1') or (is_player2 and winner == 'player2'):
                sets_won.append(set_num)
        
        return sets_won
    
    def _get_sets_lost_by_player(self, player_name: str) -> list:
        """
        Get the list of set numbers lost by a specific player.
        Returns empty list if player not found or no sets tracked.
        """
        if not hasattr(self, 'set_winners') or not self.set_winners:
            return []
        
        if not player_name:
            return []
        
        # Normalize player name for comparison
        player_normalized = player_name.lower().replace(' ', '')
        player1_normalized = (self.player1 or '').lower().replace(' ', '')
        player2_normalized = (self.player2 or '').lower().replace(' ', '')
        
        # Determine if this is player1 or player2
        is_player1 = player_normalized == player1_normalized
        is_player2 = player_normalized == player2_normalized
        
        if not is_player1 and not is_player2:
            return []
        
        # Get sets lost by this player (won by opponent)
        sets_lost = []
        for set_num, winner in self.set_winners.items():
            if (is_player1 and winner == 'player2') or (is_player2 and winner == 'player1'):
                sets_lost.append(set_num)
        
        return sets_lost
    
    def _detect_set_reference(self, query: str) -> int:
        """
        Detect if the query references a specific set.
        Returns the set number (1, 2, 3, 4, 5) or None.
        Returns None if MULTIPLE sets are mentioned (e.g., "set 3 and set 4").
        """
        import re
        
        query_lower = query.lower()
        
        # Check for multiple set references (e.g., "set 3 and set 4")
        # If found, return None to avoid filtering
        set_count = len(re.findall(r'set\s+\d+', query_lower))
        if set_count > 1:
            return None
        
        # Direct number references
        # Match "set 3", "in set 3", "3rd set", "the 3rd set", etc.
        set_match = re.search(r'set\s+(\d+)', query_lower)  # "set 3"
        if not set_match:
            set_match = re.search(r'(\d+)(?:st|nd|rd|th)?\s+set', query_lower)  # "3rd set"
        if set_match:
            return int(set_match.group(1))
        
        # Word-based references
        set_words = {
            'first': 1, 'second': 2, 'third': 3, 'fourth': 4, 'fifth': 5,
            '1st': 1, '2nd': 2, '3rd': 3, '4th': 4, '5th': 5
        }
        
        for word, num in set_words.items():
            if f"{word} set" in query_lower:
                return num
        
        # Special references
        if any(word in query_lower for word in ['final set', 'deciding set', 'last set']):
            return self.total_sets if self.total_sets else None
        
        return None
    
    def _detect_multiple_set_references(self, query: str) -> List[int]:
        """
        Detect if the query references MULTIPLE specific sets (for comparison questions).
        Returns a list of set numbers [1, 5] or empty list if not a multi-set comparison.
        Examples: "Set 1 vs Set 5", "Set 1 versus Set 5", "compare Set 1 and Set 5"
        """
        import re
        
        query_lower = query.lower()
        
        # Find all set number references
        set_numbers = []
        
        # Match "set 1", "set 5", etc.
        for match in re.finditer(r'set\s+(\d+)', query_lower):
            set_num = int(match.group(1))
            if 1 <= set_num <= 5 and set_num not in set_numbers:
                set_numbers.append(set_num)
        
        # Also check for word-based references
        set_words = {
            'first': 1, 'second': 2, 'third': 3, 'fourth': 4, 'fifth': 5,
            '1st': 1, '2nd': 2, '3rd': 3, '4th': 4, '5th': 5
        }
        
        for word, num in set_words.items():
            if f"{word} set" in query_lower and num not in set_numbers:
                set_numbers.append(num)
        
        # Only return if we found multiple sets AND it's a comparison question
        if len(set_numbers) >= 2:
            comparison_indicators = ['vs', 'versus', 'compared to', 'compare', 'vs.', 'v.']
            if any(indicator in query_lower for indicator in comparison_indicators):
                set_numbers.sort()  # Return in order [1, 5]
                return set_numbers
        
        return []
    
    def _detect_game_reference(self, query: str) -> str:
        """
        Detect if the query references a specific game or game score.
        Returns a game score pattern like "3-2" or None.
        """
        import re
        
        query_lower = query.lower()
        
        # Game score patterns (e.g., "at 4-3", "when it was 5-5", "3-2")
        game_score_match = re.search(r'(?:at\s+|when\s+it\s+was\s+|score\s+was\s+)?(\d+)-(\d+)', query_lower)
        if game_score_match:
            return f"{game_score_match.group(1)}-{game_score_match.group(2)}"
        
        # Game number references (e.g., "game 5", "5th game")
        game_num_match = re.search(r'(?:game\s+|the\s+)?(\d+)(?:st|nd|rd|th)?\s+game', query_lower)
        if game_num_match:
            # This would need more complex logic to determine the exact game score
            # For now, just return a marker that we need game-specific data
            return f"game_{game_num_match.group(1)}"
        
        return None
        
    def load_exact_full_format(self, file_path: str = "EXACT_FULL_FORMAT.md") -> None:
        """
        Load and process the specified natural language file into chunks with embeddings.
        """
        print(f"Loading {file_path}...")
        
        # Extract player names from filename (e.g., "Jannik_Sinner_Carlos_Alcaraz_20250608_NL.md")
        import os
        filename = os.path.basename(file_path)
        parts = filename.replace('_NL.md', '').split('_')
        if len(parts) >= 4:
            # Reconstruct player names (handle names with spaces)
            # Find the date (8 digits) to split the names
            date_idx = next((i for i, part in enumerate(parts) if part.isdigit() and len(part) == 8), None)
            if date_idx and date_idx >= 2:
                player1_parts = parts[:date_idx//2] 
                player2_parts = parts[date_idx//2:date_idx]
                self.player1 = ' '.join(player1_parts)
                self.player2 = ' '.join(player2_parts)
                print(f"Extracted player names: {self.player1} vs {self.player2}")
        
        # Read the file
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Extract match score for set mapping (needed for transformation)
        self._parse_match_score(content)
        
        # Transform point-by-point data to add shot attribution (NEW!)
        content = self._transform_point_by_point_in_content(content)
        
        # Extract structured point-by-point data for analysis
        self._extract_point_by_point_data(content)
        
        # Split content into sections (tables vs point-by-point)
        sections = self._split_into_sections(content)
        
        # Process each section
        all_chunks = []
        for section_name, section_text in sections.items():
            print(f"Processing section: {section_name}")
            
            # Determine chunk type based on section content
            chunk_type = self._determine_chunk_type(section_name, section_text)
            
            chunks = self._create_chunks_with_metadata(
                section_text, 
                chunk_type=chunk_type,
                section=section_name,
                match_id=self.match_id
            )
            all_chunks.extend(chunks)
        
        # Generate embeddings for all chunks
        print("Generating embeddings...")
        self.chunks = self._embed_chunks(all_chunks)
        
        # Create FAISS index
        print("Creating vector index...")
        self._create_vector_index()
        
        print(f"Loaded {len(self.chunks)} chunks with embeddings")
        
    def _split_into_sections(self, content: str) -> Dict[str, str]:
        """
        Split the natural language content using improved semantic + size-aware chunking.
        Creates optimal chunks based on content type and size for better searchability.
        """
        sections = {}
        lines = content.split('\n')
        
        # Define section patterns and chunking strategies
        section_config = {
            'MATCH OVERVIEW:': 'small',
            'RALLY OUTCOMES STATISTICS:': 'medium', 
            'OVERVIEW STATISTICS:': 'small',
            'SERVE1 STATISTICS (SUMMARY):': 'medium',
            'SERVE1 STATISTICS (DETAILED):': 'large',
            'SERVE2 STATISTICS (SUMMARY):': 'medium',
            'SERVE2 STATISTICS (DETAILED):': 'large',
            'RETURN1 STATISTICS (DETAILED):': 'large',
            'RETURN2 STATISTICS (DETAILED):': 'large',
            'KEY POINTS STATISTICS (SERVES):': 'medium',
            'KEY POINTS STATISTICS (RETURNS):': 'medium',
            'SHOTS1 STATISTICS:': 'large',
            'SHOTS2 STATISTICS:': 'large',
            # CRITICAL: SHOTDIR sections must NOT be split - they contain win percentages
            # in the "DETAILED BREAKDOWN" subsection that must stay with the totals
            'SHOTDIR1 STATISTICS:': 'medium',
            'SHOTDIR2 STATISTICS:': 'medium',
            'EXPLICIT TOTALS FOR SHOT DIRECTION + OUTCOME COMBINATIONS:': 'small',
            'NETPTS1 STATISTICS:': 'small',
            'NETPTS2 STATISTICS:': 'small',
            'POINT-BY-POINT NARRATIVE:': 'narrative'
        }
        
        current_section = None
        current_text = []
        current_strategy = None
        
        
        for line in lines:
            line_stripped = line.strip()
            
            # Check if this line starts a new section
            section_found = None
            strategy_found = None
            
            for pattern, strategy in section_config.items():
                if line_stripped.startswith(pattern):
                    section_found = pattern.rstrip(':').lower().replace(' ', '_').replace('(', '').replace(')', '')
                    strategy_found = strategy
                    break
            
            if section_found:
                # Process previous section with its strategy
                if current_section and current_text:
                    self._process_section_with_strategy(sections, current_section, current_text, current_strategy)
                
                # Start new section
                current_section = section_found
                current_strategy = strategy_found
                current_text = [line]
            else:
                current_text.append(line)
        
        # Process the last section
        if current_section and current_text:
            self._process_section_with_strategy(sections, current_section, current_text, current_strategy)
        
        print(f"Created {len(sections)} optimized chunks using semantic boundaries")
        return sections
    
    def _process_section_with_strategy(self, sections: Dict[str, str], section_name: str, 
                                     lines: List[str], strategy: str):
        """Process a section according to its chunking strategy."""
        content = '\n'.join(lines)
        
        if strategy == 'small':
            # Keep small sections intact (MATCH OVERVIEW, NETPTS, etc.)
            sections[section_name] = content
            
        elif strategy == 'medium':
            # Split medium sections by player if beneficial
            player_chunks = self._split_by_player_if_beneficial(content, section_name)
            if len(player_chunks) > 1:
                for i, chunk in enumerate(player_chunks):
                    sections[f"{section_name}_player_{i+1}"] = chunk
            else:
                sections[section_name] = content
                
        elif strategy == 'large':
            # Split large detailed sections by logical subsections
            subsection_chunks = self._split_large_section_intelligently(content, section_name)
            if len(subsection_chunks) > 1:
                for i, chunk in enumerate(subsection_chunks):
                    sections[f"{section_name}_part_{i+1}"] = chunk
            else:
                sections[section_name] = content
                
        elif strategy == 'narrative':
            # Split point-by-point by game groups (every 12-15 points)
            point_chunks = self._split_narrative_by_games(content)
            for i, chunk in enumerate(point_chunks):
                sections[f"{section_name}_games_{i+1}"] = chunk
            
        elif strategy == 'return_split':
            # Custom strategy for return statistics: split by outcomes and depth
            return_chunks = self._split_return_statistics_by_outcomes_and_depth(content, section_name)
            if len(return_chunks) > 1:
                for i, chunk in enumerate(return_chunks):
                    if i == 0:
                        sections[f"{section_name}_outcomes"] = chunk
                    else:
                        sections[f"{section_name}_depth"] = chunk
            else:
                sections[section_name] = content
    
    def _split_return_statistics_by_outcomes_and_depth(self, content: str, section_name: str) -> List[str]:
        """Split return statistics into outcomes and depth sections."""
        lines = content.split('\n')
        outcomes_section = []
        depth_section = []
        current_section = None
        
        for line in lines:
            # Check for depth section indicators
            if any(phrase in line.lower() for phrase in [
                'shallow returns', 'deep returns', 'very deep returns', 
                'unforced errors when returning', 'net approaches when returning'
            ]):
                current_section = 'depth'
            
            # Add line to appropriate section
            if current_section == 'depth':
                depth_section.append(line)
            else:
                outcomes_section.append(line)
        
        chunks = []
        if outcomes_section:
            chunks.append('\n'.join(outcomes_section))
        if depth_section:
            chunks.append('\n'.join(depth_section))
        
        return chunks if len(chunks) > 1 else [content]
    
    def _split_by_player_if_beneficial(self, content: str, section_name: str, player1: str = None, player2: str = None) -> List[str]:
        """Split content by player if it creates meaningful chunks."""
        lines = content.split('\n')
        player1_lines = []
        player2_lines = []
        header_lines = []
        
        # For key points sections, we need to include the authoritative totals
        authoritative_totals = []
        if 'key_points_statistics' in section_name:
            # Look for authoritative totals in the content
            content_lines = content.split('\n')
            in_authoritative_section = False
            for line in content_lines:
                if 'AUTHORITATIVE TOTALS FOR KEY POINTS:' in line:
                    in_authoritative_section = True
                    authoritative_totals.append(line)
                elif in_authoritative_section and line.strip() == '':
                    # End of authoritative section
                    break
                elif in_authoritative_section:
                    authoritative_totals.append(line)
        
        for line in lines:
            if player1 and player1 in line and not line.strip().endswith(':'):
                player1_lines.append(line)
            elif player2 and player2 in line and not line.strip().endswith(':'):
                player2_lines.append(line)
            elif line.strip().endswith(':') or line.startswith('---') or line.startswith('='):
                header_lines.append(line)
            else:
                # Neutral lines go to both if we're splitting, otherwise to header
                if player1_lines or player2_lines:
                    continue
                header_lines.append(line)
        
        # Only split if both players have significant content
        if len(player1_lines) >= 3 and len(player2_lines) >= 3:
            chunks = []
            if player1_lines:
                # Include authoritative totals at the beginning for key points sections
                if authoritative_totals:
                    chunks.append('\n'.join(authoritative_totals + [''] + header_lines + player1_lines))
                else:
                    chunks.append('\n'.join(header_lines + player1_lines))
            if player2_lines:
                # Include authoritative totals at the beginning for key points sections
                if authoritative_totals:
                    chunks.append('\n'.join(authoritative_totals + [''] + header_lines + player2_lines))
                else:
                    chunks.append('\n'.join(header_lines + player2_lines))
            return chunks
            
        return [content]  # Don't split if not beneficial
    
    def _split_large_section_intelligently(self, content: str, section_name: str) -> List[str]:
        """Split large sections by natural semantic boundaries."""
        lines = content.split('\n')
        chunks = []
        current_chunk = []
        
        # Identify natural break points
        for i, line in enumerate(lines):
            current_chunk.append(line)
            
            # Look for natural breaks in detailed statistics
            is_break_point = (
                len(current_chunk) > 40 and  # Minimum chunk size
                (line.strip().endswith('court.') or 
                 line.strip().endswith('serves.') or
                 line.strip().endswith('returns.') or
                 (i < len(lines) - 1 and lines[i+1].strip() == '') or  # Empty line follows
                 ('served to the' in line and 'court' in line and 
                  i > 0 and 'served to the' not in lines[i-1]))
            )
            
            if is_break_point:
                chunks.append('\n'.join(current_chunk))
                current_chunk = []
        
        # Handle remaining content
        if current_chunk:
            if chunks and len(current_chunk) < 20:
                # Append small remainder to last chunk
                chunks[-1] += '\n' + '\n'.join(current_chunk)
            else:
                chunks.append('\n'.join(current_chunk))
        
        return chunks if len(chunks) > 1 else [content]
    
    def _split_narrative_by_games(self, content: str) -> List[str]:
        """Split point-by-point narrative by game groups for optimal chunk size."""
        lines = content.split('\n')
        chunks = []
        current_chunk = []
        point_count = 0
        
        for line in lines:
            current_chunk.append(line)
            
            # Count actual points
            if line.startswith('Point '):
                point_count += 1
                
                # Create new chunk every 20 points (more comprehensive coverage)
                # This ensures longer rallies don't get split across chunks
                if point_count % 20 == 0 and len(current_chunk) > 10:
                    chunks.append('\n'.join(current_chunk))
                    current_chunk = []
        
        # Handle remaining points
        if current_chunk:
            if chunks and len(current_chunk) < 8:
                # Append small remainder to last chunk
                chunks[-1] += '\n' + '\n'.join(current_chunk)
            else:
                chunks.append('\n'.join(current_chunk))
        
        return chunks if chunks else [content]
    
    def _extract_set_numbers_from_chunk(self, chunk_text: str) -> List[int]:
        """
        Extract which set(s) this chunk contains based on score patterns.
        Returns list of set numbers (e.g., [2, 3] for a mixed chunk).
        """
        import re
        
        if not hasattr(self, 'set_mapping') or not self.set_mapping:
            return []
        
        set_numbers = set()
        
        # Find all "Score: X-Y" patterns in chunk
        score_matches = re.findall(r'Score: (\d+)-(\d+)', chunk_text)
        
        for server_sets, returner_sets in score_matches:
            set_score = f"{server_sets}-{returner_sets}"
            
            # Reverse lookup: which set has this score pattern?
            for set_num, expected_score in self.set_mapping.items():
                # Check both the expected score and its reverse (server perspective flip)
                score_parts = expected_score.split('-')
                reversed_score = f"{score_parts[1]}-{score_parts[0]}" if len(score_parts) == 2 else expected_score
                
                if set_score == expected_score or set_score == reversed_score:
                    set_numbers.add(set_num)
        
        return sorted(list(set_numbers))
    
    def _extract_game_scores_from_chunk(self, chunk_text: str) -> List[str]:
        """
        Extract which game scores appear in this chunk.
        Returns list of game scores (e.g., ['0-0', '1-0', '2-1']).
        """
        import re
        
        game_scores = set()
        
        # Find all "Score: X-Y G1-G2" patterns in chunk
        # Format: "Score: 2-0 4-5 0-15" where 4-5 is the game score
        score_matches = re.findall(r'Score: \d+-\d+ (\d+-\d+)', chunk_text)
        
        for game_score in score_matches:
            game_scores.add(game_score)
        
        return sorted(list(game_scores))
    
    def _transform_point_by_point_in_content(self, content: str) -> str:
        """
        Find and transform the point-by-point section in the full content.
        Adds player attribution to each shot in rallies.
        """
        import re
        
        # Find the point-by-point section
        pbp_start = content.find('POINT-BY-POINT NARRATIVE:')
        if pbp_start == -1:
            return content  # No PBP section found
        
        # Find where it ends (look for next major section or end of file)
        # PBP is typically the last section, but check anyway
        pbp_end = len(content)
        for next_section in ['RALLY OUTCOMES STATISTICS:', 'OTHER DATA:']:
            section_pos = content.find(next_section, pbp_start + 1)
            if section_pos != -1 and section_pos < pbp_end:
                pbp_end = section_pos
        
        # Extract, transform, and replace
        raw_pbp = content[pbp_start:pbp_end]
        print("[TRANSFORM] Adding shot attribution to point-by-point data...")
        transformed_pbp = self._transform_point_by_point_data(raw_pbp)
        
        return content[:pbp_start] + transformed_pbp + content[pbp_end:]
    
    def _transform_point_by_point_data(self, raw_pbp_text: str) -> str:
        """
        Transform raw PBP notation into explicit, LLM-friendly format with shot attribution.
        """
        import re
        
        # Keep the header
        result = "POINT-BY-POINT NARRATIVE:\n"
        result += "-" * 30 + "\n\n"
        
        # Find all points
        points = re.findall(r'(Point \d+.*?)(?=Point \d+|$)', raw_pbp_text, re.DOTALL)
        
        transformed_count = 0
        for point_text in points:
            if not point_text.strip():
                continue
            transformed = self._transform_single_point(point_text.strip())
            result += transformed + "\n\n"
            transformed_count += 1
        
        return result
    
    def _transform_single_point(self, point_text: str) -> str:
        """Transform a single point into explicit format with shot attribution."""
        import re
        
        # Parse point header
        header_match = re.search(
            r'Point (\d+) \[Server: (.*?) \| Returner: (.*?) \| Score: ([\d-]+) ([\d-]+) ([\d-]+)\]:',
            point_text
        )
        
        if not header_match:
            return point_text  # Fallback to original
        
        point_num = header_match.group(1)
        server = header_match.group(2).strip()
        returner = header_match.group(3).strip()
        set_score = header_match.group(4)
        game_score = header_match.group(5)
        point_score = header_match.group(6)
        
        # CRITICAL: Validate and fix server == returner bug using rally structure
        # SEMICOLONS INDICATE A CHANGE IN HITTER
        rally_text = point_text[header_match.end():].strip()
        
        # Check if server == returner (this is the bug!)
        if server.strip().lower() == returner.strip().lower() and self.player1 and self.player2:
            # Use rally structure (semicolons = hitter alternation) to determine correct returner
            shots = [s.strip() for s in rally_text.split(';') if s.strip()]
            
            if len(shots) >= 2:
                # Rally structure: Shot 0 = server, Shot 1 = returner, Shot 2 = server, etc.
                # First shot should be serve (by server), second shot is return (by returner)
                first_shot = shots[0].lower()
                is_serve = '1st serve' in first_shot or '2nd serve' in first_shot or 'serve' in first_shot
                
                if is_serve:
                    # Determine which player the server is by matching server name
                    server_lower = server.lower().strip()
                    p1_lower = self.player1.lower().strip()
                    p2_lower = self.player2.lower().strip()
                    
                    # Use fuzzy matching to determine server
                    if server_lower == p1_lower or (p1_lower in server_lower or server_lower in p1_lower):
                        # Server is player1, returner is player2
                        returner = self.player2
                    elif server_lower == p2_lower or (p2_lower in server_lower or server_lower in p2_lower):
                        # Server is player2, returner is player1
                        returner = self.player1
                    else:
                        # Can't match - use context from player names
                        # If server name is closer to player1, returner is player2
                        sim1 = 1.0 if server_lower == p1_lower else (0.9 if p1_lower in server_lower or server_lower in p1_lower else 0.0)
                        sim2 = 1.0 if server_lower == p2_lower else (0.9 if p2_lower in server_lower or server_lower in p2_lower else 0.0)
                        returner = self.player2 if sim1 > sim2 else self.player1
                    
                else:
                    # First shot is not a serve - can't infer from structure, use best guess
                    server_lower = server.lower().strip()
                    p1_lower = self.player1.lower().strip()
                    p2_lower = self.player2.lower().strip()
                    sim1 = 1.0 if server_lower == p1_lower else (0.9 if p1_lower in server_lower or server_lower in p1_lower else 0.0)
                    sim2 = 1.0 if server_lower == p2_lower else (0.9 if p2_lower in server_lower or server_lower in p2_lower else 0.0)
                    returner = self.player2 if sim1 > sim2 else self.player1
            else:
                # Single shot (ace/service winner) - CRITICAL: Server ALWAYS hits the shot
                # Since server is correct, returner MUST be the other player
                server_lower = server.lower().strip()
                p1_lower = self.player1.lower().strip()
                p2_lower = self.player2.lower().strip()
                
                # Match server to determine which player it is, then returner is the other
                if server_lower == p1_lower or (p1_lower in server_lower or server_lower in p1_lower):
                    # Server is player1, returner is player2
                    returner = self.player2
                elif server_lower == p2_lower or (p2_lower in server_lower or server_lower in p2_lower):
                    # Server is player2, returner is player1
                    returner = self.player1
                else:
                    # Can't match - use similarity as fallback
                    sim1 = 1.0 if server_lower == p1_lower else (0.9 if p1_lower in server_lower or server_lower in p1_lower else 0.0)
                    sim2 = 1.0 if server_lower == p2_lower else (0.9 if p2_lower in server_lower or server_lower in p2_lower else 0.0)
                    returner = self.player2 if sim1 > sim2 else self.player1
                
        
        # Parse rally with corrected returner
        rally_shots = self._parse_rally_sequence(rally_text, server, returner)
        
        # UNIFIED: Use _determine_point_winner
        point_winner = self._determine_point_winner(rally_shots, server, returner)
        
        # Build the transformed point text
        result = f"Point {point_num} [Server: {server} | Returner: {returner} | Score: {set_score} {game_score} {point_score}]:\n"
        
        # Add rally with attribution
        rally_description = []
        for shot in rally_shots:
            shot_desc = f"{shot['description']} [{shot['player']}]"
            rally_description.append(shot_desc)
        
        result += "; ".join(rally_description) + "."
        
        # Add point winner
        if point_winner:
            result += f" [Point won by: {point_winner}]"
        
        return result
    
    def _extract_point_by_point_data(self, content: str) -> None:
        """
        Extract point-by-point data into structured format for analysis.
        Populates self.point_by_point with list of point dictionaries.
        """
        import re
        
        self.point_by_point = []
        
        # Find the point-by-point section
        pbp_start = content.find('POINT-BY-POINT NARRATIVE:')
        if pbp_start == -1:
            print("[WARN] No POINT-BY-POINT NARRATIVE section found")
            return
        
        # Find where it ends
        pbp_end = len(content)
        for next_section in ['RALLY OUTCOMES STATISTICS:', 'OTHER DATA:', 'KEY POINTS']:
            section_pos = content.find(next_section, pbp_start + 1)
            if section_pos != -1 and section_pos < pbp_end:
                pbp_end = section_pos
        
        pbp_text = content[pbp_start:pbp_end]
        
        # Parse each point - look for transformed format with [Server: ...] headers
        # Format: Point N [Server: X | Returner: Y | Score: A-B C-D E-F]:
        point_pattern = r'Point\s+(\d+)\s+\[Server:\s*([^\|]+)\s*\|\s*Returner:\s*([^\|]+)\s*\|\s*Score:\s*([^\]]+)\]:\s*(.+?)(?=Point\s+\d+\s+\[|$)'
        
        points = re.findall(point_pattern, pbp_text, re.DOTALL)
        
        for point_num, server, returner, score, point_text in points:
            server = server.strip()
            returner = returner.strip()
            score = score.strip()
            point_text = point_text.strip()
            
            # Clean up the point text (remove trailing newlines, etc.)
            point_text = re.sub(r'\s+', ' ', point_text).strip()
            
            self.point_by_point.append({
                'point_number': int(point_num),
                'server': server,
                'returner': returner,
                'score': score,
                'point_text': point_text,
                'description': point_text  # Alias for compatibility
            })
        
        print(f"[PBP] Extracted {len(self.point_by_point)} points for analysis")
        
        # Enrich point data with context, pressure, and tactics
        self._enrich_point_data()
        
        # Extract game winners after loading point data
        self._extract_game_winners()
    
    def _extract_point_by_point_from_nl_file(self, nl_filename: str) -> None:
        """
        Load and extract point-by-point data from NL file.
        This is used when embeddings are cached but PBP data needs to be loaded.
        The NL file has [Point won by:] tags which are essential for analysis.
        """
        print(f"[EXTRACT] Reading NL file for point-by-point data: {nl_filename}")
        with open(nl_filename, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Extract player names from content if not already set
        if not self.player1 or not self.player2:
            import re
            players_match = re.search(r'players were (.+?)\s+and\s+(.+?)\.', content, re.IGNORECASE)
            if players_match:
                self.player1 = players_match.group(1).strip()
                self.player2 = players_match.group(2).strip()
                print(f"[EXTRACT] Found players: {self.player1} vs {self.player2}")
        
        # Extract tournament info for Grand Slam detection
        if not self.tournament:
            import re
            tournament_match = re.search(r'at the (.+?) tournament', content, re.IGNORECASE)
            if tournament_match:
                self.tournament = tournament_match.group(1).strip()
                print(f"[EXTRACT] Found tournament: {self.tournament}")
        
        # Parse match score for set mapping
        self._parse_match_score(content)
        
        # Extract structured point-by-point data (includes [Point won by:] tags)
        self._extract_point_by_point_data(content)
    
    def _load_point_by_point_from_json(self, pointlog_rows: list) -> None:
        """
        Load point-by-point data from structured JSON (pointlog_rows).
        This is more reliable than parsing text.
        """
        if not pointlog_rows:
            print("[WARN] No pointlog_rows provided")
            return
        
        self.point_by_point = []
        
        for row in pointlog_rows:
            # Extract the key fields from JSON structure
            point_number = row.get('point_number', 0)
            server = row.get('server', '')
            returner = row.get('returner', '')
            
            # Build score string from sets, games, points
            sets = row.get('sets', '')
            games = row.get('games', '')
            points = row.get('points', '')
            score = f"{sets} {games} {points}".strip()
            
            # Get the point description/rally text
            point_text = row.get('description', '')
            
            # Some JSON formats have 'formatted' field
            if not point_text and 'formatted' in row:
                # Extract from formatted: "Point N: description"
                formatted = row['formatted']
                if ':' in formatted:
                    point_text = formatted.split(':', 1)[1].strip()
            
            if point_text:
                self.point_by_point.append({
                    'point_number': point_number,
                    'server': server,
                    'returner': returner,
                    'score': score,
                    'point_text': point_text,
                    'description': point_text  # Alias for compatibility
                })
        
        print(f"[JSON-PBP] Loaded {len(self.point_by_point)} points from JSON")
        
        # Enrich point data with context, pressure, and tactics
        self._enrich_point_data()
        
        # Extract game winners after loading point data
        self._extract_game_winners()
    
    def _extract_game_winners(self) -> None:
        """
        Parse point-by-point data to determine which player won each game.
        Populates self.game_winners with mapping of (set_num, game_num) -> winner.
        Also populates self.game_servers with mapping of (set_num, game_num) -> server.
        """
        if not self.point_by_point:
            return
        
        self.game_winners = {}
        self.game_servers = {}
        prev_games = None
        current_set = 1
        current_game = 0  # Current game number (0 = not started, 1 = first game, etc.)
        prev_set = 1
        current_game_server = None  # Track who's serving the current game
        
        for point_data in self.point_by_point:
            score = point_data.get('score', '')
            server = point_data.get('server', '')
            returner = point_data.get('returner', '')
            
            # Parse score: "0-0 0-0 0-0" -> sets, games, points
            parts = score.strip().split()
            if len(parts) < 2:
                continue
            
            try:
                sets_score = parts[0]  # e.g., "0-0"
                games_score = parts[1]  # e.g., "3-2"
                
                # Detect set change
                if '-' in sets_score:
                    set_parts = sets_score.split('-')
                    p1_sets = int(set_parts[0])
                    p2_sets = int(set_parts[1])
                    new_set = p1_sets + p2_sets + 1
                    
                    if new_set != current_set:
                        # Record final game of previous set if needed
                        if prev_games is not None and current_game > 0:
                            if '-' in prev_games:
                                prev_parts = prev_games.split('-')
                                prev_p1 = int(prev_parts[0])
                                prev_p2 = int(prev_parts[1])
                                # Determine winner of last game
                                if prev_p1 > prev_p2:
                                    self.game_winners[(prev_set, current_game)] = 'player1'
                                elif prev_p2 > prev_p1:
                                    self.game_winners[(prev_set, current_game)] = 'player2'
                        
                        prev_set = current_set
                        current_set = new_set
                        prev_games = None  # Reset for new set
                        current_game = 0  # Reset for new set
                
                # Detect game change (when games_score changes, a game just completed)
                if games_score != prev_games:
                    if prev_games is None:
                        # First point of set - initialize current_game
                        if '-' in games_score:
                            game_parts = games_score.split('-')
                            p1_games = int(game_parts[0])
                            p2_games = int(game_parts[1])
                            
                            # If first point already shows a completed game (not 0-0)
                            if p1_games > 0 or p2_games > 0:
                                # Game 1 is already complete
                                current_game = 1
                                if p1_games > p2_games:
                                    self.game_winners[(current_set, 1)] = 'player1'
                                elif p2_games > p1_games:
                                    self.game_winners[(current_set, 1)] = 'player2'
                                # Can't determine server for completed game 1, skip
                                # Move to next game since game 1 is complete
                                current_game = 2
                                # Record server for game 2 (current point's server)
                                server_key = 'player1' if server == self.player1 else 'player2'
                                self.game_servers[(current_set, current_game)] = server_key
                                current_game_server = server_key
                            else:
                                # Starting at 0-0, we're in game 1 (not completed yet)
                                current_game = 1
                                # Record server for game 1
                                server_key = 'player1' if server == self.player1 else 'player2'
                                self.game_servers[(current_set, current_game)] = server_key
                                current_game_server = server_key
                    else:
                        # A game was just completed - determine who won the game that just ended
                        if '-' in games_score and '-' in prev_games:
                            game_parts = games_score.split('-')
                            p1_games = int(game_parts[0])
                            p2_games = int(game_parts[1])
                            
                            prev_parts = prev_games.split('-')
                            prev_p1 = int(prev_parts[0])
                            prev_p2 = int(prev_parts[1])
                            
                            # Determine who won by checking which player's score increased
                            # Record for the game that just completed (prev_games represents the completed game)
                            # current_game is the game we were in, which just completed
                            if current_game > 0:
                                if p1_games > prev_p1:
                                    # Player 1's game count increased - they won
                                    self.game_winners[(current_set, current_game)] = 'player1'
                                elif p2_games > prev_p2:
                                    # Player 2's game count increased - they won
                                    self.game_winners[(current_set, current_game)] = 'player2'
                            
                            # Move to next game AFTER recording the winner
                            current_game += 1
                            # Record server for the new game (current point's server)
                            server_key = 'player1' if server == self.player1 else 'player2'
                            self.game_servers[(current_set, current_game)] = server_key
                            current_game_server = server_key
                        else:
                            # Games score changed but not in expected format, increment anyway
                            if current_game == 0:
                                current_game = 1
                            else:
                                current_game += 1
                
                prev_games = games_score
                
            except (ValueError, IndexError):
                continue
        
        # Record final game if match ended mid-game (though this is rare)
        # Actually, if we're at the end, the last game should already be recorded
        # But let's handle the case where the last point is the final point of the last game
        if prev_games is not None and current_game > 0:
            game_key = (current_set, current_game)
            if game_key not in self.game_winners:
                # Last game might not have been recorded yet
                if '-' in prev_games:
                    prev_parts = prev_games.split('-')
                    prev_p1 = int(prev_parts[0])
                    prev_p2 = int(prev_parts[1])
                    # Determine winner of last game
                    if prev_p1 > prev_p2:
                        self.game_winners[game_key] = 'player1'
                    elif prev_p2 > prev_p1:
                        self.game_winners[game_key] = 'player2'
        
        if self.game_winners:
            print(f"[GAMES] Tracked {len(self.game_winners)} games across {current_set} sets")
    
    def _is_game_query(self, question: str) -> bool:
        """
        Detect if query is about games (not points).
        
        Examples of game queries:
        - "How many games did each player win?"
        - "How many service games did Sinner hold?"
        - "What was the total number of games won?"
        """
        question_lower = question.lower()
        
        # Game indicators
        game_keywords = [
            'games won', 'games did', 'service games', 'service game',
            'games held', 'games hold', 'hold',
            'total number of games', 'how many games', 'game count',
            'break serve', 'breaks', 'broke serve', 'broken serve'
        ]
        
        # Check for game keywords
        has_game_keyword = any(kw in question_lower for kw in game_keywords)
        
        # Exclude if clearly asking about points
        point_keywords = ['points', 'point won', 'point by point']
        has_point_keyword = any(kw in question_lower for kw in point_keywords)
        
        # CRITICAL: "service game" + "percentage" queries MUST use game-level tracking
        # They count GAMES held/won, not POINTS won
        is_service_game_percentage = ('service game' in question_lower or 'service games' in question_lower) and \
                                     any(kw in question_lower for kw in ['percentage', 'percent', '%', 'win rate'])
        
        # Break queries are game-level queries (count games won on opponent's serve)
        is_break_query = 'break' in question_lower and 'break point' not in question_lower
        
        # Return True for:
        # 1. Regular game count queries (has_game_keyword without points)
        # 2. Service game percentage queries (must use game-level tracking)
        # 3. Break queries (game-level, not point-level)
        return (has_game_keyword and not has_point_keyword) or is_service_game_percentage or is_break_query
    
    def _is_shot_level_query(self, question: str, classification: Dict) -> bool:
        """
        Detect if query is about SHOT-LEVEL analysis (individual shots during rallies)
        vs POINT-LEVEL analysis (point outcomes).
        
        SHOT-LEVEL queries should use EMBEDDINGS (narrative) because NL file has
        pre-computed shot statistics. POINT-LEVEL queries use the TREE for outcome analysis.
        
        Examples of SHOT-LEVEL queries:
        - "How many forehands did Sinner hit?"
        - "What percentage of Medvedev's shots were winners?"
        - "How many crosscourt winners?" (counting shots with direction + outcome)
        - "How many inside-out forehands?" (specific shot type + direction)
        
        Examples of POINT-LEVEL queries (NOT shot-level):
        - "How many points did Sinner win?" (point outcome)
        - "What's the break point conversion rate?" (point outcome in situation)
        - "Win percentage on second serve?" (point outcome filtered by serve)
        
        Returns:
            bool: True if query is about shot-level analysis, False otherwise
        """
        question_lower = question.lower()
        
        # === INDICATOR 1: Explicit "shot" or "shots" in question ===
        # But exclude "shot" as verb (e.g., "what shot did")
        has_shots_keyword = ' shot ' in question_lower or ' shots ' in question_lower or \
                          question_lower.startswith('shot ') or question_lower.endswith(' shot') or \
                          question_lower.startswith('shots ') or question_lower.endswith(' shots')
        
        # === INDICATOR 2: metrics_parsed contains shot_type or direction filters ===
        # These filters on metrics indicate we're filtering individual shots, not just points
        metric_filters = classification.get('metric_filters', {})
        has_shot_filters_in_metrics = False
        if metric_filters:
            for metric_key, metric_data in metric_filters.items():
                filters = metric_data.get('filters', {})
                if filters.get('shot_type') or filters.get('direction') or filters.get('shot_modifier'):
                    has_shot_filters_in_metrics = True
                    break
        
        # === INDICATOR 3: Question asks about shot types from config ===
        # Use GROUP_CONFIG to dynamically get all known shot types
        shot_type_terms = []
        shot_type_config = self.GROUP_CONFIG.get('shot_type', {}).get('default_branches', [])
        if shot_type_config:
            for st in shot_type_config:
                # Add both underscore and space/hyphen versions
                shot_type_terms.append(st.lower())
                shot_type_terms.append(st.lower().replace('_', ' '))
                shot_type_terms.append(st.lower().replace('_', '-'))
        
        # Also check shot modifiers (inside-out, inside-in, etc.)
        shot_modifier_config = self.match_filter_inventory.get('shot_modifiers', [])
        shot_modifier_terms = [sm.lower().replace('_', ' ') for sm in shot_modifier_config]
        shot_modifier_terms += [sm.lower().replace('_', '-') for sm in shot_modifier_config]
        
        # Also check directions (crosscourt, down-the-line, etc.)
        direction_config = self.GROUP_CONFIG.get('direction', {}).get('default_branches', [])
        direction_terms = []
        for d in direction_config:
            direction_terms.append(d.lower())
            direction_terms.append(d.lower().replace('_', ' '))
            direction_terms.append(d.lower().replace('_', '-'))
        
        # Check if question mentions specific shot types, modifiers, or directions
        has_shot_type_term = any(term in question_lower for term in shot_type_terms)
        has_shot_modifier_term = any(term in question_lower for term in shot_modifier_terms)
        has_direction_term = any(term in question_lower for term in direction_terms)
        
        # === INDICATOR 4: shot_count metric present ===
        metrics = classification.get('metrics', [])
        has_shot_count_metric = 'shot_count' in metrics
        
        # === INDICATOR 4b: Direction/shot_type + outcome queries (shot-level) ===
        # "crosscourt winners", "forehand unforced errors" = count shots with filters+outcome
        # These have shot filters (direction/shot_type/modifier) on point-ending outcome metrics
        has_direction_on_outcome_metric = False
        if metric_filters:
            for metric_key, metric_data in metric_filters.items():
                filters = metric_data.get('filters', {})
                metric_name = metric_data.get('metric', metric_key)
                # Check if it's a point-ending outcome metric with shot-level filters
                # Use config to check if metric is a point-ending outcome
                if metric_name in self.SELF_EVIDENT_OUTCOME_METRICS:
                    # Check if it has any shot-level filters (direction, shot_type, shot_modifier)
                    if filters.get('direction') or filters.get('shot_type') or filters.get('shot_modifier'):
                        has_direction_on_outcome_metric = True
                        break
        
        # === INDICATOR 5: Percentage questions about shots ===
        # "What percentage of X's shots were Y?" or "X's shot percentage"
        is_shot_percentage = ('percentage' in question_lower or 'percent' in question_lower or '%' in question_lower) and \
                            has_shots_keyword
        
        # === INDICATOR 6: Net points, approaches, net statistics ===
        # Questions about "net points", "approach", "approaching net" are shot-level stats from embeddings
        # Volley routing rule:
        # - If "volley" is used as a filter (e.g., "all volleys", "volleys hit") -> shot-level
        # - If "volley" is used as a label for the winning shot only (e.g., "volley winners") -> point-level
        #   BUT only if the tree explicitly tracks whether the point-ending shot was a volley
        # Safer rule: Unless the tree explicitly tracks point-ending volleys, treat all volley queries as shot-level
        net_keywords = [
            'net points', 'net point', 'points at net', 'point at net',
            'approach the net', 'approaching the net', 'approaching net', 'approaching',
            'net approach', 'net approaches', 'approached the net', 'approached net',
            'times at net', 'time at net', 'at the net', 'at net',
            'net play', 'net statistics', 'net stats', 'net performance',
            'came to net', 'come to net', 'coming to net',
            'net points won', 'net points lost', 'net point won', 'net point lost',
            'approached', 'approaches', 'net approaches'
        ]
        has_net_stat_keyword = any(kw in question_lower for kw in net_keywords)
        
        # Also check for net_points_won metric
        has_net_points_metric = 'net_points_won' in metrics or 'net_approach' in metrics
        
        # === EXCLUSIONS: Point-level keywords that override shot-level ===
        # If explicitly asking about points won/lost, it's point-level even with shot filters
        # EXCEPTION: "net points" is shot-level even though it contains "points"
        point_outcome_keywords = [
            'points won', 'points did', 'win percentage', 'win rate',
            'break point', 'break points', 'conversion', 'converted',
            'first serve in', 'second serve', 'serve percentage'
        ]
        has_point_outcome = any(kw in question_lower for kw in point_outcome_keywords) and not has_net_stat_keyword
        
        # === DECISION LOGIC ===
        # Shot-level if:
        # 1. Has "shots" keyword AND (shot filters OR shot types OR percentage about shots)
        # 2. Has shot_count metric
        # 3. Has shot-type/direction/modifier terms with metrics (counting specific shots)
        # 4. Has net statistics keywords (net points, approaches)
        # 5. Has direction filter on outcome metrics (crosscourt winners, DTL errors)
        # But NOT if it has point outcome keywords (those are point-level)
        
        is_shot_level = (
            (has_shots_keyword and (has_shot_filters_in_metrics or has_shot_type_term or is_shot_percentage)) or
            has_shot_count_metric or
            (has_shot_filters_in_metrics and (has_shot_type_term or has_direction_term or has_shot_modifier_term)) or
            has_net_stat_keyword or
            has_net_points_metric or
            has_direction_on_outcome_metric
        ) and not has_point_outcome
        
        return is_shot_level
    
    def _handle_game_query(self, question: str, classification: Dict) -> str:
        """
        Handle queries about games (not points).
        
        Uses game tracking from self.game_winners.
        Supports both count and percentage queries.
        """
        question_lower = question.lower()
        player_filter = classification.get('filters', {}).get('player', '')
        
        # Ensure game_winners is populated
        if not hasattr(self, 'game_winners') or not self.game_winners:
            self._extract_game_winners()
        
        # Check if asking for percentage
        is_percentage_query = any(kw in question_lower for kw in ['percentage', 'percent', '%', 'win rate'])
        
        # Check if asking about service games
        is_service_games = 'service' in question_lower
        
        # Determine which player(s) to show
        show_both = not player_filter or player_filter.lower() == 'both' or 'each player' in question_lower
        
        if is_percentage_query and is_service_games:
            # Service game win percentage: (service games held) / (total service games)
            # USE TREE STRUCTURE: Build game aggregation from point metadata (uses set_number, game_number_in_set)
            # This ensures we're using the proper point->game->set->match hierarchy
            if not hasattr(self, '_game_aggregation') or not self._game_aggregation:
                self._build_game_aggregation()
            
            p1_service_games_held = 0
            p1_total_service_games = 0
            p2_service_games_held = 0
            p2_total_service_games = 0
            
            # Use _game_aggregation which is built from point metadata tree structure
            # Each game has: winner, server, is_break, set_number, game_number_in_set
            for game_key, game_data in self._game_aggregation.items():
                winner = game_data.get('winner', '')
                server = game_data.get('server', '')
                
                # Skip games without server or winner
                if not server or not winner:
                    continue
                
                # Normalize player names using same pattern as _get_games_won_by_player for consistency
                server_normalized = (server or '').lower().replace(' ', '')
                winner_normalized = (winner or '').lower().replace(' ', '')
                player1_normalized = (self.player1 or '').lower().replace(' ', '')
                player2_normalized = (self.player2 or '').lower().replace(' ', '')
                
                is_player1_server = server_normalized == player1_normalized
                is_player2_server = server_normalized == player2_normalized
                is_player1_winner = winner_normalized == player1_normalized
                is_player2_winner = winner_normalized == player2_normalized
                
                if is_player1_server:
                    p1_total_service_games += 1
                    if is_player1_winner:
                        p1_service_games_held += 1
                elif is_player2_server:
                    p2_total_service_games += 1
                    if is_player2_winner:
                        p2_service_games_held += 1
                else:
                    # Debug: why didn't match?
                    print(f"[GAME-QUERY] WARNING: Server '{server}' didn't match '{self.player1}' or '{self.player2}' for game {game_key}")
            
            print(f"[GAME-QUERY] Using _game_aggregation (tree structure) - {len(self._game_aggregation)} games")
            print(f"[GAME-QUERY] {self.player1}: {p1_service_games_held}/{p1_total_service_games} service games held")
            print(f"[GAME-QUERY] {self.player2}: {p2_service_games_held}/{p2_total_service_games} service games held")
            
            # Calculate percentages
            p1_pct = (p1_service_games_held / p1_total_service_games * 100) if p1_total_service_games > 0 else 0
            p2_pct = (p2_service_games_held / p2_total_service_games * 100) if p2_total_service_games > 0 else 0
            
            if show_both:
                response = f"Based on the calculated match data:\n\n"\
                      f"- **{self.player1}**: {p1_pct:.1f}% ({p1_service_games_held} of {p1_total_service_games} service games held)\n"\
                      f"- **{self.player2}**: {p2_pct:.1f}% ({p2_service_games_held} of {p2_total_service_games} service games held)"
                return response
            else:
                # Use same normalization pattern as _get_games_won_by_player for consistency
                player_filter_normalized = (player_filter or '').lower().replace(' ', '')
                player1_normalized = (self.player1 or '').lower().replace(' ', '')
                player2_normalized = (self.player2 or '').lower().replace(' ', '')
                is_player1 = player_filter_normalized == player1_normalized
                pct = p1_pct if is_player1 else p2_pct
                held = p1_service_games_held if is_player1 else p2_service_games_held
                total = p1_total_service_games if is_player1 else p2_total_service_games
                return f"Based on the calculated match data, {player_filter} had a **{pct:.1f}% service game win percentage** ({held} of {total} service games held)."
        
        else:
            # Count query (not percentage)
            # UNIFIED: ALWAYS calculate both players - filter at display time
            p1_games = len(self._get_games_won_by_player(self.player1))
            p2_games = len(self._get_games_won_by_player(self.player2))
            
            metric_label = "service games held" if is_service_games and ('held' in question_lower or 'hold' in question_lower) else "games won"
            
            if show_both:
                response = f"Based on the calculated match data:\n\n"\
                      f"- **{self.player1}**: {p1_games} {metric_label}\n"\
                      f"- **{self.player2}**: {p2_games} {metric_label}\n\n"\
                      f"**Total:** {p1_games + p2_games} games"
                
                # Note: Narrative synthesis removed - game queries are simple counts
                # If narrative context is needed, it should be handled at a higher level
                
                return response
            else:
                # Single player - extract from already-calculated data
                # Use same normalization pattern as _get_games_won_by_player for consistency
                player_filter_normalized = (player_filter or '').lower().replace(' ', '')
                player1_normalized = (self.player1 or '').lower().replace(' ', '')
                player2_normalized = (self.player2 or '').lower().replace(' ', '')
                is_player1 = player_filter_normalized == player1_normalized
                games = p1_games if is_player1 else p2_games
                return f"Based on the calculated match data, {player_filter} had **{games} {metric_label}**."
    
    def _get_games_won_by_player(self, player_name: str, set_filter: int = None, role: str = None) -> list:
        """
        Get the list of (set, game) tuples won by a specific player.
        
        Args:
            player_name: Name of player
            set_filter: Optional set number to filter by
            role: Optional 'server' or 'returner' to filter by service games
        
        Returns:
            List of (set_num, game_num) tuples
        """
        if not hasattr(self, 'game_winners') or not self.game_winners:
            return []
        
        if not player_name:
            return []
        
        # Normalize player name
        player_normalized = player_name.lower().replace(' ', '')
        player1_normalized = (self.player1 or '').lower().replace(' ', '')
        player2_normalized = (self.player2 or '').lower().replace(' ', '')
        
        is_player1 = player_normalized == player1_normalized
        is_player2 = player_normalized == player2_normalized
        
        if not is_player1 and not is_player2:
            return []
        
        # Get games won
        games_won = []
        for (set_num, game_num), winner in self.game_winners.items():
            if set_filter:
                if isinstance(set_filter, (list, tuple)) and set_num not in set_filter:
                    continue
                elif not isinstance(set_filter, (list, tuple)) and set_num != set_filter:
                    continue
            
            if (is_player1 and winner == 'player1') or (is_player2 and winner == 'player2'):
                # TODO: Add role filtering if needed (requires tracking server per game)
                games_won.append((set_num, game_num))
        
        return games_won
    
    def _get_games_lost_by_player(self, player_name: str, set_filter: int = None, role: str = None) -> list:
        """
        Get the list of (set, game) tuples lost by a specific player.
        
        If role='returner', this counts games where the player was the returner and WON (broke serve).
        Otherwise, it counts games where the player LOST (their serve was broken or they lost as returner).
        """
        if not hasattr(self, 'game_winners') or not self.game_winners:
            return []
        
        if not player_name:
            return []
        
        # Normalize player name
        player_normalized = player_name.lower().replace(' ', '')
        player1_normalized = (self.player1 or '').lower().replace(' ', '')
        player2_normalized = (self.player2 or '').lower().replace(' ', '')
        
        is_player1 = player_normalized == player1_normalized
        is_player2 = player_normalized == player2_normalized
        
        if not is_player1 and not is_player2:
            return []
        
        # Get game servers to determine who was serving
        if not hasattr(self, 'game_servers') or not self.game_servers:
            return []
        
        games_result = []
        for (set_num, game_num), winner in self.game_winners.items():
            if set_filter:
                if isinstance(set_filter, (list, tuple)) and set_num not in set_filter:
                    continue
                elif not isinstance(set_filter, (list, tuple)) and set_num != set_filter:
                    continue
            
            server = self.game_servers.get((set_num, game_num), '')
            server_is_player1 = server and player1_normalized in server.lower()
            server_is_player2 = server and player2_normalized in server.lower()
            
            if role == 'returner':
                # For "break serve": count games where player was returner AND won
                if is_player1:
                    # Player1 was returner if server was player2, and player1 won
                    if server_is_player2 and winner == 'player1':
                        games_result.append((set_num, game_num))
                elif is_player2:
                    # Player2 was returner if server was player1, and player2 won
                    if server_is_player1 and winner == 'player2':
                        games_result.append((set_num, game_num))
            else:
                # Regular games_lost: count games where player lost
                if (is_player1 and winner == 'player2') or (is_player2 and winner == 'player1'):
                    games_result.append((set_num, game_num))
        
        return games_result
    
    def _get_overall_game_number(self, set_num: int, game_num: int) -> int:
        """
        Convert (set_num, game_num) to overall game number across the match.
        
        Examples:
        - (1, 4) -> 4 (if set 1 has 4+ games)
        - (2, 5) -> 15 (if set 1 had 10 games, then 10 + 5 = 15)
        - (3, 4) -> 25 (if set 1 had 10 games, set 2 had 11 games, then 10 + 11 + 4 = 25)
        
        Args:
            set_num: Set number (1-indexed)
            game_num: Game number within that set (1-indexed)
        
        Returns:
            Overall game number (1-indexed), or None if (set_num, game_num) not found
        """
        if not hasattr(self, 'game_winners') or not self.game_winners:
            return None
        
        # Verify that (set_num, game_num) exists
        if (set_num, game_num) not in self.game_winners:
            return None
        
        # Count all games in sets before this set
        games_in_previous_sets = 0
        for (s, g), _ in self.game_winners.items():
            if s < set_num:
                games_in_previous_sets += 1
        
        # Add the game number in this set
        overall_game = games_in_previous_sets + game_num
        
        return overall_game
    
    def _parse_rally_sequence(self, rally_text: str, server: str, returner: str) -> List[Dict]:
        """
        Parse rally into sequence of shots with player attribution.
        EXTRACTS player from [Player Name] tags in NL file (authoritative).
        Falls back to alternation logic if tags are missing.
        Returns list of {player, description, outcome} dicts.
        """
        import re
        
        shots = []
        current_player = server  # Server always starts (fallback for alternation)
        in_rally = False  # Track if we're in rally (after successful serve)
        shot_number = 0  # Track shot number (excludes faults)
        
        # CRITICAL: Handle "fault. 2nd serve" patterns - ensure 2nd serve is a separate segment
        # Pattern 1: "fault (reason). 2nd serve" - with reason in parentheses
        rally_text = re.sub(r'fault \([^)]+\)\.\s+(2nd serve)', r'fault. SERVE_SEPARATOR \1', rally_text)
        # Pattern 2: "fault. 2nd serve" - without reason
        rally_text = re.sub(r'fault\.\s+(2nd serve)', r'fault. SERVE_SEPARATOR \1', rally_text, flags=re.IGNORECASE)
        # Pattern 3: ", fault. 2nd serve" - comma before fault
        rally_text = re.sub(r',\s*fault\.\s+(2nd serve)', r', fault. SERVE_SEPARATOR \1', rally_text, flags=re.IGNORECASE)
        # Pattern 4: Handle let serves - "let. 1st serve" or "let. 2nd serve"
        rally_text = re.sub(r'let\.\s+(\d(?:st|nd)\s+serve)', r'let. SERVE_SEPARATOR \1', rally_text, flags=re.IGNORECASE)
        
        # Split by semicolons (each shot)
        shot_parts = rally_text.split(';')
        
        # Also split by SERVE_SEPARATOR marker
        expanded_parts = []
        for part in shot_parts:
            if 'SERVE_SEPARATOR' in part:
                sub_parts = part.split('SERVE_SEPARATOR')
                expanded_parts.extend(sub_parts)
            else:
                expanded_parts.append(part)
        shot_parts = expanded_parts
        
        for shot_part in shot_parts:
            shot_part = shot_part.strip()
            if not shot_part:
                continue
            
            # EXTRACT player from [Player Name] tag (authoritative from NL file)
            player_from_tag = None
            player_tag_match = re.search(r'\[([A-Z][^\]]+)\]', shot_part)
            if player_tag_match:
                player_from_tag = player_tag_match.group(1).strip()
                # Skip [Point won by:] tags
                if 'point won by' in player_from_tag.lower():
                    player_from_tag = None
            
            # Clean up shot description (remove tags)
            shot_clean = shot_part.strip()
            shot_clean = re.sub(r'\s*\[point won by:.*?\]', '', shot_clean, flags=re.IGNORECASE)
            shot_clean = re.sub(r'\s*\[[A-Z][^\]]*\]\s*\.?$', '', shot_clean)  # Remove trailing [Player Name] tags
            shot_clean = shot_clean.strip()
            
            # Check for outcomes - ORDER MATTERS! Check specific outcomes before generic ones
            outcome = None
            shot_lower = shot_clean.lower()
            if 'double fault' in shot_lower or ('2nd serve' in shot_lower and 'fault' in shot_lower):
                outcome = 'DOUBLE_FAULT'
            elif 'ace' in shot_lower:
                outcome = 'ACE'
            elif 'service winner' in shot_lower:
                outcome = 'SERVICE_WINNER'
            elif 'winner' in shot_lower:
                outcome = 'WINNER'
            elif 'unforced error' in shot_lower:
                outcome = 'UNFORCED ERROR'
            elif 'forced error' in shot_lower:
                outcome = 'FORCED ERROR'
            elif 'fault' in shot_lower and ('1st serve' in shot_lower or '2nd serve' in shot_lower):
                # Only mark as FAULT if it's a serve fault, not other uses of "fault"
                outcome = 'FAULT'
            elif 'let' in shot_lower and ('1st serve' in shot_lower or '2nd serve' in shot_lower):
                outcome = 'LET'
            
            # Determine player: use tag if available, otherwise use alternation logic
            shot_player = player_from_tag if player_from_tag else current_player
            
            # Handle serves - ALWAYS assigned to server
            if '1st serve' in shot_clean.lower() or '2nd serve' in shot_clean.lower():
                # Serve is always by the server (override tag if needed)
                shot_player = server
                
                # Increment shot number only for non-faults
                if outcome not in ('FAULT', 'LET'):
                    shot_number += 1
                
                # Extract full shot metadata
                shot_meta = self._extract_shot_metadata(shot_clean)
                shots.append({
                    'player': shot_player,
                    'description': shot_clean,
                    'outcome': outcome or shot_meta.get('outcome'),
                    'shot_number': shot_number if outcome not in ('FAULT', 'LET') else None,
                    # === NEW TAXONOMY ===
                    'shot_phase': shot_meta.get('shot_phase'),
                    'contact_type': shot_meta.get('contact_type'),
                    'spin': shot_meta.get('spin'),
                    'intent': shot_meta.get('intent'),
                    'location': shot_meta.get('location'),
                    # === CORE DIMENSIONS ===
                    'shot_type': shot_meta.get('shot_type'),
                    'direction': shot_meta.get('direction'),
                    'depth': shot_meta.get('depth'),
                    'serve_target': shot_meta.get('serve_target'),
                    # === LEGACY (backward compatibility) ===
                    'shot_modifier': shot_meta.get('shot_modifier'),
                    'shot_modifiers': shot_meta.get('shot_modifiers'),
                    'at_net': shot_meta.get('at_net'),
                    'court_position': shot_meta.get('court_position'),
                    'is_return': shot_meta.get('is_return')
                })
                # If successful serve, next shot is returner's
                # CRITICAL: Faults and Lets do NOT start the rally - server serves again
                if outcome not in ('FAULT', 'LET', None) or (outcome is None and 'fault' not in shot_clean.lower() and 'let' not in shot_clean.lower()):
                    current_player = returner
                    in_rally = True
                else:
                    # Fault or Let - next serve attempt, stay on server
                    current_player = server
                    in_rally = False
            else:
                # Regular rally shot
                shot_number += 1
                # Extract full shot metadata
                shot_meta = self._extract_shot_metadata(shot_clean)
                shots.append({
                    'player': shot_player,
                    'description': shot_clean,
                    'outcome': outcome or shot_meta.get('outcome'),
                    'shot_number': shot_number,
                    # === NEW TAXONOMY ===
                    'shot_phase': shot_meta.get('shot_phase'),
                    'contact_type': shot_meta.get('contact_type'),
                    'spin': shot_meta.get('spin'),
                    'intent': shot_meta.get('intent'),
                    'location': shot_meta.get('location'),
                    # === CORE DIMENSIONS ===
                    'shot_type': shot_meta.get('shot_type'),
                    'direction': shot_meta.get('direction'),
                    'depth': shot_meta.get('depth'),
                    'serve_target': shot_meta.get('serve_target'),
                    # === LEGACY (backward compatibility) ===
                    'shot_modifier': shot_meta.get('shot_modifier'),
                    'shot_modifiers': shot_meta.get('shot_modifiers'),
                    'at_net': shot_meta.get('at_net'),
                    'court_position': shot_meta.get('court_position'),
                    'is_return': shot_meta.get('is_return')
                })
                # Alternate for next shot (fallback logic)
                current_player = returner if current_player == server else server
        
        return shots
    
    def _extract_shot_metadata(self, shot_description: str) -> Dict:
        """
        ROBUST SHOT METADATA EXTRACTOR - NEW TAXONOMY
        
        Extracts ALL components from complex shot descriptions using a cleaner taxonomy:
        "forehand at the net volley down the line,winner"
        "backhand slice approach shot crosscourt (deep)"
        
        NEW STRUCTURE:
        - shot_type: forehand, backhand, serve (base stroke) - NOTE: overhead is NOT a shot_type
        - shot_phase: serve, return, rally, net (tactical phase)
        - contact_type: groundstroke, volley, half_volley, swinging_volley, overhead (how ball is struck)
        - spin: slice, flat, topspin
        - intent: approach, drop_shot, lob, passing_shot, winner_attempt
        - location: baseline, mid_court, net, service_line
        - direction: crosscourt, down_the_line, inside_out, inside_in, down_the_middle
        - depth: deep, shallow, very_deep
        - serve_target: wide, body, t (for serves only)
        - outcome: winner, unforced_error, forced_error, ace, etc.
        - is_return: True if this is a return shot
        
        LEGACY FIELDS (for backward compatibility):
        - shot_modifier: primary modifier (deprecated, use contact_type/spin/intent)
        - shot_modifiers: LIST of ALL modifiers (deprecated)
        - at_net: True/False (deprecated, use location=='net')
        - court_position: (deprecated, use location)
        """
        desc = shot_description.lower()
        
        # === SHOT TYPE (primary stroke) ===
        # NOTE: overhead/smash is NOT a shot_type, it's a contact_type
        # shot_type indicates forehand/backhand stroke used for overhead
        shot_type = None
        if 'forehand' in desc:
            shot_type = 'forehand'
        elif 'backhand' in desc:
            shot_type = 'backhand'
        elif 'serve' in desc:
            shot_type = 'serve'
        # Note: 'overhead' and 'smash' are handled in contact_type, not shot_type
        
        # === CONTACT TYPE (how ball is struck) ===
        contact_type = 'groundstroke'  # Default
        if 'overhead' in desc or 'smash' in desc:
            contact_type = 'overhead'
            # For overheads, try to determine shot_type from context if not already set
            if shot_type is None:
                # Default to forehand if not specified (most overheads are forehand)
                shot_type = 'forehand'
        elif 'swinging volley' in desc:
            contact_type = 'swinging_volley'
        elif 'half volley' in desc or 'half-volley' in desc:
            contact_type = 'half_volley'
        elif 'drop volley' in desc:
            contact_type = 'drop_volley'
        elif 'volley' in desc:
            contact_type = 'volley'
        
        # === SPIN (ball rotation) ===
        spin = None
        if 'topspin' in desc:
            spin = 'topspin'
        elif 'slice' in desc or 'chip' in desc:
            spin = 'slice'
        elif 'flat' in desc:
            spin = 'flat'
        # If not specified, infer from contact type
        elif contact_type in ['volley', 'swinging_volley', 'half_volley']:
            spin = 'flat'  # Volleys are typically flat
        # Note: We don't infer spin from shot_type as shot_type values don't contain spin info
        
        # === INTENT (tactical purpose) ===
        intent = None
        if 'approach shot' in desc or 'approach' in desc:
            intent = 'approach'
        elif 'drop shot' in desc:
            intent = 'drop_shot'
        elif 'lob' in desc:
            intent = 'lob'
        elif 'passing shot' in desc or 'pass' in desc:
            intent = 'passing_shot'
        elif 'winner' in desc or 'ace' in desc or 'service winner' in desc:
            intent = 'winner_attempt'
        
        # === LEGACY: SHOT MODIFIERS (for backward compatibility) ===
        shot_modifiers = []
        if contact_type != 'groundstroke':
            shot_modifiers.append(contact_type)
        if spin:
            shot_modifiers.append(spin)
        if intent:
            shot_modifiers.append(intent)
        
        # Primary modifier (first one found, most specific)
        shot_modifier = shot_modifiers[0] if shot_modifiers else None
        
        # === DIRECTION ===
        direction = None
        if 'inside-out' in desc or 'inside out' in desc:
            direction = 'inside_out'
        elif 'inside-in' in desc or 'inside in' in desc:
            direction = 'inside_in'
        elif 'crosscourt' in desc or 'cross court' in desc or 'cross-court' in desc:
            direction = 'crosscourt'
        elif 'down the line' in desc or 'down-the-line' in desc or 'dtl' in desc:
            direction = 'down_the_line'
        elif 'down the middle' in desc or 'middle' in desc:
            direction = 'down_the_middle'
        
        # === LOCATION (court position) ===
        location = 'baseline'  # Default
        if 'at net' in desc or 'at the net' in desc:
            location = 'net'
        elif contact_type in ['volley', 'half_volley', 'swinging_volley', 'drop_volley', 'overhead']:
            location = 'net'
        elif intent == 'approach' or 'approach' in desc:
            location = 'mid_court'
        elif 'service line' in desc:
            location = 'service_line'
        
        # === SHOT PHASE (tactical context) ===
        is_return = 'return' in desc
        is_serve = shot_type and 'serve' in shot_type.lower() or '1st serve' in desc or '2nd serve' in desc
        shot_phase = 'rally'  # Default
        if is_serve:
            shot_phase = 'serve'
        elif is_return:
            shot_phase = 'return'
        elif location == 'net':
            shot_phase = 'net'
        # else: rally (default)
        
        # === LEGACY: AT NET (for backward compatibility) ===
        at_net = (location == 'net')
        
        # === LEGACY: COURT POSITION (for backward compatibility) ===
        court_position = location
        if location == 'mid_court':
            court_position = 'approach'
        
        # === DEPTH ===
        depth = None
        if 'very deep' in desc or '(very deep)' in desc:
            depth = 'very_deep'
        elif '(deep)' in desc or 'deep)' in desc:
            depth = 'deep'
        elif '(shallow)' in desc or 'shallow)' in desc:
            depth = 'shallow'
        
        # === SERVE TARGET (for serves) ===
        serve_target = None
        if is_serve:  # Use is_serve from above
            if 'wide' in desc:
                serve_target = 'wide'
            elif 'to body' in desc or 'body' in desc:
                serve_target = 'body'
            elif 'down the t' in desc:
                serve_target = 't'
        
        # === OUTCOME ===
        outcome = None
        if 'ace' in desc:
            outcome = 'ace'
        elif 'double fault' in desc:
            outcome = 'double_fault'
        elif 'service winner' in desc:
            outcome = 'service_winner'
        elif 'unforced error' in desc:
            outcome = 'unforced_error'
        elif 'forced error' in desc:
            outcome = 'forced_error'
        elif 'winner' in desc:
            outcome = 'winner'
        elif 'fault' in desc:
            outcome = 'fault'
        
        return {
            # === NEW TAXONOMY (primary) ===
            'shot_type': shot_type,           # forehand, backhand, serve (overhead is contact_type, not shot_type)
            'shot_phase': shot_phase,         # serve, return, rally, net
            'contact_type': contact_type,     # groundstroke, volley, half_volley, swinging_volley, overhead
            'spin': spin,                     # slice, flat, topspin
            'intent': intent,                 # approach, drop_shot, lob, passing_shot, winner_attempt
            'location': location,             # baseline, mid_court, net, service_line
            'direction': direction,           # crosscourt, down_the_line, inside_out, inside_in, down_the_middle
            'depth': depth,                   # shallow, deep, very_deep
            'serve_target': serve_target,     # wide, body, t (serves only)
            'outcome': outcome,               # winner, unforced_error, forced_error, ace, etc.
            'is_return': is_return,           # Boolean
            
            # === LEGACY FIELDS (backward compatibility) ===
            'shot_modifier': shot_modifier,   # Deprecated: use contact_type/spin/intent
            'shot_modifiers': shot_modifiers, # Deprecated: ALL modifiers as list
            'at_net': at_net,                 # Deprecated: use location=='net'
            'court_position': court_position, # Deprecated: use location
            
            # === RAW ===
            'raw': shot_description
        }
    
    def _calculate_rally_length(self, rally_shots: List[Dict], point_text: str = '') -> int:
        """
        SINGLE SOURCE OF TRUTH for rally length calculation.
        
        Tennis convention: Rally starts at the RETURN, not the serve.
        - Ace (unreturned serve) = 0-shot rally
        - Serve + Return = 1-shot rally
        - Serve + Return + Groundstroke = 2-shot rally
        
        CRITICAL: Source data only annotates LONGER rallies (4+ shots).
        For short rallies, no annotation exists, so we must calculate.
        - If annotated "(X-shot rally)" exists → TRUST IT (it's correct)
        - If NOT annotated (short rallies) → CALCULATE from shots
        """
        import re
        
        # SPECIAL CASE: Aces are 0-shot rallies
        # Check for ace in point text OR in shot outcomes
        if 'ace' in point_text.lower():
            return 0
        
        # Exclude faults and lets
        actual_shots = [s for s in rally_shots if s.get('outcome') not in ['FAULT', 'LET']]
        
        # Check for ace in shot outcomes
        if any(s.get('outcome') == 'ace' for s in actual_shots):
            return 0
        
        # PREFER the annotated rally count "(X-shot rally)" if it exists (LONGER rallies)
        # The annotation is CORRECT and already excludes serves
        annotated_rally_match = (
            re.search(r'\((\d+)\s*-\s*shot\s+rally\)', point_text, re.IGNORECASE) or
            re.search(r'\((\d+)\s*shot\s+rally\)', point_text, re.IGNORECASE) or
            re.search(r'\((\d+)\s*-\s*shot\)', point_text, re.IGNORECASE)
        )
        if annotated_rally_match:
            return int(annotated_rally_match.group(1))
        
        # FALLBACK: Calculate for SHORT rallies (not annotated in source)
        # Count rally shots: EXCLUDE serves (rally starts at return)
        # In tennis, rallies start at the return (shot 2), not the serve (shot 1)
        # Serve + Return = 1 shot, Serve + Return + Groundstroke = 2 shots, etc.
        rally_length = len([
            s for s in actual_shots 
            if not (s.get('shot_type') or '').lower().startswith('serve') 
            and s.get('shot_number') != 1
        ])
        
        return rally_length
    
    # =========================================================================
    # SHOT NORMALIZATION SYSTEM
    # =========================================================================
    # Maps variations/aliases to canonical forms and defines hierarchies
    # =========================================================================
    
    # ALIASES: Map variations to canonical form
    SHOT_ALIASES = {
        # Direction aliases
        'cc': 'crosscourt',
        'xc': 'crosscourt',
        'x-court': 'crosscourt',
        'cross-court': 'crosscourt',
        'cross court': 'crosscourt',
        'dtl': 'down_the_line',
        'down the line': 'down_the_line',
        'down-the-line': 'down_the_line',
        'line': 'down_the_line',
        'dtm': 'down_the_middle',
        'down the middle': 'down_the_middle',
        'middle': 'down_the_middle',
        'center': 'down_the_middle',
        'io': 'inside_out',
        'inside out': 'inside_out',
        'inside-out': 'inside_out',
        'ii': 'inside_in',
        'inside in': 'inside_in',
        'inside-in': 'inside_in',
        
        # Shot type aliases
        'fh': 'forehand',
        'bh': 'backhand',
        'sv': 'serve',
        'ret': 'return',
        'oh': 'overhead',
        
        # Modifier aliases
        'slice': 'slice',
        'chip': 'slice',
        'underspin': 'slice',
        'topspin': 'topspin',
        'flat': 'flat',
        'vb': 'volley',
        'vol': 'volley',
        'sv': 'swinging_volley',
        'hv': 'half_volley',
        'dv': 'drop_volley',
        'ds': 'drop_shot',
        'dropshot': 'drop_shot',
        'drop': 'drop_shot',
        'app': 'approach',
        'approach': 'approach',
        'approach shot': 'approach',
        
        # Serve target aliases (NOTE: These are CONTEXT-SPECIFIC - only for serve detection)
        # NOT included here to avoid conflicts with direction aliases
        # Serve target aliases are handled in serve-specific detection code
        
        # Depth aliases
        'deep': 'deep',
        'very deep': 'very_deep',
        'shallow': 'shallow',
        'short': 'shallow',
        
        # Outcome aliases
        'winner': 'winner',
        'wnr': 'winner',
        'w': 'winner',
        'ue': 'unforced_error',
        'unforced': 'unforced_error',
        'unforced error': 'unforced_error',
        'fe': 'forced_error',
        'forced': 'forced_error',
        'forced error': 'forced_error',
        'ace': 'ace',
        'df': 'double_fault',
        'double fault': 'double_fault',
    }
    
    # HIERARCHY: Supersets contain their subsets
    # When filtering by superset, include all subsets
    SHOT_HIERARCHY = {
        # Shot types: these are independent (forehand is not a superset of backhand)
        
        # Modifiers: volleys hierarchy
        'volley': ['volley', 'swinging_volley', 'half_volley', 'drop_volley'],
        'net_shot': ['volley', 'swinging_volley', 'half_volley', 'drop_volley', 'overhead'],
        
        # Depth hierarchy
        'any_deep': ['deep', 'very_deep'],
        
        # Direction groupings
        'wide_shots': ['crosscourt', 'inside_out', 'inside_in'],  # Shots that go wide
        'center_shots': ['down_the_middle', 'down_the_line'],  # Shots that go center/line
        
        # Outcome groupings
        'errors': ['unforced_error', 'forced_error', 'double_fault'],
        'winners_all': ['winner', 'ace', 'service_winner'],
        'point_ending': ['winner', 'ace', 'unforced_error', 'forced_error', 'double_fault'],
        
        # Court position groupings
        'at_net': ['volley', 'half_volley', 'drop_volley', 'overhead', 'swinging_volley'],
        'baseline': ['groundstroke', 'slice', 'topspin'],
    }
    
    def _normalize_value(self, value: str, category: str = None) -> str:
        """
        Normalize a shot/filter value to its canonical form.
        
        Args:
            value: The raw value (e.g., "cc", "dtl", "forehand")
            category: Optional hint about what type of value this is
            
        Returns:
            Canonical form (e.g., "crosscourt", "down_the_line")
        """
        if not value:
            return None
            
        value_lower = value.lower().strip()
        
        # Check aliases first
        if value_lower in self.SHOT_ALIASES:
            return self.SHOT_ALIASES[value_lower]
        
        # Already canonical
        return value_lower.replace(' ', '_').replace('-', '_')
    
    def _expand_to_matching_values(self, value: str, actual_values: set = None) -> list:
        """
        Expand a filter value to all matching values (including subsets).
        
        Args:
            value: Normalized filter value (e.g., "volley")
            actual_values: Set of values that actually exist in the data
            
        Returns:
            List of all values that should match (e.g., ["volley", "swinging_volley", "half_volley"])
        """
        if not value:
            return []
        
        # Normalize first
        normalized = self._normalize_value(value)
        
        # Check if this is a superset
        if normalized in self.SHOT_HIERARCHY:
            expanded = self.SHOT_HIERARCHY[normalized]
        else:
            expanded = [normalized]
        
        # If we have actual values, filter to only those that exist
        if actual_values:
            expanded = [v for v in expanded if v in actual_values]
        
        return expanded if expanded else [normalized]
    
    def _values_match(self, query_value: str, data_value: str, expand_hierarchy: bool = True) -> bool:
        """
        Check if a query value matches a data value, handling aliases and hierarchies.
        
        Args:
            query_value: What the user asked for (e.g., "cc", "volley")
            data_value: What's in the data (e.g., "crosscourt", "swinging_volley")
            expand_hierarchy: Whether to check superset matches
            
        Returns:
            True if they match
        """
        if not query_value or not data_value:
            return False
        
        # Normalize both
        norm_query = self._normalize_value(query_value)
        norm_data = self._normalize_value(data_value)
        
        # Direct match
        if norm_query == norm_data:
            return True
        
        # Hierarchy match (query is superset of data)
        if expand_hierarchy and norm_query in self.SHOT_HIERARCHY:
            return norm_data in self.SHOT_HIERARCHY[norm_query]
        
        return False
    
    def _get_point_metadata(self, point_data: Dict) -> Dict:
        """
        UNIVERSAL POINT METADATA EXTRACTOR
        
        Extracts ALL metadata from a point ONCE, to be used throughout the system.
        This is the SINGLE SOURCE OF TRUTH for all point analysis.
        
        Returns:
            {
                'point_number': int,
                'server': str,
                'returner': str,
                'score': str,
                'set_number': int,
                'rally_length': int,
                'rally_category': str ('1-3', '4-6', '7-9', '10+'),
                'point_winner': str,
                'winning_shot': {
                    'player': str,
                    'shot_type': str ('forehand', 'backhand', 'serve'),
                    'shot_modifier': str ('volley', 'slice', 'drop_shot', etc.),
                    'direction': str ('crosscourt', 'down_the_line', 'inside_out', etc.),
                    'at_net': bool,
                    'depth': str ('deep', 'shallow', 'very_deep'),
                    'outcome': str ('winner', 'ace', 'unforced_error', etc.)
                },
                'serve_info': {
                    'serve_number': int (1 or 2),
                    'serve_target': str ('wide', 'body', 't'),
                    'is_ace': bool,
                    'is_double_fault': bool
                },
                'return_info': {
                    'return_depth': str ('deep', 'shallow', 'very_deep'),
                    'return_direction': str,
                    'return_in_play': bool
                },
                'serve_plus_one': {
                    'shot_type': str,
                    'direction': str
                },
                'situation': {
                    'is_break_point': bool,
                    'is_game_point': bool,
                    'is_deuce': bool,
                    'is_tiebreak': bool,
                    'court_side': str ('deuce', 'ad')
                },
                'error_info': {
                    'error_player': str,
                    'error_type': str ('unforced', 'forced'),
                    'error_shot_type': str
                }
            }
        """
        point_text = point_data.get('point_text', point_data.get('description', ''))
        server = point_data.get('server', '')
        returner = point_data.get('returner', '')
        score = point_data.get('score', '')
        point_number = point_data.get('point_number', 0)
        
        # Parse rally ONCE
        rally_shots = self._parse_rally_sequence(point_text, server, returner)
        actual_shots = [s for s in rally_shots if s.get('outcome') not in ['FAULT', 'LET']]
        
        # Use centralized rally length calculation (single source of truth)
        rally_length = self._calculate_rally_length(rally_shots, point_text)
        
        # Rally category
        if rally_length <= 3:
            rally_category = '1-3'
        elif rally_length <= 6:
            rally_category = '4-6'
        elif rally_length <= 9:
            rally_category = '7-9'
        else:
            rally_category = '10+'
        
        # Extract point winner from [Point won by:] tag
        point_winner = None
        winner_match = re.search(r'\[Point won by:\s*([^\]]+)\]', point_text)
        if winner_match:
            point_winner = winner_match.group(1).strip()
        
        # === WINNING SHOT METADATA ===
        winning_shot = {}
        error_info = {}
        if actual_shots:
            last_shot = actual_shots[-1]
            last_desc = last_shot.get('description', '')
            
            winning_shot = {
                'player': last_shot.get('player', ''),
                'shot_type': last_shot.get('shot_type'),
                'shot_modifier': last_shot.get('shot_modifier'),
                'shot_modifiers': last_shot.get('shot_modifiers', []),  # ALL modifiers
                'direction': last_shot.get('direction'),
                'at_net': last_shot.get('at_net', False),
                'court_position': last_shot.get('court_position'),
                'depth': last_shot.get('depth'),
                'spin': last_shot.get('spin'),
                'outcome': last_shot.get('outcome')
            }
            
            # Error info
            outcome = last_shot.get('outcome', '')
            if outcome in ['UNFORCED ERROR', 'FORCED ERROR']:
                # Extract error shot type from description - find the FIRST (leftmost) occurrence
                # This is more accurate than checking in a fixed order
                last_description = last_shot.get('description', '').lower()
                error_shot_type = None
                earliest_pos = len(last_description)
                for shot in ['backhand', 'forehand', 'serve']:
                    pos = last_description.find(shot)
                    if pos != -1 and pos < earliest_pos:
                        earliest_pos = pos
                        error_shot_type = shot
                # Fallback to shot_type from parsed metadata if description parsing fails
                if not error_shot_type:
                    error_shot_type = last_shot.get('shot_type')
                
                error_info = {
                    'error_player': last_shot.get('player', ''),
                    'error_type': 'unforced' if 'UNFORCED' in outcome else 'forced',
                    'error_shot_type': error_shot_type
                }
        
        # === SERVE INFO ===
        point_lower = point_text.lower()
        has_1st_fault = bool(re.search(r'1st serve[^;]*fault', point_lower))
        has_2nd_serve = '2nd serve' in point_lower
        is_2nd_serve_point = has_1st_fault or has_2nd_serve
        
        serve_target = None
        if is_2nd_serve_point:
            match = re.search(r'2nd serve\s+([^;,]+)', point_lower)
            serve_desc = match.group(1) if match else ''
        else:
            match = re.search(r'1st serve\s+([^;,]+)', point_lower)
            serve_desc = match.group(1) if match else ''
        
        if 'wide' in serve_desc:
            serve_target = 'wide'
        elif 'body' in serve_desc:
            serve_target = 'body'
        elif 'down the t' in serve_desc or 't' in serve_desc.split()[-2:] if serve_desc else False:
            serve_target = 't'
        
        serve_info = {
            'serve_number': 2 if is_2nd_serve_point else 1,
            'serve_target': serve_target,
            'is_ace': winning_shot.get('outcome') == 'ACE',
            'is_double_fault': winning_shot.get('outcome') == 'DOUBLE_FAULT'
        }
        
        # === RETURN INFO ===
        return_info = {'return_depth': None, 'return_direction': None, 'return_in_play': rally_length >= 2}
        if len(actual_shots) >= 2:
            return_shot = actual_shots[1]  # Shot index 1 is the return
            return_info['return_depth'] = return_shot.get('depth')
            return_info['return_direction'] = return_shot.get('direction')
        
        # === SERVE+1 INFO ===
        serve_plus_one = {'shot_type': None, 'direction': None}
        if len(actual_shots) >= 3:
            third_shot = actual_shots[2]  # Server's 2nd shot (serve+1)
            serve_plus_one['shot_type'] = third_shot.get('shot_type')
            serve_plus_one['direction'] = third_shot.get('direction')
        
        # === SITUATION INFO ===
        situation = {
            'is_break_point': self._is_break_point_score(score),
            'is_game_point': self._is_game_point_score(score),
            'is_set_point': self._is_set_point_score(score),
            'is_match_point': self._is_match_point_score(score),
            'is_deuce': self._is_deuce_score(score),
            'is_tiebreak': self._is_tiebreak_point(score),
            'court_side': self._determine_court_side(score)
        }
        
        # === SET AND GAME INFO ===
        set_number = self._extract_current_set(score)
        game_info = self._extract_game_info(score, point_number)
        
        # === SHOT COUNTS (for all shots in the point, not just outcomes) ===
        # This enables questions like "percentage of shots that were winners"
        shot_counts = {
            'total': 0,
            'by_player': {},  # {player_name: count}
            'by_type': {},    # {forehand: count, backhand: count, ...}
            'by_player_type': {},  # {player_name: {forehand: count, backhand: count}}
            'winners': 0,
            'errors': 0,
        }
        
        for shot in actual_shots:
            shot_counts['total'] += 1
            shot_player = shot.get('player', '')
            shot_type = shot.get('shot_type', 'unknown')
            outcome = shot.get('outcome', '')
            
            # Count by player
            if shot_player:
                shot_counts['by_player'][shot_player] = shot_counts['by_player'].get(shot_player, 0) + 1
                
                # Count by player + type
                if shot_player not in shot_counts['by_player_type']:
                    shot_counts['by_player_type'][shot_player] = {}
                shot_counts['by_player_type'][shot_player][shot_type] = \
                    shot_counts['by_player_type'][shot_player].get(shot_type, 0) + 1
            
            # Count by shot type
            if shot_type:
                shot_counts['by_type'][shot_type] = shot_counts['by_type'].get(shot_type, 0) + 1
            
            # Count outcomes - GENERIC using OUTCOME_CONFIG
            outcome_config = self._get_outcome_config(outcome)
            winning_shot_type = outcome_config.get('winning_shot_type', '')
            is_positive = outcome_config.get('is_positive', True)
            
            if winning_shot_type in ['winner', 'ace', 'service_winner']:
                shot_counts['winners'] += 1
            elif 'error' in winning_shot_type:
                shot_counts['errors'] += 1
        
        return {
            'point_number': point_number,
            'server': server,
            'returner': returner,
            'score': score,
            # === SET/GAME HIERARCHY ===
            'set_number': set_number,
            'game_number_in_set': game_info.get('game_number_in_set'),
            'game_number_overall': game_info.get('game_number_overall'),
            'set_score': game_info.get('set_score'),
            'game_score': game_info.get('game_score'),
            'point_score': game_info.get('point_score'),
            # === POINT DATA ===
            'rally_length': rally_length,
            'rally_category': rally_category,
            'point_winner': point_winner,
            'winning_shot': winning_shot,
            'serve_info': serve_info,
            'return_info': return_info,
            'serve_plus_one': serve_plus_one,
            'situation': situation,
            'error_info': error_info,
            'all_shots': actual_shots,  # ALL shots with full metadata
            'shot_counts': shot_counts,  # Aggregated shot counts for this point
            'raw_text': point_text
        }
    
    def _determine_court_side(self, score: str) -> str:
        """Determine if point is on deuce or ad side based on score."""
        if not score:
            return None
        
        # Parse game score (last part of score)
        parts = score.split()
        if not parts:
            return None
        
        game_score = parts[-1] if parts else ''
        
        # Points mapping
        point_values = {'0': 0, '15': 1, '30': 2, '40': 3, 'AD': 4, 'A': 4}
        
        try:
            if '-' in game_score:
                server_pts, returner_pts = game_score.split('-')
                server_val = point_values.get(server_pts, 0)
                returner_val = point_values.get(returner_pts, 0)
                total_points = server_val + returner_val
                # Even total = deuce side, odd = ad side
                return 'deuce' if total_points % 2 == 0 else 'ad'
        except:
            pass
        
        return None
    
    def _extract_game_info(self, score: str, point_number: int = 0) -> Dict:
        """
        Extract comprehensive game/set information from score string.
        
        Handles scores like:
        - "0-0 1-2 15-30" -> set 1, game 4 in set (1+2+1), game 4 overall
        - "1-1 3-4 40-30" -> set 3, game 8 in set (3+4+1), game 8 + prev sets overall
        
        Returns:
            {
                'set_number': int,                  # Current set (1-indexed)
                'game_number_in_set': int,          # Game within this set (1-indexed)
                'game_number_overall': int,         # Game across whole match (1-indexed)
                'set_score': str,                   # e.g., "1-1"
                'game_score': str,                  # e.g., "3-4"
                'point_score': str,                 # e.g., "40-30"
                'games_in_set_server': int,         # Server's games in this set
                'games_in_set_returner': int,       # Returner's games in this set
                'total_sets_server': int,           # Server's sets won
                'total_sets_returner': int,         # Returner's sets won
            }
        """
        import re
        
        result = {
            'set_number': 1,
            'game_number_in_set': 1,
            'game_number_overall': 1,
            'set_score': '0-0',
            'game_score': '0-0',
            'point_score': '0-0',
            'games_in_set_server': 0,
            'games_in_set_returner': 0,
            'total_sets_server': 0,
            'total_sets_returner': 0,
        }
        
        if not score:
            return result
        
        # Parse all X-X patterns from score
        patterns = re.findall(r'(\d+)-(\d+)', score)
        
        if len(patterns) < 2:
            return result
        
        # First pattern is usually set score, second is game score
        try:
            # Set score (e.g., "1-1" means 1 set each)
            set_server = int(patterns[0][0])
            set_returner = int(patterns[0][1])
            result['set_score'] = f"{set_server}-{set_returner}"
            result['total_sets_server'] = set_server
            result['total_sets_returner'] = set_returner
            result['set_number'] = set_server + set_returner + 1  # Current set (1-indexed)
            
            # Game score (e.g., "3-4" means 7 games played in this set)
            games_server = int(patterns[1][0])
            games_returner = int(patterns[1][1])
            result['game_score'] = f"{games_server}-{games_returner}"
            result['games_in_set_server'] = games_server
            result['games_in_set_returner'] = games_returner
            
            # Game number in set (1-indexed, current game being played)
            result['game_number_in_set'] = games_server + games_returner + 1
            
            # Estimate total games in previous sets (assume ~10 games per set avg)
            # This is approximate - for accurate tracking, need to parse full match history
            games_in_previous_sets = (set_server + set_returner) * 10  # Rough estimate
            result['game_number_overall'] = games_in_previous_sets + games_server + games_returner + 1
            
            # Point score (if available)
            if len(patterns) >= 3:
                result['point_score'] = f"{patterns[2][0]}-{patterns[2][1]}"
            else:
                # Check for tennis point patterns like "15-30", "40-AD"
                point_match = re.search(r'(0|15|30|40|AD)-(0|15|30|40|AD)', score, re.IGNORECASE)
                if point_match:
                    result['point_score'] = point_match.group(0)
        except (ValueError, IndexError):
            pass
        
        return result
    
    def _build_game_aggregation(self) -> Dict:
        """
        Build game-level aggregation from point-by-point data.
        
        Creates a mapping of (set_num, game_num) -> {
            'winner': player_name,
            'server': player_name,
            'points_won_server': int,
            'points_won_returner': int,
            'total_points': int,
            'is_break': bool,
        }
        
        This enables queries like:
        - "How many games did Sinner win?"
        - "Games won in set 2"
        - "How many service games did Medvedev hold?"
        - "Break percentage"
        """
        if not hasattr(self, 'point_by_point') or not self.point_by_point:
            return {}
        
        games = {}  # (set_num, game_num_in_set) -> game data
        set_winners = {}  # set_num -> winner (player name)
        current_set = 1
        current_game = 1
        current_server = None
        prev_server = None  # Track previous server for set score normalization
        points_in_game = {'server': 0, 'returner': 0}
        games_in_set = {'player1': 0, 'player2': 0}  # Track games won per set
        
        prev_set_score = None
        prev_game_score = None
        
        for point in self.point_by_point:
            # Get metadata
            if '_metadata' in point:
                meta = point['_metadata']
            else:
                meta = self._get_point_metadata(point)
            
            server = meta.get('server', '')
            returner = meta.get('returner', '')
            point_winner = meta.get('point_winner', '')
            set_score = meta.get('set_score', '0-0')
            game_score = meta.get('game_score', '0-0')
            
            # IMPORTANT: Check game change BEFORE set change, because when a set ends,
            # the last game of that set completes AND the set changes at the same time.
            # We need to record the game completion first, then handle the set change.
            
            # Detect game change (game score changed)
            # Check if game ended - this can happen within same set OR when set changes
            game_ended = False
            if prev_game_score and game_score != prev_game_score:
                game_ended = True
            
            # If game ended, record it BEFORE handling set change
            if game_ended:
                # Game ended - record the game winner
                game_key = (current_set, current_game)
                
                # Determine game winner by comparing the NEW score (game_score) to games_in_set
                # IMPORTANT: Score format is "server_games-returner_games" (server's score first)
                # game_score is from the CURRENT point (new server), showing state AFTER the game ended
                # games_in_set shows what we've recorded so far (before this game)
                game_winner = None
                try:
                    # Use the NEW score (game_score) with the NEW server (server)
                    new_parts = game_score.split('-')
                    if len(new_parts) == 2:
                        # Parse game score - format is "Server's games - Returner's games"
                        new_server_games = int(new_parts[0])
                        new_returner_games = int(new_parts[1])
                        
                        # Map to player1/player2 based on who is NOW serving (the new server)
                        def normalize_name(n):
                            return (n or '').lower().replace(' ', '').replace('.', '')
                        
                        new_server_norm = normalize_name(server)  # Use 'server' (new server), not 'current_server' (old)
                        p1_norm = normalize_name(self.player1)
                        p2_norm = normalize_name(self.player2)
                        
                        if new_server_norm == p1_norm:
                            # Player 1 is now serving: first num = P1's games, second = P2's games
                            score_p1 = new_server_games
                            score_p2 = new_returner_games
                        elif new_server_norm == p2_norm:
                            # Player 2 is now serving: first num = P2's games, second = P1's games
                            score_p1 = new_returner_games
                            score_p2 = new_server_games
                        else:
                            # Unknown server - skip score-based detection
                            score_p1 = score_p2 = -1
                        
                        recorded_p1 = games_in_set.get('player1', 0)
                        recorded_p2 = games_in_set.get('player2', 0)
                        
                        # If the NEW score shows more games for a player than we've recorded,
                        # that player won this game
                        if score_p1 > recorded_p1:
                            game_winner = self.player1
                        elif score_p2 > recorded_p2:
                            game_winner = self.player2
                except (ValueError, AttributeError):
                    pass
                
                # Fallback: use points if score parsing didn't work
                if not game_winner:
                    if points_in_game['server'] > points_in_game['returner']:
                        game_winner = current_server
                    elif points_in_game['returner'] > points_in_game['server']:
                        game_winner = returner if current_server else ''
                    else:
                        # Equal or no points - use server as default
                        game_winner = current_server
                
                # Check if server held or got broken
                is_break = game_winner and current_server and \
                          not self._names_match_robust(game_winner, current_server)
                
                # Only record if we don't already have this game (avoid duplicates)
                if game_key not in games:
                    games[game_key] = {
                        'winner': game_winner,
                        'server': current_server,
                        'points_won_server': points_in_game['server'],
                        'points_won_returner': points_in_game['returner'],
                        'total_points': points_in_game['server'] + points_in_game['returner'],
                        'is_break': is_break,
                        'set_number': current_set,
                        'game_number_in_set': current_game,
                    }
                    
                    # Track games won in this set
                    # Use exact matching to avoid "Player 1" matching "Player 2"
                    if game_winner:
                        winner_norm = (game_winner or '').lower().replace(' ', '').replace('.', '')
                        p1_norm = (self.player1 or '').lower().replace(' ', '').replace('.', '')
                        p2_norm = (self.player2 or '').lower().replace(' ', '').replace('.', '')
                        
                        if winner_norm == p1_norm:
                            games_in_set['player1'] += 1
                        elif winner_norm == p2_norm:
                            games_in_set['player2'] += 1
                    
                    # Check if set is complete:
                    # 1. Player has 6+ games AND 2+ game lead (6-4, 7-5, etc.)
                    # 2. OR player has 7 games and opponent has 6 (7-6 tiebreak win)
                    p1_games = games_in_set['player1']
                    p2_games = games_in_set['player2']
                    
                    # Standard win: 6+ games with 2+ game lead
                    if p1_games >= 6 and (p1_games - p2_games) >= 2:
                        # Player 1 won the set (e.g., 6-4, 7-5)
                        set_winners[current_set] = self.player1
                    elif p2_games >= 6 and (p2_games - p1_games) >= 2:
                        # Player 2 won the set (e.g., 6-4, 7-5)
                        set_winners[current_set] = self.player2
                    # Tiebreak win: 7-6
                    elif p1_games == 7 and p2_games == 6:
                        # Player 1 won the set in a tiebreak (7-6)
                        set_winners[current_set] = self.player1
                    elif p2_games == 7 and p1_games == 6:
                        # Player 2 won the set in a tiebreak (7-6)
                        set_winners[current_set] = self.player2
                
                current_game += 1
                points_in_game = {'server': 0, 'returner': 0}
            
            # Now detect set change (set score changed)
            # IMPORTANT: Set scores are in "Server's sets - Returner's sets" format
            # We need to normalize to P1-P2 format before comparing
            def normalize_set_score(raw_score, server_name, player1_name, player2_name):
                """Convert server-returner set score to P1-P2 format."""
                if not raw_score or '-' not in raw_score:
                    return (0, 0)
                parts = raw_score.split('-')
                if len(parts) != 2:
                    return (0, 0)
                try:
                    first = int(parts[0])
                    second = int(parts[1])
                except ValueError:
                    return (0, 0)
                
                # Normalize names for comparison
                norm = lambda n: (n or '').lower().replace(' ', '').replace('.', '')
                server_norm = norm(server_name)
                p1_norm = norm(player1_name)
                p2_norm = norm(player2_name)
                
                if server_norm == p1_norm:
                    # Server is P1: first = P1's sets, second = P2's sets
                    return (first, second)
                elif server_norm == p2_norm:
                    # Server is P2: first = P2's sets, second = P1's sets
                    return (second, first)
                else:
                    # Unknown server - return as-is
                    return (first, second)
            
            # Normalize current and previous set scores
            curr_normalized = normalize_set_score(set_score, server, self.player1, self.player2)
            prev_normalized = normalize_set_score(prev_set_score, prev_server if prev_server else server, self.player1, self.player2) if prev_set_score else (0, 0)
            
            # Detect actual set change by comparing normalized scores
            actual_set_change = curr_normalized != prev_normalized and (curr_normalized[0] + curr_normalized[1]) > (prev_normalized[0] + prev_normalized[1])
            
            if actual_set_change:
                # Set changed - check if we need to record set winner from games won
                # If set winner not already recorded from game completion rule, determine from final game scores
                if current_set not in set_winners:
                    # Set ended but winner not detected yet - determine from accumulated games
                    p1_games = games_in_set['player1']
                    p2_games = games_in_set['player2']
                    
                    # Standard win: 6+ games with 2+ game lead
                    if p1_games >= 6 and (p1_games - p2_games) >= 2:
                        set_winners[current_set] = self.player1
                    elif p2_games >= 6 and (p2_games - p1_games) >= 2:
                        set_winners[current_set] = self.player2
                    # Tiebreak win: 7-6
                    elif p1_games == 7 and p2_games == 6:
                        set_winners[current_set] = self.player1
                    elif p2_games == 7 and p1_games == 6:
                        set_winners[current_set] = self.player2
                    # Fallback: determine from who has more games (shouldn't happen in normal tennis)
                    elif p1_games > p2_games:
                        set_winners[current_set] = self.player1
                    elif p2_games > p1_games:
                        set_winners[current_set] = self.player2
                
                # Move to new set
                current_set += 1
                current_game = 1  # Reset to game 1 for new set
                games_in_set = {'player1': 0, 'player2': 0}  # Reset games won for new set
                # Don't reset points_in_game here - it was already reset when we recorded the game above
                # But if for some reason it wasn't reset, reset it now
                if points_in_game['server'] > 0 or points_in_game['returner'] > 0:
                    points_in_game = {'server': 0, 'returner': 0}
            
            # Track current server (changes each game)
            # Track previous server before updating current
            prev_server = current_server
            
            if server:
                current_server = server
            
            # Count point for server or returner
            if point_winner:
                if self._names_match_robust(point_winner, server):
                    points_in_game['server'] += 1
                elif self._names_match_robust(point_winner, returner):
                    points_in_game['returner'] += 1
            
            prev_set_score = set_score
            prev_game_score = game_score
        
        # Record final game if match ended
        # This game hasn't been recorded yet because there was no "next point" to trigger detection
        game_key = (current_set, current_game)
        
        # Always try to record the final game if it doesn't exist
        if game_key not in games:
            # Determine game winner - use the final score to infer who won this game
            # IMPORTANT: Score format is "server_games-returner_games" (server's score first)
            game_winner = None
            
            # Try to determine winner from the final game score
            # The final score shows the result AFTER the last game was won
            # Score format is "server_games - returner_games"
            try:
                final_parts = prev_game_score.split('-') if prev_game_score else []
                if len(final_parts) == 2:
                    server_games = int(final_parts[0])
                    returner_games = int(final_parts[1])
                    
                    # Map to player1/player2 based on who was serving
                    def normalize_name(n):
                        return (n or '').lower().replace(' ', '').replace('.', '')
                    
                    server_norm = normalize_name(current_server)
                    p1_norm = normalize_name(self.player1)
                    p2_norm = normalize_name(self.player2)
                    
                    if server_norm == p1_norm:
                        final_p1 = server_games
                        final_p2 = returner_games
                    elif server_norm == p2_norm:
                        final_p1 = returner_games
                        final_p2 = server_games
                    else:
                        final_p1 = final_p2 = -1
                    
                    # Compare with games_in_set to see who won the last game
                    p1_recorded = games_in_set.get('player1', 0)
                    p2_recorded = games_in_set.get('player2', 0)
                    
                    if final_p1 > p1_recorded:
                        game_winner = self.player1
                    elif final_p2 > p2_recorded:
                        game_winner = self.player2
            except (ValueError, AttributeError):
                pass
            
            # Fallback: use accumulated points if available
            if not game_winner:
                if points_in_game['server'] > points_in_game['returner']:
                    game_winner = current_server
                elif points_in_game['returner'] > points_in_game['server']:
                    game_winner = returner if current_server else ''
                else:
                    # No clear winner from points - use server as fallback
                    game_winner = current_server
            
            # Check if server held or got broken
            is_break = game_winner and current_server and \
                      not self._names_match_robust(game_winner, current_server)
            
            games[game_key] = {
                'winner': game_winner,
                'server': current_server,
                'points_won_server': points_in_game['server'],
                'points_won_returner': points_in_game['returner'],
                'total_points': points_in_game['server'] + points_in_game['returner'],
                'is_break': is_break,
                'set_number': current_set,
                'game_number_in_set': current_game,
            }
            
            # Update games_in_set for set winner detection
            if game_winner:
                if self._names_match_robust(game_winner, self.player1):
                    games_in_set['player1'] += 1
                elif self._names_match_robust(game_winner, self.player2):
                    games_in_set['player2'] += 1
            
            # Check if set is complete after recording final game
            p1_games = games_in_set.get('player1', 0)
            p2_games = games_in_set.get('player2', 0)
            
            # Standard win: 6+ games with 2+ game lead
            if p1_games >= 6 and (p1_games - p2_games) >= 2:
                set_winners[current_set] = self.player1
            elif p2_games >= 6 and (p2_games - p1_games) >= 2:
                set_winners[current_set] = self.player2
            # Tiebreak win: 7-6
            elif p1_games == 7 and p2_games == 6:
                set_winners[current_set] = self.player1
            elif p2_games == 7 and p1_games == 6:
                set_winners[current_set] = self.player2
        
        # Check final set completion if match ended (in case winner not detected above)
        # If final set winner not recorded yet, determine from accumulated games
        if current_set not in set_winners:
            p1_games = games_in_set.get('player1', 0)
            p2_games = games_in_set.get('player2', 0)
            
            # Standard win: 6+ games with 2+ game lead
            if p1_games >= 6 and (p1_games - p2_games) >= 2:
                set_winners[current_set] = self.player1
            elif p2_games >= 6 and (p2_games - p1_games) >= 2:
                set_winners[current_set] = self.player2
            # Tiebreak win: 7-6
            elif p1_games == 7 and p2_games == 6:
                set_winners[current_set] = self.player1
            elif p2_games == 7 and p1_games == 6:
                set_winners[current_set] = self.player2
            # Fallback: determine from who has more games
            elif p1_games > p2_games:
                set_winners[current_set] = self.player1
            elif p2_games > p1_games:
                set_winners[current_set] = self.player2
        
        # Store for later use
        self._game_aggregation = games
        self._set_winners_from_tree = set_winners  # Store set winners from tree structure
        return games
    
    def _get_games_count(self, player_filter: str = None, set_filter: int = None, 
                        role_filter: str = None) -> Dict:
        """
        Get games count for player(s), optionally filtered by set or role.
        
        Args:
            player_filter: 'both', player name, or None (all)
            set_filter: Specific set number to filter by
            role_filter: 'server' (held serve) or 'returner' (broke serve)
        
        Returns:
            {
                'player1_games': int,
                'player2_games': int,
                'total_games': int,
                'player1_holds': int,  # Service games won
                'player2_holds': int,
                'player1_breaks': int, # Return games won (broke opponent)
                'player2_breaks': int,
            }
        """
        # Build aggregation if not already done
        if not hasattr(self, '_game_aggregation') or not self._game_aggregation:
            self._build_game_aggregation()
        
        # Fallback to existing game_winners if aggregation failed
        if not hasattr(self, '_game_aggregation') or not self._game_aggregation:
            # Use legacy game_winners dict
            games = getattr(self, 'game_winners', {})
            p1_games = sum(1 for w in games.values() if w == 'player1')
            p2_games = sum(1 for w in games.values() if w == 'player2')
            return {
                'player1_games': p1_games,
                'player2_games': p2_games,
                'total_games': p1_games + p2_games,
                'player1_holds': 0,
                'player2_holds': 0,
                'player1_breaks': 0,
                'player2_breaks': 0,
            }
        
        result = {
            'player1_games': 0,
            'player2_games': 0,
            'total_games': 0,
            'player1_holds': 0,
            'player2_holds': 0,
            'player1_breaks': 0,
            'player2_breaks': 0,
        }
        
        player1 = self.player1
        player2 = self.player2
        
        for game_key, game_data in self._game_aggregation.items():
            set_num, game_num = game_key
            
            # Apply set filter (supports both single value and list)
            if set_filter:
                if isinstance(set_filter, (list, tuple)) and set_num not in set_filter:
                    continue
                elif not isinstance(set_filter, (list, tuple)) and set_num != set_filter:
                    continue
            
            winner = game_data.get('winner', '')
            server = game_data.get('server', '')
            is_break = game_data.get('is_break', False)
            
            # Determine if player1 or player2 won
            is_p1_win = winner and self._names_match_robust(player1, winner)
            is_p2_win = winner and self._names_match_robust(player2, winner)
            is_p1_serving = server and self._names_match_robust(player1, server)
            
            # Apply role filter - GENERIC using role expectation
            if role_filter:
                # Determine if winner was in the expected role
                winner_was_serving = (is_p1_win and is_p1_serving) or (is_p2_win and not is_p1_serving)
                winner_was_returning = (is_p1_win and not is_p1_serving) or (is_p2_win and is_p1_serving)
                
                role_config = self.ROLE_CONFIG.get(role_filter, {})
                expected_role = role_config.get('player_field', '')  # 'server' or 'returner'
                
                # Skip if winner wasn't in the expected role
                if expected_role == 'server' and not winner_was_serving:
                    continue
                elif expected_role == 'returner' and not winner_was_returning:
                    continue
            
            # Count games
            result['total_games'] += 1
            
            if is_p1_win:
                result['player1_games'] += 1
                if is_p1_serving:
                    result['player1_holds'] += 1
                else:
                    result['player1_breaks'] += 1
            elif is_p2_win:
                result['player2_games'] += 1
                if not is_p1_serving:  # P2 was serving
                    result['player2_holds'] += 1
                else:
                    result['player2_breaks'] += 1
        
        return result
    
    def _aggregate_games_from_points(self, points: list, filters: Dict = None) -> Dict:
        """
        Aggregate games and sets from a collection of points.
        
        Detects game transitions from score changes and counts winners.
        
        Args:
            points: List of point data dictionaries
            filters: Optional filters (set, game_number, game_number_in_set)
        
        Returns:
            {
                'player1_games': int,
                'player2_games': int,
                'total_games': int,
                'player1_holds': int,
                'player2_holds': int,
                'player1_breaks': int,
                'player2_breaks': int,
                'player1_sets': int,
                'player2_sets': int,
                'total_sets': int,
            }
        """
        import re
        
        filters = filters or {}
        set_filter = filters.get('set')
        game_filter = filters.get('game_number')  # Overall game number
        game_in_set_filter = filters.get('game_number_in_set')
        
        player1 = self.player1
        player2 = self.player2
        
        result = {
            'player1_games': 0,
            'player2_games': 0,
            'total_games': 0,
            'player1_holds': 0,
            'player2_holds': 0,
            'player1_breaks': 0,
            'player2_breaks': 0,
            'player1_sets': 0,
            'player2_sets': 0,
            'total_sets': 0,
        }
        
        # Track unique games: (set_number, game_score_at_start) -> {winner, server, is_break}
        games_seen = {}
        sets_completed = {}  # set_number -> winner
        games_per_set = {}  # set_number -> {player1: count, player2: count}
        
        prev_set_score = None
        prev_game_score = None
        prev_server = None
        current_game_points = []
        current_set = 1
        current_game_in_set = 1
        current_server = None
        overall_game_num = 0
        
        # Helper to normalize set scores from server-returner format to P1-P2 format
        def normalize_set_score(raw_score, server_name):
            """Convert server-returner set score to P1-P2 format."""
            if not raw_score or '-' not in raw_score:
                return (0, 0)
            parts = raw_score.split('-')
            if len(parts) != 2:
                return (0, 0)
            try:
                first = int(parts[0])
                second = int(parts[1])
            except ValueError:
                return (0, 0)
            
            # Normalize names for comparison
            norm = lambda n: (n or '').lower().replace(' ', '').replace('.', '')
            server_norm = norm(server_name)
            p1_norm = norm(player1)
            p2_norm = norm(player2)
            
            if server_norm == p1_norm:
                return (first, second)
            elif server_norm == p2_norm:
                return (second, first)
            else:
                return (first, second)
        
        for point_data in points:
            # Get metadata (use cached if available)
            if '_metadata' in point_data:
                meta = point_data['_metadata']
            else:
                meta = self._get_point_metadata(point_data)
            
            server = meta.get('server', '')
            point_winner = meta.get('point_winner', '')
            set_score = meta.get('set_score', '0-0')
            game_score = meta.get('game_score', '0-0')
            point_set_num = meta.get('set_number', 1)
            
            # Apply set filter (supports both single value and list)
            if set_filter:
                if isinstance(set_filter, (list, tuple)):
                    if point_set_num not in set_filter:
                        continue
                elif point_set_num != set_filter:
                    continue
            
            # Detect set change using normalized scores
            curr_normalized = normalize_set_score(set_score, server)
            prev_normalized = normalize_set_score(prev_set_score, prev_server if prev_server else server) if prev_set_score else (0, 0)
            
            # Actual set change: normalized scores differ AND total sets increased
            actual_set_change = curr_normalized != prev_normalized and (curr_normalized[0] + curr_normalized[1]) > (prev_normalized[0] + prev_normalized[1])
            
            if actual_set_change:
                # Set completed - determine who won the previous set
                # Compare normalized scores to see who gained a set
                if curr_normalized[0] > prev_normalized[0]:
                    sets_completed[current_set] = player1
                elif curr_normalized[1] > prev_normalized[1]:
                    sets_completed[current_set] = player2
                
                current_set += 1
                current_game_in_set = 1
                current_game_points = []
            
            # Detect game change (game score changed within same set)
            # Use normalized set scores for "same set" comparison
            same_set = curr_normalized == prev_normalized
            if prev_game_score and game_score != prev_game_score and same_set:
                # Game completed - determine winner using score comparison
                game_key = (current_set, current_game_in_set)
                
                # Try score-based winner detection first (more reliable)
                is_p1_win = False
                is_p2_win = False
                
                # Initialize games_per_set for this set if not exists
                if current_set not in games_per_set:
                    games_per_set[current_set] = {'player1': 0, 'player2': 0}
                
                # Parse NEW game_score to determine who won (not prev_game_score!)
                # Score format: "server_games - returner_games"
                # game_score is from the NEW server's perspective (after game ended)
                try:
                    new_parts = game_score.split('-')
                    if len(new_parts) == 2:
                        new_server_games = int(new_parts[0])
                        new_returner_games = int(new_parts[1])
                        
                        # Map to P1/P2 based on NEW server (who is serving in the current point)
                        norm = lambda n: (n or '').lower().replace(' ', '').replace('.', '')
                        new_server_norm = norm(server)  # Use 'server' (new), not 'current_server' (old)
                        p1_norm = norm(player1)
                        p2_norm = norm(player2)
                        
                        if new_server_norm == p1_norm:
                            p1_score = new_server_games
                            p2_score = new_returner_games
                        elif new_server_norm == p2_norm:
                            p1_score = new_returner_games
                            p2_score = new_server_games
                        else:
                            p1_score = p2_score = -1
                        
                        # Compare to recorded games to determine winner
                        recorded_p1 = games_per_set[current_set]['player1']
                        recorded_p2 = games_per_set[current_set]['player2']
                        
                        if p1_score > recorded_p1:
                            is_p1_win = True
                        elif p2_score > recorded_p2:
                            is_p2_win = True
                except (ValueError, AttributeError):
                    pass
                
                # Fallback: use last point winner if available
                if not is_p1_win and not is_p2_win and current_game_points:
                    last_point_winner = current_game_points[-1].get('point_winner')
                    is_p1_win = last_point_winner and self._names_match_robust(player1, last_point_winner)
                    is_p2_win = last_point_winner and self._names_match_robust(player2, last_point_winner)
                
                is_p1_serving = current_server and self._names_match_robust(player1, current_server)
                
                # Apply game number filter
                should_count = True
                overall_game_num += 1
                
                if game_filter and overall_game_num != game_filter:
                    should_count = False
                if game_in_set_filter and current_game_in_set != game_in_set_filter:
                    should_count = False
                
                if should_count and game_key not in games_seen:
                    games_seen[game_key] = True
                    result['total_games'] += 1
                    
                    if is_p1_win:
                        result['player1_games'] += 1
                        games_per_set[current_set]['player1'] += 1
                        if is_p1_serving:
                            result['player1_holds'] += 1
                        else:
                            result['player1_breaks'] += 1
                    elif is_p2_win:
                        result['player2_games'] += 1
                        games_per_set[current_set]['player2'] += 1
                        if is_p1_serving:
                            result['player2_breaks'] += 1
                        else:
                            result['player2_holds'] += 1
                
                current_game_in_set += 1
                current_game_points = []
            
            # Track previous server before updating current
            prev_server = current_server
            
            # Track current server
            if server:
                current_server = server
            
            # Add point to current game
            current_game_points.append({
                'point_winner': point_winner,
                'server': server
            })
            
            prev_set_score = set_score
            prev_game_score = game_score
        
        # Count sets from sets_completed (detected via set score changes)
        for set_num, winner in sets_completed.items():
            result['total_sets'] += 1
            if winner and self._names_match_robust(player1, winner):
                result['player1_sets'] += 1
            elif winner and self._names_match_robust(player2, winner):
                result['player2_sets'] += 1
        
        # Check for set completions NOT in sets_completed (e.g., final set of match)
        for set_num, counts in games_per_set.items():
            if set_num in sets_completed:
                continue  # Already counted via set score change
            
            p1_games = counts['player1']
            p2_games = counts['player2']
            
            # Standard win: 6+ games with 2+ game lead
            if p1_games >= 6 and (p1_games - p2_games) >= 2:
                result['total_sets'] += 1
                result['player1_sets'] += 1
            elif p2_games >= 6 and (p2_games - p1_games) >= 2:
                result['total_sets'] += 1
                result['player2_sets'] += 1
            # Tiebreak win: 7-6
            elif p1_games == 7 and p2_games == 6:
                result['total_sets'] += 1
                result['player1_sets'] += 1
            elif p2_games == 7 and p1_games == 6:
                result['total_sets'] += 1
                result['player2_sets'] += 1
        
        # If no games detected via transitions, fall back to existing game_winners
        if result['total_games'] == 0 and hasattr(self, 'game_winners') and self.game_winners:
            for game_key, winner in self.game_winners.items():
                if set_filter:
                    # Filter by set if specified (supports both single value and list)
                    if isinstance(game_key, tuple) and len(game_key) >= 1:
                        set_num = game_key[0]
                        if isinstance(set_filter, (list, tuple)):
                            if set_num not in set_filter:
                                continue
                        elif set_num != set_filter:
                            continue
                
                result['total_games'] += 1
                if winner == 'player1' or (winner and self._names_match_robust(player1, winner)):
                    result['player1_games'] += 1
                elif winner == 'player2' or (winner and self._names_match_robust(player2, winner)):
                    result['player2_games'] += 1
        
        return result
    
    def chunk_text(self, text: str, max_tokens: int = 500) -> List[str]:
        """
        Splits a long text into chunks small enough to feed an LLM.
        Uses simple token count approximation (1 token â‰ˆ 4 chars).
        """
        approx_chunk_size = max_tokens * 4  # 4 chars per token
        chunks = []
        start = 0
        while start < len(text):
            end = start + approx_chunk_size
            chunk = text[start:end]
            chunks.append(chunk)
            start = end
        return chunks
    
    def _create_chunks_with_metadata(self, text: str, chunk_type: str, section: str, match_id: str) -> List[Dict]:
        """
        Returns a list of dicts with chunk text and enhanced metadata for better searchability.
        """
        # For tennis data, we want to keep sections intact rather than splitting arbitrarily
        # Only split if the section exceeds embedding model limits (8k tokens)
        estimated_tokens = len(text) // 4  # Rough approximation
        
        if estimated_tokens > 6000:  # More conservative buffer for 8192 token limit
            # Split large sections intelligently
            chunks = self._smart_chunk_large_section(text, section)
        else:
            # Keep section intact
            chunks = [text]
        
        # Determine player focus and statistics type from section
        player_focus = self._determine_player_focus(section)
        stat_category = self._determine_stat_category(section)
        
        result_chunks = []
        for i, chunk in enumerate(chunks):
            # Extract set and game metadata for point-by-point chunks
            set_numbers = []
            game_scores = []
            if 'point-by-point' in section.lower():
                set_numbers = self._extract_set_numbers_from_chunk(chunk)
                game_scores = self._extract_game_scores_from_chunk(chunk)
            
            result_chunks.append({
                "text": chunk,
                "metadata": {
                    "type": chunk_type,
                    "section": section,
                    "match_id": match_id,
                    "player_focus": player_focus,
                    "stat_category": stat_category,
                    "set_numbers": set_numbers,  # NEW: Which sets are in this chunk (e.g., [2, 3])
                    "game_scores": game_scores,  # NEW: Which game scores appear (e.g., ['4-5', '5-5', '6-5'])
                    "contains_percentages": "%" in chunk,
                    "contains_point_details": "Point " in chunk,
                    "contains_long_rallies": any("shot rally" in line or "stroke rally" in line for line in chunk.split('\n') if "rally" in line),
                    "match_info": {
                        "date": "2025-06-28",
                        "tournament": "Bad Homburg F",
                        "players": [self.player1 if self.player1 else "Player 1", self.player2 if self.player2 else "Player 2"],
                        "match_type": "WTA"
                    }
                }
            })
        
        return result_chunks
    
    def _smart_chunk_large_section(self, text: str, section: str) -> List[str]:
        """
        Intelligently chunk large sections while preserving semantic meaning.
        """
        lines = text.split('\n')
        
        if "point-by-point" in section.lower():
            # For point-by-point, group by games (every 6-8 points)
            chunks = []
            current_chunk = []
            point_count = 0
            
            for line in lines:
                current_chunk.append(line)
                if line.startswith("Point "):
                    point_count += 1
                    if point_count >= 6:  # Start new chunk every 6 points
                        chunks.append('\n'.join(current_chunk))
                        current_chunk = []
                        point_count = 0
            
            if current_chunk:
                chunks.append('\n'.join(current_chunk))
            
            return chunks
        
        else:
            # For statistics sections, try to split by player if possible
            player1_lines = []
            player2_lines = []
            header_lines = []
            other_lines = []
            
            for line in lines:
                if self.player1 and self.player1 in line:
                    player1_lines.append(line)
                elif self.player2 and self.player2 in line:
                    player2_lines.append(line)
                elif line.strip().endswith(':') or line.startswith('---'):
                    header_lines.append(line)
                else:
                    other_lines.append(line)
            
            # If we can separate by players, create player-specific chunks
            if player1_lines or player2_lines:
                chunks = []
                if player1_lines:
                    chunks.append('\n'.join(header_lines + player1_lines))
                if player2_lines:
                    chunks.append('\n'.join(header_lines + player2_lines))
                if other_lines and not (player1_lines or player2_lines):
                    chunks.append('\n'.join(header_lines + other_lines))
                return chunks
            
            # Fallback: use precise token-based chunking
            return self._precise_token_chunk(text, max_tokens=6000)
    
    def _precise_token_chunk(self, text: str, max_tokens: int) -> List[str]:
        """Precisely chunk text using actual token counting."""
        try:
            import tiktoken
            encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")
            
            total_tokens = len(encoding.encode(text))
            if total_tokens <= max_tokens:
                return [text]
            
            
            lines = text.split('\n')
            chunks = []
            current_chunk = []
            current_tokens = 0
            
            for line in lines:
                line_tokens = len(encoding.encode(line + '\n'))
                
                if current_tokens + line_tokens > max_tokens and current_chunk:
                    # Start new chunk
                    chunks.append('\n'.join(current_chunk))
                    current_chunk = [line]
                    current_tokens = line_tokens
                else:
                    current_chunk.append(line)
                    current_tokens += line_tokens
            
            if current_chunk:
                chunks.append('\n'.join(current_chunk))
            
            return chunks
            
        except Exception as e:
            # Fallback to character-based chunking
            max_chars = max_tokens * 4  # Rough estimate
            chunks = []
            for i in range(0, len(text), max_chars):
                chunks.append(text[i:i + max_chars])
            return chunks
    
    def _apply_rate_limit(self):
        """Apply rate limiting to avoid hitting API limits."""
        current_time = time.time()
        time_since_last_call = current_time - self.last_api_call
        
        if time_since_last_call < self.min_delay:
            sleep_time = self.min_delay - time_since_last_call
            print(f"[WAIT] Rate limiting: waiting {sleep_time:.1f}s...")
            time.sleep(sleep_time)
        
        self.last_api_call = time.time()
    
    def _determine_player_focus(self, section: str) -> str:
        """Determine which player this section focuses on."""
        if "serve1" in section.lower() or "return1" in section.lower() or "shots1" in section.lower() or "shotdir1" in section.lower() or "netpts1" in section.lower():
            return self.player1 if self.player1 else "Player 1"
        elif "serve2" in section.lower() or "return2" in section.lower() or "shots2" in section.lower() or "shotdir2" in section.lower() or "netpts2" in section.lower():
            return self.player2 if self.player2 else "Player 2"
        else:
            return "Both"
    
    def _determine_stat_category(self, section: str) -> str:
        """Determine the category of statistics."""
        section_lower = section.lower()
        if "serve" in section_lower:
            return "serving"
        elif "return" in section_lower:
            return "returning"
        elif "shot" in section_lower:
            return "shots"
        elif "net" in section_lower:
            return "net_play"
        elif "key_points" in section_lower:
            return "key_points"
        elif "rally" in section_lower:
            return "rally_outcomes"
        elif "point-by-point" in section_lower:
            return "narrative"
        elif "overview" in section_lower:
            return "overview"
        else:
            return "general"
    
    def _determine_chunk_type(self, section_name: str, section_text: str) -> str:
        """Determine the type of chunk based on section name and content."""
        section_lower = section_name.lower()
        
        if "point-by-point" in section_lower or "Point " in section_text:
            return "narrative"
        elif any(keyword in section_lower for keyword in ["statistics", "serve", "return", "shots", "net"]):
            return "statistics"
        elif "overview" in section_lower:
            return "overview"
        else:
            return "general"
    
    def _detect_long_rallies(self, text: str) -> List[str]:
        """Detect and extract information about long rallies in the text."""
        long_rallies = []
        lines = text.split('\n')
        
        for line in lines:
            if "shot rally" in line or "stroke rally" in line:
                # Extract rally length and details
                if "16-shot rally" in line:
                    long_rallies.append(f"LONGEST RALLY: {line}")
                elif "10+ shot rally" in line or "11-shot rally" in line or "12-shot rally" in line or "13-shot rally" in line or "14-shot rally" in line or "15-shot rally" in line:
                    long_rallies.append(f"LONG RALLY: {line}")
        
        return long_rallies
    
    def _is_match_insight_question(self, query: str) -> bool:
        """Determine if a query is asking for match insights vs. statistics."""
        query_lower = query.lower()
        
        # Match insight keywords
        insight_keywords = [
            "key moments", "decided", "outcome", "strategy", "momentum", 
            "critical", "turning point", "what happened", "how did", 
            "why did", "analyze", "explain", "describe the match",
            "tactical", "pattern", "trend", "shift", "flow"
        ]
        
        # Statistical keywords (strong indicators)
        stat_keywords = [
            "how many", "percentage", "total", "count", "statistics",
            "breakdown", "compare", "numbers", "figures", "aces", 
            "double faults", "winners", "errors", "first serve", "second serve"
        ]
        
        insight_score = sum(1 for keyword in insight_keywords if keyword in query_lower)
        stat_score = sum(1 for keyword in stat_keywords if keyword in query_lower)
        
        # If it's clearly asking for numbers, it's stats
        if stat_score > 0:
            return False
        
        return insight_score > 0
    
    def _embed_chunks(self, chunks: List[Dict]) -> List[Dict]:
        """
        Generate embeddings for chunks using LOCAL sentence-transformers (100% FREE).
        No API calls, runs entirely on your computer!
        """
        print("[EMBED] Generating embeddings with LOCAL model (FREE - no API calls!)...")
        
        # Extract text from chunks
        texts = [chunk["text"] for chunk in chunks]
        
        # Generate embeddings locally
        embeddings = self.embedding_model.encode(
            texts, 
            show_progress_bar=True,
            batch_size=32,
            convert_to_numpy=True
        )
        
        # Add embeddings to chunks
        for i, chunk in enumerate(chunks):
            chunk["embedding"] = embeddings[i].tolist()
        
        print(f"Successfully generated {len(chunks)} embeddings locally (384 dimensions)")
        
        return chunks
    
    def _create_vector_index(self) -> None:
        """
        Create FAISS index and store metadata.
        """
        if not self.chunks:
            raise ValueError("No chunks available. Call load_exact_full_format() first.")
        
        # Get embedding dimension
        dim = len(self.chunks[0]["embedding"])
        
        # Create FAISS index
        self.index = faiss.IndexFlatL2(dim)
        
        # Convert embeddings to numpy
        vectors = np.array([c["embedding"] for c in self.chunks]).astype('float32')
        self.index.add(vectors)
        
        # Keep a parallel list of metadata for retrieval
        self.metadata_store = [c["metadata"] for c in self.chunks]
        
        print(f"Created FAISS index with {len(self.chunks)} vectors of dimension {dim}")
    
    def save_embeddings_to_disk(self, filename_prefix: str = "tennis_embeddings") -> None:
        """
        Save embeddings, FAISS index, and metadata to disk for persistence.
        """
        if not self.chunks or not self.index:
            raise ValueError("No embeddings available. Call load_exact_full_format() first.")
        
        # Save FAISS index
        faiss_filename = f"{filename_prefix}_faiss.pkl"
        with open(faiss_filename, 'wb') as f:
            pickle.dump(self.index, f)
        
        # Save metadata store (including match score, set/game winners, and point-by-point data)
        metadata_filename = f"{filename_prefix}_metadata.pkl"
        metadata_bundle = {
            'metadata_store': self.metadata_store,
            'match_score': getattr(self, 'match_score', None),
            'set_mapping': getattr(self, 'set_mapping', {}),
            'total_sets': getattr(self, 'total_sets', 0),
            'set_winners': getattr(self, 'set_winners', {}),
            'game_winners': getattr(self, 'game_winners', {}),
            'match_winner': getattr(self, 'match_winner', None),
            'match_loser': getattr(self, 'match_loser', None),
            'point_by_point': getattr(self, 'point_by_point', [])
        }
        with open(metadata_filename, 'wb') as f:
            pickle.dump(metadata_bundle, f)
        
        # Save chunks (for debugging/inspection)
        chunks_filename = f"{filename_prefix}_chunks.pkl"
        with open(chunks_filename, 'wb') as f:
            pickle.dump(self.chunks, f)
        
        print(f"Saved embeddings to disk:")
        print(f"   FAISS index: {faiss_filename}")
        print(f"   Metadata: {metadata_filename}")
        print(f"   Chunks: {chunks_filename}")
    
    def load_embeddings_from_disk(self, filename_prefix: str = "tennis_embeddings") -> bool:
        """
        Load embeddings, FAISS index, and metadata from disk.
        Returns True if successful, False if files don't exist.
        """
        try:
            # Extract player names from filename_prefix (e.g., "Jannik_Sinner_Carlos_Alcaraz_20250608")
            parts = filename_prefix.split('_')
            if len(parts) >= 4:
                # Find the date (8 digits at the end)
                date_idx = -1
                for i in range(len(parts) - 1, -1, -1):
                    if parts[i].isdigit() and len(parts[i]) == 8:
                        date_idx = i
                        break
                
                if date_idx >= 2:
                    # Everything before the date is player names
                    # Find the split point (usually middle, but handle multi-word names)
                    player_parts = parts[:date_idx]
                    # Simple heuristic: split roughly in middle
                    mid = len(player_parts) // 2
                    self.player1 = ' '.join(player_parts[:mid])
                    self.player2 = ' '.join(player_parts[mid:])
                    print(f"[CACHE] Extracted player names: {self.player1} vs {self.player2}")
            
            # Load FAISS index
            faiss_filename = f"{filename_prefix}_faiss.pkl"
            with open(faiss_filename, 'rb') as f:
                self.index = pickle.load(f)
            
            # Load metadata store and match info
            metadata_filename = f"{filename_prefix}_metadata.pkl"
            with open(metadata_filename, 'rb') as f:
                metadata_bundle = pickle.load(f)
                
                # Handle both old format (just metadata_store) and new format (bundle)
                if isinstance(metadata_bundle, dict) and 'metadata_store' in metadata_bundle:
                    # New format with match score, set mapping, set/game winners, and point-by-point
                    self.metadata_store = metadata_bundle['metadata_store']
                    self.match_score = metadata_bundle.get('match_score', None)
                    self.set_mapping = metadata_bundle.get('set_mapping', {})
                    self.total_sets = metadata_bundle.get('total_sets', 0)
                    self.set_winners = metadata_bundle.get('set_winners', {})
                    self.game_winners = metadata_bundle.get('game_winners', {})
                    self.match_winner = metadata_bundle.get('match_winner', None)
                    self.match_loser = metadata_bundle.get('match_loser', None)
                    self.point_by_point = metadata_bundle.get('point_by_point', [])
                    if self.match_score:
                        print(f"[CACHE] Loaded match score: {self.match_score}")
                    if self.set_mapping:
                        print(f"[CACHE] Loaded set mapping with {len(self.set_mapping)} entries")
                    if self.set_winners:
                        print(f"[CACHE] Loaded set winners: {self.set_winners}")
                    if self.game_winners:
                        print(f"[CACHE] Loaded {len(self.game_winners)} game winners")
                    if self.point_by_point:
                        print(f"[CACHE] Loaded {len(self.point_by_point)} points for analysis")
                        # Enrich point data if it wasn't enriched before (old cache format)
                        # Check if first point has enrichment data
                        if self.point_by_point and 'context' not in self.point_by_point[0]:
                            print(f"[CACHE] Enriching loaded points (old format)...")
                            self._enrich_point_data()
                else:
                    # Old format - just metadata_store
                    self.metadata_store = metadata_bundle
                    self.match_score = None
                    self.set_mapping = {}
                    self.total_sets = 0
                    self.set_winners = {}
                    self.game_winners = {}
                    self.match_winner = None
                    self.match_loser = None
                    self.point_by_point = []
            
            # Load chunks (optional, for debugging)
            chunks_filename = f"{filename_prefix}_chunks.pkl"
            if os.path.exists(chunks_filename):
                with open(chunks_filename, 'rb') as f:
                    self.chunks = pickle.load(f)
            else:
                # Reconstruct chunks from metadata if needed
                self.chunks = [{"metadata": meta} for meta in self.metadata_store]
            
            print(f"Loaded embeddings from disk:")
            print(f"   FAISS index: {faiss_filename}")
            print(f"   Metadata: {metadata_filename}")
            print(f"   Total chunks: {len(self.metadata_store)}")
            
            return True
            
        except FileNotFoundError:
            print(f"[ERROR] Embedding files not found. Run load_exact_full_format() first.")
            return False
        except Exception as e:
            print(f"[ERROR] Error loading embeddings: {e}")
            return False
    
    def _detect_player_mentioned(self, query: str) -> str:
        """
        Detect which player is mentioned in the query.
        Returns the player name, "both" if asking about both players, or None if no specific player is mentioned.
        """
        if not self.player1 or not self.player2:
            return None
            
        query_lower = query.lower()
        player1_lower = self.player1.lower()
        player2_lower = self.player2.lower()
        
        # Check for "both players" indicators FIRST (use class constant)
        if any(indicator in query_lower for indicator in self.BOTH_PLAYER_INDICATORS):
            return 'both'
        
        # Check for player1 (first player)
        if any(word in query_lower for word in player1_lower.split()):
            return self.player1
        
        # Check for player2 (second player)  
        if any(word in query_lower for word in player2_lower.split()):
            return self.player2
        
        return None

    def _get_player_suffix(self, player_mentioned: str) -> str:
        """
        Get the player suffix (_player_1 or _player_2) based on which player is mentioned.
        """
        if not player_mentioned or not self.player1 or not self.player2:
            return "_player_1"  # Default to player 1
            
        if player_mentioned.lower() == self.player1.lower():
            return "_player_1"
        elif player_mentioned.lower() == self.player2.lower():
            return "_player_2"
        else:
            return "_player_1"  # Default fallback

    def _detect_shot_from_query(self, query: str) -> Dict[str, Any]:
        """
        METADATA-DRIVEN shot detection.
        Matches query terms against actual values from match_filter_inventory.
        No hard-coded shot types - discovers from data.
        
        Returns dict with:
        - shot_base: Shot type from inventory (e.g., 'forehand', 'backhand') or None
        - shot_modifier: Modifier from inventory (e.g., 'slice', 'volley') or None
        - shot_type: Combined description or None
        - shot_direction: Direction from inventory or None
        """
        query_lower = query.lower()
        
        # Get inventory (built from actual match data)
        inventory = getattr(self, 'match_filter_inventory', {})
        aliases = inventory.get('common_aliases', {})
        
        # === SHOT TYPE DETECTION (from inventory) ===
        shot_base = None
        known_shot_types = inventory.get('shot_types', [])
        for st in known_shot_types:
            if st:
                st_lower = st.lower()
                # Match exact word boundaries to avoid false positives
                if st_lower in query_lower:
                    shot_base = st
                    break
        # Check aliases (fh -> forehand, bh -> backhand)
        for alias, canonical in aliases.get('shots', {}).items():
            # Match alias as word boundary
            if f" {alias} " in f" {query_lower} " or query_lower.startswith(f"{alias} ") or query_lower.endswith(f" {alias}"):
                shot_base = canonical
                break
        
        # === SHOT MODIFIER DETECTION (from inventory) ===
        shot_modifier = None
        known_modifiers = inventory.get('shot_modifiers', [])
        for mod in known_modifiers:
            if mod:
                mod_lower = mod.lower()
                mod_spaced = mod_lower.replace('_', ' ')
                if mod_lower in query_lower or mod_spaced in query_lower:
                    shot_modifier = mod
                    break
        
        # === DIRECTION DETECTION (from inventory) ===
        shot_direction = None
        known_directions = inventory.get('directions', [])
        for dir_val in known_directions:
            if dir_val:
                # Handle both underscore and space versions
                dir_lower = dir_val.lower()
                dir_spaced = dir_lower.replace('_', ' ')
                if dir_lower in query_lower or dir_spaced in query_lower:
                    shot_direction = dir_val
                    break
        # Check direction aliases (cc -> crosscourt, dtl -> down_the_line)
        for alias, canonical in aliases.get('directions', {}).items():
            if f" {alias} " in f" {query_lower} " or query_lower.startswith(f"{alias} ") or query_lower.endswith(f" {alias}"):
                shot_direction = canonical
                break
        
        # Combine into shot_type for display
        if shot_base and shot_modifier:
            shot_type = f"{shot_base} {shot_modifier}"
        elif shot_base:
            shot_type = shot_base
        elif shot_modifier:
            shot_type = shot_modifier
        else:
            shot_type = None
        
        return {
            'shot_base': shot_base,
            'shot_modifier': shot_modifier,
            'shot_type': shot_type,
            'shot_direction': shot_direction
        }

    def _detect_from_inventory(self, query_lower: str, inventory_key: str, fallback_values: list = None) -> str:
        """
        METADATA-DRIVEN value detection.
        
        Matches query terms against values from match_filter_inventory.
        Falls back to provided values if inventory doesn't have the key.
        
        Args:
            query_lower: Lowercased query string
            inventory_key: Key in match_filter_inventory to look up
            fallback_values: Default values if inventory key doesn't exist
            
        Returns:
            Matched value from inventory, or None if no match
        """
        inventory = getattr(self, 'match_filter_inventory', {})
        known_values = inventory.get(inventory_key, fallback_values or [])
        
        for val in known_values:
            if val:
                val_lower = val.lower()
                val_spaced = val_lower.replace('_', ' ')
                if val_lower in query_lower or val_spaced in query_lower:
                    return val
        return None

    def _determine_optimal_chunk_count(self, query: str) -> int:
        """
        Determine optimal number of chunks based on question complexity.
        Returns the number of chunks needed for comprehensive analysis.
        
        4-tier system:
        - Ultra-high (18): Multi-factor analysis needing ALL point-by-point data
        - High (15): Complex tactical/pattern questions
        - Detailed (8): Specific context questions
        - Simple (5): Direct factual questions
        """
        query_lower = query.lower()
        
        # Ultra-high complexity (need ALL point-by-point chunks - ~18-19 total)
        # These are RARE, genuinely complex multi-factor questions
        ultra_high_indicators = [
            # Multi-factor match analysis
            "match flow", "match progression", "match dynamics",
            "how the match unfolded", "match evolution",
            "throughout the match", "over time", "entire match",
            # Complex shot sequences and patterns
            "shot sequences", "shot sequence", "rally patterns",
            "when hit a", "when they hit", "when he hit", "when she hit",
            "response to", "respond to", "responded to", "in response",
            # Adaptation and change detection (need before/after comparison)
            "adapt", "adapted", "adaptation",
            "adjust", "adjusted", "adjustment",
            "changed over",
            "counter", "countered", "neutralize", "neutralized",
            # Behavioral transitions
            "switched to", "started hitting more", "began favoring",
            "moved away from", "increased reliance on",
            "started doing", "stopped doing",
            "changed shot direction",
            # Sequential momentum analysis (specific patterns, not common words)
            "consecutive", "streak", "run of", "string of",
            "stretch", "hot streak", "get hot", "got hot", "went on a run",
            "x/y points", "x of y points", "12/14", "10/12",  # Pattern like "12/14 points"
            # Rally length and patterns
            "long rallies", "short rallies", "rally length",
            "extended rallies", "quick points",
            "8+ shot", "5+ shot", "rallies longer", "rallies shorter",
            # Physical and performance variance
            "fatigue", "tired", "wore down",
            "variance", "highs and lows",
            "defensive to offensive", "pushed back", "stepped in",
            # Counterfactual analysis
            "what if", "if he had", "if she had",
            "could have", "should have", "would have", "prevented"
        ]
        
        # High complexity (need most point-by-point data)
        high_complexity_indicators = [
            # Match narrative and strategy
            "match pattern", "match analysis", "match strategy",
            "what was the pattern", "analyze the match",
            "turning point", "momentum", "match narrative", "match story",
            "match breakdown", "match summary", "match overview", "match recap",
            "progression", "progressed", "developed",
            "early vs late", "first set vs", "as the match", "match went on",
            # Evolution and shifts (moved from ultra_high - common but still complex)
            "evolve", "evolved", "evolution",
            "momentum shift", "momentum swing",
            "shift", "shifted",
            # Situational and conditional
            "after losing", "after winning", "after missing", "after break",
            "after", "following", "then", "led to", "triggered",
            "when rallies got", "as rallies got",
            "on important points", "on key points", "in crucial moments", "in tight moments",
            "when facing break", "when trailing", "when ahead",
            # Shot responses and effectiveness
            "most common response", "typical response", "usual response",
            "how did", "what did", "how would", "what would",
            "drop shot", "most effective", "least effective", "best response", "worst response",
            # Tactical patterns
            "serve placement", "shot selection", "shot placement",
            "approach shot", "net approach", "serve and volley", "chip and charge",
            "rally control", "dictate", "dictating", "control the point",
            "tactical", "tactics", "strategy", "strategic", "game plan",
            # Psychology and momentum
            "clutch", "pressure", "under pressure", "mental", "mentality",
            "champion", "fighting spirit", "resilience", "comeback",
            "statement", "deflate", "demoralize", "confidence",
            # Sequential patterns
            "next", "subsequent", "immediately after",
            "in response to", "as a result",
            # Comparative time periods
            "first half", "second half", "early", "late", "beginning", "end",
            "set 1 vs", "set 2 vs", "first two sets", "last three sets",
            "tiebreak vs", "regular games", "important games vs",
            # Pattern and tendency
            "pattern", "patterns", "tendency", "tendencies", "prefer", "preferred",
            "favor", "favored", "typically", "usually", "commonly", "often",
            "most of the time", "majority", "predominant", "characteristic",
            # Context-specific situations
            "set point", "game point", "match point",
            "deuce", "advantage", "30-30", "40-40",
            "must hold", "must break",
            "tiebreak", "tie-break", "deciding", "crucial game",
            # Outcome and effectiveness
            "effectiveness", "effective", "ineffective",
            "worked", "didn't work", "successful", "unsuccessful",
            "paid off", "backfired",
            # Quality and level
            "quality", "level", "standard", "performance level",
            "raised their game", "elevated", "dropped off", "declined",
            "peak", "best", "worst", "high point", "low point"
        ]
        
        # Specific but detailed questions
        detailed_indicators = [
            "break points", "game points", "key points", "pressure points",
            "shot direction", "shot types", "serve types", "return types",
            "net play", "baseline play", "point construction",
            "serve performance", "return performance", "overall performance"
        ]
        
        # Check complexity in order (most specific first)
        if any(indicator in query_lower for indicator in ultra_high_indicators):
            return 18  # Get ALL point-by-point chunks
        
        if any(indicator in query_lower for indicator in high_complexity_indicators):
            return 15  # Most point-by-point chunks
        
        if any(indicator in query_lower for indicator in detailed_indicators):
            return 8  # More context for detailed analysis
        
        # Simple specific questions
        return 5  # Default for simple questions

    def retrieve_relevant_chunks(self, query: str, top_k: int = None, filters: Dict = None) -> List[Dict]:
        """
        Retrieve the most relevant chunks for a given query with enhanced filtering.
        Uses adaptive chunk count based on question complexity.
        
        Args:
            query: The query string
            top_k: Number of chunks to retrieve
            filters: Optional filters dict (e.g., {'set': 3, 'situation': 'break_point'})
        """
        # Determine optimal chunk count based on question complexity
        if top_k is None:
            top_k = self._determine_optimal_chunk_count(query)
        
        # Extract set filter if provided
        set_filter = filters.get('set') if filters else None
        
        # BOOST chunk count for multi-set comparisons (need data from multiple sets)
        multiple_sets = self._detect_multiple_set_references(query)
        if multiple_sets and len(multiple_sets) >= 2:
            original_top_k = top_k
            top_k = 20  # Ensure we get enough chunks from all requested sets
        
        
        if not self.index:
            raise ValueError("Vector index not created. Call load_exact_full_format() first.")
        
        # Generate query embedding with LOCAL model (100% FREE!)
        query_embedding = self.embedding_model.encode([query])[0].tolist()
        
        # Search for similar chunks (get more than needed for filtering)
        search_k = min(top_k * 3, len(self.chunks))  # Get 3x more for filtering
        query_vector = np.array([query_embedding]).astype('float32')
        distances, indices = self.index.search(query_vector, search_k)
        
        # Collect candidates with metadata
        candidates = []
        for i in indices[0]:
            if i < len(self.chunks):
                chunk_info = {
                    "text": self.chunks[i]["text"],
                    "metadata": self.chunks[i]["metadata"],
                    "distance": float(distances[0][list(indices[0]).index(i)])
                }
                candidates.append(chunk_info)
        
        # Apply intelligent filtering based on query content
        filtered_chunks = self._filter_chunks_by_query(query, candidates)
        
        # CRITICAL FIX: De-prioritize match-wide summary chunks when filters are active
        # When asking "forehand winners in Set 3", we don't want the match-total SHOTS1 table
        # We want Set 3-specific point descriptions or at least acknowledge the limitation
        if filters:
            # Identify match-wide summary sections that should be de-prioritized
            summary_sections = [
                'overview_statistics',
                'shots1_statistics',
                'shots2_statistics', 
                # Note: SHOTDIR is okay because it has detailed breakdowns
                # Note: serve/return stats are okay because they're detailed
            ]
            
            # Separate summary chunks from specific chunks
            summary_chunks = []
            specific_chunks = []
            
            for chunk in filtered_chunks:
                section = chunk.get('metadata', {}).get('section', '').lower()
                if any(summary in section for summary in summary_sections):
                    summary_chunks.append(chunk)
                else:
                    specific_chunks.append(chunk)
            
            # If we have filters, prioritize specific chunks and add summaries at the end with warning
            if specific_chunks:
                # Add summaries at the end with reduced priority
                for summary_chunk in summary_chunks[:2]:  # Only keep 2 summary chunks max
                    # Add warning to metadata
                    if 'metadata' not in summary_chunk:
                        summary_chunk['metadata'] = {}
                    summary_chunk['metadata']['warning'] = 'Match-wide totals (not filtered to specific set/situation)'
                
                filtered_chunks = specific_chunks + summary_chunks[:2]
                print(f"[CHUNK-FILTER] De-prioritized {len(summary_chunks)} match-wide summary chunks due to filters: {filters}")
            else:
                # No specific chunks found, keep summaries but warn
                for summary_chunk in summary_chunks:
                    if 'metadata' not in summary_chunk:
                        summary_chunk['metadata'] = {}
                    summary_chunk['metadata']['warning'] = f"Match-wide totals only (no {filters}-specific breakdown available)"
                print(f"[CHUNK-FILTER] WARNING: Only match-wide summaries found for filtered query: {filters}")
        
        # CRITICAL FIX: For specific point number questions, force include the chunk containing that point
        import re
        point_match = re.search(r'point\s+(\d+)', query.lower())
        if point_match:
            requested_point = int(point_match.group(1))
            # Find the chunk containing this point
            point_chunk = None
            for chunk in self.chunks:
                if 'point-by-point' in chunk['metadata'].get('section', '').lower():
                    chunk_text = chunk['text']
                    if f"Point {requested_point}" in chunk_text or f"Point {requested_point} [" in chunk_text:
                        point_chunk = {
                            "text": chunk['text'],
                            "metadata": chunk['metadata'],
                            "distance": 0.0,  # Perfect match
                            "relevance_score": 10.0  # Maximum score for specific point questions
                        }
                        break
            
            # Force include the point chunk at the top
            if point_chunk:
                # Remove any existing point-by-point chunks and add this one
                filtered_chunks = [c for c in filtered_chunks if 'point-by-point' not in c['metadata'].get('section', '').lower()]
                filtered_chunks.insert(0, point_chunk)
        
        # Initialize fix flags FIRST (must be before any code path that uses them!)
        direction_outcome_fix_applied = False
        bp_gp_fix_applied = False
        universal_fix_applied = False
        net_points_fix_applied = False

        
        # MATCH OVERVIEW PRIORITY: For score/winner questions, always include match_overview
        query_lower = query.lower()
        if any(word in query_lower for word in ["score", "won", "winner", "result", "defeated", "beat", "lost", "final"]):
            match_overview_chunk = None
            for chunk in self.chunks:
                if 'match_overview' in chunk['metadata']['section']:
                    match_overview_chunk = {
                        "text": chunk['text'],
                        "metadata": chunk['metadata'],
                        "distance": 0.0,
                        "relevance_score": 10.0
                    }
                    break
            if match_overview_chunk:
                filtered_chunks = [chunk for chunk in filtered_chunks if 'match_overview' not in chunk['metadata']['section']]
                filtered_chunks.insert(0, match_overview_chunk)
        
        # OVERVIEW PRIORITY: For basic statistical questions, prioritize overview_statistics
        if not self._is_match_insight_question(query) and any(word in query.lower() for word in [
            # Winners
            "winner", "winners", "winner forehand", "winner backhand",
            # Errors
            "unforced error", "unforced errors", "unforced error forehand", "unforced error backhand",
            "forced error", "forced errors",
            # Serve statistics
            "ace", "aces", "ace percent", "ace percentage",
            "double fault", "double faults", "double fault percent", "double fault percentage",
            "first serve", "first serve in", "first serve won", "first serve percentage",
            "second serve", "second serve won", "second serve percentage",
            # Break points
            "break point", "break points", "break points saved", "break points converted",
            # Return points
            "return points", "return points won", "rpw", "rpw%",
            # General
            "total", "how many", "percentage", "percent"
        ]):
            # Find overview_statistics chunk
            overview_chunk = None
            for chunk in self.chunks:
                if 'overview_statistics' in chunk['metadata']['section']:
                    overview_chunk = {
                        "text": chunk['text'],
                        "metadata": chunk['metadata'],
                        "distance": 0.0,
                        "relevance_score": 10.0
                    }
                    break
            
            # Force overview to be the first chunk for basic stats questions
            if overview_chunk:
                # Remove any existing overview chunk
                filtered_chunks = [chunk for chunk in filtered_chunks if 'overview_statistics' not in chunk['metadata']['section']]
                # Add overview at the very top
                filtered_chunks.insert(0, overview_chunk)
        
        # CRITICAL FIX: Always include overview_statistics for statistical questions
        if not self._is_match_insight_question(query):
            # Find overview_statistics chunk
            overview_chunk = None
            for chunk in self.chunks:
                if 'overview_statistics' in chunk['metadata']['section']:
                    overview_chunk = {
                        "text": chunk['text'],
                        "metadata": chunk['metadata'],
                        "distance": 0.0,  # Perfect match
                        "relevance_score": 10.0  # Maximum score
                    }
                    break
            
            # If overview chunk exists and not already in results, add it at the top
            if overview_chunk and not any('overview_statistics' in chunk['metadata']['section'] for chunk in filtered_chunks):
                filtered_chunks.insert(0, overview_chunk)
            
            # DIRECTION + OUTCOME FIX: For questions about shots by direction AND outcome, force include all shot types for that direction/outcome combo
            direction_keywords = {
                "crosscourt": ["crosscourt", "cross court"],
                "down the line": ["down the line", "downline", "dtl"],
                "down the middle": ["down the middle", "middle", "center"],
                "inside-out": ["inside-out", "inside out"],
                "inside-in": ["inside-in", "inside in"]
            }
            
            outcome_keywords = {
                "winner": ["winner", "winners"],
                "forced error": ["forced error", "forced errors", "induced"],
                "unforced error": ["unforced error", "unforced errors"],
                "pt ending": ["pt ending", "point ending", "ended", "end points"],
                "pts won": ["pts won", "points won", "ptswon", "successful", "success", "win rate", "win percentage", "win %", "win%", "best", "most effective", "effective"],
                "pts lost": ["pts lost", "points lost", "ptslost"]
            }
            
            detected_direction = None
            detected_outcome = None
            
            # Check for direction + outcome combinations
            for direction, dir_keywords in direction_keywords.items():
                if any(keyword in query.lower() for keyword in dir_keywords):
                    detected_direction = direction
                    break
            
            for outcome, outcome_keywords_list in outcome_keywords.items():
                if any(keyword in query.lower() for keyword in outcome_keywords_list):
                    detected_outcome = outcome
            
            
            if detected_direction and detected_outcome:
                # Determine which player is being asked about
                player_mentioned = None
                if self.player1 and (self.player1.lower() in query.lower() or any(word.lower() in query.lower() for word in self.player1.lower().split())):
                    player_mentioned = self.player1
                    target_chunk_name = "shotdir1_statistics"
                elif self.player2 and (self.player2.lower() in query.lower() or any(word.lower() in query.lower() for word in self.player2.lower().split())):
                    player_mentioned = self.player2
                    target_chunk_name = "shotdir2_statistics"
                else:
                    # If no specific player mentioned, include both (for "each player" questions)
                    player_mentioned = "both"
                    target_chunk_name = None
                
                if player_mentioned == "both":
                    # Force include ALL parts of both players' shot direction chunks
                    # CRITICAL: Get ALL chunk parts to include win percentages from DETAILED BREAKDOWN
                    chunks1_found = []
                    chunks2_found = []
                    explicit_totals_found = None
                    
                    for chunk in self.chunks:
                        if "shotdir1_statistics" in chunk['metadata']['section']:
                            chunks1_found.append({
                                "text": chunk['text'],
                                "metadata": chunk['metadata'],
                                "distance": 0.0,
                                "relevance_score": 9.5
                            })
                        elif "shotdir2_statistics" in chunk['metadata']['section']:
                            chunks2_found.append({
                                "text": chunk['text'],
                                "metadata": chunk['metadata'],
                                "distance": 0.0,
                                "relevance_score": 9.5
                            })
                        elif "explicit_totals_for_shot_direction_+_outcome_combinations" in chunk['metadata']['section']:
                            explicit_totals_found = {
                                "text": chunk['text'],
                                "metadata": chunk['metadata'],
                                "distance": 0.0,
                                "relevance_score": 10.0
                            }
                    
                    # Add explicit totals chunk first (highest priority)
                    if explicit_totals_found:
                        filtered_chunks = [chunk for chunk in filtered_chunks if "explicit_totals_for_shot_direction_+_outcome_combinations" not in chunk['metadata']['section']]
                        filtered_chunks.insert(0, explicit_totals_found)
                    
                    # Add ALL matching chunks (all parts) to get win percentages
                    for chunk_found in chunks1_found + chunks2_found:
                        chunk_section = chunk_found['metadata']['section']
                        if not any(chunk_section == c['metadata']['section'] for c in filtered_chunks):
                            filtered_chunks.insert(0, chunk_found)
                else:
                    # Force include ALL parts of specific player's shot direction chunk and explicit totals
                    # CRITICAL: Get ALL chunk parts to include win percentages from DETAILED BREAKDOWN
                    target_chunks = []
                    explicit_totals_found = None
                    
                    for chunk in self.chunks:
                        chunk_section = chunk.get('metadata', {}).get('section', '')
                        if target_chunk_name in chunk_section:
                            target_chunks.append({
                                "text": chunk.get('text', ''),
                                "metadata": chunk.get('metadata', {}),
                                "distance": 0.0,
                                "relevance_score": 9.5
                            })
                        elif "explicit_totals_for_shot_direction_+_outcome_combinations" in chunk_section:
                            explicit_totals_found = {
                                "text": chunk.get('text', ''),
                                "metadata": chunk.get('metadata', {}),
                                "distance": 0.0,
                                "relevance_score": 10.0
                            }
                    
                    # Add explicit totals chunk first (highest priority)
                    if explicit_totals_found:
                        filtered_chunks = [chunk for chunk in filtered_chunks if "explicit_totals_for_shot_direction_+_outcome_combinations" not in chunk['metadata']['section']]
                        filtered_chunks.insert(0, explicit_totals_found)
                    
                    # Add ALL matching chunks (all parts) to get win percentages
                    for target_chunk in target_chunks:
                        chunk_section = target_chunk['metadata']['section']
                        if not any(chunk_section == c['metadata']['section'] for c in filtered_chunks):
                            filtered_chunks.insert(0, target_chunk)
                
                direction_outcome_fix_applied = True
            
            # DIRECTION-ONLY FIX: If direction keywords mentioned but no explicit outcome,
            # still include SHOTDIR chunks for pattern comparison questions (e.g., "most successful forehand pattern")
            if detected_direction and not detected_outcome:
                # Check if this is a comparison/pattern question about shot directions
                pattern_comparison_keywords = ["pattern", "patterns", "compare", "comparison", "which", "best", "most", "successful", "effective", "win"]
                is_pattern_question = any(kw in query.lower() for kw in pattern_comparison_keywords)
                
                if is_pattern_question:
                    # Determine which player
                    player_mentioned = None
                    if self.player1 and (self.player1.lower() in query.lower() or any(word.lower() in query.lower() for word in self.player1.lower().split())):
                        player_mentioned = self.player1
                        target_chunk_name = "shotdir1_statistics"
                    elif self.player2 and (self.player2.lower() in query.lower() or any(word.lower() in query.lower() for word in self.player2.lower().split())):
                        player_mentioned = self.player2
                        target_chunk_name = "shotdir2_statistics"
                    else:
                        player_mentioned = "both"
                        target_chunk_name = None
                    
                    if player_mentioned == "both":
                        # Include ALL parts of both players' SHOTDIR chunks (they may be split!)
                        shotdir1_chunks = []
                        shotdir2_chunks = []
                        for chunk in self.chunks:
                            if "shotdir1_statistics" in chunk['metadata']['section']:
                                shotdir1_chunks.append({"text": chunk['text'], "metadata": chunk['metadata'], "distance": 0.0, "relevance_score": 9.5})
                            elif "shotdir2_statistics" in chunk['metadata']['section']:
                                shotdir2_chunks.append({"text": chunk['text'], "metadata": chunk['metadata'], "distance": 0.0, "relevance_score": 9.5})
                        
                        # Add all SHOTDIR chunks (all parts) to get complete data including win percentages
                        for shotdir_chunk in shotdir1_chunks + shotdir2_chunks:
                            chunk_section = shotdir_chunk['metadata']['section']
                            if not any(chunk_section == c['metadata']['section'] for c in filtered_chunks):
                                filtered_chunks.insert(0, shotdir_chunk)
                    else:
                        # Include ALL parts of specific player's SHOTDIR chunk (it may be split!)
                        # CRITICAL: Don't break after first match - get ALL parts to include win percentages
                        shotdir_chunks_found = []
                        for chunk in self.chunks:
                            if target_chunk_name in chunk['metadata']['section']:
                                shotdir_chunks_found.append({"text": chunk['text'], "metadata": chunk['metadata'], "distance": 0.0, "relevance_score": 9.5})
                        
                        # Add all SHOTDIR chunks (all parts) to get complete data including win percentages
                        for shotdir_chunk in shotdir_chunks_found:
                            chunk_section = shotdir_chunk['metadata']['section']
                            if not any(chunk_section == c['metadata']['section'] for c in filtered_chunks):
                                filtered_chunks.insert(0, shotdir_chunk)
                
                direction_outcome_fix_applied = True
            
            # BP/GP ROUTING FIX: For break point and game point questions, route to correct data sources
            if any(phrase in query.lower() for phrase in ["break point", "bp", "game point", "gp", "deuce"]) and "net points" not in query.lower():
                # Determine which player is being asked about
                player_mentioned = self._detect_player_mentioned(query)
                
                if player_mentioned:
                    # Route the question to get the correct section
                    target_section = self._route_bp_gp_question(query, player_mentioned)
                    
                    if target_section != "unknown" and target_section != "both":
                        # First, check if overview statistics has the data we need
                        overview_chunk = None
                        for chunk in self.chunks:
                            if 'overview_statistics' in chunk['metadata']['section']:
                                overview_chunk = {
                                    "text": chunk['text'],
                                    "metadata": chunk['metadata'],
                                    "distance": 0.0,  # Perfect match
                                    "relevance_score": 10.0  # Highest score for overview data
                                }
                                break
                        
                        # Add overview chunk if it has BP/GP data and not already in results
                        if overview_chunk and not any('overview_statistics' in chunk['metadata']['section'] for chunk in filtered_chunks):
                            filtered_chunks.insert(0, overview_chunk)
                            bp_gp_fix_applied = True
                        
                        # Also add the specific section chunk as backup
                        target_chunk = None
                        
                        # For break point, game point, and deuce questions, prioritize key points statistics
                        if "break point" in query.lower() or "bp" in query.lower() or "game point" in query.lower() or "gp" in query.lower() or "deuce" in query.lower():
                            # Look for key points statistics first
                            # Determine which key points section to look for based on question type
                            if "break point" in query.lower() or "bp" in query.lower():
                                # For break points, use returns data for conversions, serves data for faced/saved
                                if "convert" in query.lower() or "win" in query.lower() or "won" in query.lower():
                                    # Look for returning key points statistics
                                    for chunk in self.chunks:
                                        # Get player suffix dynamically
                                        player_suffix = self._get_player_suffix(player_mentioned)
                                        if 'key_points_statistics_returns' in chunk['metadata']['section'] and player_suffix in chunk['metadata']['section']:
                                            target_chunk = {
                                                "text": chunk['text'],
                                                "metadata": chunk['metadata'],
                                                "distance": 0.0,  # Perfect match
                                                "relevance_score": 9.5  # Higher score for key points data
                                            }
                                            break
                                else:
                                    # For other break point questions, look for serving key points statistics
                                    for chunk in self.chunks:
                                        # Get player suffix dynamically
                                        player_suffix = self._get_player_suffix(player_mentioned)
                                        if 'key_points_statistics_serves' in chunk['metadata']['section'] and player_suffix in chunk['metadata']['section']:
                                            target_chunk = {
                                                "text": chunk['text'],
                                                "metadata": chunk['metadata'],
                                                "distance": 0.0,  # Perfect match
                                                "relevance_score": 9.5  # Higher score for key points data
                                            }
                                            break
                            elif "game point" in query.lower() or "gp" in query.lower():
                                # For game points, use returns data for faced, serves data for won
                                if "face" in query.lower():
                                    # Look for returning key points statistics
                                    for chunk in self.chunks:
                                        # Get player suffix dynamically
                                        player_suffix = self._get_player_suffix(player_mentioned)
                                        if 'key_points_statistics_returns' in chunk['metadata']['section'] and player_suffix in chunk['metadata']['section']:
                                            target_chunk = {
                                                "text": chunk['text'],
                                                "metadata": chunk['metadata'],
                                                "distance": 0.0,  # Perfect match
                                                "relevance_score": 9.5  # Higher score for key points data
                                            }
                                            break
                                else:
                                    # For other game point questions, look for serving key points statistics
                                    for chunk in self.chunks:
                                        # Get player suffix dynamically
                                        player_suffix = self._get_player_suffix(player_mentioned)
                                        if 'key_points_statistics_serves' in chunk['metadata']['section'] and player_suffix in chunk['metadata']['section']:
                                            target_chunk = {
                                                "text": chunk['text'],
                                                "metadata": chunk['metadata'],
                                                "distance": 0.0,  # Perfect match
                                                "relevance_score": 9.5  # Higher score for key points data
                                            }
                                            break
                            elif "deuce" in query.lower():
                                # For deuce points, use returns data for return deuce, serves data for serve deuce
                                if "return" in query.lower():
                                    # Look for returning key points statistics
                                    for chunk in self.chunks:
                                        # Get player suffix dynamically
                                        player_suffix = self._get_player_suffix(player_mentioned)
                                        if 'key_points_statistics_returns' in chunk['metadata']['section'] and player_suffix in chunk['metadata']['section']:
                                            target_chunk = {
                                                "text": chunk['text'],
                                                "metadata": chunk['metadata'],
                                                "distance": 0.0,  # Perfect match
                                                "relevance_score": 9.5  # Higher score for key points data
                                            }
                                            break
                                else:
                                    # For other deuce questions, look for serving key points statistics
                                    for chunk in self.chunks:
                                        # Get player suffix dynamically
                                        player_suffix = self._get_player_suffix(player_mentioned)
                                        if 'key_points_statistics_serves' in chunk['metadata']['section'] and player_suffix in chunk['metadata']['section']:
                                            target_chunk = {
                                                "text": chunk['text'],
                                                "metadata": chunk['metadata'],
                                                "distance": 0.0,  # Perfect match
                                                "relevance_score": 9.5  # Higher score for key points data
                                            }
                                            break
                        
                        # If no key points chunk found, fall back to regular statistics
                        # CRITICAL: Get ALL parts of split sections (return_statistics is 'large' = split)
                        if not target_chunk:
                            target_chunks_list = []
                            for chunk in self.chunks:
                                # Handle split return statistics chunks (e.g., return2_statistics_detailed_part_1)
                                if target_section in chunk['metadata']['section'] or (target_section.replace('_statistics', '') in chunk['metadata']['section'] and 'return' in chunk['metadata']['section']):
                                    target_chunks_list.append({
                                        "text": chunk['text'],
                                        "metadata": chunk['metadata'],
                                        "distance": 0.0,
                                        "relevance_score": 9.0
                                    })
                            # Use the first chunk as target_chunk for backwards compatibility
                            if target_chunks_list:
                                target_chunk = target_chunks_list[0]
                                # Add ALL parts to filtered_chunks
                                for tc in target_chunks_list[1:]:
                                    chunk_section = tc['metadata']['section']
                                    if not any(chunk_section == c['metadata']['section'] for c in filtered_chunks):
                                        filtered_chunks.insert(0, tc)
                        
                        # Add the chunk if not already in results
                        if target_chunk:
                            # For key points chunks, use the actual chunk section name
                            if 'key_points_statistics' in target_chunk['metadata']['section']:
                                key_points_section = target_chunk['metadata']['section']
                                # Remove any existing instance first
                                filtered_chunks = [chunk for chunk in filtered_chunks if key_points_section not in chunk['metadata']['section']]
                                
                                # Set maximum priority and force to top
                                target_chunk['relevance_score'] = 10.0
                                filtered_chunks.insert(0, target_chunk)
                                bp_gp_fix_applied = True
                            else:
                                # For regular statistics chunks, use target_section
                                if not any(target_section in chunk['metadata']['section'] for chunk in filtered_chunks):
                                    filtered_chunks.insert(0, target_chunk)
                                    bp_gp_fix_applied = True
                    
                    elif target_section == "both":
                        # Need both serve and return sections for BP/GP/deuce totals or ambiguous questions
                        serve_section = "serve1_statistics_summary" if (self.player1 and (self.player1.lower() in query.lower() or any(word.lower() in query.lower() for word in self.player1.lower().split()))) else "serve2_statistics_summary"
                        return_section = "return1_statistics_detailed" if (self.player1 and (self.player1.lower() in query.lower() or any(word.lower() in query.lower() for word in self.player1.lower().split()))) else "return2_statistics_detailed"
                        
                        # Add ALL parts of both sections (return_statistics is 'large' = split)
                        for section in [serve_section, return_section]:
                            section_chunks = []
                            for chunk in self.chunks:
                                if section in chunk['metadata']['section']:
                                    section_chunks.append({
                                        "text": chunk['text'],
                                        "metadata": chunk['metadata'],
                                        "distance": 0.0,
                                        "relevance_score": 9.0
                                    })
                            
                            # Add ALL matching chunks (all parts)
                            for sc in section_chunks:
                                chunk_section = sc['metadata']['section']
                                if not any(chunk_section == c['metadata']['section'] for c in filtered_chunks):
                                    filtered_chunks.insert(0, sc)
                                bp_gp_fix_applied = True
            
            # DIRECTION TOTALS FIX: For questions asking about shot direction totals (e.g., "how many crosscourt shots")
            if any(direction in query.lower() for direction in ["crosscourt", "down the line", "down the middle", "inside-out", "inside-in"]) and not any(outcome in query.lower() for outcome in ["winner", "winners", "unforced error", "unforced errors", "forced error", "forced errors", "error", "errors"]):
                # Force include ALL parts of both shotdir chunks (may be split in old pickles)
                shotdir1_chunks = []
                shotdir2_chunks = []
                
                # Find ALL shotdir1_statistics chunks (all parts)
                for chunk in self.chunks:
                    if 'shotdir1_statistics' in chunk['metadata']['section']:
                        shotdir1_chunks.append({
                            "text": chunk['text'],
                            "metadata": chunk['metadata'],
                            "distance": 0.0,
                            "relevance_score": 8.0
                        })
                    elif 'shotdir2_statistics' in chunk['metadata']['section']:
                        shotdir2_chunks.append({
                            "text": chunk['text'],
                            "metadata": chunk['metadata'],
                            "distance": 0.0,
                            "relevance_score": 8.0
                        })
                
                # Add ALL shotdir chunks if not already in results
                for sc in shotdir1_chunks + shotdir2_chunks:
                    chunk_section = sc['metadata']['section']
                    if not any(chunk_section == c['metadata']['section'] for c in filtered_chunks):
                        filtered_chunks.insert(0, sc)
            
            # UNIVERSAL FIX: For "each player" or "both players" questions, force include both players' chunks
            detected_stat_type = None  # Initialize outside the if block
            
            if any(phrase in query.lower() for phrase in ["each player", "both players", "both player"]):
                # Define all the split player statistics sections
                split_sections = {
                    "serve": ["serve1_statistics_summary", "serve2_statistics_summary", "serve1_statistics_detailed", "serve2_statistics_detailed"],
                    "shots": ["shots1_statistics", "shots2_statistics"],
                    "shotdir": ["shotdir1_statistics", "shotdir2_statistics"],
                    "return": ["return1_statistics_detailed", "return2_statistics_detailed"],
                    "netpts": ["netpts1_statistics", "netpts2_statistics"],
                    "keypoints": ["key_points_statistics_serves", "key_points_statistics_returns"]
                }
                
                # Check which statistic type the question is about (in order of specificity)
                
                # Check most specific keywords first to avoid conflicts
                if any(phrase in query.lower() for phrase in ["break point", "break points", "game point", "game points"]):
                    detected_stat_type = "keypoints"
                elif any(phrase in query.lower() for phrase in ["net points", "net approaches"]):
                    detected_stat_type = "netpts"
                elif any(phrase in query.lower() for phrase in ["volley", "volleys"]):
                    detected_stat_type = "shots"  # Volley is a shot type, not just net points
                elif any(phrase in query.lower() for phrase in ["overhead", "smash", "smashes"]):
                    detected_stat_type = "shots"  # Overhead/smash is a shot type
                elif any(phrase in query.lower() for phrase in ["crosscourt", "down the line", "down the middle", "inside-out", "inside-in"]):
                    detected_stat_type = "shotdir"
                elif any(phrase in query.lower() for phrase in ["winner", "winners", "unforced error", "unforced errors", "forehand", "backhand"]):
                    # Only set to shots if we haven't already detected a more specific type
                    if not detected_stat_type:
                        detected_stat_type = "shots"
                elif any(phrase in query.lower() for phrase in ["return", "returns", "returnable"]):
                    detected_stat_type = "return"
                elif any(phrase in query.lower() for phrase in ["ace", "aces", "serve", "serving", "double fault", "double faults", "first serve", "second serve"]):
                    detected_stat_type = "serve"
                
                # Apply the fix for the detected statistic type
                if detected_stat_type and detected_stat_type in split_sections:
                    chunk_names = split_sections[detected_stat_type]
                    
                    # Find all matching chunks (handle variable-length lists)
                    found_chunks = []
                    for chunk_name in chunk_names:
                        for chunk in self.chunks:
                            if chunk_name in chunk['metadata']['section']:
                                found_chunk = {
                                    "text": chunk['text'],
                                    "metadata": chunk['metadata'],
                                    "distance": 0.0,
                                    "relevance_score": 8.0
                                }
                                found_chunks.append(found_chunk)
                                break
                    
                    # Remove existing instances and add with high priority
                    for found_chunk in found_chunks:
                        chunk_section = found_chunk['metadata']['section']
                        # Remove any existing instance
                        filtered_chunks = [chunk for chunk in filtered_chunks if chunk['metadata']['section'] != chunk_section]
                        # Set high priority and add to top
                        found_chunk['relevance_score'] = 9.0
                        filtered_chunks.insert(0, found_chunk)
                    
                    universal_fix_applied = True
                    
                    # If we added netpts chunks, set the flag to prevent FINAL NEGATIVE FILTER from removing them
                    if detected_stat_type == "netpts":
                        net_points_fix_applied = True
            
                        # CRITICAL FIX: For ace/serve questions (only if other fixes didn't apply)
            if not universal_fix_applied and not direction_outcome_fix_applied and not bp_gp_fix_applied and any(word in query.lower() for word in ["serve", "serves", "ace", "aces", "serving", "double fault", "first serve", "second serve"]) and not any(word in query.lower() for word in ["return", "returning"]):
                serve1_summary_chunks = []
                serve2_summary_chunks = []
                serve1_detailed_chunks = []
                serve2_detailed_chunks = []
                
                # Find ALL serve1_statistics_summary chunks
                for chunk in self.chunks:
                    if 'serve1_statistics_summary' in chunk['metadata'].get('section', ''):
                        serve1_summary_chunks.append({
                            "text": chunk['text'],
                            "metadata": chunk['metadata'],
                            "distance": 0.0,
                            "relevance_score": 8.0
                        })
                
                # Find ALL serve2_statistics_summary chunks
                for chunk in self.chunks:
                    if 'serve2_statistics_summary' in chunk['metadata'].get('section', ''):
                        serve2_summary_chunks.append({
                            "text": chunk['text'],
                            "metadata": chunk['metadata'],
                            "distance": 0.0,
                            "relevance_score": 8.0
                        })
                
                # Find ALL serve1_statistics_detailed chunks
                for chunk in self.chunks:
                    if 'serve1_statistics_detailed' in chunk['metadata'].get('section', ''):
                        serve1_detailed_chunks.append({
                            "text": chunk['text'],
                            "metadata": chunk['metadata'],
                            "distance": 0.0,
                            "relevance_score": 7.5  # Slightly lower than summary
                        })
                
                # Find ALL serve2_statistics_detailed chunks
                for chunk in self.chunks:
                    if 'serve2_statistics_detailed' in chunk['metadata'].get('section', ''):
                        serve2_detailed_chunks.append({
                            "text": chunk['text'],
                            "metadata": chunk['metadata'],
                            "distance": 0.0,
                            "relevance_score": 7.5
                        })
                
                # Add serve1 summary chunks to position 0 (remove if exists first)
                for chunk in serve1_summary_chunks:
                    filtered_chunks = [c for c in filtered_chunks if c['metadata']['section'] != chunk['metadata']['section']]
                    filtered_chunks.insert(0, chunk)
                
                # Add serve2 summary chunks to position 0 (remove if exists first)
                for chunk in serve2_summary_chunks:
                    filtered_chunks = [c for c in filtered_chunks if c['metadata']['section'] != chunk['metadata']['section']]
                    filtered_chunks.insert(0, chunk)
                
                # Add serve1 detailed chunks to position 0 (for detailed questions)
                for chunk in serve1_detailed_chunks:
                    filtered_chunks = [c for c in filtered_chunks if c['metadata']['section'] != chunk['metadata']['section']]
                    filtered_chunks.insert(0, chunk)
                
                # Add serve2 detailed chunks to position 0 (for detailed questions)
                for chunk in serve2_detailed_chunks:
                    filtered_chunks = [c for c in filtered_chunks if c['metadata']['section'] != chunk['metadata']['section']]
                    filtered_chunks.insert(0, chunk)
            
            # CRITICAL FIX: For return questions (return depth, return direction, etc.)
            if any(word in query.lower() for word in ["return", "returning", "deep return", "shallow return", "return depth"]):
                
                # Detect which player is mentioned
                player_mentioned = self._detect_player_mentioned(query)
                
                # Check if this is a serve-return question (e.g., "When X served, Y's return rate")
                is_serve_return_question = any(word in query.lower() for word in ["served", "serving", "serve to", "serve wide", "serve down"])
                
                # Only force the relevant player's chunks
                if player_mentioned:
                    # FLIP logic for serve-return questions: if asking about X's serve -> need OTHER player's returns
                    if is_serve_return_question:
                        # If server is mentioned, get the OTHER player's return stats
                        if player_mentioned.lower() == self.player1.lower():
                            target_sections = "return2_statistics_detailed"  # FLIPPED: Get player2's returns
                        else:
                            target_sections = "return1_statistics_detailed"  # FLIPPED: Get player1's returns
                    else:
                        # Normal return question: player mentioned is the returner
                        if player_mentioned.lower() == self.player1.lower():
                            target_sections = "return1_statistics_detailed"
                        else:
                            target_sections = "return2_statistics_detailed"
                    
                    # Find and force the relevant player's chunks to position 0
                    chunks_to_add = []
                    for chunk in self.chunks:
                        if target_sections in chunk['metadata'].get('section', ''):
                            chunks_to_add.append({
                                "text": chunk['text'],
                                "metadata": chunk['metadata'],
                                "distance": 0.0,
                                "relevance_score": 8.0
                            })
                    
                    # Remove these chunks if they already exist, then add them at position 0
                    for chunk_to_add in chunks_to_add:
                        filtered_chunks = [c for c in filtered_chunks if c['metadata']['section'] != chunk_to_add['metadata']['section']]
                        filtered_chunks.insert(0, chunk_to_add)
                else:
                    # If no player mentioned, force both players' chunks to position 0
                    chunks_to_add = []
                    for chunk in self.chunks:
                        if 'return1_statistics_detailed' in chunk['metadata'].get('section', '') or 'return2_statistics_detailed' in chunk['metadata'].get('section', ''):
                            chunks_to_add.append({
                                "text": chunk['text'],
                                "metadata": chunk['metadata'],
                                "distance": 0.0,
                                "relevance_score": 8.0
                            })
                    
                    # Remove these chunks if they already exist, then add them at position 0
                    for chunk_to_add in chunks_to_add:
                        filtered_chunks = [c for c in filtered_chunks if c['metadata']['section'] != chunk_to_add['metadata']['section']]
                        filtered_chunks.insert(0, chunk_to_add)
            
            # CRITICAL FIX: For net points questions (always apply for net points questions)
            if any(word in query.lower() for word in ["net points", "net approaches", "approach shot", "approach shots", "net play", "at the net", "net points won", "net points lost", "net percentage", "net points won percentage", "net points percentage", "net"]):
                # Determine which player is being asked about
                player_mentioned = self._detect_player_mentioned(query)
                if player_mentioned:
                    if player_mentioned.lower() == self.player1.lower():
                        target_chunk_name = "netpts1_statistics"
                    else:
                        target_chunk_name = "netpts2_statistics"
                else:
                    # If no specific player mentioned, pull both chunks
                    player_mentioned = "both players"
                    target_chunk_name = None
                
                if target_chunk_name:
                    # Find the specific player's net points chunk
                    target_chunk = None
                    for chunk in self.chunks:
                        if target_chunk_name in chunk['metadata']['section']:
                            target_chunk = {
                                "text": chunk['text'],
                                "metadata": chunk['metadata'],
                                "distance": 0.0,  # Perfect match
                                "relevance_score": 10.0  # Maximum score for net points
                            }
                            break
                    
                    # Add or move the specific player's chunk to position 0
                    if target_chunk:
                        # Remove it if it already exists (we'll re-insert at position 0)
                        filtered_chunks = [c for c in filtered_chunks if target_chunk_name not in c['metadata']['section']]
                        # Insert at position 0
                        filtered_chunks.insert(0, target_chunk)
                        net_points_fix_applied = True
                    
                
                else:
                    # Pull both players' chunks for "each player" questions
                    netpts1_chunk = None
                    netpts2_chunk = None
                    
                    # Find netpts1_statistics chunk
                    for chunk in self.chunks:
                        if 'netpts1_statistics' in chunk['metadata']['section']:
                            netpts1_chunk = {
                                "text": chunk['text'],
                                "metadata": chunk['metadata'],
                                "distance": 0.0,  # Perfect match
                                "relevance_score": 10.0  # Maximum score for net points
                            }
                            break
                    
                    # Find netpts2_statistics chunk
                    for chunk in self.chunks:
                        if 'netpts2_statistics' in chunk['metadata']['section']:
                            netpts2_chunk = {
                                "text": chunk['text'],
                                "metadata": chunk['metadata'],
                                "distance": 0.0,  # Perfect match
                                "relevance_score": 10.0  # Maximum score for net points
                            }
                            break
                    
                    # Add netpts1 chunk if not already in results
                    if netpts1_chunk and not any('netpts1_statistics' in chunk['metadata']['section'] for chunk in filtered_chunks):
                        filtered_chunks.insert(0, netpts1_chunk)
                        net_points_fix_applied = True
                    
                    # Add netpts2 chunk if not already in results
                    if netpts2_chunk and not any('netpts2_statistics' in chunk['metadata']['section'] for chunk in filtered_chunks):
                        filtered_chunks.insert(0, netpts2_chunk)
                        net_points_fix_applied = True
        
        # MATCH RESULT FIX: For questions about match outcome, force include match_overview (FINAL PRIORITY)
        if any(phrase in query.lower() for phrase in ["final score", "who won", "match result", "outcome", "d.", "defeated", "victory", "victor"]):
            # Force include match_overview chunk
            match_overview_chunk = None
            for chunk in self.chunks:
                if 'match_overview' in chunk['metadata']['section']:
                    match_overview_chunk = {
                        "text": chunk['text'],
                        "metadata": chunk['metadata'],
                        "distance": 0.0,
                        "relevance_score": 10.0  # Maximum score for match result questions
                    }
                    break
            
            # Remove any existing match_overview chunks and add at the very top
            filtered_chunks = [chunk for chunk in filtered_chunks if 'match_overview' not in chunk['metadata']['section']]
            if match_overview_chunk:
                filtered_chunks.insert(0, match_overview_chunk)
        
        # CRITICAL FIX: For MULTI-SET comparison questions (must come BEFORE single-set logic)
        multiple_sets = self._detect_multiple_set_references(query)
        if multiple_sets and hasattr(self, 'set_mapping'):
            
            # Collect chunks from ALL requested sets
            multi_set_chunks = []
            for set_num in multiple_sets:
                if set_num in self.set_mapping:
                    target_set_score = self.set_mapping[set_num]
                    
                    # Generate score patterns for this set
                    score_parts = target_set_score.split('-')
                    if len(score_parts) == 2:
                        set_score_patterns = [
                            target_set_score,
                            f"{score_parts[1]}-{score_parts[0]}",
                        ]
                        total = int(score_parts[0]) + int(score_parts[1])
                        if total == 2 and score_parts[0] != score_parts[1]:
                            set_score_patterns.append("1-1")
                    else:
                        set_score_patterns = [target_set_score]
                    
                    # Find chunks for this set
                    for chunk in self.chunks:
                        if 'point-by-point_narrative' in chunk['metadata'].get('section', ''):
                            chunk_metadata = chunk.get('metadata', {})
                            chunk_set_numbers = chunk_metadata.get('set_numbers', [])
                            
                            # Use metadata or text fallback
                            if set_num in chunk_set_numbers:
                                multi_set_chunks.append({
                                    "text": chunk['text'],
                                    "metadata": chunk['metadata'],
                                    "distance": 0.0,
                                    "relevance_score": 10.0,
                                    "set_number": set_num  # Track which set this is from
                                })
                            elif not chunk_set_numbers:
                                chunk_text = chunk['text']
                                for pattern in set_score_patterns:
                                    if f"Score: {pattern}" in chunk_text:
                                        multi_set_chunks.append({
                                            "text": chunk['text'],
                                            "metadata": chunk['metadata'],
                                            "distance": 0.0,
                                            "relevance_score": 10.0,
                                            "set_number": set_num
                                        })
                                        break
            
            # Remove ALL point-by-point chunks and add the multi-set chunks
            if multi_set_chunks:
                filtered_chunks = [c for c in filtered_chunks if 'point-by-point_narrative' not in c['metadata'].get('section', '')]
                
                # Add chunks in set order (Set 1 first, then Set 5, etc.)
                for chunk_to_add in multi_set_chunks:
                    filtered_chunks.insert(0, chunk_to_add)
                
        
        # CRITICAL FIX: For set-specific questions (single set only)
        # Check both query text AND explicit set_filter parameter
        elif not multiple_sets:  # Only run single-set logic if NOT a multi-set comparison
            set_number = set_filter or self._detect_set_reference(query)
            # Skip if set_number is a list (set comparison with multiple sets)
            if set_number and not isinstance(set_number, list) and hasattr(self, 'set_mapping') and set_number in self.set_mapping:
                target_set_score = self.set_mapping[set_number]
                
                # Generate ALL possible score patterns for this set
                # For Set 3 with mapping "2-0", we need to match BOTH "2-0" AND "0-2" (server perspective)
                # Also handle "1-1" if it's a tied situation
                score_parts = target_set_score.split('-')
                if len(score_parts) == 2:
                    set_score_patterns = [
                        target_set_score,  # e.g., "2-0"
                        f"{score_parts[1]}-{score_parts[0]}",  # e.g., "0-2" (reversed)
                    ]
                    # Add "1-1" pattern if the total is 2 (for set 3)
                    total = int(score_parts[0]) + int(score_parts[1])
                    if total == 2 and score_parts[0] != score_parts[1]:
                        set_score_patterns.append("1-1")
                    
                else:
                    set_score_patterns = [target_set_score]
                
                # Find all point-by-point chunks containing ANY points from this set
                # Use metadata filtering (fast) with text fallback (backward compatibility)
                set_specific_chunks = []
                for chunk in self.chunks:
                    if 'point-by-point_narrative' in chunk['metadata'].get('section', ''):
                        chunk_metadata = chunk.get('metadata', {})
                        chunk_set_numbers = chunk_metadata.get('set_numbers', [])
                        
                        # Method 1: Use metadata (preferred - fast and accurate)
                        if set_number in chunk_set_numbers:
                            set_specific_chunks.append({
                                "text": chunk['text'],
                                "metadata": chunk['metadata'],
                                "distance": 0.0,
                                "relevance_score": 10.0  # Maximum score for set-specific
                            })
                        # Method 2: Text search fallback (for old chunks without metadata)
                        elif not chunk_set_numbers:  # Only if metadata is missing
                            chunk_text = chunk['text']
                            for pattern in set_score_patterns:
                                if f"Score: {pattern}" in chunk_text:
                                    set_specific_chunks.append({
                                        "text": chunk['text'],
                                        "metadata": chunk['metadata'],
                                        "distance": 0.0,
                                        "relevance_score": 10.0
                                    })
                                    break  # Don't add the same chunk twice
                
                # CRITICAL: Remove ALL point-by-point chunks from OTHER sets
                # Only keep chunks that match the target set score
                if set_specific_chunks:
                    filtered_chunks = [c for c in filtered_chunks if 'point-by-point_narrative' not in c['metadata'].get('section', '')]
                    
                    # Now add ONLY the Set 3 chunks at the top
                    for chunk_to_add in set_specific_chunks:
                        filtered_chunks.insert(0, chunk_to_add)
                        
        
        # CRITICAL FIX: For game-specific questions
        game_reference = self._detect_game_reference(query)
        if game_reference and not game_reference.startswith('game_'):  # Game score pattern like "3-2"
            
            # IMPORTANT: Search within already-filtered chunks (which may already be set-specific)
            # This prevents adding back games from other sets
            game_specific_chunks = []
            search_source = filtered_chunks if set_number else self.chunks
            
            for chunk in search_source:
                if 'point-by-point_narrative' in chunk.get('metadata', {}).get('section', ''):
                    chunk_metadata = chunk.get('metadata', {})
                    chunk_game_scores = chunk_metadata.get('game_scores', [])
                    
                    # Method 1: Use metadata (preferred)
                    if game_reference in chunk_game_scores:
                        game_specific_chunks.append({
                            "text": chunk.get('text', ''),
                            "metadata": chunk.get('metadata', {}),
                            "distance": chunk.get('distance', 0.0),
                            "relevance_score": 9.5
                        })
                    # Method 2: Text search fallback
                    elif not chunk_game_scores:  # Only if metadata missing
                        if f" {game_reference} " in chunk.get('text', ''):
                            game_specific_chunks.append({
                                "text": chunk.get('text', ''),
                                "metadata": chunk.get('metadata', {}),
                                "distance": chunk.get('distance', 0.0),
                                "relevance_score": 9.5
                            })
            
            # Remove existing PBP chunks and add only the game-specific ones
            if game_specific_chunks:
                filtered_chunks = [c for c in filtered_chunks if 'point-by-point_narrative' not in c['metadata'].get('section', '')]
                for chunk_to_add in game_specific_chunks:
                    filtered_chunks.insert(0, chunk_to_add)
        
        # POINT-BY-POINT PRIORITY: For conditional/temporal/shot-sequence questions, prioritize narrative chunks
        # ONLY include indicators that ALWAYS need PBP (not words that could be stats OR PBP)
        conditional_indicators = [
            # Conditional/situational (always need PBP context)
            "after losing", "after winning", "after missing", "after break",
            "when rallies got", "as rallies got",
            "on important points", "on key points", "in crucial moments", "in tight moments",
            "when facing break", "when trailing", "when ahead",
            # Temporal/evolution (always need PBP analysis over time)
            "evolve", "evolved", "evolution", "over time", "throughout the match",
            "progression", "progressed", "changed over", "developed",
            "early vs late", "first set vs", "as the match", "match went on",
            # Per-set/per-game breakdowns (always need PBP counting)
            "each set", "per set", "in each set", "every set", "set by set",
            "across sets", "across the sets", "across all sets", "across the five sets",
            "in set 1", "in set 2", "in set 3", "in set 4", "in set 5",
            "per game", "each game", "game by game",
            # Shot sequence/response indicators (ALWAYS need rally-level data)
            "when hit a", "when he hit", "when she hit", "when they hit",
            "response to", "respond to", "responded to", "in response",
            "shot sequence", "shot sequences", "rally patterns",
            "most common response", "typical response",
            # Sequential/consequential (always need PBP flow)
            "next shot", "following shot", "then hit",
            # Specific rally questions (need PBP not stats)
            "rallies with", "rallies where", "points where", "points when",
            "long rallies", "short rallies", "extended rallies",
            "8+ shot", "5+ shot", "10+ shot",
            # Adaptation/tactical evolution (need PBP temporal analysis)
            "adapt", "adapted", "adaptation",
            "counter", "countered", "countering",
            "switched to", "started hitting", "began favoring", "began using"
        ]
        if any(indicator in query.lower() for indicator in conditional_indicators):
            # Collect all point-by-point narrative chunks
            pbp_chunks = []
            non_pbp_chunks = []
            
            for chunk in filtered_chunks:
                if 'narrative' in chunk['metadata']['section'].lower() or 'point-by-point' in chunk['metadata']['section'].lower():
                    # Boost relevance score for PBP chunks
                    chunk['relevance_score'] = chunk.get('relevance_score', 1.0) + 5.0
                    pbp_chunks.append(chunk)
                else:
                    non_pbp_chunks.append(chunk)
            
            # Reorder: PBP chunks first, then statistical chunks
            if pbp_chunks:
                filtered_chunks = pbp_chunks + non_pbp_chunks
        
        # FINAL NEGATIVE FILTER: Remove net points chunks unless question is about net play
        if not net_points_fix_applied and not any(word in query.lower() for word in ["net points", "net approaches", "overhead", "approach shot", "approach shots", "net play", "at the net", "net points won", "net points lost", "net percentage", "net points won percentage", "net points percentage", "net"]):
            original_count = len(filtered_chunks)
            filtered_chunks = [chunk for chunk in filtered_chunks if 'netpts' not in chunk['metadata']['section']]
            if len(filtered_chunks) < original_count:
                pass
        
        # For complex analytical questions, ensure we have diverse chunk types
        if top_k > 8:
            # Ensure we have a mix of different section types for comprehensive analysis
            section_types = set()
            for chunk in filtered_chunks[:top_k]:
                section = chunk['metadata']['section']
                if 'overview' in section:
                    section_types.add('overview')
                elif 'serve' in section:
                    section_types.add('serve')
                elif 'return' in section:
                    section_types.add('return')
                elif 'shot' in section:
                    section_types.add('shot')
                elif 'key_points' in section:
                    section_types.add('key_points')
                elif 'netpts' in section:
                    section_types.add('netpts')
                elif 'rally' in section:
                    section_types.add('rally')
                elif 'match_overview' in section:
                    section_types.add('match_overview')
            
        
        # Return top_k results
        return filtered_chunks[:top_k]
    
    def _route_bp_gp_question(self, question: str, player: str) -> str:
        """
        Route break point and game point questions to correct data sources.
        Returns the appropriate section and data field to look for.
        """
        q = question.lower()
        player_lower = player.lower()
        
        # Determine which player is being asked about
        if not self.player1 or not self.player2:
            return "unknown"
            
        if player_lower == self.player1.lower():
            player_prefix = "serve1" if "serve" in q else "serve2" if "return" in q else "serve1"  # Default to serve1 for player1
        elif player_lower == self.player2.lower():
            player_prefix = "serve2" if "serve" in q else "serve1" if "return" in q else "serve2"  # Default to serve2 for player2
        else:
            # Fallback - check if any part of the player name matches
            if any(word in q for word in self.player1.lower().split()):
                player_prefix = "serve1"
            elif any(word in q for word in self.player2.lower().split()):
                player_prefix = "serve2"
            else:
                return "unknown"
        
        # --- BREAK POINTS (BP) ---
        if "break point" in q or "bp" in q:
            if "face" in q:  
                return f"{player_prefix}_statistics"  # Serving side (opponent had chance to break) - BP Faced
            elif "save" in q or "saved" in q:
                return f"{player_prefix}_statistics"  # Serving side (player defended successfully) - BP Faced, col = PtsW
            elif "opp" in q or "opportunit" in q:
                return f"{player_prefix.replace('serve', 'return')}_statistics"  # Returning side (player created break chances) - BP Opps
            elif "convert" in q or "win" in q or "won" in q:
                return f"{player_prefix.replace('serve', 'return')}_statistics"  # Returning side (player actually broke serve) - BP Opps, col = PtsW
            elif "total" in q or "overall" in q:
                return "both"  # Need both serve and return for complete totals
            else:
                # No keyword -> Default = Return side (converted), because that's most common in questions
                return f"{player_prefix.replace('serve', 'return')}_statistics"
        
        # --- GAME POINTS (GP) ---
        if "game point" in q or "gp" in q:
            if "face" in q:
                return f"{player_prefix.replace('serve', 'return')}_statistics"  # Returning side (opponent had game points on serve) - GP Faced
            elif "save" in q or "saved" in q:
                return f"{player_prefix.replace('serve', 'return')}_statistics"  # Returning side (player denied opponent's game point while returning) - GP Faced, col = PtsW
            elif "win" in q or "won" in q:
                if "serve" in q:
                    return f"{player_prefix}_statistics"  # Serving side (player won their own service game points) - Game Pts, col = PtsW
                elif "return" in q:
                    return f"{player_prefix.replace('serve', 'return')}_statistics"  # Returning side (rare phrasing, but = broke opponent on GP) - GP Faced, col = PtsW
                elif "each player" in q or "both player" in q:
                    return "both"  # Need both serve and return for "each player" questions
                else:
                    # Default: GP won on serve (most common case)
                    return f"{player_prefix}_statistics"  # Serving side (Game Pts won) - Game Pts, col = PtsW
            elif "convert" in q:
                return f"{player_prefix.replace('serve', 'return')}_statistics"  # Returning side (converted while returning) - GP Faced, col = PtsW
            elif "total" in q or "overall" in q or "each player" in q or "both player" in q:
                return "both"  # Need both serve and return for complete totals
            else:
                # No keyword -> Default = Serve side (Game Pts won), because that's the most natural reading
                return f"{player_prefix}_statistics"
        
        # --- DEUCE POINTS ---
        if "deuce" in q:
            if "serve" in q or "served" in q:
                return f"{player_prefix}_statistics"  # Serving side (deuce points on own serve) - Svg Deuce
            elif "return" in q or "returned" in q:
                return f"{player_prefix.replace('serve', 'return')}_statistics"  # Returning side (deuce points when opponent served) - Ret Deuce
            elif "each player" in q or "both player" in q:
                return "both"  # Need both serve and return for "each player" questions
            else:
                # No keyword -> Need both, since "deuce points" could mean either. Safest = "both"
                return "both"
        
        return "unknown"

    def _get_stat_keywords(self, stat_type: str) -> List[str]:
        """Get keywords that indicate a question is about a specific statistic type."""
        keywords = {
            "serve": ["ace", "aces", "serve", "serving", "double fault", "double faults", "first serve", "second serve"],
            "shots": ["winner", "winners", "unforced error", "unforced errors", "forehand", "backhand", "shot"],
            "shotdir": ["crosscourt", "down the line", "down the middle", "inside-out", "inside-in", "direction"],
            "return": ["return", "returns", "returnable", "returning"],
            "netpts": ["net points", "net approaches", "volley", "volleys", "overhead", "approach"],
            "keypoints": ["break point", "break points", "game point", "game points", "deuce", "key point"]
        }
        return keywords.get(stat_type, [])
    
    def _filter_chunks_by_query(self, query: str, candidates: List[Dict]) -> List[Dict]:
        """
        Filter and re-rank chunks based on query content and metadata.
        """
        query_lower = query.lower()
        
        # Determine query intent
        player_mentioned = self._detect_player_mentioned(query)
        
        stat_category = None
        if any(word in query_lower for word in ["return", "returning"]):
            stat_category = "returning"
        elif any(word in query_lower for word in ["serve", "serving", "aces", "double fault"]):
            stat_category = "serving"
        elif any(word in query_lower for word in ["shot", "winner", "error", "forehand", "backhand"]):
            stat_category = "shots"
        elif any(word in query_lower for word in ["net", "volley", "approach"]):
            stat_category = "net_play"
        elif any(word in query_lower for word in ["key point", "break point", "game point", "set point", "match point", "deuce", "advantage", "bp", "gp", "converted", "faced", "saved"]):
            stat_category = "key_points"
        elif any(word in query_lower for word in ["point", "rally", "narrative", "longest", "shot", "stroke", "key moments", "decided", "outcome", "strategy", "momentum", "critical", "turning point"]):
            stat_category = "narrative"
        elif any(word in query_lower for word in ["overview", "summary", "total"]):
            stat_category = "overview"
        
        # Score and filter chunks
        scored_chunks = []
        for chunk in candidates:
            score = 1.0 - chunk["distance"]  # Convert distance to similarity score
            metadata = chunk["metadata"]
            
            # CRITICAL FIX: Prioritize overview statistics for statistical questions
            if not self._is_match_insight_question(query):
                # For statistical questions, heavily prioritize overview and authoritative totals
                if "overview_statistics" in metadata.get("section", "").lower():
                    score += 5.0  # Extremely high boost for overview statistics
                elif "authoritative totals" in chunk["text"].lower():
                    score += 3.0  # Very high boost for authoritative totals
                elif "serve1_statistics_summary" in metadata.get("section", "").lower():
                    score += 2.0  # High boost for serve summary with authoritative totals
                elif "serve2_statistics_summary" in metadata.get("section", "").lower():
                    score += 2.0  # High boost for serve summary with authoritative totals
                # KEY POINTS HIERARCHY: Prioritize key points section for break points and game points
                elif "key_points" in metadata.get("section", "").lower():
                    if any(word in query_lower for word in ["break point", "break points", "bp", "converted", "faced", "saved"]):
                        score += 3.0  # Very high boost for break point questions
                    elif any(word in query_lower for word in ["game point", "game points", "gp", "set point", "set points", "match point", "match points"]):
                        score += 3.0  # Very high boost for game/set/match point questions
                    elif any(word in query_lower for word in ["key point", "key points", "critical point", "deuce", "advantage"]):
                        score += 2.5  # High boost for general key point questions
                
                # SHOT HIERARCHY: Establish clear priority for shot-related questions
                # 1. SHOT STATISTICS: For forehand/backhand SIDE (all shots from that side - volleys, dropshots, etc.)
                if any(word in query_lower for word in ["forehand side", "backhand side", "volley", "dropshot", "lob", "net play", "swinging volley"]) and "shots" in metadata.get("section", "").lower():
                    if "shots1_statistics" in metadata.get("section", "").lower() or "shots2_statistics" in metadata.get("section", "").lower():
                        score += 2.5  # High boost for shot statistics (side-based shots)
                
                # Also use SHOT STATISTICS for general shot performance questions
                if any(word in query_lower for word in ["shot", "winner", "error", "unforced", "forced", "total shots"]) and "shots" in metadata.get("section", "").lower():
                    if "shots1_statistics" in metadata.get("section", "").lower() or "shots2_statistics" in metadata.get("section", "").lower():
                        score += 2.0  # High boost for general shot statistics
                
                # 2. SHOT DIRECTION: For forehand/backhand GROUNDSTROKES and placement patterns
                if any(word in query_lower for word in ["forehand groundstroke", "backhand groundstroke", "groundstroke", "crosscourt", "down the line", "down the middle", "inside out", "inside in", "direction", "placement", "pattern"]) and "shotdir" in metadata.get("section", "").lower():
                    if "authoritative totals" in chunk["text"].lower():
                        score += 2.0  # High boost for shot direction (groundstrokes and placement)
                
                # Special case: When "forehand" or "backhand" mentioned alone, prefer SHOT DIRECTION (groundstrokes)
                if any(word in query_lower for word in ["forehand", "backhand"]) and not any(word in query_lower for word in ["side", "volley", "dropshot", "lob"]) and "shotdir" in metadata.get("section", "").lower():
                    if "authoritative totals" in chunk["text"].lower():
                        score += 1.8  # Slightly lower than explicit groundstroke questions
                
                # 3. SHOT DIRECTIONAL BREAKDOWN: For directional + outcome performance (detailed breakdowns)
                if any(word in query_lower for word in ["crosscourt winner", "down the line error", "inside out performance", "directional outcome"]) and "shotdir" in metadata.get("section", "").lower():
                    if "detailed breakdown" in chunk["text"].lower() or "table2" in metadata.get("section", "").lower():
                        score += 1.5  # Medium boost for detailed directional breakdowns
                
                # For net statistics
                if any(word in query_lower for word in ["net", "volley", "approach", "passed"]) and "netpts" in metadata.get("section", "").lower():
                    score += 1.0
                

                
                # Special boost for court-specific questions
                if any(word in query_lower for word in ["deuce court", "ad court", "wide", "body", "t"]):
                    if "serve" in metadata.get("section", "").lower() and any(word in chunk["text"].lower() for word in ["deuce", "ad", "wide", "body", "t"]):
                        score += 0.5
            
            # Boost score for player match
            if player_mentioned and metadata.get("player_focus") == player_mentioned:
                score += 0.3
            elif player_mentioned and metadata.get("player_focus") == "Both":
                score += 0.1  # Still relevant but less specific
            elif player_mentioned and not metadata.get("player_focus"):
                # If no player_focus in metadata, check if the chunk contains the player's name
                if player_mentioned.lower() in chunk["text"].lower():
                    score += 0.2
            
            # Boost score for category match
            if stat_category and metadata.get("stat_category") == stat_category:
                score += 0.25
            
            # Boost for percentage queries
            if any(word in query_lower for word in ["percent", "%", "rate", "ratio"]) and metadata.get("contains_percentages"):
                score += 0.15
            
            # Boost for point-by-point queries
            if any(word in query_lower for word in ["point", "rally", "what happened"]) and metadata.get("contains_point_details"):
                score += 0.2
            
            # Extra boost for rally-specific queries
            if any(word in query_lower for word in ["longest rally", "rally", "shot rally", "stroke rally"]) and metadata.get("contains_point_details"):
                score += 0.3
            
            # Extra boost for match insight/strategy queries
            if any(word in query_lower for word in ["key moments", "decided", "outcome", "strategy", "momentum", "critical", "turning point"]) and metadata.get("contains_point_details"):
                score += 0.4  # Higher boost for narrative chunks
            
            # Prioritize narrative chunks for match insight questions
            if self._is_match_insight_question(query) and metadata.get("contains_point_details"):
                score += 0.5  # Very high boost for narrative chunks
            elif self._is_match_insight_question(query) and "rally_outcomes" in metadata.get("section", ""):
                score -= 0.3  # Penalize rally outcomes for insight questions
            
            chunk["relevance_score"] = score
            scored_chunks.append(chunk)
        
        # Sort by relevance score (descending)
        scored_chunks.sort(key=lambda x: x["relevance_score"], reverse=True)
        
        return scored_chunks
    
    def _fallback_metadata_retrieval(self, query: str, top_k: int) -> List[Dict]:
        """
        Fallback retrieval method using metadata matching when embeddings aren't available.
        """
        query_lower = query.lower()
        
        # Simple keyword-based matching
        relevant_chunks = []
        for chunk in self.chunks:
            text_lower = chunk["text"].lower()
            metadata = chunk["metadata"]
            
            # Calculate basic relevance score
            score = 0
            
            # Check for direct text matches
            query_words = query_lower.split()
            text_words = text_lower.split()
            common_words = set(query_words) & set(text_words)
            score += len(common_words) * 0.1
            
            # Check metadata relevance
            # Player-specific scoring
            if player_mentioned and metadata.get("player_focus") == player_mentioned:
                score += 0.5
            
            if score > 0:
                relevant_chunks.append({
                    "text": chunk["text"],
                    "metadata": metadata,
                    "distance": 1.0 - score,  # Convert to distance-like metric
                    "relevance_score": score
                })
        
        # Sort by relevance and return top_k
        relevant_chunks.sort(key=lambda x: x["relevance_score"], reverse=True)
        return relevant_chunks[:top_k]
    
    def _extract_specific_point(self, text: str, point_number: int) -> str:
        """
        Extract only the specific point from point-by-point text.
        Returns the point text if found, empty string otherwise.
        """
        import re
        # Pattern to match "Point X [" where X is the point number
        pattern = rf"Point {point_number}\s*\[.*?\]:(.*?)(?=Point \d+\s*\[|$)"
        match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)
        if match:
            point_text = match.group(0).strip()
            return point_text
        return ""
    
    def answer_query_with_llm(self, query: str, relevant_chunks: List[Dict]) -> str:
        """
        Use LLM to answer the query based on retrieved chunks.
        """
        if not relevant_chunks:
            return "I don't have enough relevant information to answer this question."
        
        # Check if query asks about a specific point number
        import re
        point_match = re.search(r'point\s+(\d+)', query.lower())
        requested_point = None
        if point_match:
            requested_point = int(point_match.group(1))
        
        # Prepare context from retrieved chunks
        context_parts = []
        for chunk in relevant_chunks:
            section_info = f"[{chunk['metadata']['section']} - {chunk['metadata']['type']}]"
            # Add player identification to section info if available
            player_focus = chunk['metadata'].get('player_focus', '')
            if player_focus:
                if player_focus == self.player1:
                    section_info += f" [PLAYER: {self.player1}]"
                elif player_focus == self.player2:
                    section_info += f" [PLAYER: {self.player2}]"
                elif player_focus == "Both":
                    section_info += f" [PLAYER: BOTH PLAYERS]"
            # Also check section name for player indicators
            section_name = chunk['metadata'].get('section', '').lower()
            if 'return1' in section_name or 'serve1' in section_name or 'shots1' in section_name:
                section_info += f" [PLAYER: {self.player1 if self.player1 else 'Player 1'}]"
            elif 'return2' in section_name or 'serve2' in section_name or 'shots2' in section_name:
                section_info += f" [PLAYER: {self.player2 if self.player2 else 'Player 2'}]"
            
            # If asking about a specific point, extract only that point from point-by-point chunks
            chunk_text = chunk['text']
            if requested_point and 'point-by-point' in chunk['metadata'].get('section', '').lower():
                extracted_point = self._extract_specific_point(chunk_text, requested_point)
                if extracted_point:
                    chunk_text = extracted_point
                    section_info += f" [EXTRACTED POINT {requested_point} ONLY]"
                elif f"Point {requested_point}" in chunk_text:
                    # Fallback: try to extract manually if regex didn't work
                    lines = chunk_text.split('\n')
                    point_lines = []
                    in_point = False
                    for line in lines:
                        if f"Point {requested_point}" in line:
                            in_point = True
                            point_lines.append(line)
                        elif in_point and line.strip() and not line.strip().startswith("Point "):
                            point_lines.append(line)
                        elif in_point and line.strip().startswith("Point "):
                            break
                    if point_lines:
                        chunk_text = '\n'.join(point_lines)
                        section_info += f" [EXTRACTED POINT {requested_point} ONLY]"
            
            context_parts.append(f"{section_info}\n{chunk_text}")
        
        context = "\n\n".join(context_parts)
        
        # Enhanced prompt with specific instructions for different question types
        is_statistical = self._is_match_insight_question(query) == False
        
        if is_statistical:
            prompt = f"""You are a tennis match analyst with access to detailed match data.

IMPORTANT: Do not use emojis in your response. Use plain text only.

ðŸš¨ CRITICAL RULES FOR READING POINT-BY-POINT DATA ðŸš¨

**RULE #1: Score Notation - "Score: 2-0" and "Score: 0-2" can be THE SAME SET!**
- Score format: Score: [Sets_Server]-[Sets_Returner] [Games]-[Games] [Points]
- The set numbers FLIP based on who is serving
- Example for Set 3 (after Sinner leads 2-0 in sets):
  - When Sinner serves: "Score: 2-0 4-5" â† SET 3
  - When Alcaraz serves: "Score: 0-2 4-5" â† SET 3 (SAME SET!)
- **DO NOT call this an "inconsistency"** - it's normal server/returner perspective

**RULE #2: Point Header Format - READ IT CAREFULLY**
- Every point starts with: "Point X [Server: PLAYER_NAME | Returner: PLAYER_NAME | Score: ...]"
- **CRITICAL**: The Server is the player who SERVES the point
- **CRITICAL**: The Returner is the player who RETURNS the serve
- **CRITICAL**: The Score shows [Sets_Server]-[Sets_Returner] [Games_Server]-[Games_Returner] [Points_Server]-[Points_Returner]
- **CRITICAL**: The format is ALWAYS: "Score: X-Y A-B C-D" where:
  - X-Y = Sets (X sets won by Server, Y sets won by Returner)
  - A-B = Games (A games won by Server in current set, B games won by Returner in current set)
  - C-D = Points (C points for Server in current game, D points for Returner in current game)
- **CRITICAL**: When Server has 1 game and Returner has 2 games, the score is "1-2" (NOT "0-0" or "2-1")
- **DO NOT flip or confuse Server/Returner roles** - read them directly from the header
- Example: "Point 24 [Server: Jannik Sinner | Returner: Ben Shelton | Score: 0-0 1-2 40-15]"
  - Jannik Sinner is serving
  - Ben Shelton is returning
  - Score: 0-0 in sets, 1-2 in games (Sinner has 1 game, Shelton has 2 games - Shelton leads), 40-15 in current game (Sinner serving, 40-15)

**RULE #3: Each Point Shows the Winner Explicitly**
- Every point ends with: "[Point won by: PLAYER_NAME]"
- Use this tag to determine who won each point - don't guess!
- To determine game outcomes: count sequential point winners
- Example: If Points 204-207 all show "[Point won by: Alcaraz]" -> Alcaraz won all 4 points

**RULE #4: Each Shot Shows Who Hit It**
- The FIRST shot in a point is ALWAYS by the Server (from the header)
- The SECOND shot is ALWAYS by the Returner (from the header)
- Subsequent rally shots are tagged with player names: "forehand winner [ALCARAZ]"
- Don't try to track alternation - just read the tags!
- Example: "1st serve down the T [Jannik Sinner]; forehand chip/slice return [Ben Shelton]"
  - Jannik Sinner served (matches Server in header)
  - Ben Shelton returned (matches Returner in header)

**RULE #5: Never Fabricate - Verify Everything**
- DO NOT say "held to love" or "broke serve" without counting actual point winners
- DO NOT guess game outcomes - count the "[Point won by:]" tags
- If you see mixed sets in a chunk, filter by score pattern (Score: 0-2 vs Score: 1-2)
- DO NOT explain score notation or reasoning in your answer (e.g. don't say "the score structure suggests...")
- Just provide clean, narrative answers without showing your internal reasoning process

**RULE #5B: When Asked About a Set - Describe ALL Games, Not Just the Tiebreak**
- If asked "what happened in Set X", describe ALL games from 0-0 through the end
- DO NOT only describe the tiebreak and skip the regular games (1-0, 2-1, 3-2, etc.)
- Tiebreaks are important, but so are the 12+ regular games that came before them
- Example: For "what happened in Set 5", describe games from 0-0, 1-0, 1-1... all the way to 6-6 AND the tiebreak

**RULE #6: TENNIS SET SCORING - CRITICAL FOR SET/GAME QUESTIONS**
- A set is won by the first player to win 6 games (with a 2-game margin), or 7-6 in a tiebreak
- IMPORTANT: If a player is leading 5-4 and wins the next game -> They win the set 6-4 (NOT 5-5!)
- IMPORTANT: If a set is tied 5-5, the next game makes it 6-5 (NOT the end of the set)
- IMPORTANT: If a player is leading 6-5 and wins the next game -> They win the set 7-5
- IMPORTANT: If a set is tied 6-6 -> Tiebreak is played
- Examples:
  * Leading 5-4, break serve -> Set ends 6-4 âœ“
  * Tied 5-5, hold serve -> Score becomes 6-5 (set continues) âœ“
  * Leading 6-5, hold serve -> Set ends 7-5 âœ“

**RULE #7: MATCH FORMAT SCORING - WHICH SET ARE WE IN?**
- Best-of-3 matches: First to win 2 sets (men's non-Slams, all women's matches)
- Best-of-5 matches: First to win 3 sets (men's Grand Slams)
- CRITICAL: Count completed sets to determine which set is being played:
  * "Score: 0-0 ..." = SET 1 (match just started)
  * "Score: 1-0 ..." or "Score: 0-1 ..." = SET 2 (one player leads 1-0)
  * "Score: 1-1 ..." = SET 3 (sets tied 1-1)
  * "Score: 2-0 ..." or "Score: 0-2 ..." = SET 3 (one player leads 2-0 in best-of-5)
  * "Score: 2-1 ..." or "Score: 1-2 ..." = SET 4 (in best-of-5, one player leads 2-1)
  * "Score: 2-2 ..." = SET 5 (in best-of-5, sets tied 2-2 - THE DECIDING SET!)
- Examples for best-of-5:
  * "Score: 2-2 6-6 0-0" = SET 5 tiebreak (NOT Set 4!)
  * Match CANNOT end at 2-2; someone must win Set 5 to win 3-2
- DO NOT say "the match ended 3-1 after 4 sets" if you see 2-2 scoring!

**CRITICAL EXAMPLE - Tracking Games Through Server Changes:**
Game 9 ends at: "Score: 0-2 5-3" -> Player serving is DOWN 5-3 in games, opponent LEADS 5-3
Player leading 5-3 LOSES Game 9 -> Score becomes 5-4 (still leading, but by less)
Game 10 starts at: "Score: 2-0 4-5" -> Player serving is DOWN 4-5 in games, opponent LEADS 5-4
Player leading 5-4 WINS Game 10 -> Score becomes 6-4 -> SET OVER! âœ“
**DO NOT say "5-5" - when you see the set score jump from "0-2"/"2-0" to "1-2", the set ENDED!**

IMPORTANT INSTRUCTIONS FOR STATISTICAL QUESTIONS:
- **CRITICAL: When asked "who won" or "who won the match"**, ALWAYS include BOTH the winner's name AND the final score in your answer (e.g., "Carlos Alcaraz won the match, defeating Novak Djokovic 6-4 7-6(4) 6-2")
- **CRITICAL: When asked for the "score" or "final score"**, provide the complete score including the winner (e.g., "Carlos Alcaraz d. Novak Djokovic 6-4 7-6(4) 6-2")
- **CRITICAL: When asked about BOTH or EACH players' statistics** (e.g., "Ben Shelton's returning effectiveness" AND "Jannik Sinner's returning effectiveness"):
  - **ALWAYS check the section headers** -(e.g. look for "RETURN1 STATISTICS (DETAILED):" vs "RETURN2 STATISTICS (DETAILED):" or "SERVE1 STATISTICS" vs "SERVE2 STATISTICS")
  - **ALWAYS check player names in the text** - each statistic line includes the player name (e.g., "Ben Shelton returned 21 times" vs "Jannik Sinner returned 19 times")
  - **DO NOT assume both players have the same statistics** - even if numbers look similar, verify which player each number belongs to by checking the player name in that line
  - **Report statistics separately for each player** - clearly label which statistics belong to which player
  - **If you see identical numbers for both players, double-check the player names in the source text** - this is likely an error if the numbers are truly identical
- When asked for "counts" or "numbers", always return the raw count if available (e.g., "12 points"). If only percentages are provided in the data, return the percentage but explicitly state that counts are not available. Never infer or estimate counts from percentages.
- [WARN] When adding categories (e.g., unforced + forced errors), only add if both are raw counts
- [ERROR] Never add percentages together
- Treat "forced errors" and "induced forced errors" as the same thing
- When asked for "converted" break points, look for "Break Points won" or "converted" data
- For court-specific questions (deuce court, ad court), combine both courts for totals unless specifically asked for one court
- For "game points", look in the key points section for "game points" data
- For shot statistics, use the authoritative totals rows first, then go to breakdowns or details as needed(e.g., "Player 1 hit forehand shots 111 times")
- For shot direction totals, use the "AUTHORITATIVE TOTALS" row first, then go to breakdowns or details as needed
- For net statistics, use the net points section data

Context from the match (retrieved from relevant sections):
{context}

Question: {query}

**CRITICAL INSTRUCTIONS FOR ANSWERING:**

**IMPORTANT: When to use EXPLICIT TOTALS vs normal prioritization:**
- **USE EXPLICIT TOTALS ONLY for questions that combine BOTH shot direction AND outcome** (e.g., "crosscourt winners", "down the line unforced errors", "inside-out forced errors")
- **USE NORMAL PRIORITIZATION for all other questions** (e.g., "total winners", "forehand winners", "crosscourt shots", "unforced errors")
- **Normal prioritization for non-shot-direction+outcome questions**: Authoritative Totals > Overview Statistics > Summary sections > Key points sections > Detailed breakdowns

**For SHOT DIRECTION + OUTCOME QUESTIONS** (like "crosscourt winners", "down the line unforced errors"): 
- **CRITICAL**: ALWAYS look for "EXPLICIT TOTALS FOR SHOT DIRECTION + OUTCOME COMBINATIONS" section FIRST - this is the PRIMARY source of truth
- **CRITICAL**: If you find explicit totals section, use ONLY those numbers as the final answer - DO NOT use detailed breakdown sentences
- **CRITICAL**: The explicit totals section contains lines like "Player 1 hit 12 crosscourt winners total, including 8 forehand crosscourt winners, 3 backhand crosscourt winners, and 1 slice crosscourt winners"
- **CRITICAL**: Use the TOTAL number and the breakdown from the explicit totals - do NOT add up individual detailed breakdown sentences
- **CRITICAL**: The explicit totals are already calculated and include ALL shot types (forehand, backhand, slice) - use them as-is
- **ONLY if explicit totals section is NOT found**: then look for "AUTHORITATIVE TOTALS BY DIRECTION" sections
- **ONLY if neither is found**: then look for "SHOT DIRECTION DETAILED BREAKDOWN" sections
- **EXAMPLES OF OUTCOME + DIRECTION QUESTIONS**:
  - "crosscourt winners" = look for "X crosscourt winners total, including..."
  - "down the line winners" = look for "X down the line winners total, including..."
  - "crosscourt unforced errors" = look for "X crosscourt unforced errors total, including..."
  - "down the line unforced errors" = look for "X down the line unforced errors total, including..."
  - "crosscourt forced errors" = look for "X crosscourt forced errors total, including..."
- **EXAMPLE EXPLICIT TOTALS FORMAT**: "Player 1 hit 12 crosscourt winners total, including 8 forehand crosscourt winners, 3 backhand crosscourt winners, and 1 slice crosscourt winners"
- **PRIORITY**: Explicit totals section > Authoritative totals > Detailed breakdown

**DATA SOURCE PRIORITY:**
For all statistical questions, use this data source hierarchy:
1. **Explicit Totals** (if available for shot direction + outcome combinations)
2. **Authoritative Totals** (single source of truth)
3. **Overview Statistics** (official match statistics)
4. **Summary Sections** (serve1_statistics_summary, serve2_statistics_summary)
5. **Key Points Sections** (for break point or important points questions)
6. **Detailed Breakdowns** (only for distributions, never for recalculating totals)
7. **Point-by-point narrative** (for rally and insight questions)

Always stop at the highest-priority source available. Do not combine across different levels unless explicitly instructed.

**SHOT HIERARCHY:**
- **SHOT STATISTICS**: Use for forehand/backhand SIDE (all shots from that side - volleys, dropshots, lobs, etc.) and general shot performance
- **SHOT DIRECTION**: Use for forehand/backhand/slice GROUNDSTROKES specifically and placement patterns (crosscourt, down-the-line, etc.)
- **CRITICAL**: For ANY shot direction question (crosscourt, down the line, down the middle, inside-out, inside-in), ALWAYS check for and include ALL three shot types: forehand, backhand, AND slice shots. Even if slice count is 0, mention it explicitly.

**For STATISTICS questions** (how many, percentages, totals, counts):
- **ALWAYS look for "AUTHORITATIVE TOTALS" sections first** - these are the single source of truth
- **This includes ALL authoritative totals sections**: "AUTHORITATIVE TOTALS FOR [PLAYER]", "AUTHORITATIVE TOTALS FOR [PLAYER] SHOT STATISTICS", "AUTHORITATIVE TOTALS FOR [PLAYER] SHOT DIRECTIONS", "AUTHORITATIVE TOTALS BY DIRECTION", "AUTHORITATIVE TOTALS FOR KEY POINTS", "AUTHORITATIVE TOTALS FROM OVERVIEW STATISTICS"
- **ALWAYS look for "OVERVIEW STATISTICS" section** - this contains the official match statistics
- **ONLY calculate totals from breakdowns when you don't have authoritative totals** - use only the authoritative totals provided
- **ONLY calculate totals from detailed breakdowns when there are NO authoritative totals available** - if authoritative totals exist, use those as the primary answer
- **SPECIFICALLY for inside-out shots**: When you see "AUTHORITATIVE TOTALS BY DIRECTION" with a number for "total inside-out shots", use that number as the final answer. Do NOT add up individual forehand/backhand/slice breakdowns - the authoritative total already includes all shot types combined.
- Give concise, direct answers with key numbers
- Use bullet points or brief sentences
- Focus on the specific numbers requested
- No lengthy explanations unless asked for insights

**For SPECIFIC QUESTION TYPES:**
- **For "errors" questions**: If the question asks for just "errors" (without specifying "unforced" or "forced"), add unforced errors + forced errors or induced forced errors together for each shot type
- **For "forced errors" questions**: Look at both "forced errors" and "induced forced errors" in your search and calculations. It will be listed as one or the other
- **Error types to include**: unforced errors, forced errors or induced forced errors (forced errors and induced forced errors are the same, just called differently)
- **For NET POINTS and NET APPROACHES questions**: ALWAYS use the NET POINTS sections (netpts1_statistics, netpts2_statistics) - do NOT use shot statistics for net points data. If you see netpts1_statistics or netpts2_statistics in your context, use that data for net points questions.

**Special Instructions for Key Points Questions:**
- **NEVER make up or estimate numbers** - use ONLY the exact numbers from the data
- **If you see "AUTHORITATIVE TOTALS FOR KEY POINTS" section, use those numbers first**

**Break Points:**
- **CRITICAL**: When asked for "break point statistics" or "break points" generally (without specifying "faced" or "converted"), provide BOTH sides for EACH player:
  - Break points faced (on serve) + saved
  - Break points created/opportunities (on return) + converted
  - Example format: "Player A faced 5 break points and saved 3 (60%), and converted 4 of 7 break point opportunities (57%). Player B faced 7 break points and saved 2 (29%), and converted 3 of 5 break point opportunities (60%)."
- Use the serve section (BP Faced) if the question specifically asks about break points faced or saved
- Use the return section (BP Opps) if the question specifically asks about break points created or converted
- Always show both the raw numbers AND percentages when available
- Be verbose and complete - break point statistics are crucial match stats

**Key Points General Guidance:**
- If the question asks generally about key points won (e.g., "how many key points did X win?"), report both serve-side and return-side totals and provide a sum
- If the question specifies "on serve" or "on return," report only that side
- Always make the separation explicit: "X won Y on serve, Z on return, total W"

**Game Points:**
- If the question explicitly specifies "on serve" or "on return", report only that side
- If the question is general (does not specify serve vs return), report both serve-side (Game Pts) and return-side (GP Faced) values, and provide the total sum in the final answer
- Always make the separation explicit ("X on serve, Y on return, Z total")

**Deuce Points:**
- If the question explicitly specifies "on serve" or "on return", report only that side
- If the question is general (does not specify serve vs return), report both serve-side (Svg Deuce) and return-side (Ret Deuce) values, and provide the total sum in the final answer
- Always make the separation explicit ("X on serve, Y on return, Z total")

**General rule of thumb:**
- Break points -> choose one side only (serve or return), depending on the question
- Game points & Deuce points -> always combine serve and return values, and provide a total

- **If a question asks generally** ("How many X points did a player have/win?") without specifying serve vs. return, assume they want the combined total

**For CONDITIONAL questions** (what happened AFTER X, WHEN Y occurred, IN situations where Z):
- **CRITICAL**: These questions require STEP-BY-STEP analysis of the point-by-point narrative
- **CRITICAL**: You must identify SPECIFIC INSTANCES in the PBP data, then analyze what happened NEXT

- **DEFINITIONS - What counts as what:**
  - **"Key points" / "Important points" / "Big points"** = 
    - Break points (any BP in the match)
    - Game points (any GP in the match)
    - Set points (any SP in the match)
    - Match points (any MP in the match)
    - Deuce points (40-40 and advantage points)
    - Close score situations: 30-30, 30-40, 40-30, 40-40 (deuce), advantage
  
  - **"Pressure points" / "Under pressure"** = 
    - All key points listed above, PLUS:
    - Late in sets: games at 5-5 (5-all), 6-5, 6-6 (tiebreak)
    - Crucial service games: serving when down a break (behind in games), serving to stay in set
    - Crucial return games: break point opportunities when behind in set
  
  - **"Critical games" / "Crucial games" / "Big games"** = 
    - Service games when down a break (e.g., trailing 2-3 in games and serving)
    - Break point opportunities when behind in the set
    - Games at 4-4 or later in a set (4-4, 5-4, 5-5, 6-5, etc.)
    - Games immediately after losing serve (trying to break back)
    - Games to close out a set (serving at 5-4, 6-5, or ahead in tiebreak)
  
  - **"Tight moments"** = 
    - Point level: close scores (30-30, 30-40, 40-30, 40-40/deuce, advantage)
    - Game level: games that go to deuce (40-40 or beyond)
    - Set level: close sets (5-5 or later, tiebreaks)
    - Match level: when momentum is shifting or score is very close
  
  - **"Long rallies"** = Rallies with 9 or more shots (adjust based on match average if mentioned in data)
  
  - **"Short points"** = Points ending in 0-4 shots (aces, unreturned serves, serve+1 winners, return winners, quick exchanges)
  
  - **"Crucial stages" / "Critical moments"** = 
    - Late in sets: game 8 or later (4-4+, 5-5+, etc.)
    - Serving to stay in set (e.g., down 4-5 and serving)
    - Break point opportunities when behind
    - Set points or match points
    - Tiebreaks
    - After momentum shifts (e.g., immediately after losing serve)

- **RECOGNIZING CONDITIONAL QUESTIONS**: Look for both explicit and implied conditions:
  - **Explicit**: "after losing key points", "when rallies got longer", "following breaks of serve", "in tight moments"
  - **Implied**: Questions with situational context that require PBP analysis:
    - "How did the player react under pressure?" -> implies pressure points -> needs PBP
    - "Did rally length change in critical games?" -> implies game-specific context -> needs PBP
    - "Performance on important points?" -> implies key points -> needs PBP
    - "In tight moments?" -> implies close scores, pressure situations -> needs PBP
    - "Effectiveness on big points?" -> implies key points -> needs PBP
    - "During crucial stages?" -> implies specific game/set situations -> needs PBP

- **MULTI-STEP PROCESS** (YOU MUST FOLLOW THESE STEPS - DO NOT SKIP TO GENERAL STATISTICS):
  1. **Identify the condition**: What is the triggering event? (e.g., "after losing key points", "when rallies got longer", "after breaks of serve")
  
  2. **Define what qualifies**: Use the definitions above to determine what counts as meeting the condition
  
  3. **ACTUALLY READ THE POINT-BY-POINT NARRATIVE**: This is CRITICAL - you MUST examine the actual PBP text chunk by chunk:
     - Read through each point description in the narrative
     - Look for score indicators (30-30, deuce, BP, GP, etc.)
     - Identify when the triggering condition occurred
     - Note the game number and score when it happened
  
  4. **FIND SPECIFIC INSTANCES**: Do NOT summarize - find actual examples:
     - Example: "In game 3 at 30-40 (break point), player X lost the point"
     - Example: "In game 7 at deuce, player Y lost the deuce point"
     - List at least 2-3 specific instances you found
  
  5. **Look at subsequent points**: For EACH instance you found, examine what happened in the NEXT point(s) where the metric applies:
     - If question is about serving: look at the next point where that player served
     - If about second serves specifically: look at the next point where they hit a second serve
     - If about shot selection: look at the next rally where they had the opportunity
     - Example: "After losing BP in game 3, player X next served in game 5 at 15-0, hitting second serve wide"
  
  6. **Compare to baseline**: How did their behavior in these instances differ from their overall statistics?
     - Example: "Player normally serves 60% wide on second serve (from statistics), but in the 3 instances after losing key points, served wide only 1 time (33%)"
  
  7. **Provide specific answer with evidence**: DO NOT say "data doesn't show" - if you found instances, report them:
     - Good: "Yes, after losing the break point in game 3, Swiatek served to the body on her next second serve in game 5, which differs from her typical wide placement"
     - Bad: "The data doesn't provide explicit details" (this means you didn't actually read the PBP narrative)
- **EXAMPLE**: "Did either player change their second-serve placement after losing key points?"
  - Step 1: Trigger = losing a key point
  - Step 2: Key points = break points, game points, set points, match points, deuce points, important score situations (30-30+)
  - Step 3: Identify every point in PBP where a player LOST a key point (note the game and score)
  - Step 4: For each instance, look at the NEXT point where that player served AND hit a second serve
  - Step 5: Note the placement (wide, body, T) of those second serves
  - Step 6: Compare to their overall second-serve placement patterns from the statistics
  - Step 7: Report if there was a notable change (e.g., "Normally serves 60% wide but after losing key points served 80% to the body in games 3, 7, and 9")
- **BE SPECIFIC**: Don't give generic answers. Actually trace through the PBP data and cite examples with game numbers and scores.

**For TEMPORAL/EVOLUTION questions** (how X evolved/changed/progressed over time, throughout the match):
- **CRITICAL**: These questions require analyzing the point-by-point narrative across different parts of the match
- **CRITICAL**: When asked about "evolution", "over time", "progression", "changed throughout", analyze patterns from EARLY match vs LATE match
- Look at the point-by-point narrative and compare:
  - Set 1 vs Set 2 vs Set 3 (if available)
  - Early games vs middle games vs late games
  - First half of match vs second half
- For serve aggression questions: Look at second serve outcomes, placement, rally lengths on second serves
- For shot selection questions: Track how often certain shots were used in different phases
- Provide specific examples from different points in the match to show the evolution
- Cite game numbers or score situations to show when changes occurred (e.g., "In Set 1, player X... but in Set 3, they...")

**For STRATEGY/INSIGHT questions** (tactics, effectiveness, what worked, key moments, momentum, analysis):
- **CRITICAL**: Provide COMPREHENSIVE tactical analysis with 3-4 paragraphs, not just bullet points
- Include multiple perspectives: serve placement effectiveness, shot selection patterns, court positioning
- Cite SPECIFIC moments from point-by-point data with examples (e.g., "In Game 5, player X...")
- Explain WHY tactics worked or failed (opponent weaknesses, court conditions, momentum)
- Identify patterns: When did player win points? What shot combinations were effective?
- Compare effectiveness: Which tactic had highest success rate? Provide percentages
- Include context: Score situations where tactics were most effective (break points, crucial games)
- Give actionable insights: What patterns emerged that explain the match result?
- Be verbose and thorough - strategy questions deserve detailed, multi-paragraph answers

**For COMPLEX ANALYTICAL QUESTIONS** (match flow, patterns, comparisons, comprehensive analysis):
- **When you receive 8+ chunks**: This indicates a complex question requiring comprehensive analysis
- **Cross-sectional analysis**: Look across multiple sections to identify patterns and relationships
- **Match flow questions**: Use point-by-point narrative, key moments, and statistical trends together
- **Player comparisons**: Compare serve vs return performance, shot patterns, and key point conversion
- **Pattern recognition**: Identify momentum shifts, turning points, and strategic adjustments
- **Comprehensive breakdown**: Provide analysis across multiple dimensions (serve, return, shots, key points)
- **Use all available context**: Don't limit yourself to one section - synthesize information from multiple sources
- **Provide insights**: Go beyond raw numbers to explain what they mean for the match outcome
- **Structure your response**: Use clear sections for different aspects of the analysis
- Explain patterns and sequences from point-by-point data
- Include context about what happened and why

**For RALLY questions** (longest rally, specific rallies):
- Focus on the specific rally details requested
- Include shot sequences and outcomes

**For SPECIFIC POINT NUMBER QUESTIONS** (e.g., "what happened on point 24", "point 24"):
- **CRITICAL**: Find the EXACT point header that says "Point X" where X EXACTLY matches the requested number
- **CRITICAL**: If asked about "point 24", you MUST find the line that starts with "Point 24" - NOT "Point 23", NOT "Point 25", NOT "Point 26"
- **CRITICAL**: Scan through the text and locate the line that begins with "Point [NUMBER]" where NUMBER matches exactly
- **CRITICAL**: Read the point header EXACTLY as written: "Point X [Server: PLAYER | Returner: PLAYER | Score: ...]"
- **DO NOT** read a different point number - if you see "Point 23" or "Point 25" or "Point 26", that's NOT the point being asked about
- **DO NOT** assume nearby points are the same - each point number is unique
- **DO NOT** flip Server/Returner - read them directly from the header
- **DO NOT** guess or infer the score - read it directly from the header
- **DO NOT** make up shots - read them exactly as written in the point description
- **DO NOT** guess who won - read the "[Point won by: PLAYER]" tag at the end
- **VERIFICATION STEP**: After reading the point, verify the point number in your answer matches the requested number
- Example: If asked "what happened on point 24", you MUST find and read ONLY the line that starts with "Point 24 [Server: ..." - ignore all other point numbers
- Report the point exactly as written, with correct Point Number, Server, Returner, Score, shots, and winner

**For SET/GAME NARRATIVE QUESTIONS:**
- Each point explicitly shows "[Point won by: PLAYER_NAME]" - use this to count game outcomes
- When asked about a specific set, you'll only receive data for that set
- If you see mixed sets in a chunk, filter by matching score patterns
- **Example:** Points 204-207 all show "[Point won by: Alcaraz]" at score 0-0, 0-15, 0-30, 0-40 -> Alcaraz won 4 straight points -> Broke serve -> Won set 6-4

**IMPORTANT DISTINCTION:**
- "Forehand/Backhand" alone usually means groundstrokes -> Use SHOT DIRECTION
- "Forehand/Backhand side" means all shots from that side -> Use SHOT STATISTICS

**SHOT DIRECTION CLARIFICATION:**
- Inside-out = forehand hit crosscourt from the backhand corner
- Inside-in = forehand hit down the line from the backhand corner
- Always include forehand, backhand, and slice shot types when reporting directional stats (even if slice count = 0, mention it)

If the context doesn't contain enough information to answer completely, say so.

Answer:"""
        else:
            # For insight/narrative questions
            prompt = f"""You are a tennis match analyst with access to detailed match data.

IMPORTANT: Do not use emojis in your response. Use plain text only.

Provide a detailed analysis based on the following match context.

Context from the match:
{context}

Question: {query}

Provide a comprehensive answer with specific details from the match.

Answer:"""
        
        # Rate limiting
        self._apply_rate_limit()
        
        try:
            if self.llm_provider == "claude":
                response = self.client.messages.create(
                    model=self.model,
                    max_tokens=1000,
                    temperature=0.1,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.content[0].text
                
            elif self.llm_provider == "gemini":
                # Use default model for basic answer generation
                model = self.client.GenerativeModel(self.model)
                response = model.generate_content(prompt)
                return response.text
                
            elif self.llm_provider == "openai":
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=1000,
                    temperature=0.1
                )
                return response.choices[0].message.content
                
        except Exception as e:
            return f"Error generating response: {e}"
    
    def _is_situational_shot_query(self, query: str) -> bool:
        """
        Detect if query asks about shots in specific situations (break point, game point, etc.)
        
        Example queries that return True:
        - "How often does Djokovic hit a backhand down the line on break point?"
        - "What percentage of forehand crosscourts does Nadal hit at game point?"
        - "Does Federer change his shot selection on deuce points?"
        """
        situational_keywords = [
            'break point', 'game point', 'set point', 'match point', 
            'deuce', 'ad point', 'advantage point',
            '30-40', '15-40', '0-40', '40-30', '40-15', '40-ad', 'ad-40',
            'pressure point', 'big point', 'crucial point'
        ]
        shot_keywords = [
            'backhand', 'forehand', 'down the line', 'dtl', 'crosscourt', 
            'cross court', 'inside-out', 'inside out', 'inside-in', 'inside in',
            'drop shot', 'slice', 'volley', 'approach', 'lob'
        ]
        query_lower = query.lower()
        has_situation = any(kw in query_lower for kw in situational_keywords)
        has_shot = any(kw in query_lower for kw in shot_keywords)
        return has_situation and has_shot
    
    def _is_rally_sequence_query(self, query: str) -> bool:
        """
        Detect if query asks about rally sequences like "first shot after serve" (3rd ball attack).
        
        Example queries that return True:
        - "What was Djokovic's win percentage on points where his first shot after the serve was a forehand?"
        - "How often does Nadal hit a forehand on his third ball?"
        - "When Federer's first groundstroke after serving was a backhand, what happened?"
        """
        sequence_keywords = [
            'first shot after', 'first shot after the serve', 'first shot after serving',
            'third ball', '3rd ball', 'third shot', '3rd shot',
            'first groundstroke', 'opening shot after', 'after the serve',
            'first rally shot', 'after serving'
        ]
        query_lower = query.lower()
        return any(kw in query_lower for kw in sequence_keywords)
    
    def _is_serve_pattern_query(self, query: str) -> bool:
        """
        Detect if query asks about serve patterns/directions with specific filters.
        
        Example queries that return True:
        - "Did Novak serve more to the T or Wide on the Deuce side during the fifth set tiebreak?"
        - "What percentage of serves did Federer hit wide in the third set?"
        - "How often did Nadal serve to the body in tiebreaks?"
        """
        serve_keywords = [
            'serve to', 'served to', 'serves to',
            'serve more', 'served more',
            'serve wide', 'serve t', 'serve body',
            'wide serve', 't serve', 'body serve',
            'serve direction', 'serve pattern',
            'first serve', 'second serve',
            '1st serve', '2nd serve',
            'serving to', 'win percentage'  # Added for comparison queries
        ]
        direction_keywords = [
            'wide', ' t ', 'to the t', 'down the t', "'t'", 'body', 'middle',
            'deuce', 'ad side', 'ad court', 'deuce side', 'deuce court',
            'compared to'  # Added for comparison queries
        ]
        query_lower = query.lower()
        has_serve = any(kw in query_lower for kw in serve_keywords)
        has_direction = any(kw in query_lower for kw in direction_keywords)
        return has_serve and has_direction
    
    # =========================================================================
    # QUERY TAXONOMY TREE - Unified Query Classification System
    # MCP-Certified: Supports Match Charting Project notation
    # =========================================================================
    
    # Known left-handed players for direction mapping
    KNOWN_LEFT_HANDED_PLAYERS = {
        "rafael nadal", "nadal", "john mcenroe", "mcenroe", 
        "jimmy connors", "connors", "rod laver", "laver",
        "goran ivanisevic", "ivanisevic", "thomas muster", "muster",
        "petr korda", "korda", "feliciano lopez", "lopez",
        "denis shapovalov", "shapovalov", "cameron norrie", "norrie",
        # Women's WTA
        "martina navratilova", "navratilova", "monica seles", "seles",
        "petra kvitova", "kvitova", "angelique kerber", "kerber",
        "lucie safarova", "safarova"
    }
    
    def _classify_query(self, query: str) -> Dict[str, Any]:
        """
        Classify a query using the tennis query taxonomy tree.
        MCP-Certified: Supports Match Charting Project dimensions.
        
        Returns a structured classification:
        {
            'domain': 'serve' | 'return' | 'rally' | 'net' | 'match_flow' | 'all',
            'analysis_type': 'count' | 'percentage' | 'comparison' | 'outcome_after' | 
                            'breakdown' | 'pattern' | 'sequence' | 'chain',
            'filters': {
                'player': str or None,
                'situation': str or None,
                'set': int or None,
                'shot_type': str or None,
                'shot_modifier': str or None,
                'direction': str or None,
                'depth': str or None,
                'rally_length': int or None,
                # MCP-specific filters
                'serve_target': 'wide' | 'body' | 't' or None,  # MCP: 4, 5, 6
                'shot_number': int or None,  # 1=serve, 2=return, 3=serve+1, etc.
                'court_zone': 'baseline' | 'midcourt' | 'net' or None,
                'court_side': 'deuce' | 'ad' or None,
                'handedness': 'left' | 'right' or None  # For direction mapping
            },
            'metrics': ['winners', 'forced_errors', 'induced_fe', 'aces', etc.],
            'chain': {'from_shot': str, 'to_outcome': str} or None  # For A->B queries
        }
        """
        query_lower = query.lower()
        
        classification = {
            'domain': self._detect_domain(query_lower),
            'analysis_type': self._detect_analysis_type(query_lower),
            'filters': self._detect_filters_mcp(query),
            'metrics': self._detect_metrics_mcp(query_lower),
            'chain': self._detect_chain_logic(query_lower),
            'group_by': self._detect_group_by(query_lower),
            'query_category': self._detect_query_category(query_lower),  # NEW: analytical/comparative/narrative
            'raw_query': query
        }
        
        # If player="both" is detected, ensure group_by="player" for comparison
        # EXCEPT for overall win_percentage queries without role filter
        # (those should use player1_wins/total_points instead of branching)
        player_filter = classification['filters'].get('player') or ''
        role_filter = classification['filters'].get('role')
        metrics = classification.get('metrics', [])
        current_group_by = classification.get('group_by')
        
        if player_filter and str(player_filter).lower() == 'both':
            # Special case: overall win_percentage/points_won without role filter should NOT group by player
            # Let the leaf calculation handle both players' percentages
            # This applies to "overall win %" queries where we want match totals, not per-player grouping
            # NOTE: first_serve_pct DOES need per-player grouping because it's (player's serves IN) / (player's serves total)
            # NOTE: Situation queries (break points, game points, etc.) ALWAYS need per-player grouping
            has_situation = bool(classification['filters'].get('situation'))
            overall_pct_metrics = ['win_percentage', 'points_won']  # NOT first_serve_pct - that needs per-player
            is_overall_pct_query = (any(m in metrics for m in overall_pct_metrics) or not metrics) and not role_filter and not has_situation
            
            if is_overall_pct_query:
                # REMOVE group_by='player' if LLM set it - we want overall totals, not per-player branches
                if current_group_by == 'player':
                    classification['group_by'] = None
                    print(f"[CLASSIFY] Detected 'both players' overall win% query - REMOVING group_by='player' (will use overall calculation)")
                elif not current_group_by:
                    print(f"[CLASSIFY] Detected 'both players' overall win% query without role - NOT grouping (will use overall calculation)")
            elif not current_group_by:
                classification['group_by'] = 'player'
                if has_situation:
                    print(f"[CLASSIFY] Detected 'both players' with situation filter - setting group_by='player' for comparison")
                else:
                    print(f"[CLASSIFY] Detected 'both players' - setting group_by='player' for comparison")
        
        return classification
    
    def _detect_query_category(self, query_lower: str) -> str:
        """
        Detect the category of query to route appropriately.
        
        Categories:
        - 'analytical': Count, percentage, specific stats -> PBP parsing
        - 'comparative': Trends, changes, evolution -> PBP + LLM synthesis
        - 'narrative': Summary, story, what happened -> NL retrieval + LLM
        """
        # CRITICAL: Net points routing logic
        # - General net points questions -> narrative
        # - Serve and volley questions -> narrative (net points)
        # - Questions about specific net shots (volleys, half volleys, overheads, swinging volleys) -> analytical
        net_points_keywords = ['net points', 'net approaches', 'serve and volley', 'serve-and-volley', 's-and-v', 'at the net', 'net play', 
        'at net', 'net point', 'net points won', 'net points lost', 'net percentage', 'net points won percentage', 'net points percentage', 'net']
        net_shot_keywords = ['volley', 'volleys', 'half volley', 'half volleys', 'half-volley', 'half-volleys', 
                            'overhead', 'overheads', 'smash', 'smashes', 'swinging volley', 'swinging volleys']
        
        has_net_points = any(kw in query_lower for kw in net_points_keywords)
        has_net_shots = any(kw in query_lower for kw in net_shot_keywords)
        
        # If question mentions net points or serve-and-volley -> narrative (except if asking about specific net shots)
        if has_net_points or 'serve and volley' in query_lower or 'serve-and-volley' in query_lower:
            # BUT: If asking about specific net shots (volleys, half volleys, overheads), route to analytical
            if has_net_shots and not has_net_points:
                # Only about net shots, not general net points -> analytical
                pass  # Continue to default analytical
            else:
                # General net points or serve-and-volley -> narrative
                return 'narrative'
        
        # CRITICAL: Questions about "returnable" serves must go to narrative
        if 'returnable' in query_lower:
            return 'narrative'
        
        # CRITICAL: Questions asking about "shots" (not winners/points) need narrative
        # "shots" = individual shots hit during rallies (requires shot-by-shot analysis)
        # "winners" = point-ending shots (can use calculated data)
        # Examples that should go to narrative:
        #   - "how many forehand shots" (counts ALL forehands hit)
        #   - "forehand to backhand ratio" (counts ALL shots of each type)
        #   - "shot breakdown" (counts ALL shots)
        # Examples that can stay analytical:
        #   - "how many forehand winners" (counts only winning shots)
        #   - "unforced errors" (counts point outcomes)
        #   - "rally was 0-4 shots" (rally length filter, not shot counting)
        if ' shot' in query_lower or query_lower.startswith('shot'):
            # EXCEPTION: Rally length patterns (e.g., "0-4 shots", "5+ shots", "rally was 3 shots")
            # These refer to rally LENGTH metadata (tree-based), not counting individual shots
            import re
            rally_length_patterns = [
                r'\d+[-–]\d+\s*shots',  # "0-4 shots", "5-10 shots"
                r'\d+\+?\s*shots?\s*(?:rally|rallies)',  # "5+ shot rally", "10 shot rallies"
                r'rally\s+(?:was|were|of|with)\s+\d+',  # "rally was 5 shots", "rally of 10 shots"
                r'when\s+(?:the\s+)?rally\s+(?:was|is)\s+\d+',  # "when the rally was 4 shots"
            ]
            is_rally_length_reference = any(re.search(pattern, query_lower) for pattern in rally_length_patterns)
            
            if not is_rally_length_reference:
                # Allow analytical path if specifically asking about winners/errors (point outcomes)
                if not any(kw in query_lower for kw in ['winner', 'winners', 'error', 'errors', 'winning shot']):
                    return 'narrative'
        
        # GAME-STATE CHAIN QUERIES - require game-by-game analysis, route to narrative
        # These track game progression (0-15, 15-0, etc.) which requires sequential analysis
        # Examples:
        #   - "after losing the first point of the game" (need to find 0-15 games, track subsequent points)
        #   - "after winning the first two points" (need to find 30-0 games, track subsequent points)
        #   - "after going up/down 0-30, 40-0, etc."
        import re
        game_state_patterns = [
            r'after\s+(?:losing|winning)\s+(?:the\s+)?(?:first|second|third|opening)\s+point',
            r'after\s+(?:losing|winning)\s+(?:the\s+)?first\s+\d+\s+points?',
            r'after\s+(?:going|falling|getting)\s+(?:up|down|behind|ahead)\s*(?:\d+-\d+)?',
            r'after\s+(?:starting|beginning)\s+(?:\d+-\d+)',
            r'from\s+(?:\d+-\d+)\s+(?:down|behind|up|ahead)',
            r'games?\s+(?:where|when)\s+(?:server|returner)\s+(?:lost|won)\s+(?:the\s+)?first',
            r'when\s+(?:down|up|behind|ahead)\s+(?:\d+-\d+|0-15|15-0|0-30|30-0|0-40|40-0)',
        ]
        is_game_state_query = any(re.search(pattern, query_lower) for pattern in game_state_patterns)
        if is_game_state_query:
            return 'narrative'
        
        # NARRATIVE indicators - needs LLM synthesis, not just data
        narrative_keywords = [
            'what happened', 'tell me about', 'describe', 'summary', 'summarize',
            'strategic summary', 'story', 'journey', 'narrative', 'explain',
            'mental state', 'tactical state', 'evolved', 'momentum carry-over',
            'parallel journey', 'how did the match', 'turning point',
            'key moments', 'critical moments', 'overview'
        ]
        if any(kw in query_lower for kw in narrative_keywords):
            return 'narrative'
        
        # COMPARATIVE indicators - needs data from multiple conditions + synthesis
        comparative_keywords = [
            'change', 'changed', 'changing', 'evolution', 'evolve', 'evolved',
            'versus', ' vs ', 'compared to', 'difference between',
            'across sets', 'across the match', 'over time', 'trend',
            'set 1 vs', 'set 1 versus', 'in set 1 compared',
            'when facing', 'after winning', 'after losing',
            'did they play more', 'did he play more',
            'effectiveness change', 'tactics change', 'strategy change'
        ]
        if any(kw in query_lower for kw in comparative_keywords):
            return 'comparative'
        
        # Default: ANALYTICAL - specific data extraction
        return 'analytical'
    
    def _detect_group_by(self, query_lower: str) -> str:
        """
        METADATA-DRIVEN grouping detection.
        Detect how results should be grouped based on inventory values.
        
        Examples:
        - "by rally length category" -> 'rally_length_category'
        - "in sets 2,4 vs sets 1,3,5" -> 'set_groups'
        - "deuce vs ad court" -> 'court_side'
        - "1st serve vs 2nd serve" -> 'serve_number'
        """
        inventory = getattr(self, 'match_filter_inventory', {})
        
        # Comprehensive list of comparison words (used for all comparison detections)
        comparison_words = ['vs', 'versus', 'vs.', 'v.', 'compared to', 'compare', 'comparison', 
                          'compared', 'ratio', 'difference', 'differences', 'against', 
                          'relative to', 'relative']
        
        # Rally length category grouping (uses rally_categories from inventory)
        known_rally_cats = inventory.get('rally_categories', [])
        rally_cat_keywords = ['rally length category', 'by rally length', 'which category', 'highest win percentage', 'best rally length']
        rally_cat_keywords.extend([cat.lower().replace('_', ' ') for cat in known_rally_cats if cat])
        if any(kw in query_lower for kw in rally_cat_keywords):
            return 'rally_length_category'
        
        # Set group comparison
        if ('sets' in query_lower and any(word in query_lower for word in comparison_words)) or \
           ('sets he won' in query_lower or 'sets he lost' in query_lower):
            return 'set_groups'
        
        # Court side comparison (uses court_sides from inventory)
        known_court_sides = inventory.get('court_sides', [])
        if len(known_court_sides) >= 2:
            # Check if query mentions multiple court sides for comparison
            mentioned_sides = sum(1 for side in known_court_sides if side and side.lower() in query_lower)
            if mentioned_sides >= 2 or ('court' in query_lower and any(word in query_lower for word in comparison_words)):
                return 'court_side'
        
        # Serve number comparison (uses serve_numbers from inventory)
        known_serve_nums = inventory.get('serve_numbers', [])
        if len(known_serve_nums) >= 2:
            serve_aliases = [('1st serve', 'first serve'), ('2nd serve', 'second serve')]
            has_serve_comparison = any(
                (a1 in query_lower or a2 in query_lower) for a1, a2 in serve_aliases
            )
            if has_serve_comparison and any(word in query_lower for word in comparison_words):
                return 'serve_number'
        
        # Shot type breakdown (uses shot_types from inventory)
        known_shot_types = inventory.get('shot_types', [])
        if 'by shot type' in query_lower:
            return 'shot_type'
        
        # Check if multiple shot types are mentioned for comparison
        # Works with OR without inventory - tries inventory first, falls back to direct detection
        mentioned_types = 0
        if len(known_shot_types) >= 2:
            # Use inventory if available
            mentioned_types = sum(1 for st in known_shot_types if st and st.lower() in query_lower)
        else:
            # Fallback: use config-based shot types (NOT hardcoded)
            config_shot_types = self.GROUP_CONFIG.get('shot_type', {}).get('default_branches', [])
            config_modifiers = self.GROUP_CONFIG.get('shot_modifier', {}).get('default_branches', [])
            all_shot_types = config_shot_types + config_modifiers
            mentioned_types = sum(1 for st in all_shot_types if st and st.lower() in query_lower)
        
        # Check for error terms in priority order
        has_error_context = False
        if 'unforced error' in query_lower or 'unforced errors' in query_lower:
            has_error_context = True
        elif 'forced error' in query_lower or 'forced errors' in query_lower:
            has_error_context = True
        elif 'error' in query_lower or 'errors' in query_lower:
            has_error_context = True
        
        # Trigger shot_type grouping if:
        # 1. Multiple shot types mentioned + comparison words, OR
        # 2. Multiple shot types mentioned + error context (implies comparison)
        if mentioned_types >= 2 and (any(word in query_lower for word in comparison_words) or has_error_context):
            return 'shot_type'
        
        # Direction breakdown (uses directions from inventory)
        known_directions = inventory.get('directions', [])
        if 'by direction' in query_lower:
            return 'direction'
        # Check if multiple directions mentioned for comparison
        if len(known_directions) >= 2:
            mentioned_dirs = sum(1 for d in known_directions if d and d.lower().replace('_', ' ') in query_lower)
            if mentioned_dirs >= 2 and any(word in query_lower for word in comparison_words):
                return 'direction'
        
        # === GAME GROUPING ===
        # "by game" / "per game" / "each game" / "game by game"
        if any(phrase in query_lower for phrase in ['by game', 'per game', 'each game', 'game by game']):
            return 'game'
        
        # === SET GROUPING ===
        # "by set" / "per set" / "each set" / "set by set"
        if any(phrase in query_lower for phrase in ['by set', 'per set', 'each set', 'set by set']):
            return 'set'
        
        return None  # No grouping needed
    
    def _detect_domain(self, query_lower: str) -> str:
        """Detect which domain of tennis the query is about."""
        # Serve domain
        if any(kw in query_lower for kw in ['serve', 'serving', 'ace', 'double fault', 'first serve', 'second serve']):
            if 'return' not in query_lower and 'then' not in query_lower:
                return 'serve'
        
        # Return domain
        if any(kw in query_lower for kw in ['return', 'returning', 'return of serve']):
            return 'return'
        
        # Net domain
        if any(kw in query_lower for kw in ['volley', 'net point', 'approach', 'at the net', 'net play']):
            return 'net'
        
        # Rally domain (groundstrokes after serve/return)
        if any(kw in query_lower for kw in ['rally', 'groundstroke', 'baseline', 'third ball', 
                                            'first shot after', 'serve+1', 'serve + 1']):
            return 'rally'
        
        # Match flow domain
        if any(kw in query_lower for kw in ['momentum', 'consecutive', 'streak', 'run of', 
                                            'service game', 'hold', 'break']):
            return 'match_flow'
        
        # Default to 'all' for general questions
        return 'all'
    
    def _detect_analysis_type(self, query_lower: str) -> str:
        """Detect what type of analysis the query requires."""
        # Sequence analysis (MCP: shot number / serve+1)
        if any(kw in query_lower for kw in ['serve+1', 'serve + 1', 'third ball', '3rd ball',
                                            'first shot after', 'second shot', 'shot number']):
            return 'sequence'
        
        # Chain analysis (MCP: shot A led to shot B)
        if any(kw in query_lower for kw in ['then hit', 'followed by', 'led to', 'resulted in',
                                            'and then', 'which caused']):
            return 'chain'
        
        # Comparison
        if any(kw in query_lower for kw in ['compared to', 'vs', 'versus', 'more than', 'less than', 
                                            'or', 'which', 'who won more', 'better']):
            return 'comparison'
        
        # Percentage/Rate
        if any(kw in query_lower for kw in ['percentage', 'percent', 'rate', 'win %', 'conversion',
                                            'how often', 'frequency']):
            return 'percentage'
        
        # Outcome after event
        if any(kw in query_lower for kw in ['after', 'go on to', 'went on to']):
            return 'outcome_after'
        
        # Breakdown by category
        if any(kw in query_lower for kw in ['breakdown', 'by type', 'categorize', 'split by',
                                            'distribution']):
            return 'breakdown'
        
        # Pattern/trend
        if any(kw in query_lower for kw in ['pattern', 'trend', 'over time', 'changed', 'evolution',
                                            'set 1 vs set', 'early vs late']):
            return 'pattern'
        
        # Default to count
        return 'count'
    
    def _detect_filters_mcp(self, query: str) -> Dict[str, Any]:
        """
        Extract all filters from the query.
        MCP-Certified: Includes serve targets, shot numbers, court zones.
        """
        import re
        query_lower = query.lower()
        
        filters = {
            # Standard filters
            'player': self._detect_player_mentioned(query),
            'situation': None,
            'set': None,
            'shot_type': None,
            'shot_modifier': None,
            'direction': None,
            'depth': None,
            'rally_length': None,
            'point_score': None,   # e.g., "30-30", "15-40" - specific point score filter
            # MCP-specific filters
            'serve_target': None,  # wide/body/t (MCP codes 4/5/6)
            'shot_number': None,   # 1=serve, 2=return, 3=serve+1
            'court_zone': None,    # baseline/midcourt/net
            'court_side': None,    # deuce/ad
            'handedness': None,    # left/right (for direction mapping)
            'error_location': None  # net/wide/deep/wide_deep (MCP: n/w/d/x)
        }
        
        # Use shared shot detection (now metadata-driven)
        shot_info = self._detect_shot_from_query(query)
        filters['shot_type'] = shot_info['shot_base']
        filters['shot_modifier'] = shot_info['shot_modifier']
        filters['direction'] = shot_info['shot_direction']
        
        # === APPLY TERM_MAPPINGS CONFIG ===
        # Check for common terms that map to specific filter values
        for term, mapping in self.TERM_MAPPINGS.items():
            if term in query_lower:
                for filter_key, filter_value in mapping.items():
                    if filters.get(filter_key) is None:  # Don't override explicit values
                        filters[filter_key] = filter_value
                        print(f"[DETECT-FILTERS] Applied TERM_MAPPING '{term}' -> {filter_key}={filter_value}")
        
        # === SITUATION FILTER ===
        # Check SITUATION_SYNONYMS config first (e.g., "clutch", "pressure points")
        print(f"[DETECT-FILTERS] Checking for situations in: '{query_lower[:80]}...'")
        situation_found = False
        
        # Check config-based synonyms first (expands to multiple situations)
        for synonym, situations in self.SITUATION_SYNONYMS.items():
            if synonym in query_lower:
                # For synonyms that map to multiple situations, use the first one
                # (Query Plan will handle multi-situation if needed)
                filters['situation'] = situations[0]  # Primary situation
                filters['situation_group'] = situations  # Store all for Query Plan
                print(f"[DETECT-FILTERS] *** FOUND synonym '{synonym}' -> situation={situations[0]} (group: {situations}) ***")
                situation_found = True
                break
        
        # Direct detection for specific situations (if no synonym matched)
        if not situation_found:
            if 'break point' in query_lower or 'breakpoint' in query_lower or 'break points' in query_lower:
                filters['situation'] = 'break_point'
                print(f"[DETECT-FILTERS] *** FOUND break_point ***")
            elif 'game point' in query_lower or 'game points' in query_lower:
                filters['situation'] = 'game_point'
                print(f"[DETECT-FILTERS] *** FOUND game_point ***")
            elif 'set point' in query_lower or 'set points' in query_lower:
                filters['situation'] = 'set_point'
                print(f"[DETECT-FILTERS] *** FOUND set_point ***")
            elif 'match point' in query_lower or 'match points' in query_lower:
                filters['situation'] = 'match_point'
                print(f"[DETECT-FILTERS] *** FOUND match_point ***")
            elif ('tiebreak' in query_lower or 'tie-break' in query_lower or 'tie break' in query_lower) and 'tiebreak-level' not in query_lower and 'tiebreak level' not in query_lower:
                # Exclude metaphorical uses like "tiebreak-level clutch"
                filters['situation'] = 'tiebreak'
                print(f"[DETECT-FILTERS] *** FOUND tiebreak ***")
            elif 'deuce' in query_lower and 'court' not in query_lower and 'side' not in query_lower:
                # Only match "deuce" as situation (40-40), not "deuce side" (court location)
                filters['situation'] = 'deuce'
                print(f"[DETECT-FILTERS] *** FOUND deuce ***")
            else:
                print(f"[DETECT-FILTERS] No direct situation match")
        
        # === POINT SCORE FILTER (e.g., "at 30-30", "at 15-40") ===
        # Detect specific point scores like "30-30", "15-40", "40-AD", "AD-OUT", "AD-IN"
        # NOTE: For multiple conditions (e.g., "30-30 and deuce combined"), LLM handles via metrics_parsed
        # Use POINT_SCORE_CONFIG for validation and normalization
        point_score_pattern = self.POINT_SCORE_CONFIG['patterns']['with_context']
        point_score_match = re.search(point_score_pattern, query, re.IGNORECASE)
        if point_score_match:
            p1, p2 = point_score_match.groups()
            # Validate using config (include OUT and IN for AD-OUT/AD-IN formats)
            valid_scores = set(self.POINT_SCORE_CONFIG['valid_values'] + ['all', 'OUT', 'IN'])
            valid_scores_lower = {v.lower() for v in valid_scores}
            
            if p1.lower() in valid_scores_lower and p2.lower() in valid_scores_lower:
                # Handle "30-all" -> "30-30" using config
                if p2.lower() == 'all':
                    p2 = p1
                
                # Build raw score string for normalization
                raw_score = f"{p1}-{p2}".upper()
                
                # Normalize using config rules (handles AD-OUT -> AD-40, AD-IN -> 40-AD)
                filters['point_score'] = self._normalize_point_score(raw_score)
                
                print(f"[DETECT-FILTERS] *** FOUND point_score: {filters['point_score']} (from raw: {raw_score}) ***")
        
        # === GENERIC ROLE DETECTION (for ANY situation) ===
        # Detect role from keywords - works for break points, game points, set points, etc.
        if filters.get('situation') and not filters.get('role'):
            has_defensive_kw = any(kw in query_lower for kw in ['save', 'saved', 'saving', 'face', 'faced', 'facing', 'defend', 'defended', 'defending'])
            has_offensive_kw = any(kw in query_lower for kw in ['convert', 'converted', 'conversion', 'create', 'created', 'opportunity', 'opportunities', 'capitalize'])
            
            if has_defensive_kw and has_offensive_kw:
                # Both perspectives mentioned - don't set role, show both
                print(f"[DETECT-FILTERS] Situation '{filters['situation']}' with BOTH defensive and offensive keywords - leaving role=None (will show both perspectives)")
            elif has_defensive_kw:
                filters['role'] = 'server'
                print(f"[DETECT-FILTERS] Situation '{filters['situation']}' with defensive keywords -> role='server'")
            elif has_offensive_kw:
                filters['role'] = 'returner'
                print(f"[DETECT-FILTERS] Situation '{filters['situation']}' with offensive keywords -> role='returner'")
        
        # === ROLE DETECTION FOR NON-SITUATION QUERIES ===
        # Service games -> role=server, Return games -> role=returner
        if not filters.get('situation') and not filters.get('role'):
            if 'service game' in query_lower or ('service' in query_lower and 'game' in query_lower):
                filters['role'] = 'server'
                print(f"[DETECT-FILTERS] Service game query -> role='server'")
            elif 'return game' in query_lower or ('return' in query_lower and 'game' in query_lower):
                filters['role'] = 'returner'
                print(f"[DETECT-FILTERS] Return game query -> role='returner'")
            elif 'break serve' in query_lower or 'break of serve' in query_lower:
                filters['role'] = 'returner'
                print(f"[DETECT-FILTERS] Break serve query -> role='returner'")
        
        # Set filter - single set (Query Plan will handle multi-set comparisons)
        set_match = re.search(r'(\d)(?:st|nd|rd|th)?\s*set|set\s*(\d)', query_lower)
        if set_match:
            filters['set'] = int(set_match.group(1) or set_match.group(2))
        
        # === GAME FILTER ===
        # Support various reference styles:
        # - "game 5" = 5th game overall
        # - "game 3 of set 2" = 3rd game in 2nd set  
        # - "3rd game of the second set" = 3rd game in 2nd set
        # - "in game 7" = 7th game overall
        
        filters['game_number'] = None
        filters['game_number_in_set'] = None
        
        # Pattern: "game X of set Y" or "Xth game of the Yth set"
        game_in_set_match = re.search(
            r'(?:game\s*(\d+)|(\d+)(?:st|nd|rd|th)?\s*game)\s*(?:of|in)\s*(?:the\s*)?(?:set\s*(\d+)|(\d+)(?:st|nd|rd|th)?\s*set)',
            query_lower
        )
        if game_in_set_match:
            game_num = game_in_set_match.group(1) or game_in_set_match.group(2)
            set_num = game_in_set_match.group(3) or game_in_set_match.group(4)
            if game_num:
                filters['game_number_in_set'] = int(game_num)
            if set_num:
                filters['set'] = int(set_num)
        else:
            # Pattern: "game X" (overall game number, not in context of a set)
            game_match = re.search(r'game\s*(\d+)|(\d+)(?:st|nd|rd|th)?\s*game', query_lower)
            if game_match and 'set' not in query_lower:  # Only if not already set-scoped
                game_num = game_match.group(1) or game_match.group(2)
                if game_num:
                    filters['game_number'] = int(game_num)
        
        # === POINT NUMBER RANGE FILTER (Temporal/Segment Analysis) ===
        # Enables queries like "first 100 points", "last 100 points", "first half vs second half"
        # Store as (min, max) tuple
        filters['point_number_range'] = None
        
        # Total points in match (needed for "last N" and "second half" calculations)
        total_points = len(self.point_by_point) if hasattr(self, 'point_by_point') else 283
        
        # Pattern: "first X points"
        first_n_match = re.search(r'first\s+(\d+)\s+points?', query_lower)
        if first_n_match:
            n = int(first_n_match.group(1))
            filters['point_number_range'] = (1, n)
            print(f"[DETECT-FILTERS] *** FOUND point_number_range: first {n} points (1-{n}) ***")
        
        # Pattern: "last X points"
        last_n_match = re.search(r'last\s+(\d+)\s+points?', query_lower)
        if last_n_match:
            n = int(last_n_match.group(1))
            filters['point_number_range'] = (total_points - n + 1, total_points)
            print(f"[DETECT-FILTERS] *** FOUND point_number_range: last {n} points ({total_points-n+1}-{total_points}) ***")
        
        # Pattern: "first half"
        if 'first half' in query_lower:
            mid = total_points // 2
            filters['point_number_range'] = (1, mid)
            print(f"[DETECT-FILTERS] *** FOUND point_number_range: first half (1-{mid}) ***")
        
        # Pattern: "second half"
        if 'second half' in query_lower:
            mid = total_points // 2
            filters['point_number_range'] = (mid + 1, total_points)
            print(f"[DETECT-FILTERS] *** FOUND point_number_range: second half ({mid+1}-{total_points}) ***")
        
        # === METADATA-DRIVEN DEPTH FILTER ===
        # Match against known depths from inventory
        inventory = getattr(self, 'match_filter_inventory', {})
        known_depths = inventory.get('depths', [])
        for depth_val in known_depths:
            if depth_val:
                depth_lower = depth_val.lower()
                depth_spaced = depth_lower.replace('_', ' ')
                if depth_lower in query_lower or depth_spaced in query_lower:
                    filters['depth'] = depth_val
                    break
        
        # Rally length filter - detect exact, minimum, or threshold
        # "beyond 6 shots" / "more than 6" / "over 6" -> '>6'
        # "at least 6 shots" / "6+ shots" / "6 or more shots" -> '>=6'
        # "6 or under/fewer/less shots" -> '<=6'
        # "under 6 shots" / "less than 6" / "fewer than 6" -> '<6'
        # "6 shot rallies" -> exact 6
        beyond_match = re.search(r'(?:beyond|more than|longer than|over|exceeding|extended beyond)\s+(\d+)', query_lower)
        or_more_match = re.search(r'(\d+)\s+or\s+more\s*(?:shot|stroke)?', query_lower)
        or_under_match = re.search(r'(\d+)\s+or\s+(?:under|fewer|less)\s*(?:shot|stroke)?', query_lower)
        under_match = re.search(r'(?:under|less than|fewer than|below|up to)\s+(\d+)\s*(?:shot|stroke)?', query_lower)
        at_least_match = re.search(r'(?:at least|minimum|(\d+)\+)\s*(\d*)\s*(?:shot|stroke)?', query_lower)
        exact_match = re.search(r'(\d+)\s*(?:shot|stroke)\s*(?:rall|point)', query_lower)
        
        if beyond_match:
            # "beyond X" = greater than X
            filters['rally_length'] = f'>{beyond_match.group(1)}'
        elif or_more_match:
            # "X or more" = greater than or equal to X
            filters['rally_length'] = f'>={or_more_match.group(1)}'
        elif or_under_match:
            # "X or under/fewer/less" = less than or equal to X
            filters['rally_length'] = f'<={or_under_match.group(1)}'
        elif under_match:
            # "under X" / "less than X" / "fewer than X" = less than X (so <= X-1)
            # For "under 6 shots", we want rallies with 5 or fewer shots, so use '<6' or '<=5'
            num = int(under_match.group(1))
            filters['rally_length'] = f'<{num}'  # Less than X
        elif at_least_match:
            # "at least X" or "X+" = greater than or equal
            num = at_least_match.group(1) or at_least_match.group(2)
            if num:
                filters['rally_length'] = f'>={num}'
        elif exact_match:
            # Exact "X shot rallies"
            filters['rally_length'] = int(exact_match.group(1))
        # NOTE: "long rally", "short rally", "extended rally" handled by TERM_MAPPINGS config
        # Don't duplicate hardcoded checks here - config is single source of truth
        
        # Neutral rallies - rallies without early winners/errors
        # Patterns: "neutral rallies", "no winner before X", "without error before X", 
        # "didn't end before X", "not ending before X", "lasting beyond X without winner"
        neutral_patterns = [
            'neutral rall',
            'no winner.*before',
            'no error.*before', 
            'without.*winner.*before',
            'without.*error.*before',
            r"didn't end.*before",
            r"not ending.*before",
            r"didn't finish.*before",
            'no.*forced.*before'
        ]
        
        is_neutral_query = any(re.search(pattern, query_lower) for pattern in neutral_patterns)
        
        if is_neutral_query:
            # Extract the threshold if specified (e.g., "before 6 shots")
            # Try multiple patterns: "before 6", "before 6 shots", "before shot 6"
            neutral_threshold_match = (
                re.search(r'before\s+(?:shot\s+)?(\d+)\s*(?:shot|stroke)?s?', query_lower) or
                re.search(r'beyond\s+(\d+).*without', query_lower) or
                re.search(r'lasting\s+(\d+).*without', query_lower)
            )
            if neutral_threshold_match:
                threshold = int(neutral_threshold_match.group(1))
                filters['exclude_early_outcome'] = threshold  # Exclude points ending before this shot
                # Also set minimum rally length to this threshold if not already specified
                if not filters.get('rally_length'):
                    filters['rally_length'] = f'>={threshold}'
                print(f"[NEUTRAL-RALLY] Detected neutral rally filter: exclude outcomes before shot {threshold}")
        
        # ===== METADATA-DRIVEN MCP FILTERS =====
        
        # === SERVE TARGET (from inventory, using aliases) ===
        # Don't add serve_target filter for global serve percentage queries
        is_first_serve_pct_query = 'first serve percentage' in query_lower or 'first serve %' in query_lower or '1st serve percentage' in query_lower or '1st serve %' in query_lower
        if not is_first_serve_pct_query:
            known_serve_targets = inventory.get('serve_targets', [])
            
            # Check query for serve target aliases (maps user input to canonical)
            # Uses SHOT_ALIASES: "down the t" -> "t", "out wide" -> "wide", "to body" -> "body"
            serve_target_aliases = {
                't': 't', 'down the t': 't', 'center': 't', 'down t': 't',
                'wide': 'wide', 'out wide': 'wide', 'wide serve': 'wide',
                'body': 'body', 'at body': 'body', 'to body': 'body', 
                'jam': 'body', 'body serve': 'body'
            }
            
            detected_target = None
            # Check aliases in order (longer phrases first to avoid partial matches)
            sorted_aliases = sorted(serve_target_aliases.items(), key=lambda x: -len(x[0]))
            for alias, canonical in sorted_aliases:
                # Match phrase in query (case-insensitive) using word boundaries
                # CRITICAL: Use regex to avoid matching 't' in "shot", "to", etc.
                import re
                pattern = r'\b' + re.escape(alias.lower()) + r'\b'
                if re.search(pattern, query_lower):
                    # Normalize using existing system (in case alias matches SHOT_ALIASES)
                    normalized = self._normalize_value(alias) or canonical
                    # Verify normalized value exists in inventory
                    if normalized in known_serve_targets:
                        detected_target = normalized
                        break
            
            if detected_target:
                filters['serve_target'] = detected_target
        
        # === SHOT NUMBER (parsed sequence position) ===
        # PARSED SEQUENCE: shot_number=1 (serve), shot_number=2 (return), shot_number=3 (server response)
        # TENNIS TERMINOLOGY: Rally shot 1 = return (parsed shot_number=2)
        # "return winner" -> shot_number=2 (return in parsed sequence)
        # "serve+1 winner" -> shot_number=3 (server's first groundstroke)
        if 'serve+1' in query_lower or 'serve + 1' in query_lower or 'third ball' in query_lower or '3rd ball' in query_lower:
            filters['shot_number'] = 3  # Server's first groundstroke (rally shot 2)
            print(f"[DETECT-FILTERS] Set shot_number=3 (serve+1)")
        elif 'first shot after serve' in query_lower:
            filters['shot_number'] = 3
            print(f"[DETECT-FILTERS] Set shot_number=3 (first after serve)")
        elif 'return' in query_lower:
            # Only set shot_number=2 for specific return shot outcomes (winner, ace, error)
            # For "return points won" or "return percentage", use role='returner' without shot_number
            if any(term in query_lower for term in ['return winner', 'return ace', 'return error', 'return unforced']):
                filters['shot_number'] = 2  # Return shot specifically
                print(f"[DETECT-FILTERS] Set shot_number=2 (return shot outcome)")
            filters['role'] = 'returner'  # Always set role for return queries
            print(f"[DETECT-FILTERS] Set role=returner (return query)")
        
        # === COURT ZONE (from inventory) ===
        # Map natural language to known court zones
        court_zone_aliases = {
            'at the net': 'net', 'net approach': 'net', 'volley': 'net',
            'baseline': 'baseline',
            "no man's land": 'midcourt', 'midcourt': 'midcourt'
        }
        for phrase, zone in court_zone_aliases.items():
            if phrase in query_lower:
                filters['court_zone'] = zone
                break
        
        # === COURT SIDE (from inventory) ===
        known_court_sides = inventory.get('court_sides', [])
        for side in known_court_sides:
            if side:
                side_lower = side.lower()
                if f"{side_lower} court" in query_lower or f"{side_lower} side" in query_lower:
                    filters['court_side'] = side
                    break
        # Handle "advantage court" alias
        if not filters.get('court_side') and 'advantage court' in query_lower:
            filters['court_side'] = 'ad'
        
        # === HANDEDNESS (player-specific, not from inventory) ===
        player = filters['player']
        if player:
            player_lower = player.lower()
            if any(lefty in player_lower for lefty in self.KNOWN_LEFT_HANDED_PLAYERS):
                filters['handedness'] = 'left'
            else:
                filters['handedness'] = 'right'
        
        # === ERROR LOCATION (semantic mapping with context) ===
        # These are contextual mappings, not pure inventory lookups
        if 'into the net' in query_lower or 'net error' in query_lower:
            filters['error_location'] = 'net'
        elif 'wide' in query_lower and 'error' in query_lower:
            filters['error_location'] = 'wide'
        elif 'long' in query_lower and 'error' in query_lower:
            filters['error_location'] = 'deep'
        
        return filters
    
    def _detect_metrics_mcp(self, query_lower: str) -> list:
        """
        Detect what metrics the query is asking about.
        MCP-Certified: Distinguishes induced forced errors from clean winners.
        
        SHOT-LEVEL METRICS:
        - total_shots: count ALL shots hit (not just point outcomes)
        - forehand_shots: count all forehand shots
        - backhand_shots: count all backhand shots
        """
        metrics = []
        
        # === SHOT-LEVEL METRICS ===
        # Shot counting is handled dynamically in tree traversal based on metadata.
        # The metric 'shot_count' triggers shot-level counting during traversal.
        # Shot type filtering (forehand, backhand, etc.) is applied via filters, not metric names.
        
        # "how many shots" / "total shots" / "shot count" / "percentage of shots"
        # Also catch patterns like "percentage of [player's] shots were winners"
        is_shot_query = any(phrase in query_lower for phrase in ['how many shot', 'total shot', 'shot count', 
                                                      'number of shot', 'percentage of shot', 
                                                      'percent of shot', '% of shot'])
        # Also check for "percentage...shots" pattern (with words in between)
        is_shot_percentage = ('percentage' in query_lower or 'percent' in query_lower or '%' in query_lower) and \
                           ('shots' in query_lower or 'shot' in query_lower)
        
        # "success rate" for shots = points won / total shots where that direction/type was used
        # Patterns: "crosscourt success rate", "down-the-line shot success rate", "forehand success rate"
        # Use config for direction and shot type terms
        direction_config = self.GROUP_CONFIG.get('direction', {}).get('default_branches', [])
        shot_type_config = self.GROUP_CONFIG.get('shot_type', {}).get('default_branches', [])
        # Build search terms (include both underscore and space/hyphen versions)
        direction_terms = []
        for d in direction_config:
            direction_terms.append(d.lower())
            direction_terms.append(d.lower().replace('_', ' '))
            direction_terms.append(d.lower().replace('_', '-'))
        shot_type_terms = [s.lower() for s in shot_type_config] if shot_type_config else []
        is_shot_success_rate = 'success rate' in query_lower and any(term in query_lower for term in direction_terms + shot_type_terms + ['shot'])
        
        if is_shot_query or is_shot_percentage:
            metrics.append('shot_count')
            # The specific outcome metric (winners, errors, etc.) will be detected by other logic below
        
        # For shot success rate: will be routed to narrative in post-processing
        if is_shot_success_rate:
            print(f"[DETECT-METRICS] Detected shot success rate (will route to narrative)")
        
        # "forehand to backhand ratio" / "shot ratio" - needs shot_count with grouping by shot_type
        if ('forehand' in query_lower and 'backhand' in query_lower) and ('ratio' in query_lower or 'shot' in query_lower):
            metrics.append('shot_count')
            # Shot type comparison is handled by group_by='shot_type', not separate metrics
        
        # Return winners (specific metric - return + winner)
        if 'return' in query_lower and 'winner' in query_lower:
            metrics.append('return_winners')
            print(f"[DETECT-METRICS] Detected 'return_winners' (specific metric)")
        # Clean winners (MCP: *)
        elif 'winner' in query_lower and 'induced' not in query_lower:
            metrics.append('winners')
        
        # Induced forced errors (MCP: # - opponent touched but couldn't control)
        if 'forced error' in query_lower or "couldn't get it back" in query_lower or \
           "couldn't return" in query_lower or 'induced' in query_lower:
            metrics.append('induced_forced_errors')
        
        # Unforced errors (MCP: @ - player's own mistake)
        if 'unforced error' in query_lower:
            metrics.append('unforced_errors')
        
        # General errors (needs disambiguation)
        if 'error' in query_lower and 'forced' not in query_lower and 'unforced' not in query_lower:
            metrics.append('errors')
        
        # Aces (clean serve winner, no touch)
        # Be specific: "ace" not "aced" or part of other words like "faced", "placed"
        # Use word boundaries to avoid matching "face", "place", "race", etc.
        import re
        ace_pattern = r'\bace\b|\baces\b'
        if re.search(ace_pattern, query_lower):
            metrics.append('aces')
        
        # Service winners (touched but not returned)
        if 'service winner' in query_lower or 'unreturned serve' in query_lower:
            metrics.append('service_winners')
        
        # Double faults
        if 'double fault' in query_lower:
            metrics.append('double_faults')
        
        # === SERVE PERCENTAGE METRICS ===
        # First serve percentage (% of first serves that went IN)
        if any(phrase in query_lower for phrase in ['first serve percentage', 'first serve %', 
                                                     '1st serve percentage', '1st serve %',
                                                     'first serve in %', 'first serve in percentage']):
            print(f"[DETECT-METRICS] Detected 'first_serve_pct' (accuracy metric)")
            metrics.append('first_serve_pct')
        
        # First serve WIN percentage (% of first serve points WON)
        if any(phrase in query_lower for phrase in ['first serve win percentage', 'first serve win %',
                                                     'first serve won percentage', 'first serve won %',
                                                     '1st serve win %', '1st serve won %',
                                                     'first serve points won']):
            print(f"[DETECT-METRICS] Detected 'first_serve_win_pct' (effectiveness metric)")
            metrics.append('first_serve_win_pct')
        
        # Second serve percentage (% of second serves that went IN - not double faulted)
        if any(phrase in query_lower for phrase in ['second serve percentage', 'second serve %',
                                                     '2nd serve percentage', '2nd serve %',
                                                     'second serve in %', 'second serve in percentage',
                                                     '2nd serve in %', '2nd serve in percentage']):
            print(f"[DETECT-METRICS] Detected 'second_serve_pct' (accuracy metric)")
            metrics.append('second_serve_pct')
        
        # Second serve WIN percentage (% of second serve points WON)
        if any(phrase in query_lower for phrase in ['second serve win percentage', 'second serve win %',
                                                     'second serve won percentage', 'second serve won %',
                                                     '2nd serve win %', '2nd serve won %',
                                                     '2nd serve win percentage', '2nd serve won percentage',
                                                     'second serve points won', '2nd serve points won']):
            print(f"[DETECT-METRICS] Detected 'second_serve_win_pct' (effectiveness metric)")
            metrics.append('second_serve_win_pct')
        
        # Points
        if 'points won' in query_lower or 'won points' in query_lower:
            metrics.append('points_won')
        if 'points lost' in query_lower or 'lost points' in query_lower:
            metrics.append('points_lost')
        
        # === GAME-LEVEL METRICS ===
        # Games won: "how many games", "games won", "total games", "game count"
        # Also handles "number of games won by each player", "games won by Sinner"
        game_patterns = ['games won', 'number of games', 'total games', 'game count', 
                        'how many games', 'games did', 'games each', 'held serve']
        if any(phrase in query_lower for phrase in game_patterns) or \
           re.search(r'games.*won|won.*games', query_lower):
            metrics.append('games_won')
        if 'games lost' in query_lower or 'broken' in query_lower:
            metrics.append('games_lost')
        # Service game holds
        if 'hold' in query_lower and 'how many' in query_lower:
            metrics.append('service_games_held')
        # Service game win percentage
        if 'service game' in query_lower and ('win' in query_lower or 'percentage' in query_lower or '%' in query_lower):
            metrics.append('service_games_held')
        
        # === BREAK POINTS vs BREAKS OF SERVE ===
        # CRITICAL: Check for "break point" FIRST (situation/points) before "break" (games)
        # Break points are POINTS in a specific situation, breaks are GAMES won on opponent's serve
        if 'break point' in query_lower or 'break points' in query_lower or 'breakpoint' in query_lower or 'bp' in query_lower:
            print(f"[DETECT-METRICS] *** BREAK POINT query detected - using points_won ***")
            # This is about break POINTS (situation), not games broken
            # Remove any incorrectly added game metrics
            if 'breaks' in metrics:
                metrics.remove('breaks')
                print(f"[DETECT-METRICS] Removed 'breaks' metric (not for break points)")
            if 'games_lost' in metrics:
                metrics.remove('games_lost')
                print(f"[DETECT-METRICS] Removed 'games_lost' metric (not for break points)")
            # Break point queries count/convert points
            # Ensure points_won is the metric (break points are about points, not specific outcomes)
            if not metrics or 'points_won' not in metrics:
                metrics = ['points_won']  # Break points = points won/lost in that situation
                print(f"[DETECT-METRICS] Set metric to 'points_won' for break points")
        elif 'break' in query_lower:
            # Only count "break" as games_lost if NOT talking about break points
            # Match patterns like "resulted in breaks", "break of serve", "games broken", "break serve", etc.
            if any(phrase in query_lower for phrase in ['resulted in break', 'break of serve', 'break serve', 'games broken', 'break game', 'return game']):
                print(f"[DETECT-METRICS] Detected 'break' (games) query - adding 'breaks' metric")
                metrics.append('breaks')
                # "break serve" implies returner role (you break when returning)
                if 'break serve' in query_lower or 'break of serve' in query_lower:
                    # Role will be set in filter detection if not already set
                    pass
        
        # === SET-LEVEL METRICS ===
        set_patterns = ['sets won', 'number of sets', 'total sets', 'set count',
                       'how many sets', 'sets did', 'sets each']
        if any(phrase in query_lower for phrase in set_patterns) or \
           re.search(r'sets.*won|won.*sets', query_lower):
            metrics.append('sets_won')
        
        # Dominance ratio (MCP concept: winners + induced FE vs own errors)
        if 'dominance' in query_lower or 'aggression' in query_lower:
            metrics.append('dominance_ratio')
        
        final_metrics = metrics if metrics else ['points_won']
        if 'first_serve' in query_lower or '1st serve' in query_lower:
            print(f"[DETECT-METRICS] FINAL metrics returned: {final_metrics}")
        return final_metrics
    
    def _detect_chain_logic(self, query_lower: str) -> Dict[str, str]:
        """
        Detect chain/sequence logic: Shot A -> Outcome B
        MCP: Critical for understanding "slice led to error" type queries.
        
        METADATA-DRIVEN: Uses inventory for shot types and outcomes.
        """
        import re
        
        chain = None
        
        # Inventory (actual match data) -> GROUP_CONFIG (all possible values)
        inventory = getattr(self, 'match_filter_inventory', {})
        known_shot_types = inventory.get('shot_types') or self.GROUP_CONFIG.get('shot_type', {}).get('default_branches', [])
        known_modifiers = inventory.get('shot_modifiers') or self.GROUP_CONFIG.get('shot_modifier', {}).get('default_branches', [])
        known_serve_targets = inventory.get('serve_targets') or self.GROUP_CONFIG.get('serve_target', {}).get('default_branches', [])
        known_outcomes = inventory.get('outcomes') or self.GROUP_CONFIG.get('outcome', {}).get('default_branches', [])
        
        # Build dynamic patterns from inventory
        shot_pattern = '|'.join([s.lower().replace('_', ' ') for s in known_shot_types + known_modifiers])
        serve_pattern = '|'.join([f"{t.lower()} serve" for t in known_serve_targets])
        outcome_pattern = '|'.join([o.lower().replace('_', ' ') for o in known_outcomes])
        
        # Dynamic chain patterns
        chain_patterns = [
            rf'({shot_pattern}).*(?:then|led to|resulted in|caused).*?({outcome_pattern})',
            rf'({serve_pattern}).*(?:then|and then).*?({shot_pattern}|{outcome_pattern})',
            rf'after.*?({outcome_pattern}).*?(hold|break|won|lost)'
        ]
        
        for pattern in chain_patterns:
            match = re.search(pattern, query_lower)
            if match:
                chain = {
                    'from_shot': match.group(1),
                    'to_outcome': match.group(2)
                }
                break
        
        return chain
    
    def _is_set_group_comparison_query(self, query: str) -> bool:
        """
        Detect if query compares metrics between different set groups.
        
        Example queries:
        - "Compare Federer's forehand winners in sets 2 and 4 versus sets 1, 3, and 5"
        - "Winner to error ratio in sets he won vs sets he lost"
        """
        query_lower = query.lower()
        
        # Must have set comparison indicators
        has_set_groups = bool(re.search(r'sets?\s*[\d,\s]+.*(?:versus|vs\.?|compared to|against).*sets?\s*[\d,\s]+', query_lower))
        has_won_lost_comparison = ('sets he won' in query_lower or 'sets he lost' in query_lower or 
                                   'winning sets' in query_lower or 'losing sets' in query_lower)
        
        # Must have ratio or comparison keywords
        has_ratio = any(kw in query_lower for kw in ['ratio', 'versus', 'vs', 'compared', 'comparison', 'to error'])
        
        return (has_set_groups or has_won_lost_comparison) and has_ratio
    
    def _build_query_tree(self, classification: Dict) -> Dict:
        """
        Build an N-dimensional query tree from classification.
        
        Tree Structure:
        {
            'type': 'filter' | 'group' | 'metric',
            'dimension': 'situation' | 'serve_target' | etc.,
            'value': value (for filters) or None (for groups),
            'children': [child nodes] or None (for leaf metrics),
            'metric': metric name (for leaf nodes)
        }
        
        Example tree for "On break points, serving to T, compare 1st vs 2nd serve win %":
        
        ROOT
        â””â”€ filter: situation=break_point
           â””â”€ filter: serve_target=t
              â””â”€ group: serve_number
                 â”œâ”€ leaf: serve_number=1st -> win_percentage
                 â””â”€ leaf: serve_number=2nd -> win_percentage
        """
        filters = classification.get('filters', {})
        metrics = classification.get('metrics', ['points_won'])
        
        # Check if this is a set comparison query
        has_set_comparison = filters.get('set_group_a') and filters.get('set_group_b')
        
        # Extract all filter dimensions (order matters for tree depth)
        filter_dimensions = []
        
        # Priority order for filter application
        # NOTE: set_group_a/b are NOT filters - they define comparison groups
        dimension_order = [
            ('situation', filters.get('situation')),
            ('set', filters.get('set')),
            # Skip set_group_a/b - handled as grouping below
            ('point_score', filters.get('point_score')),  # Specific point score (e.g., "30-30", "15-40")
            ('serve_number', filters.get('serve_number')),
            ('serve_target', filters.get('serve_target')),
            ('court_side', filters.get('court_side')),
            ('court_zone', filters.get('court_zone')),  # For net points
            ('shot_type', filters.get('shot_type')),
            ('shot_modifier', filters.get('shot_modifier')),
            ('direction', filters.get('direction')),
            ('depth', filters.get('depth')),
            ('shot_number', filters.get('shot_number')),  # Shot number in rally
            ('role', filters.get('role')),
            ('rally_length', filters.get('rally_length')),  # Exact rally length
            ('rally_length_range', filters.get('rally_length_range')),  # Rally length range (min, max)
            ('exclude_early_outcome', filters.get('exclude_early_outcome')),  # Neutral rallies (exclude points ending early)
        ]
        
        # Don't add 'both' as a player filter - it means no filter
        player_filter = filters.get('player')
        if player_filter and player_filter.lower() != 'both':
            dimension_order.append(('player', player_filter))
        
        for dim, val in dimension_order:
            # Skip None and string "null" values
            if val is not None and not (isinstance(val, str) and val.lower() == 'null'):
                # EXCEPTION: Skip shot_type filter when using shot_count metrics
                # shot_count needs ALL points to iterate through shots, filtering happens at SHOT level
                if dim == 'shot_type':
                    is_shot_level_query = any(m.startswith('shot_count') or m.startswith('shots_count') or m in ['shots', 'shot'] for m in metrics)
                    if is_shot_level_query:
                        print(f"[TREE] Skipping shot_type='{val}' filter because shot_count metric filters at shot level, not point level")
                        continue
                # EXCEPTION: Skip shot_type='serve' when role='server' is present
                # (serve effectiveness means ALL service points, not just aces/DFs)
                if dim == 'shot_type' and isinstance(val, str) and val.lower() == 'serve' and filters.get('role') == 'server':
                    print(f"[TREE] Skipping shot_type='serve' filter because role='server' is set")
                    continue
                # EXCEPTION: Skip shot_number=1 when role='server' is present
                # (serve effectiveness includes all shots in the point, not just the serve itself)
                if dim == 'shot_number' and val == 1 and filters.get('role') == 'server':
                    print(f"[TREE] Skipping shot_number=1 filter because role='server' is set")
                    continue
                filter_dimensions.append((dim, val))
        
        # Extract grouping dimensions (can be multiple for N-D)
        group_dimensions = []
        
        # Helper to check if value is valid (not None, not string "null")
        def is_valid(val):
            if val is None:
                return False
            if isinstance(val, str) and val.lower() == 'null':
                return False
            return True
        
        # If set comparison exists, add set_groups as a grouping dimension
        if has_set_comparison:
            group_dimensions.append('set_groups')
        
        # Primary group (if not already set_groups)
        group_by = classification.get('group_by')
        if is_valid(group_by) and group_by != 'set_groups':
            # CRITICAL: Skip shot_type grouping at POINT level when using shot_count metric
            # shot_count needs ALL points to iterate through shots, grouping happens at SHOT level
            # Check for both 'shot_count' (transformed) and 'shots' (pre-transform)
            # Also handle multiple shot_count metrics like ['shot_count', 'shot_count_1']
            is_shot_level_query = any(m.startswith('shot_count') or m.startswith('shots_count') or m in ['shots', 'shot'] for m in metrics)
            print(f"[TREE-DEBUG] Checking shot_type skip: metrics={metrics}, is_shot_level_query={is_shot_level_query}, group_by={group_by}")
            if group_by == 'shot_type' and is_shot_level_query:
                print(f"[TREE] Skipping shot_type grouping at point level (shot_count metric will group at shot level)")
            else:
                group_dimensions.append(group_by)
        
        # Secondary group (2D) - skip if string "null"
        secondary = classification.get('secondary_group_by')
        if is_valid(secondary):
            group_dimensions.append(secondary)
        
        # Tertiary group (3D) - skip if string "null"
        tertiary = classification.get('tertiary_group_by')
        if is_valid(tertiary):
            group_dimensions.append(tertiary)
        
        # Build tree recursively
        root = self._build_tree_node(filter_dimensions, group_dimensions, metrics, classification)
        
        return {
            'root': root,
            'classification': classification,
            'depth': len(filter_dimensions) + len(group_dimensions),
            'dimensions': {
                'filters': filter_dimensions,
                'groups': group_dimensions,
                'metrics': metrics
            }
        }
    
    def _build_tree_node(self, remaining_filters: list, remaining_groups: list, 
                         metrics: list, classification: Dict, depth: int = 0) -> Dict:
        """Recursively build tree nodes."""
        
        # If we have filters remaining, create filter node
        if remaining_filters:
            dim, val = remaining_filters[0]
            return {
                'type': 'filter',
                'dimension': dim,
                'value': val,
                'depth': depth,
                'children': [self._build_tree_node(
                    remaining_filters[1:], remaining_groups, metrics, classification, depth + 1
                )]
            }
        
        # If we have groups remaining, create group node with branches
        if remaining_groups:
            group_dim = remaining_groups[0]
            group_values = self._get_group_values(group_dim, classification)
            
            return {
                'type': 'group',
                'dimension': group_dim,
                'value': None,
                'depth': depth,
                'children': [
                    {
                        'type': 'branch',
                        'dimension': group_dim,
                        'value': val,
                        'label': label,
                        'depth': depth + 1,
                        'children': [self._build_tree_node(
                            [], remaining_groups[1:], metrics, classification, depth + 2
                        )]
                    }
                    for val, label in group_values.items()
                ]
            }
        
        # Leaf node - compute metrics
        return {
            'type': 'leaf',
            'dimension': 'metrics',
            'metrics': metrics,
            'depth': depth,
            'children': None
        }
    
    def _get_group_values(self, group_dim: str, classification: Dict = None) -> Dict[str, str]:
        """
        Get all possible values for a grouping dimension.
        GENERIC: Uses GROUP_CONFIG as single source of truth.
        """
        # Handle set_groups dynamically based on classification
        if group_dim == 'set_groups' and classification:
            filters = classification.get('filters', {})
            set_a = filters.get('set_group_a', [])
            set_b = filters.get('set_group_b', [])
            
            # Create dynamic labels based on actual sets
            set_a_str = ', '.join(str(s) for s in set_a) if set_a else 'A'
            set_b_str = ', '.join(str(s) for s in set_b) if set_b else 'B'
            
            return {
                'a': f'Set {set_a_str}' if len(set_a) == 1 else f'Sets {set_a_str}',
                'b': f'Set {set_b_str}' if len(set_b) == 1 else f'Sets {set_b_str}'
            }
        
        # Handle situation comparison dynamically (tiebreak vs rest)
        if group_dim == 'situation' and classification:
            filters = classification.get('filters', {})
            situation_a = filters.get('situation_group_a')
            situation_b = filters.get('situation_group_b')
            
            if situation_a and situation_b:
                # Create dynamic labels
                label_a = situation_a.replace('_', ' ').title()
                label_b = situation_b.replace('_', ' ').title() if situation_b != 'non_tiebreak' else 'Rest of Match'
                
                return {
                    'a': label_a,
                    'b': label_b
                }
        
        # Handle player grouping dynamically
        # Use actual names as KEYS so filter works correctly
        if group_dim == 'player':
            player1 = self.player1 or 'Player 1'
            player2 = self.player2 or 'Player 2'
            return {
                player1: player1,
                player2: player2
            }
        
        # GENERIC: Use GROUP_CONFIG instead of hard-coded dictionary
        return self._get_all_group_values(group_dim, classification)
    
    def _traverse_tree(self, tree: Dict, points: list) -> Dict:
        """
        Traverse the N-dimensional tree, filtering and grouping points.
        
        Returns nested results matching tree structure.
        """
        root = tree['root']
        classification = tree['classification']
        
        return self._traverse_node(root, points, classification)
    
    def _traverse_node(self, node: Dict, points: list, classification: Dict) -> Dict:
        """Recursively traverse a tree node."""
        
        node_type = node['type']
        dimension = node['dimension']
        value = node.get('value')
        
        if node_type == 'filter':
            # Apply filter to narrow down points
            filtered_points = self._apply_dimension_filter(points, dimension, value, classification)
            print(f"[TRAVERSE] Filter {dimension}={value}: {len(points)} -> {len(filtered_points)} points")
            
            # Continue to children with filtered points
            if node['children']:
                child_results = self._traverse_node(node['children'][0], filtered_points, classification)
            else:
                child_results = {}
            
            return {
                'type': 'filter',
                'dimension': dimension,
                'value': value,
                'points_before': len(points),
                'points_after': len(filtered_points),
                'children': child_results,
                'points': filtered_points  # CRITICAL: Store filtered points for consistent display
            }
        
        elif node_type == 'group':
            # Branch into multiple groups
            print(f"[TRAVERSE] Group {dimension}: {len(points)} points incoming")
            branch_results = {}
            
            for child in node['children']:
                branch_value = child['value']
                branch_label = child['label']
                
                # Filter points for this branch
                branch_points = self._apply_dimension_filter(points, dimension, branch_value, classification)
                print(f"[TRAVERSE]   Branch {branch_value}: {len(branch_points)} points")
                
                # Continue down this branch
                if child['children']:
                    sub_results = self._traverse_node(child['children'][0], branch_points, classification)
                else:
                    sub_results = self._compute_leaf_metrics(branch_points, classification)
                
                branch_results[branch_value] = {
                    'label': branch_label,
                    'count': len(branch_points),
                    'results': sub_results,
                    'points': branch_points  # Store actual points for debugging
                }
            
            return {
                'type': 'group',
                'dimension': dimension,
                'total_points': len(points),
                'branches': branch_results
            }
        
        elif node_type == 'branch':
            # This is a branch within a group - continue to children
            if node['children']:
                result = self._traverse_node(node['children'][0], points, classification)
                if 'points' not in result:
                    result['points'] = points
                return result
            else:
                metrics = self._compute_leaf_metrics(points, classification)
                metrics['points'] = points
                return metrics
        
        elif node_type == 'leaf':
            # Compute metrics at leaf
            metrics = self._compute_leaf_metrics(points, classification)
            metrics['points'] = points  # Store points for consistent display
            return metrics
        
        return {}
    
    def _names_match_robust(self, name1: str, name2: str) -> bool:
        """
        Robust name matching that handles:
        - Case differences
        - Punctuation (N. Djokovic vs Novak Djokovic)
        - Non-breaking spaces
        - Partial matches (last name only)
        """
        if not name1 or not name2:
            return False
        
        # Normalize both names
        def normalize(n):
            n = n.replace('\xa0', ' ').replace('\u00a0', ' ')  # Non-breaking spaces
            n = re.sub(r'[^\w\s]', '', n)  # Remove punctuation (periods, commas)
            n = re.sub(r'\s+', ' ', n).strip().lower()
            return n
        
        n1 = normalize(name1)
        n2 = normalize(name2)
        
        # Exact match after normalization
        if n1 == n2:
            return True
        
        # One contains the other (handles "Djokovic" matching "Novak Djokovic")
        if n1 in n2 or n2 in n1:
            return True
        
        # Last name match (most robust)
        def get_last_name(n):
            parts = n.split()
            return parts[-1] if parts else n
        
        if get_last_name(n1) == get_last_name(n2):
            return True
        
        # Check if any word in one name matches any word in the other
        words1 = set(n1.split())
        words2 = set(n2.split())
        if words1 & words2:  # Intersection - any common words
            return True
        
        return False
    
    def _apply_dimension_filter(self, points: list, dimension: str, value: Any, 
                                 classification: Dict) -> list:
        """
        ROBUST DIMENSION FILTER: Uses metadata for ALL filtering decisions.
        Apply a single dimension filter to points.
        """
        filtered = []
        player1 = self.player1
        player2 = self.player2
        filters = classification.get('filters', {})
        
        for point_data in points:
            # Get cached metadata or compute it
            if '_metadata' not in point_data:
                point_data['_metadata'] = self._get_point_metadata(point_data)
            meta = point_data['_metadata']
            
            # Legacy access for gradual migration
            point_text = meta.get('raw_text', '')
            point_lower = point_text.lower()
            score = meta.get('score', '')
            server = meta.get('server', '')
            returner = meta.get('returner', '')
            
            passes_filter = True
            
            if dimension == 'situation':
                # Handle situation group comparisons (a vs b)
                if value == 'a':
                    situation_a = filters.get('situation_group_a')
                    if situation_a == 'tiebreak':
                        passes_filter = 'tiebreak' in score.lower() or self._is_tiebreak_point(score)
                    elif situation_a == 'break_point':
                        passes_filter = self._is_break_point_score(score)
                    elif situation_a == 'game_point':
                        passes_filter = self._is_game_point_score(score)
                    elif situation_a == 'deuce':
                        passes_filter = self._is_deuce_score(score)
                elif value == 'b':
                    situation_b = filters.get('situation_group_b')
                    if situation_b == 'non_tiebreak':
                        # Non-tiebreak = NOT in tiebreak
                        passes_filter = 'tiebreak' not in score.lower() and not self._is_tiebreak_point(score)
                    elif situation_b == 'non_break_point':
                        passes_filter = not self._is_break_point_score(score)
                # Regular situation filters - GENERIC using SITUATION_CONFIG
                # Handle both single values and lists (for situation groups)
                elif isinstance(value, list):
                    # List of situations - check if ANY match (OR logic)
                    passes_filter = False
                    for sit in value:
                        if sit in self.SITUATION_CONFIG:
                            if self._check_situation(sit, score):
                                passes_filter = True
                                break
                        elif sit == 'tiebreak':
                            # Fallback for tiebreak
                            if 'tiebreak' in score.lower() or self._is_tiebreak_point(score):
                                passes_filter = True
                                break
                elif value in self.SITUATION_CONFIG:
                    passes_filter = self._check_situation(value, score)
                    # Fallback for tiebreak (check string too)
                    if value == 'tiebreak' and not passes_filter:
                        passes_filter = 'tiebreak' in score.lower() or self._is_tiebreak_point(score)
                else:
                    # Unknown situation value - don't pass filter
                    passes_filter = False
                    print(f"[WARN] Unknown situation value: {value} (type: {type(value)})")
            
            elif dimension == 'set' or dimension == 'sets':
                # Prefer metadata set_number if available, otherwise parse from score
                current_set = meta.get('set_number')
                if current_set is None:
                    current_set = self._extract_current_set(score)
                # Handle both single value and list (e.g., [1, 2] for "Sets 1-2")
                if isinstance(value, str) and value.isdigit():
                    value = int(value)
                if isinstance(value, (list, tuple)):
                    # List of sets - check if current set is in the list
                    passes_filter = (current_set in value)
                else:
                    # Single set - exact match
                    passes_filter = (current_set == value)
            
            elif dimension == 'set_group_a' or dimension == 'set_group_b':
                current_set = meta.get('set_number')
                if current_set is None:
                    current_set = self._extract_current_set(score)
                set_list = value if isinstance(value, list) else [value]
                passes_filter = (current_set in set_list)
            
            elif dimension == 'set_groups':
                # Handle grouping by set comparison (branch value is 'a' or 'b')
                current_set = meta.get('set_number')
                if current_set is None:
                    current_set = self._extract_current_set(score)
                if value == 'a':
                    set_list = filters.get('set_group_a', [])
                elif value == 'b':
                    set_list = filters.get('set_group_b', [])
                else:
                    set_list = []
                passes_filter = (current_set in set_list)
            
            elif dimension == 'serve_number':
                # CRITICAL: ALWAYS calculate from text to avoid stale cache issues
                # Don't rely on enriched serve_number which may be from old cache
                point_text_lower = point_text.lower()
                has_2nd_serve = '2nd serve' in point_text_lower or 'second serve' in point_text_lower
                has_1st_fault = bool(re.search(r'1st serve[^;]*fault', point_text_lower))
                is_second_serve = has_2nd_serve or has_1st_fault
                serve_num = 2 if is_second_serve else 1
                
                # DEBUG: Count second serves by server
                if not hasattr(self, '_serve_debug'):
                    self._serve_debug = {'total': 0, 'empty_text': 0, 'by_server': {}, 'filter_value': value}
                
                if is_second_serve:
                    self._serve_debug['total'] += 1
                    svr = server or 'UNKNOWN'
                    self._serve_debug['by_server'][svr] = self._serve_debug['by_server'].get(svr, 0) + 1
                    
                if not point_text_lower:
                    self._serve_debug['empty_text'] += 1
                
                if value == 1 or value == '1st':
                    passes_filter = (serve_num == 1)
                elif value == 2 or value == '2nd':
                    passes_filter = (serve_num == 2)
            
            elif dimension == 'shot_number':
                # Shot position in PARSED sequence (1=serve, 2=return, 3=server's response, etc.)
                # CRITICAL: This matches _parse_rally_sequence numbering, NOT tennis rally counting
                # Get rally shots from metadata
                rally_shots = meta.get('rally_shots', [])
                if not rally_shots:
                    # Fallback: parse rally from text
                    point_text = meta.get('raw_text', '')
                    server = meta.get('server', '')
                    returner = meta.get('returner', '')
                    rally_shots = self._parse_rally_sequence(point_text, server, returner) if point_text else []
                
                # Check if the WINNING shot (last shot) has the target shot_number
                # For "return winners": value=2, we want points where winning shot was shot_number=2 (return)
                if rally_shots:
                    # Get the last non-fault shot (the winning shot)
                    actual_shots = [s for s in rally_shots if s.get('outcome') not in ['FAULT', 'LET']]
                    if actual_shots:
                        winning_shot = actual_shots[-1]
                        winning_shot_number = winning_shot.get('shot_number')
                        passes_filter = (winning_shot_number == value)
                    else:
                        passes_filter = False
                else:
                    passes_filter = False
            
            elif dimension == 'serve_target' or dimension == 'serve_direction':
                # Use metadata for serve target WITH NORMALIZATION
                serve_target = meta.get('serve_info', {}).get('serve_target')
                # Use _values_match to handle aliases (t -> down_the_t, etc.)
                passes_filter = self._values_match(value, serve_target) if value else True
            
            elif dimension == 'court_side':
                # Use metadata for court side
                court_side = meta.get('situation', {}).get('court_side')
                passes_filter = (court_side == value)
            
            elif dimension == 'shot_type':
                # GENERIC: For error metrics, use error_shot_type; for others, use winning_shot_type
                metrics = classification.get('metrics', [])
                current_metric = metrics[0] if metrics else None
                error_metrics = ['unforced_errors', 'forced_errors', 'errors']
                
                if current_metric in error_metrics:
                    # Use error_shot_type for error metrics
                    error_info = meta.get('error_info', {})
                    shot_type_to_check = error_info.get('error_shot_type')
                else:
                    # Use winning_shot_type for non-error metrics
                    shot_type_to_check = meta.get('winning_shot', {}).get('shot_type')
                
                # Use _values_match for alias handling and hierarchy expansion
                passes_filter = self._values_match(value, shot_type_to_check) if value else True
            
            elif dimension == 'direction':
                # Use metadata for winning shot direction WITH NORMALIZATION
                winning_direction = meta.get('winning_shot', {}).get('direction')
                # Use _values_match to handle aliases (cc -> crosscourt, dtl -> down_the_line)
                passes_filter = self._values_match(value, winning_direction) if value else True
            
            elif dimension == 'depth':
                # Use metadata for winning shot depth WITH NORMALIZATION
                winning_depth = meta.get('winning_shot', {}).get('depth')
                # Use _values_match to handle aliases and hierarchies
                passes_filter = self._values_match(value, winning_depth) if value else True
            
            elif dimension == 'court_zone':
                # Use metadata to determine if shot was at net WITH HIERARCHY
                at_net = meta.get('winning_shot', {}).get('at_net', False)
                shot_modifier = meta.get('winning_shot', {}).get('shot_modifier', '')
                shot_modifiers = meta.get('winning_shot', {}).get('shot_modifiers', [])
                
                # Get all net-related modifiers from hierarchy
                net_modifiers = self.SHOT_HIERARCHY.get('at_net', ['volley', 'half_volley', 'overhead', 'swinging_volley', 'drop_volley'])
                
                # Net indicators: at_net flag OR any net-related modifier
                is_net_shot = at_net or shot_modifier in net_modifiers or any(m in net_modifiers for m in shot_modifiers)
                
                # GENERIC court zone matching using COURT_ZONE_CONFIG
                zone_config = self.COURT_ZONE_CONFIG.get(value, {})
                expected_net = zone_config.get('detection_value', value == 'net')
                passes_filter = is_net_shot == expected_net
            
            elif dimension == 'shot_modifier':
                # Filter by shot modifier WITH HIERARCHY EXPANSION
                winning_modifiers = meta.get('winning_shot', {}).get('shot_modifiers', [])
                primary_modifier = meta.get('winning_shot', {}).get('shot_modifier')
                if primary_modifier and primary_modifier not in winning_modifiers:
                    winning_modifiers = [primary_modifier] + winning_modifiers
                
                # Check if ANY of the winning shot's modifiers match (using hierarchy)
                passes_filter = any(self._values_match(value, mod) for mod in winning_modifiers) if value else True
            
            elif dimension == 'point_score':
                # Filter by specific point score (e.g., "30-30", "15-40", "40-AD")
                # SUPPORTS LISTS: "30-30 and deuce combined" -> ['30-30', '40-40'] (OR logic)
                # Note: point_score is stored at top level of metadata, not in game_info
                actual_point_score = meta.get('point_score', '')
                actual_normalized = self._normalize_point_score(actual_point_score)
                
                # Helper to check if point score matches (exact match on last part of score string)
                def _point_score_matches(target_score: str, actual_normalized: str, full_score: str) -> bool:
                    # Primary: exact match on normalized point score
                    if target_score == actual_normalized:
                        return True
                    # Fallback: extract last part of full score (e.g., "0-0 1-1 0-40" -> "0-40")
                    if full_score:
                        score_parts = full_score.strip().split()
                        if score_parts:
                            last_part = self._normalize_point_score(score_parts[-1])
                            return target_score == last_part
                    return False
                
                # Handle list values (OR logic) vs single value
                if isinstance(value, list):
                    # OR logic: matches ANY score in the list
                    passes_filter = False
                    for score_val in value:
                        value_normalized = self._normalize_point_score(score_val)
                        if _point_score_matches(value_normalized, actual_normalized, score):
                                passes_filter = True
                                break
                else:
                    # Single value: exact match
                    value_normalized = self._normalize_point_score(value)
                    passes_filter = _point_score_matches(value_normalized, actual_normalized, score)
            
            elif dimension == 'role':
                # CRITICAL: Check player from BOTH filters AND classification (query planner may not include it in filters)
                player_filter = (filters.get('player') or classification.get('player') or '').lower()
                # GENERIC role handling using ROLE_CONFIG
                if value in self.ROLE_CONFIG:
                    role_player = self._get_player_for_role(value, server, returner, meta.get('point_winner', ''), point_data.get('error_player', ''))
                    if player_filter and player_filter != 'both':
                        # Player specified with role â†' filter by that role's player
                        passes_filter = player_filter in role_player.lower() if role_player else True
                    else:
                        # No specific player, role means keep all points (everyone plays both roles)
                        passes_filter = True
            
            elif dimension == 'player':
                # Player filter - context-dependent
                domain = classification.get('domain', '')
                role_filter = filters.get('role')
                group_by = classification.get('group_by', '')
                metrics = classification.get('metrics', [])
                analysis_type = classification.get('analysis_type', '')
                
                # Get point winner from metadata
                point_winner = meta.get('point_winner', '')
                if not point_winner:
                    # Fallback: extract from description
                    desc = (point_data.get('description', '') or point_data.get('point_text', '')).lower()
                    if 'point won by:' in desc:
                        pw_match = re.search(r'point won by:\s*([^\]]+)', desc)
                        if pw_match:
                            point_winner = pw_match.group(1).strip()
                
                # Skip if player is 'both' - this means compare all players
                if (value or '').lower() == 'both':
                    passes_filter = True
                # CRITICAL FIX: When role filter is specified (server/returner),
                # ALWAYS filter by the role, NOT by who won the point
                # This ensures win_percentage is calculated correctly - GENERIC using ROLE_CONFIG
                elif role_filter:
                    role_player = self._get_player_for_role(role_filter, server, returner, point_winner, point_data.get('error_player', ''))
                    passes_filter = self._names_match_robust(value, role_player)
                # For domain-based queries, filter by the domain's associated player - GENERIC
                elif domain and domain in self.DOMAIN_CONFIG:
                    domain_player = self._get_player_for_domain(domain, server, returner)
                    if domain_player:
                        passes_filter = self._names_match_robust(value, domain_player)
                    else:
                        passes_filter = True  # No specific player for this domain
                # When GROUPING by player for "who won more points" type questions WITHOUT role filter,
                # filter by WHO WON THE POINT, not who was involved
                elif group_by == 'player' and ('points_won' in metrics or 'win_percentage' in metrics or analysis_type in ['ratio', 'comparison']):
                    passes_filter = self._names_match_robust(value, point_winner)
                # For shot-based groupings (shot_type/direction/etc.), use metric's player_role to determine who to filter by
                # "Sinner's forehand winners" -> player_role='winner' -> filter to points Sinner won
                # "Sinner's backhand errors" -> player_role='error' -> filter to points where Sinner hit the error
                # GENERIC: For ALL other cases (including shot-level groupings), use metric config
                # NO HARDCODED LISTS - driven by METRIC_CONFIG and count_filter
                else:
                    # Get the metric's config to determine how to interpret "player" filter
                    # CONFIG-DRIVEN: Use count_filter + player_role to determine player field
                    primary_metric = metrics[0] if metrics else 'win_percentage'  # Default
                    metric_config = TennisChatAgentEmbeddingQALocal.METRIC_CONFIG.get(primary_metric, {})
                    player_role = metric_config.get('player_role', 'both')
                    count_filter = metric_config.get('count_filter', 'always')
                    
                    # CRITICAL DECISION LOGIC:
                    # count_filter='won' → filter to points player WON (point_winner)
                    # count_filter='lost' → filter to points player LOST
                    # count_filter='always' OR player_role='both' → points player was INVOLVED in
                    # player_role!='both' → use ROLE_CONFIG to get specific player_field
                    
                    player_field_used = None
                    
                    # PRIORITY 1: Check count_filter (most specific)
                    if count_filter == 'won':
                        # "Points won", "Win %", "Effectiveness" → point_winner
                        passes_filter = self._names_match_robust(value, point_winner)
                        player_field_used = 'point_winner'
                    elif count_filter == 'lost':
                        # "Points lost" → opposite of point_winner (but player was involved)
                        passes_filter = not self._names_match_robust(value, point_winner) and (
                            self._names_match_robust(value, server) or self._names_match_robust(value, returner)
                        )
                        player_field_used = 'not_point_winner'
                    elif player_role and player_role != 'both':
                        # PRIORITY 2: Check player_role for specific field
                        role_config = self.ROLE_CONFIG.get(player_role, {})
                        player_field = role_config.get('player_field', '')
                        
                        if player_field:
                            field_to_player = {
                                'server': server,
                                'returner': returner,
                                'point_winner': point_winner,
                                'error_player': point_data.get('error_player', '')
                            }
                            target_player = field_to_player.get(player_field, '')
                            passes_filter = self._names_match_robust(value, target_player)
                            player_field_used = player_field
                        else:
                            # Fallback: points involved in
                            passes_filter = self._names_match_robust(value, server) or self._names_match_robust(value, returner)
                            player_field_used = 'involved(fallback)'
                    else:
                        # DEFAULT: count_filter='always' or player_role='both' → points player was involved in
                        passes_filter = self._names_match_robust(value, server) or self._names_match_robust(value, returner)
                        player_field_used = 'involved'
                    
                    # DEBUG: Show player matching logic for first few points
                        point_num = point_data.get('point_number', '?')
                        if not hasattr(self, '_player_filter_debug_count'):
                            self._player_filter_debug_count = 0
                        if self._player_filter_debug_count < 5:
                            self._player_filter_debug_count += 1
                        # Removed console print - point information only shown to user on screen
            
            # For grouping dimensions (when used as filter)
            elif dimension == 'serve_direction':
                # Use metadata for serve target (same as serve_target)
                serve_target = meta.get('serve_info', {}).get('serve_target')
                passes_filter = (serve_target == value)
            
            elif dimension == 'shot_direction':
                # Use metadata for winning shot direction
                winning_direction = meta.get('winning_shot', {}).get('direction')
                passes_filter = (winning_direction == value)
            
            elif dimension == 'return_depth':
                # Use metadata for return depth
                return_depth = meta.get('return_info', {}).get('return_depth')
                depth_map = {'shallow': 'shallow', 'deep': 'deep', 'very_deep': 'very_deep', 'unspecified': None}
                passes_filter = (return_depth == depth_map.get(value))
            
            elif dimension == 'rally_length_category':
                # Use metadata for rally category
                rally_category = meta.get('rally_category')
                passes_filter = (rally_category == value)
            
            elif dimension == 'point_number_range':
                # Temporal/segment filter - filter by point number range
                # Value is (min, max) tuple/list (inclusive)
                point_num = point_data.get('point_number', 0)
                if isinstance(value, (tuple, list)) and len(value) == 2:
                    min_point, max_point = value
                    passes_filter = (min_point <= point_num <= max_point)
                else:
                    # Invalid format - don't pass
                    passes_filter = False
            
            elif dimension == 'rally_length':
                # Use metadata for rally length (exact, comparison, or range)
                rally_len = meta.get('rally_length', 0)
                if isinstance(value, int):
                    passes_filter = (rally_len == value)
                elif isinstance(value, (tuple, list)) and len(value) == 2:
                    # CRITICAL: Handle tuple/list range (min, max) - e.g., (0, 4) or [0, 4] means 0-4 shots
                    min_val, max_val = value
                    passes_filter = (min_val <= rally_len <= max_val)
                elif isinstance(value, str):
                    # IMPORTANT: Check '>=' before '>' ('>=' startswith '>')
                    if value.startswith('>='):
                        threshold = int(value[2:])
                        passes_filter = (rally_len >= threshold)
                    elif value.startswith('>'):
                        threshold = int(value[1:])
                        passes_filter = (rally_len > threshold)
                    elif value.startswith('<='):
                        threshold = int(value[2:])
                        passes_filter = (rally_len <= threshold)
                    elif value.startswith('<'):
                        threshold = int(value[1:])
                        passes_filter = (rally_len < threshold)
                    else:
                        passes_filter = False  # Unknown string format
                else:
                    passes_filter = False  # Unknown format, reject
            
            elif dimension == 'rally_length_range':
                # Use metadata for rally length range (min, max)
                rally_len = meta.get('rally_length', 0)
                if isinstance(value, (list, tuple)) and len(value) == 2:
                    min_len, max_len = value
                    min_ok = rally_len >= min_len if min_len is not None else True
                    max_ok = rally_len <= max_len if max_len is not None else True
                    passes_filter = min_ok and max_ok
                else:
                    passes_filter = True  # Unknown format, don't filter
            
            elif dimension == 'exclude_early_outcome':
                # Exclude points that ended before a certain shot (neutral rallies)
                # value = threshold shot number (e.g., 6 means exclude points ending before shot 6)
                rally_len = meta.get('rally_length', 0)
                passes_filter = (rally_len >= value)  # Rally must reach at least this length
            
            elif dimension == 'pressure_level':
                # Use enriched pressure data
                pressure_data = point_data.get('pressure', {})
                tightness = pressure_data.get('score_tightness', 0)
                
                if value == 'low':
                    passes_filter = 0 <= tightness <= 3
                elif value == 'medium':
                    passes_filter = 4 <= tightness <= 6
                elif value == 'high':
                    passes_filter = 7 <= tightness <= 10
            
            elif dimension == 'serve_plus_one_type':
                # Use metadata for serve+1 shot type
                serve_plus_one_type = meta.get('serve_plus_one', {}).get('shot_type')
                
                if value == 'none':
                    passes_filter = not serve_plus_one_type
                else:
                    passes_filter = (serve_plus_one_type == value)
            
            # === NEW ENHANCED DIMENSIONS ===
            elif dimension == 'shot_modifier':
                # Filter by ANY shot modifier in the winning shot
                shot_modifiers = meta.get('winning_shot', {}).get('shot_modifiers', [])
                passes_filter = (value in shot_modifiers)
            
            elif dimension == 'court_position':
                # Filter by court position (net, baseline, approach)
                court_pos = meta.get('winning_shot', {}).get('court_position')
                passes_filter = (court_pos == value)
            
            elif dimension == 'spin':
                # Filter by spin type (topspin, slice, flat)
                spin = meta.get('winning_shot', {}).get('spin')
                passes_filter = (spin == value)
            
            elif dimension == 'is_net_point':
                # Filter for net points specifically
                at_net = meta.get('winning_shot', {}).get('at_net', False)
                passes_filter = (at_net == (value == 'true' or value == True))
            
            elif dimension == 'is_return':
                # Filter for return shots
                actual_shots = meta.get('all_shots', meta.get('actual_shots', []))
                if len(actual_shots) >= 2:
                    return_shot = actual_shots[1]
                    is_return = return_shot.get('is_return', False) or 'return' in return_shot.get('description', '').lower()
                    passes_filter = is_return
                else:
                    passes_filter = False
            
            elif dimension == 'after_rally_length':
                # Use enriched context data (legacy bucket approach)
                context = point_data.get('context', {})
                prev_rally = context.get('prev_rally_length', 0)
                
                if value == 'first_point':
                    passes_filter = prev_rally == 0
                elif value == 'after_short':
                    passes_filter = 1 <= prev_rally <= 4
                elif value == 'after_medium':
                    passes_filter = 5 <= prev_rally <= 9
                elif value == 'after_long':
                    passes_filter = prev_rally >= 10
            
            elif dimension == 'prev_rally_length':
                # NEW: Filter by previous rally length with comparison operators (e.g., ">=7")
                # Get prev_rally from enriched data
                prev_rally = point_data.get('_prev_rally_length', 0)
                
                if isinstance(value, str):
                    # Comparison filter: ">=7", "<=4", etc.
                    if value.startswith('>='):
                        passes_filter = prev_rally >= int(value[2:])
                    elif value.startswith('<='):
                        passes_filter = prev_rally <= int(value[2:])
                    elif value.startswith('>'):
                        passes_filter = prev_rally > int(value[1:])
                    elif value.startswith('<'):
                        passes_filter = prev_rally < int(value[1:])
                    else:
                        # Try exact match
                        try:
                            passes_filter = prev_rally == int(value)
                        except ValueError:
                            passes_filter = True  # Unknown format, don't filter
                elif isinstance(value, int):
                    passes_filter = prev_rally == value
                elif isinstance(value, (tuple, list)) and len(value) == 2:
                    # Range filter: (min, max) or [min, max]
                    passes_filter = value[0] <= prev_rally <= value[1]
            
            if passes_filter:
                filtered.append(point_data)
        
        return filtered
    
    def _count_game_points(self, game_score: str) -> int:
        """Count total points played in game from score like '30-15'."""
        score_map = {'0': 0, '15': 1, '30': 2, '40': 3, 'AD': 4}
        parts = game_score.replace('-', ' ').split()
        total = 0
        for p in parts:
            total += score_map.get(p.upper(), 0)
        return total
    
    def _is_tiebreak_point(self, score: str) -> bool:
        """Check if score indicates tiebreak."""
        # Tiebreak scores are like "6-6 3-2" where game scores are numeric
        parts = score.split()
        if len(parts) >= 2:
            game_part = parts[-1]
            if '-' in game_part:
                try:
                    a, b = game_part.split('-')
                    int(a)
                    int(b)
                    # If both parts are numeric and set score is 6-6, it's a tiebreak
                    if len(parts) >= 2 and '6-6' in score:
                        return True
                except:
                    pass
        return False
    
    def _calculate_pressure_index(self, score_str: str) -> int:
        """
        Calculate pressure index (0-10) based on score state.
        Higher values indicate more pressure/critical situations.
        """
        if not score_str:
            return 0
        
        score_str_lower = score_str.lower()
        base_pressure = 0
        
        # Check for tiebreak situations (high pressure)
        if self._is_tiebreak_point(score_str):
            base_pressure += 5
        
        # Check for final set scores with tiebreak
        if '7-6' in score_str or '6-7' in score_str:
            base_pressure += 5
        
        # Check for deuce (close game)
        if 'deuce' in score_str_lower or '40-40' in score_str:
            base_pressure += 3
        
        # Check for break point (critical)
        if 'break point' in score_str_lower:
            base_pressure += 4
        
        # Check for close scores (30-30, 40-30, 30-40)
        if '30-30' in score_str or '40-30' in score_str or '30-40' in score_str:
            base_pressure += 2
        
        # Check for advantage situations
        if 'ad-' in score_str_lower or '-ad' in score_str_lower:
            base_pressure += 3
        
        # Check for critical game scores (5-5, 6-5, 5-6 in games)
        import re
        games_patterns = re.findall(r'\b(\d+)-(\d+)\b', score_str)
        for g1, g2 in games_patterns:
            g1_int, g2_int = int(g1), int(g2)
            # Close game scores at end of set
            if (g1_int >= 5 and g2_int >= 5):
                base_pressure += 2
                break
        
        return min(base_pressure, 10)
    
    def _extract_winner_from_point(self, point_dict: Dict) -> Optional[str]:
        """
        Extract the winner of a point from the point description.
        Returns player name or None if not found.
        """
        description = point_dict.get('description', '') or point_dict.get('point_text', '')
        
        # Look for [Point won by: Player Name] tag
        import re
        winner_match = re.search(r'\[Point won by:\s*([^\]]+)\]', description, re.IGNORECASE)
        if winner_match:
            return winner_match.group(1).strip()
        
        # Look for outcomes that indicate winner
        server = point_dict.get('server', '')
        returner = point_dict.get('returner', '')
        
        desc_lower = description.lower()
        
        # Outcomes that indicate server won
        if any(term in desc_lower for term in ['ace', 'service winner', 'double fault']):
            if 'double fault' in desc_lower:
                return returner  # Returner wins on double fault
            return server
        
        # Look for "winner" or "error" near player names
        # This is a simple heuristic - may need refinement
        if 'winner' in desc_lower:
            # Try to determine who hit the winner
            # If it's the last shot in rally, we need more context
            pass
        
        return None
    
    def _enrich_point_data(self):
        """
        Runs ONCE after loading data. Adds 'context', 'pressure', and 'tactics' to every point.
        Turns 'Hard' dynamic questions into 'Easy' static filters.
        
        This enrichment allows queries like:
        - "Did X serve worse after long rallies?" -> filter(prev_rally_length > 15)
        - "Who played better on big points?" -> filter(is_pressure_point == True)
        - "How effective was Serve + Forehand?" -> filter(serve_plus_one_shot == 'Forehand')
        """
        if not self.point_by_point:
            print("[ENRICH] No point-by-point data to enrich")
            return
        
        print("[ENRICH] Running Data Enrichment Pass...")
        
        # State trackers
        prev_rally_length = 0
        prev_winner = None
        match_cumulative_shots = 0
        points_in_current_set = 0
        current_set_score = None
        
        for i, point in enumerate(self.point_by_point):
            # Track which set we're in
            score_str = point.get('score', '')
            if score_str and score_str != current_set_score:
                # Extract set score (first part of score string, e.g., "2-2" from "2-2 6-6 0-0")
                import re
                set_match = re.match(r'(\d+-\d+)', score_str)
                if set_match:
                    new_set_score = set_match.group(1)
                    if new_set_score != current_set_score:
                        current_set_score = new_set_score
                        points_in_current_set = 0  # Reset for new set
            
            points_in_current_set += 1
            
            # 1. Parse rally to get shot count
            rally_shots = self._parse_rally_sequence(
                point.get('description', ''),
                point.get('server', ''),
                point.get('returner', '')
            )
            
            # Use centralized rally length calculation (single source of truth)
            rally_len = self._calculate_rally_length(rally_shots, point.get('description', ''))
            
            # CRITICAL: Store rally_length on point for filter checking
            point['rally_length'] = rally_len
            
            # CRITICAL: Store prev_rally_length (for "after X rally" queries)
            point['_prev_rally_length'] = prev_rally_length
            
            # Also get actual_shots for later use (exclude faults/lets)
            actual_shots = [s for s in rally_shots if s.get('outcome') not in ['FAULT', 'LET']]
            
            # CRITICAL: Store set_number on point for filter checking
            score_str = point.get('score', '')
            set_number = self._extract_current_set(score_str)
            point['set_number'] = set_number
            
            # Also store game_number_in_set for filter checking
            game_info = self._extract_game_info(score_str, point.get('point_number', 0))
            point['game_number_in_set'] = game_info.get('game_number_in_set')
            
            # 1b. Compute and store error_player AND winning shot info (needed for metrics)
            computed_winner, winning_shot_type, error_player = self._determine_point_winner(
                actual_shots, 
                point.get('server', ''), 
                point.get('returner', ''),
                return_details=True
            )
            point['error_player'] = error_player or ''
            
            # 2. Extract winner from tag (if available), otherwise use computed winner from rally analysis
            winner = self._extract_winner_from_point(point)
            if not winner and computed_winner:
                winner = computed_winner  # Fall back to rally-based determination
            # CRITICAL: Store point_winner on point for tree filtering (e.g., points_won metric)
            point['point_winner'] = winner or ''
            
            # CRITICAL: Store serve_number for serve analysis (1st vs 2nd serve queries)
            # Detect from text: multiple patterns for second serve
            description_lower = point.get('description', '').lower()
            has_2nd_serve_text = '2nd serve' in description_lower or 'second serve' in description_lower
            has_1st_fault = bool(re.search(r'1st serve[^;]*fault', description_lower))  # "1st serve..., fault" = 2nd serve played
            is_second_serve = has_2nd_serve_text or has_1st_fault
            point['serve_number'] = 2 if is_second_serve else 1
            
            # CRITICAL: Store winning shot info for shot-level queries
            # This enables Query Plan to filter/count by shot type without re-parsing
            if actual_shots:
                last_shot = actual_shots[-1]
                point['winning_shot'] = {
                    'shot_type': last_shot.get('shot_type', ''),
                    'direction': last_shot.get('direction', ''),
                    'shot_modifier': last_shot.get('shot_modifier', ''),
                    'outcome': last_shot.get('outcome', winning_shot_type or ''),
                    'at_net': last_shot.get('location') == 'net'
                }
            else:
                point['winning_shot'] = {
                    'shot_type': '', 'direction': '', 'shot_modifier': '', 
                    'outcome': winning_shot_type or '', 'at_net': False
                }
            
            # 3. Add CONTEXT (Fatigue/History/Momentum)
            point['context'] = {
                'prev_rally_length': prev_rally_length,
                'match_cumulative_shots': match_cumulative_shots,  # Proxy for fatigue
                'points_in_set': points_in_current_set,
                'is_momentum_swing': (prev_winner is not None and prev_winner != winner) if winner else False
            }
            
            # 4. Add PRESSURE (Score State) and SITUATIONS
            score_tightness = self._calculate_pressure_index(score_str)
            is_tiebreak = self._is_tiebreak_point(score_str)
            
            # Identify all situations from score (stored for fast access)
            situations = {
                'is_break_point': self._is_break_point_score(score_str),
                'is_game_point': self._is_game_point_score(score_str),
                'is_set_point': self._is_set_point_score(score_str),
                'is_match_point': self._is_match_point_score(score_str),
                'is_deuce': self._is_deuce_score(score_str),
                'is_tiebreak': is_tiebreak,
                'court_side': self._determine_court_side(score_str)
            }
            
            point['pressure'] = {
                'score_tightness': score_tightness,  # 0 (easy) to 10 (critical)
                'is_pressure_point': score_tightness >= 7,  # High-pressure threshold
                'is_critical': score_tightness >= 7 or situations['is_break_point'] or situations['is_match_point'],
                'is_tiebreak': is_tiebreak
            }
            
            # Store situations for fast filtering (computed once during enrichment)
            point['situation'] = situations
            
            # 5. Add SEQUENCE/TACTICS (Serve + 1, Return + 1)
            # Pre-calculate the "Serve + 1" and "Return + 1" shots
            tactics = {
                'serve_plus_one_shot': None,
                'serve_plus_one_outcome': None,
                'return_plus_one_shot': None,
                'return_plus_one_outcome': None,
                'rally_length': rally_len
            }
            
            if len(actual_shots) >= 3:
                # Shot 0=Serve, 1=Return, 2=Server's next shot (Serve+1)
                serve_plus_one = actual_shots[2]
                tactics['serve_plus_one_shot'] = serve_plus_one.get('description')
                tactics['serve_plus_one_outcome'] = serve_plus_one.get('outcome')
            
            if len(actual_shots) >= 4:
                # Shot 3=Returner's next shot after return (Return+1)
                return_plus_one = actual_shots[3]
                tactics['return_plus_one_shot'] = return_plus_one.get('description')
                tactics['return_plus_one_outcome'] = return_plus_one.get('outcome')
            
            point['tactics'] = tactics
            
            # 6. Add BREAK_BACK detection (breaking immediately after being broken)
            # Requires game_winners and game_servers to be populated first (done in _extract_game_winners)
            is_break_back = False
            if hasattr(self, 'game_winners') and hasattr(self, 'game_servers') and self.game_winners and self.game_servers:
                current_set = set_number
                current_game = game_info.get('game_number_in_set', 0)
                
                if current_game > 1:  # Need at least 2 games to detect break back
                    # Get current game winner and server (the game this point belongs to)
                    current_game_winner = self.game_winners.get((current_set, current_game))
                    current_server = self.game_servers.get((current_set, current_game))
                    
                    # Get previous game winner and server
                    prev_game_winner = self.game_winners.get((current_set, current_game - 1))
                    prev_server = self.game_servers.get((current_set, current_game - 1))
                    
                    # Check if both games were breaks
                    # A break = returner won the game (game winner != server)
                    current_is_break = (current_game_winner and current_server and current_game_winner != current_server)
                    prev_is_break = (prev_game_winner and prev_server and prev_game_winner != prev_server)
                    
                    # Break back = both games were breaks AND the player who broke back is the same player who got broken
                    # Scenario: Player A served game N and lost (got broken)
                    #           Player B served game N+1 and lost (got broken back by Player A)
                    # So: current_game_winner (who broke) == prev_server (who got broken)
                    if current_is_break and prev_is_break and current_game_winner == prev_server:
                        is_break_back = True
            
            point['is_break_back_game'] = is_break_back
            
            # Update state for NEXT point
            prev_rally_length = rally_len
            match_cumulative_shots += rally_len
            if winner:
                prev_winner = winner
        
        print(f"[ENRICH] [OK] Enriched {len(self.point_by_point)} points with:")
        print(f"         - Context (fatigue, momentum, set position)")
        print(f"         - Pressure (tightness index, critical points)")
        print(f"         - Tactics (serve+1, return+1, rally length)")
        
        # Now build the complete filter inventory
        self._build_match_filter_inventory()
    
    def _build_match_filter_inventory(self):
        """
        CRITICAL: Build complete inventory of ALL filterable values from THIS match.
        
        This is the USER's proposed architecture:
        1. Traverse ALL points ONCE at load time
        2. Extract ALL metadata from EVERY shot
        3. Build a complete "filter set" of what actually exists
        4. LLM maps questions to this KNOWN filter set
        
        Benefits:
        - LLM knows exactly what's available (no guessing)
        - Filter values are ground truth from actual data
        - Fast queries (no parsing at query time)
        - Handles complex shots (serve+1, at-net volleys, etc.)
        """
        print("\n[INVENTORY] Building complete match filter inventory...")
        
        # Initialize inventory with sets (for unique values)
        inventory = {
            # === NEW TAXONOMY (primary) ===
            'shot_phases': set(),           # serve, return, rally, net
            'contact_types': set(),         # groundstroke, volley, half_volley, swinging_volley, overhead
            'spins': set(),                 # slice, flat, topspin
            'intents': set(),               # approach, drop_shot, lob, passing_shot, winner_attempt
            'locations': set(),             # baseline, mid_court, net, service_line
            
            # === CORE DIMENSIONS ===
            'shot_types': set(),            # forehand, backhand, serve, overhead
            'directions': set(),            # crosscourt, down_the_line, inside_out, inside_in, down_the_middle
            'depths': set(),                # shallow, deep, very_deep
            'serve_targets': set(),         # wide, body, t
            'outcomes': set(),              # winner, unforced_error, forced_error, ace, etc.
            
            # === LEGACY (read-only, derived - never queried directly) ===
            'spin_types': set(),            # LEGACY: use 'spins' instead (still collected for compat)
            'court_positions': set(),       # LEGACY: use 'locations' instead (still collected for compat)
            'net_play_types': set(),        # LEGACY: derive from location=net + contact_type (read-only)
            
            # === SERVE SPECIFICS ===
            'serve_numbers': set(),         # 1, 2
            
            # === COURT/SITUATION ===
            'court_sides': set(),           # ad, deuce
            'sets_played': set(),           # 1, 2, 3, 4, 5
            
            # === PATTERNS (complex - serve+1, return+1) ===
            'serve_plus_one_patterns': set(),  # e.g., "serve_wide -> forehand_crosscourt"
            'serve_plus_one_shot_types': set(),
            'return_plus_one_patterns': set(),
            
            # === OUTCOME ANALYSIS ===
            'winner_shot_types': set(),
            'error_shot_types': set(),
            
            # === RALLY CATEGORIES ===
            'rally_categories': set(),      # 1-3, 4-6, 7-9, 10+
            
            # === COMBINED TAGS (for complex shots) ===
            'combined_shot_tags': set(),
            
            # === PLAYERS ===
            'players': set(),
            
            # === PRESSURE LEVELS ===
            'pressure_levels': set(),       # low, medium, high
        }
        
        # Counters for statistics
        stats = {
            'total_points': 0,
            'total_shots': 0,
            'aces': 0,
            'double_faults': 0,
            'winners': 0,
            'unforced_errors': 0,
            'forced_errors': 0,
        }
        
        for point in self.point_by_point:
            stats['total_points'] += 1
            
            # Get full metadata for this point (uses cached if available)
            if '_metadata' in point:
                metadata = point['_metadata']
            else:
                metadata = self._get_point_metadata(point)
                point['_metadata'] = metadata  # Cache it
            
            # === EXTRACT PLAYERS ===
            server = metadata.get('server', '')
            returner = metadata.get('returner', '')
            if server:
                inventory['players'].add(server)
            if returner:
                inventory['players'].add(returner)
            
            # === EXTRACT SET AND GAME INFO ===
            set_num = metadata.get('set_number')
            if set_num:
                inventory['sets_played'].add(set_num)
            
            # Track games in set and overall
            game_in_set = metadata.get('game_number_in_set')
            if game_in_set and 'games_per_set' not in inventory:
                inventory['games_per_set'] = {}
            if game_in_set and set_num:
                if set_num not in inventory.get('games_per_set', {}):
                    inventory['games_per_set'] = inventory.get('games_per_set', {})
                    inventory['games_per_set'][set_num] = set()
                inventory['games_per_set'][set_num].add(game_in_set)
            
            # === EXTRACT COURT SIDE ===
            situation = metadata.get('situation', {})
            court_side = situation.get('court_side')
            if court_side:
                inventory['court_sides'].add(court_side)
            
            # === EXTRACT SERVE INFO ===
            serve_info = metadata.get('serve_info', {})
            serve_target = serve_info.get('serve_target')
            if serve_target:
                inventory['serve_targets'].add(serve_target)
            serve_num = serve_info.get('serve_number')
            if serve_num:
                inventory['serve_numbers'].add(serve_num)
            
            # Track outcomes
            if serve_info.get('is_ace'):
                stats['aces'] += 1
                inventory['outcomes'].add('ace')
            if serve_info.get('is_double_fault'):
                stats['double_faults'] += 1
                inventory['outcomes'].add('double_fault')
            
            # === EXTRACT RALLY CATEGORY ===
            rally_cat = metadata.get('rally_category')
            if rally_cat:
                inventory['rally_categories'].add(rally_cat)
            
            # === EXTRACT PRESSURE LEVEL ===
            pressure = point.get('pressure', {})
            tightness = pressure.get('score_tightness', 0)
            if tightness <= 3:
                inventory['pressure_levels'].add('low')
            elif tightness <= 6:
                inventory['pressure_levels'].add('medium')
            else:
                inventory['pressure_levels'].add('high')
            
            # === PROCESS EACH SHOT IN RALLY ===
            # Metadata uses 'all_shots' key (not 'actual_shots')
            actual_shots = metadata.get('all_shots', metadata.get('actual_shots', []))
            for shot_idx, shot in enumerate(actual_shots):
                stats['total_shots'] += 1
                
                # === NEW TAXONOMY COLLECTION ===
                shot_phase = shot.get('shot_phase')
                if shot_phase:
                    inventory['shot_phases'].add(shot_phase)
                
                contact_type = shot.get('contact_type')
                if contact_type:
                    inventory['contact_types'].add(contact_type)
                
                spin = shot.get('spin')
                if spin:
                    inventory['spins'].add(spin)
                    inventory['spin_types'].add(spin)  # LEGACY
                
                intent = shot.get('intent')
                if intent:
                    inventory['intents'].add(intent)
                
                location = shot.get('location')
                if location:
                    inventory['locations'].add(location)
                    inventory['court_positions'].add(location)  # LEGACY
                
                # === CORE DIMENSIONS ===
                shot_type = shot.get('shot_type')
                if shot_type:
                    inventory['shot_types'].add(shot_type)
                
                direction = shot.get('direction')
                if direction:
                    inventory['directions'].add(direction)
                
                depth = shot.get('depth')
                if depth:
                    inventory['depths'].add(depth)
                
                # === DEPRECATED: SHOT MODIFIERS (no longer collected in inventory) ===
                # shot_modifiers is deprecated - use contact_type/spin/intent instead
                # Still included in shot metadata for backward compatibility only
                
                # === BUILD COMBINED SHOT TAGS ===
                # For complex shots like "forehand volley at net crosscourt"
                combined_tag = self._build_combined_shot_tag(shot)
                if combined_tag:
                    inventory['combined_shot_tags'].add(combined_tag)
                
                # === LEGACY: NET PLAY TRACKING (READ-ONLY, DERIVED - never queried directly) ===
                # This is for backward compatibility only. New queries should use location=net + contact_type
                # Derive net play type from location + contact_type + shot_type - GENERIC
                if location == 'net':
                    # Net contact types that can be combined with shot_type
                    net_contact_types = {'volley', 'overhead'}
                    
                    if contact_type in net_contact_types:
                        if shot_type:
                            net_type = f"{shot_type}_{contact_type}"
                        else:
                            net_type = contact_type
                    elif shot_type:
                        net_type = f"{shot_type}_at_net"  # e.g., "forehand_at_net", "backhand_at_net"
                    else:
                        net_type = 'net_play'
                    inventory['net_play_types'].add(net_type)
                
                # === OUTCOME TRACKING ===
                outcome = shot.get('outcome')
                if outcome:
                    outcome_key = outcome.lower().replace(' ', '_')
                    inventory['outcomes'].add(outcome_key)
                    
                    # Track stats using OUTCOME_CONFIG
                    outcome_config = self._get_outcome_config(outcome)
                    winning_shot_type = outcome_config.get('winning_shot_type', '')
                    is_positive = outcome_config.get('is_positive', True)
                    
                    # Track stats using winning_shot_type - GENERIC approach
                    # Use WINNER_TYPES set for winner detection
                    if winning_shot_type in self.WINNER_TYPES:
                        stats['winners'] += 1
                        if shot_type:
                            inventory['winner_shot_types'].add(shot_type)
                    elif 'unforced' in winning_shot_type:
                        stats['unforced_errors'] += 1
                        if shot_type:
                            inventory['error_shot_types'].add(shot_type)
                    elif 'forced' in winning_shot_type and 'unforced' not in winning_shot_type:
                        stats['forced_errors'] += 1
            
            # === SERVE+1 PATTERN ===
            serve_plus_one = metadata.get('serve_plus_one', {})
            sp1_shot_type = serve_plus_one.get('shot_type')
            sp1_direction = serve_plus_one.get('direction')
            if sp1_shot_type:
                inventory['serve_plus_one_shot_types'].add(sp1_shot_type)
                # Build pattern string
                pattern = f"serve -> {sp1_shot_type}"
                if sp1_direction:
                    pattern += f"_{sp1_direction}"
                inventory['serve_plus_one_patterns'].add(pattern)
        
        # Convert sets to sorted lists for JSON serialization
        self.match_filter_inventory = {
            # === NEW TAXONOMY (primary) ===
            'shot_phases': sorted(inventory['shot_phases']),
            'contact_types': sorted(inventory['contact_types']),
            'spins': sorted(inventory['spins']),
            'intents': sorted(inventory['intents']),
            'locations': sorted(inventory['locations']),
            
            # === CORE DIMENSIONS ===
            'shot_types': sorted(inventory['shot_types']),
            'directions': sorted(inventory['directions']),
            'depths': sorted(inventory['depths']),
            
            # === LEGACY (backward compatibility - read-only, never queried directly) ===
            'spin_types': sorted(inventory['spin_types']),  # LEGACY: use 'spins'
            'court_positions': sorted(inventory['court_positions']),  # LEGACY: use 'locations'
            'net_play_types': sorted(inventory['net_play_types']),  # LEGACY: derive from location=net + contact_type
            'serve_targets': sorted(inventory['serve_targets']),
            'serve_numbers': sorted(inventory['serve_numbers']),
            'court_sides': sorted(inventory['court_sides']),
            'sets_played': sorted(inventory['sets_played']),
            'rally_categories': sorted(inventory['rally_categories']),
            'pressure_levels': sorted(inventory['pressure_levels']),
            'outcomes': sorted(inventory['outcomes']),
            'winner_shot_types': sorted(inventory['winner_shot_types']),
            'error_shot_types': sorted(inventory['error_shot_types']),
            'serve_plus_one_shot_types': sorted(inventory['serve_plus_one_shot_types']),
            'serve_plus_one_patterns': sorted(inventory['serve_plus_one_patterns']),
            'combined_shot_tags': sorted(list(inventory['combined_shot_tags'])[:50]),  # Limit to prevent huge list
            'players': sorted(inventory['players']),
            # === NORMALIZATION INFO ===
            # Aliases that map to canonical forms (user can use any, system normalizes)
            'common_aliases': {
                'directions': {'cc': 'crosscourt', 'xc': 'crosscourt', 'dtl': 'down_the_line', 'dtm': 'down_the_middle', 'io': 'inside_out', 'ii': 'inside_in'},
                'shots': {'fh': 'forehand', 'bh': 'backhand'},
                'outcomes': {'ue': 'unforced_error', 'fe': 'forced_error', 'df': 'double_fault'},
                'serve_targets': {'down the t': 't', 'center': 't', 'middle': 't', 'out wide': 'wide', 'to body': 'body', 'at body': 'body', 'jam': 'body'},
            },
            # Hierarchies - supersets that include subsets
            'hierarchies': {
                'volley': 'includes swinging_volley, half_volley, drop_volley',
                'net_shot': 'includes all volleys + overhead',
                'errors': 'includes unforced_error, forced_error, double_fault',
                'winners_all': 'includes winner, ace, service_winner',
            },
        }
        
        # Store stats
        self.match_stats_summary = stats
        
        # Print inventory summary
        print(f"[INVENTORY] [OK] Built filter inventory from {stats['total_points']} points, {stats['total_shots']} shots:")
        print(f"            === NEW TAXONOMY ===")
        print(f"            Shot Phases: {self.match_filter_inventory['shot_phases']}")
        print(f"            Contact Types: {self.match_filter_inventory['contact_types']}")
        print(f"            Spins: {self.match_filter_inventory['spins']}")
        print(f"            Intents: {self.match_filter_inventory['intents']}")
        print(f"            Locations: {self.match_filter_inventory['locations']}")
        print(f"            === CORE DIMENSIONS ===")
        print(f"            Shot Types: {self.match_filter_inventory['shot_types']}")
        print(f"            Directions: {self.match_filter_inventory['directions']}")
        print(f"            Serve Targets: {self.match_filter_inventory['serve_targets']}")
        print(f"            === LEGACY (read-only, derived) ===")
        print(f"            Net Play: {self.match_filter_inventory['net_play_types']}")
        print(f"            === OTHER ===")
        print(f"            Serve+1 Types: {self.match_filter_inventory['serve_plus_one_shot_types']}")
        print(f"            Sets Played: {self.match_filter_inventory['sets_played']}")
        print(f"            Rally Categories: {self.match_filter_inventory['rally_categories']}")
        print(f"            Stats: {stats['aces']} aces, {stats['double_faults']} DFs, "
              f"{stats['winners']} winners, {stats['unforced_errors']} UEs")
    
    def _build_combined_shot_tag(self, shot: Dict) -> str:
        """
        Build a combined tag for complex shots.
        e.g., "forehand volley at net crosscourt" -> "forehand_volley_net_crosscourt"
        
        This allows filtering/searching by any combination of attributes.
        """
        parts = []
        
        shot_type = shot.get('shot_type')
        if shot_type:
            parts.append(shot_type)
        
        # Add modifiers
        modifiers = shot.get('shot_modifiers', [])
        modifier = shot.get('shot_modifier')
        if modifier and modifier not in modifiers:
            modifiers = [modifier] + modifiers
        
        for mod in modifiers:
            if mod and mod != shot_type:
                parts.append(mod)
        
        # Add position
        if shot.get('at_net') or shot.get('court_position') == 'net':
            if 'net' not in parts and 'volley' not in parts:
                parts.append('net')
        
        # Add direction
        direction = shot.get('direction')
        if direction:
            parts.append(direction)
        
        # Add depth
        depth = shot.get('depth')
        if depth:
            parts.append(depth)
        
        return '_'.join(parts) if len(parts) >= 2 else None
    
    def get_available_filters(self) -> Dict:
        """
        Return the complete filter inventory for this match.
        
        This is what the LLM should use to understand what's available to filter on.
        """
        if not hasattr(self, 'match_filter_inventory') or not self.match_filter_inventory:
            return {"error": "Filter inventory not built. Run _build_match_filter_inventory() first."}
        
        return {
            'match': f"{self.player1} vs {self.player2}",
            'total_points': self.match_stats_summary.get('total_points', 0),
            'total_shots': self.match_stats_summary.get('total_shots', 0),
            'available_filters': self.match_filter_inventory,
            'quick_stats': self.match_stats_summary
        }

    def _compute_leaf_metrics(self, points: list, classification: Dict) -> Dict:
        """
        Compute metrics at a leaf node.
        
        UNIFIED PATH: Always track BOTH players. Player filter applied at end.
        This ensures single-player and both-player queries use identical calculation logic.
        
        GENERIC GROUP BY: If classification has a tree-level group_by dimension,
        points are grouped by that dimension and metrics computed per group.
        """
        from collections import defaultdict
        
        metrics = classification.get('metrics', ['points_won'])
        filters = classification.get('filters', {})
        player_filter = filters.get('player')
        
        # ============================================================
        # GENERIC GROUP BY SUPPORT
        # When group_by is a tree-level dimension, compute metrics per group
        # ============================================================
        group_by = classification.get('group_by')
        all_group_by = classification.get('all_group_by', [])  # For multi-dimensional
        
        # Check if we have a tree-level group_by that's NOT player (player is handled below)
        # CRITICAL: Skip dimensions that are already in filters (they've been pre-filtered by query plan)
        tree_group_by = None
        if group_by and group_by in self.TREE_LEVEL_DIMENSIONS and group_by != 'player' and group_by not in filters:
            tree_group_by = group_by
        elif all_group_by:
            # Check all_group_by for non-player tree dimensions NOT already filtered
            for gb in all_group_by:
                if gb in self.TREE_LEVEL_DIMENSIONS and gb != 'player' and gb not in filters:
                    tree_group_by = gb
                    break
        
        if tree_group_by and points:
            print(f"[GROUP-BY] Computing metrics grouped by: {tree_group_by}")
            
            # Use GROUP_CONFIG for metadata paths (single source of truth)
            group_config = self.GROUP_CONFIG.get(tree_group_by, {})
            metadata_path = group_config.get('metadata_path')
            normalize_fn = group_config.get('normalize')
            
            # Group points by the dimension from metadata
            groups = defaultdict(list)
            for pt in points:
                # Ensure metadata is computed
                if '_metadata' not in pt:
                    pt['_metadata'] = self._get_point_metadata(pt)
                
                # Get group key from metadata using config path
                meta = pt['_metadata']
                group_key = None
                
                if metadata_path:
                    # Navigate path from GROUP_CONFIG
                    group_key = meta
                    for key in metadata_path:
                        if isinstance(group_key, dict):
                            group_key = group_key.get(key)
                        else:
                            group_key = None
                            break
                else:
                    # Direct access for dimensions without explicit path
                    group_key = meta.get(tree_group_by)
                
                # Apply normalization if defined (e.g., 2 -> '2nd')
                if group_key is not None and normalize_fn:
                    try:
                        group_key = normalize_fn(group_key)
                    except:
                        pass
                
                if group_key is None:
                    group_key = 'unknown'
                groups[str(group_key)].append(pt)
            
            # Compute metrics for EACH group (recursively, without group_by to avoid infinite loop)
            grouped_results = {
                'grouped_by': tree_group_by,
                'groups': {},
                'total_points': len(points),
                'player1_name': self.player1,
                'player2_name': self.player2
            }
            
            # Create classification without group_by for recursive call
            sub_classification = dict(classification)
            sub_classification['group_by'] = None
            sub_classification['all_group_by'] = []
            
            for group_value, group_points in groups.items():
                if group_value == 'unknown':
                    continue  # Skip unknown values
                    
                # Compute metrics for this group
                sub_results = self._compute_leaf_metrics(group_points, sub_classification)
                
                # Extract key stats for this group
                grouped_results['groups'][group_value] = {
                    'count': len(group_points),
                    'player1_wins': sub_results.get('player1_wins', 0),
                    'player2_wins': sub_results.get('player2_wins', 0),
                    'player1_pct': sub_results.get('player1_pct', 0),
                    'player2_pct': sub_results.get('player2_pct', 0),
                    'per_player_metrics': sub_results.get('per_player_metrics', {})
                }
            
            print(f"[GROUP-BY] Found {len(grouped_results['groups'])} groups: {list(grouped_results['groups'].keys())}")
            
            # Also compute overall (ungrouped) metrics for context
            overall_classification = dict(classification)
            overall_classification['group_by'] = None
            overall_classification['all_group_by'] = []
            overall_results = self._compute_leaf_metrics(points, overall_classification)
            
            # Merge overall results with grouped results
            grouped_results['per_player_metrics'] = overall_results.get('per_player_metrics', {})
            grouped_results['metrics'] = overall_results.get('metrics', {})
            grouped_results['player1_wins'] = overall_results.get('player1_wins', 0)
            grouped_results['player2_wins'] = overall_results.get('player2_wins', 0)
            grouped_results['player1_pct'] = overall_results.get('player1_pct', 0)
            grouped_results['player2_pct'] = overall_results.get('player2_pct', 0)
            
            return grouped_results
        
        # ============================================================
        # ORIGINAL LOGIC (no group_by or player-only group_by)
        # ============================================================
        
        player1 = self.player1
        player2 = self.player2
        
        # UNIFIED: Always track both players - player filter applied at END
        # No more is_both_players branching in the calculation logic
        
        results = {
            'total_points': len(points),
            'player1_wins': 0,
            'player2_wins': 0,
            'player1_name': player1,
            'player2_name': player2,
            'metrics': {},
            'per_player_metrics': {}  # ALWAYS populated - for ALL queries
        }
        
        # ALWAYS initialize per_player_metrics for ALL metrics
        for metric in metrics:
            results['metrics'][metric] = {'count': 0, 'examples': []}
            results['per_player_metrics'][metric] = {
                'player1': {'count': 0, 'total': 0},
                'player2': {'count': 0, 'total': 0}
            }
        
        # === GAME-LEVEL AND SET-LEVEL METRICS ===
        # Games and sets aggregate from points - handle separately
        game_level_metrics = {'games_won', 'games_lost', 'service_games_held', 'breaks', 'sets_won'}
        active_game_metrics = [m for m in metrics if m in game_level_metrics]
        
        if active_game_metrics:
            # Aggregate games from points in this branch
            game_results = self._aggregate_games_from_points(points, filters)
            
            # UNIFIED: ALWAYS track both players for game-level metrics too
            for metric in active_game_metrics:
                if metric == 'games_won':
                    results['per_player_metrics'][metric]['player1']['count'] = game_results.get('player1_games', 0)
                    results['per_player_metrics'][metric]['player1']['total'] = game_results.get('total_games', 0)
                    results['per_player_metrics'][metric]['player2']['count'] = game_results.get('player2_games', 0)
                    results['per_player_metrics'][metric]['player2']['total'] = game_results.get('total_games', 0)
                    results['metrics'][metric]['count'] = game_results.get('player1_games', 0) + game_results.get('player2_games', 0)
                elif metric == 'service_games_held':
                    results['per_player_metrics'][metric]['player1']['count'] = game_results.get('player1_holds', 0)
                    results['per_player_metrics'][metric]['player1']['total'] = game_results.get('player1_service_games', 0)
                    results['per_player_metrics'][metric]['player2']['count'] = game_results.get('player2_holds', 0)
                    results['per_player_metrics'][metric]['player2']['total'] = game_results.get('player2_service_games', 0)
                    results['metrics'][metric]['count'] = game_results.get('player1_holds', 0) + game_results.get('player2_holds', 0)
                elif metric == 'breaks':
                    results['per_player_metrics'][metric]['player1']['count'] = game_results.get('player1_breaks', 0)
                    results['per_player_metrics'][metric]['player1']['total'] = game_results.get('player2_service_games', 0)  # Opp's service games
                    results['per_player_metrics'][metric]['player2']['count'] = game_results.get('player2_breaks', 0)
                    results['per_player_metrics'][metric]['player2']['total'] = game_results.get('player1_service_games', 0)  # Opp's service games
                    results['metrics'][metric]['count'] = game_results.get('player1_breaks', 0) + game_results.get('player2_breaks', 0)
                elif metric == 'sets_won':
                    results['per_player_metrics'][metric]['player1']['count'] = game_results.get('player1_sets', 0)
                    results['per_player_metrics'][metric]['player1']['total'] = game_results.get('total_sets', 0)
                    results['per_player_metrics'][metric]['player2']['count'] = game_results.get('player2_sets', 0)
                    results['per_player_metrics'][metric]['player2']['total'] = game_results.get('total_sets', 0)
                    results['metrics'][metric]['count'] = game_results.get('player1_sets', 0) + game_results.get('player2_sets', 0)
        
        for point_data in points:
            point_text = point_data.get('point_text', point_data.get('description', ''))
            server = point_data.get('server', '')
            returner = point_data.get('returner', '')
            
            # CRITICAL: Get point winner - prefer enriched field, fallback to text extraction
            # Enriched data has point_winner set during _enrich_point_data()
            point_winner = point_data.get('point_winner')
            if not point_winner:
                # Fallback: Extract from [Point won by: Player] tag in NL text
                winner_match = re.search(r'\[Point won by:\s*([^\]]+)\]', point_text)
                if winner_match:
                    point_winner = winner_match.group(1).strip()
            
            # Parse rally for shot counting and other analysis
            rally_shots = self._parse_rally_sequence(point_text, server, returner)
            actual_shots = [s for s in rally_shots if s.get('outcome') != 'FAULT']
            
            # UNIFIED: Use _determine_point_winner for shot type determination
            # Only use it for shot_type/error_player if point_winner not already from [Point won by:] tag
            _, winning_shot_type, error_player = self._determine_point_winner(
                actual_shots, server, returner, return_details=True
            )
            
            # NOTE: error_player is already stored during _enrich_point_data at load time
            
            # Count wins (using robust name matching)
            if point_winner:
                if player1 and self._names_match_robust(player1, point_winner):
                    results['player1_wins'] += 1
                elif player2 and self._names_match_robust(player2, point_winner):
                    results['player2_wins'] += 1
            
            # Track metrics
            # Get serve_number from point metadata (1 = first serve in, 2 = had to use 2nd serve)
            serve_info = point_data.get('serve_info', {})
            serve_number = serve_info.get('serve_number', 1) if serve_info else 1
            # Fallback: detect from text if no serve_info metadata
            if not serve_info or serve_number is None:
                has_second_serve = '2nd serve' in point_text.lower() or 'second serve' in point_text.lower()
                serve_number = 2 if has_second_serve else 1
            
            # CRITICAL: Include ALL point metadata needed for filter checking!
            # Must include: set, rally_length, point_score, game_number_in_set, point_number
            point_data_for_metric = {
                'point_text': point_text,
                'rally_length': point_data.get('rally_length') or point_data.get('_metadata', {}).get('rally_length') or self._calculate_rally_length(rally_shots, point_text),
                '_prev_rally_length': point_data.get('_prev_rally_length', 0),  # For "after X rally" queries
                'server': server,
                'returner': returner,
                'error_player': error_player,
                'point_winner': point_winner,
                'serve_number': serve_number,
                # CRITICAL: Add metadata fields for filter checking
                'set': point_data.get('set_number') or point_data.get('set') or point_data.get('_metadata', {}).get('set_number'),
                'point_score': point_data.get('score') or point_data.get('point_score'),
                'point_number': point_data.get('point_number'),
                'game_number_in_set': point_data.get('game_number_in_set') or point_data.get('_metadata', {}).get('game_number_in_set'),
                'game_number': point_data.get('game_number') or point_data.get('_metadata', {}).get('game_number'),
            }
            
            for metric in metrics:
                # === SHOT-LEVEL METRICS (count individual shots, not point outcomes) ===
                # Dynamic shot counting based on metadata - no hard-coded shot types
                # Handle 'shot_count', 'shot_count_1', 'shots_count', etc. (for multiple metrics_parsed)
                is_shot_count_metric = (metric.startswith('shot_count') or 
                                       metric.startswith('shots_count') or 
                                       metric in ['shots', 'shot'])
                if is_shot_count_metric:
                    # Get filters - check metric_filters first (from metrics_parsed), then global
                    metric_filter_data = classification.get('metric_filters', {}).get(metric, {})
                    per_metric_filters = metric_filter_data.get('filters', {}) if metric_filter_data else {}
                    global_filters = classification.get('filters', {})
                    
                    # Per-metric filters override global filters
                    shot_type_filter = per_metric_filters.get('shot_type') or global_filters.get('shot_type')
                    direction_filter = per_metric_filters.get('direction') or global_filters.get('direction')
                    metric_player_filter = per_metric_filters.get('player') or player_filter
                    group_by = classification.get('group_by')
                    
                    # When group_by='shot_type', we need to count shots BY TYPE
                    # This is different from point-level grouping!
                    if group_by == 'shot_type':
                        # Initialize per-shot-type counts if not present
                        if 'shot_counts_by_type' not in results:
                            results['shot_counts_by_type'] = {}
                        
                        # Debug first point only
                        if not hasattr(self, '_shot_count_debug_done'):
                            self._shot_count_debug_done = True
                            print(f"[SHOT-COUNT-DEBUG] metric='{metric}', metric_player_filter='{metric_player_filter}', shot_type_filter='{shot_type_filter}', group_by='{group_by}'")
                            print(f"[SHOT-COUNT-DEBUG] First point has {len(actual_shots)} shots")
                            if actual_shots:
                                print(f"[SHOT-COUNT-DEBUG] Sample shot: {actual_shots[0]}")
                        
                        # Also track detailed breakdown by contact_type and intent
                        if 'shot_breakdown' not in results:
                            results['shot_breakdown'] = {}
                        
                        for shot in actual_shots:
                            shot_player = shot.get('player', '')
                            shot_type = (shot.get('shot_type') or '').lower()
                            shot_direction = shot.get('direction', '')
                            contact_type = shot.get('contact_type', 'groundstroke')
                            intent = shot.get('intent', '')
                            
                            # Skip if no shot_type
                            if not shot_type:
                                continue
                            
                            # Apply player filter - only count this player's shots
                            if metric_player_filter:
                                match = self._names_match_robust(metric_player_filter, shot_player)
                                # Debug first few shots
                                if not hasattr(self, '_shot_player_debug_count'):
                                    self._shot_player_debug_count = 0
                                if self._shot_player_debug_count < 5:
                                    self._shot_player_debug_count += 1
                                    print(f"[SHOT-PLAYER-DEBUG] filter='{metric_player_filter}' vs shot_player='{shot_player}' -> match={match}")
                                if not match:
                                    continue
                            
                            # Apply shot_type filter from metric_filters (for metrics_parsed)
                            if shot_type_filter and shot_type != shot_type_filter.lower():
                                continue
                            
                            # Apply direction filter if present
                            if direction_filter and shot_direction != direction_filter:
                                continue
                            
                            # Count by shot type (simple total)
                            if shot_type not in results['shot_counts_by_type']:
                                results['shot_counts_by_type'][shot_type] = 0
                            results['shot_counts_by_type'][shot_type] += 1
                            
                            # Track detailed breakdown by contact_type + intent (they don't overlap)
                            if shot_type not in results['shot_breakdown']:
                                results['shot_breakdown'][shot_type] = {
                                    'groundstroke': 0,
                                    'volley': 0,
                                    'swinging_volley': 0,
                                    'half_volley': 0,
                                    'overhead': 0,
                                    'drop_shot': 0,
                                    'lob': 0
                                }
                            
                            # Categorize by contact_type and intent
                            # NOTE: Approach shots are included in groundstrokes (not a separate category)
                            if intent in ['drop_shot', 'lob']:
                                results['shot_breakdown'][shot_type][intent] += 1
                            elif contact_type in ['volley', 'swinging_volley', 'half_volley', 'overhead']:
                                results['shot_breakdown'][shot_type][contact_type] += 1
                            else:  # Default to groundstroke (includes approach shots)
                                results['shot_breakdown'][shot_type]['groundstroke'] += 1
                        
                        continue
                    
                    # Standard shot_count (no grouping) - count all shots matching filters
                    # If there's a shot_type filter, populate shot_counts_by_type for formatting
                    if shot_type_filter and 'shot_counts_by_type' not in results:
                        results['shot_counts_by_type'] = {}
                    
                    shot_count = 0
                    p1_shots = 0
                    p2_shots = 0
                    for shot in actual_shots:
                        shot_player = shot.get('player', '')
                        shot_type_val = (shot.get('shot_type') or '').lower()
                        shot_direction = shot.get('direction', '')
                        
                        # Apply shot type filter dynamically from classification
                        if shot_type_filter and shot_type_val != shot_type_filter.lower():
                            continue
                        
                        # Apply direction filter if present
                        if direction_filter and shot_direction != direction_filter:
                            continue
                        
                        # Track per-player BEFORE applying player filter (for per_player_metrics)
                        is_p1_shot = player1 and self._names_match_robust(player1, shot_player)
                        is_p2_shot = player2 and self._names_match_robust(player2, shot_player)
                        if is_p1_shot:
                            p1_shots += 1
                        elif is_p2_shot:
                            p2_shots += 1
                        
                        # Apply player filter (use metric-specific if available)
                        if metric_player_filter and not self._names_match_robust(metric_player_filter, shot_player):
                            continue
                        
                        shot_count += 1
                        
                        # If filtering by shot_type, track in shot_counts_by_type for formatting
                        if shot_type_filter:
                            if shot_type_val not in results['shot_counts_by_type']:
                                results['shot_counts_by_type'][shot_type_val] = 0
                            results['shot_counts_by_type'][shot_type_val] += 1
                    
                    results['metrics'][metric]['count'] += shot_count
                    # CRITICAL: Also track per_player_metrics so player filter doesn't clobber with 0
                    results['per_player_metrics'][metric]['player1']['count'] += p1_shots
                    results['per_player_metrics'][metric]['player1']['total'] += p1_shots  # For shots, count=total
                    results['per_player_metrics'][metric]['player2']['count'] += p2_shots
                    results['per_player_metrics'][metric]['player2']['total'] += p2_shots
                    continue
                
                # === UNIFIED PATH: ALWAYS track both players ===
                # Player filter is applied at the END, not during tracking
                
                # GENERIC N-METRIC: Check if this metric has its own filter set
                metric_filters_map = classification.get('metric_filters', {})
                metric_specific = metric_filters_map.get(metric, {})
                
                if metric_specific and metric_specific.get('filters'):
                    # Create a modified classification with metric-specific filters
                    # MERGE: start with global filters, then OVERRIDE with metric-specific
                    merged_filters = dict(filters)  # Copy global filters
                    merged_filters.update({k: v for k, v in metric_specific['filters'].items() if v is not None})
                    
                    metric_classification = dict(classification)
                    metric_classification['filters'] = merged_filters
                    
                    # Use the original metric name (not the unique key)
                    actual_metric = metric_specific.get('metric', metric)
                    
                    self._track_per_player_metric(
                        actual_metric, results, point_text, actual_shots,
                        point_winner, winning_shot_type, server,
                        player1, player2, point_data_for_metric, metric_classification
                    )
                else:
                    # No metric-specific filters, use global classification
                    self._track_per_player_metric(
                        metric, results, point_text, actual_shots,
                        point_winner, winning_shot_type, server,
                        player1, player2, point_data_for_metric, classification
                    )
        
        # === UNIFIED: Calculate per-player percentages for ALL metrics ===
        for metric in results.get('per_player_metrics', {}):
            p1_data = results['per_player_metrics'][metric]['player1']
            p2_data = results['per_player_metrics'][metric]['player2']
            
            p1_data['pct'] = round(100 * p1_data['count'] / p1_data['total'], 1) if p1_data['total'] > 0 else 0
            p2_data['pct'] = round(100 * p2_data['count'] / p2_data['total'], 1) if p2_data['total'] > 0 else 0
        
        # Calculate overall point win percentages
        if results['total_points'] > 0:
            results['player1_pct'] = round(100 * results['player1_wins'] / results['total_points'], 1)
            results['player2_pct'] = round(100 * results['player2_wins'] / results['total_points'], 1)
        else:
            results['player1_pct'] = 0
            results['player2_pct'] = 0
        
        # === PLAYER FILTER: Extract single player's data if filtered ===
        # This is the ONLY place where player filter matters - at the END
        if player_filter and player_filter.lower() != 'both':
            # Determine which player was requested
            is_player1 = player1 and self._names_match_robust(player_filter, player1)
            player_key = 'player1' if is_player1 else 'player2'
            
            # Copy that player's per_player_metrics to results['metrics'] for display
            for metric in results.get('per_player_metrics', {}):
                player_data = results['per_player_metrics'][metric][player_key]
                results['metrics'][metric]['count'] = player_data['count']
                results['metrics'][metric]['total'] = player_data['total']
                results['metrics'][metric]['pct'] = player_data['pct']
                # _serve_total is same as total (unified structure)
                results['metrics'][metric]['_serve_total'] = player_data['total']
        else:
            # NO player filter: Aggregate BOTH players' data into results['metrics']
            # This ensures percentages display correctly for "both player" queries
            for metric in results.get('per_player_metrics', {}):
                p1_data = results['per_player_metrics'][metric]['player1']
                p2_data = results['per_player_metrics'][metric]['player2']
                
                # Sum totals and counts from both players
                total_count = p1_data.get('count', 0) + p2_data.get('count', 0)
                total_total = p1_data.get('total', 0) + p2_data.get('total', 0)
                
                results['metrics'][metric]['count'] = total_count
                results['metrics'][metric]['total'] = total_total
                results['metrics'][metric]['_serve_total'] = total_total
                
                # Calculate combined percentage
                if total_total > 0:
                    results['metrics'][metric]['pct'] = round(100 * total_count / total_total, 1)
                else:
                    results['metrics'][metric]['pct'] = 0
        
        # DEBUG: Show shot counts if we have them
        if 'shot_counts_by_type' in results and results['shot_counts_by_type']:
            total = sum(results['shot_counts_by_type'].values())
            print(f"[DEBUG] Shot counts by type: {results['shot_counts_by_type']} (total: {total})")
        
        return results
    
    def _track_per_player_metric(self, metric: str, results: Dict, point_text: str, 
                                  actual_shots: list, point_winner: str, winning_shot_type: str,
                                  server: str, player1: str, player2: str, 
                                  point_data_for_metric: Dict, classification: Dict = None) -> None:
        """
        UNIFIED CONFIG-DRIVEN metric tracking for ALL metrics.
        
        ONE code path handles ALL metrics - the config defines:
        - player_role: whose metric (server/returner/winner/error/both)
        - total_filter: which points count toward the denominator
        - count_filter: which points count toward the numerator
        - keywords: optional text patterns to match
        """
        point_lower = point_text.lower()
        filters = classification.get('filters', {}) if classification else {}
        role_filter = filters.get('role')
        returner = point_data_for_metric.get('returner', '')
        error_player = point_data_for_metric.get('error_player', '')
        
        # Generic helper: safely convert any value to lowercase string, handling None
        def safe_lower(val):
            return str(val or '').lower()
        
        # CRITICAL: ALWAYS calculate serve_number from text to avoid stale cache issues
        has_2nd_serve = '2nd serve' in point_lower or 'second serve' in point_lower
        has_1st_fault = bool(re.search(r'1st serve[^;]*fault', point_lower))
        is_second_serve = has_2nd_serve or has_1st_fault
        serve_number = 2 if is_second_serve else 1
        
        # === GENERIC FILTER CHECKING - Works for ALL filter types ===
        # Tree traversal filters with global filters, but metric-specific filters need per-metric checks
        # This ensures each metric only counts points matching ITS specific filters
        
        # DEBUG: Track point for detailed filter checking (limit to first 3 points)
        point_num = point_data_for_metric.get('point_number', '?')
        debug_prefix = f"[METRIC-FILTER] Point {point_num} | Metric: {metric}"
        
        # Track debug output count per metric to limit spam
        debug_key = f"_metric_filter_debug_{metric}"
        if not hasattr(self, debug_key):
            setattr(self, debug_key, 0)
        debug_count = getattr(self, debug_key)
        should_debug = debug_count < 3
        
        # serve_number filter
        serve_number_filter = filters.get('serve_number')
        if serve_number_filter is not None:
            if serve_number != serve_number_filter:
                if should_debug:
                    print(f"{debug_prefix} | FILTERED: serve_number={serve_number} != filter={serve_number_filter}")
                return
            if should_debug:
                print(f"{debug_prefix} | âœ“ serve_number={serve_number} matches filter={serve_number_filter}")
        
        # REMOVED: situation filter check
        # Situation filtering is done by the TREE during traversal, not here.
        # The tree uses _check_situation(score) which works correctly.
        # Re-checking here using metadata.is_break_point causes false negatives
        # because metadata isn't always populated.
        
        # Generic shot-based filter check (for shot_type, direction, court_zone, depth)
        # These filters check if any shot in the rally matches the filter value
        shot_based_filters = ['shot_type', 'direction', 'court_zone', 'depth']
        for filter_key in shot_based_filters:
            filter_val = filters.get(filter_key)
            if filter_val:
                filter_str = safe_lower(filter_val)
                # Special handling for shot_type: also check winning_shot_type
                if filter_key == 'shot_type' and winning_shot_type:
                    winning_match = filter_str in safe_lower(winning_shot_type)
                    if not winning_match:
                        shot_matches = any(safe_lower(shot.get(filter_key)) == filter_str for shot in actual_shots)
                        if not shot_matches:
                            shot_types_found = [safe_lower(s.get(filter_key) or '') for s in actual_shots if s.get(filter_key) is not None]
                            if should_debug:
                                print(f"{debug_prefix} | FILTERED: {filter_key}={filter_str} not found (winning={safe_lower(winning_shot_type)}, shots={shot_types_found})")
                            return
                        if should_debug:
                            print(f"{debug_prefix} | MATCH {filter_key}={filter_str} matches in rally shots (not winning shot)")
                    else:
                        if should_debug:
                            print(f"{debug_prefix} | âœ“ {filter_key}={filter_str} matches winning_shot_type={safe_lower(winning_shot_type)}")
                else:
                    shot_matches = any(safe_lower(shot.get(filter_key) or '') == filter_str for shot in actual_shots)
                    if not shot_matches:
                        values_found = [safe_lower(s.get(filter_key) or '') for s in actual_shots if s.get(filter_key) is not None]
                        if should_debug:
                            print(f"{debug_prefix} | FILTERED: {filter_key}={filter_str} not found in shots (found={values_found})")
                        return
                    if should_debug:
                        print(f"{debug_prefix} | MATCH {filter_key}={filter_str} matches in rally shots")
        
        # REMOVED: court_side, serve_target filter checks
        # These are TREE-LEVEL filters - already applied during tree traversal!
        # The points passed to _track_per_player_metric have ALREADY been filtered.
        # Re-checking here fails because point_data_for_metric doesn't include these fields.
        
        # set filter (supports both single value and list)
        set_filter = filters.get('set')
        if set_filter is not None:
            point_set = point_data_for_metric.get('set')
            # Handle both single value and list (e.g., [1, 2] for "Sets 1-2")
            if isinstance(set_filter, (list, tuple)):
                if point_set not in set_filter:
                    if should_debug:
                        print(f"{debug_prefix} | FILTERED: set={set_filter} doesn't contain point_set={point_set}")
                    return
            else:
                if point_set != set_filter:
                    if should_debug:
                        print(f"{debug_prefix} | FILTERED: set={set_filter} != point_set={point_set}")
                    return
            if should_debug:
                print(f"{debug_prefix} | OK set={set_filter} matches point_set={point_set}")
        
        # CRITICAL: rally_length filter (supports ranges, comparisons, exact matches)
        rally_filter = filters.get('rally_length')
        if rally_filter is not None:
            pt_rally = point_data_for_metric.get('rally_length', 0)
            passes_rally_filter = False
            
            if isinstance(rally_filter, (tuple, list)) and len(rally_filter) == 2:
                # Range filter: (min, max) or [min, max]
                min_val, max_val = rally_filter
                passes_rally_filter = min_val <= pt_rally <= max_val
                if not passes_rally_filter:
                    if should_debug:
                        print(f"{debug_prefix} | FILTERED: rally_length {pt_rally} not in range ({min_val}, {max_val})")
                    return
            elif isinstance(rally_filter, str):
                # Comparison filter: ">=5", "<=10", ">3", "<7"
                if rally_filter.startswith('<='):
                    passes_rally_filter = pt_rally <= int(rally_filter[2:])
                elif rally_filter.startswith('>='):
                    passes_rally_filter = pt_rally >= int(rally_filter[2:])
                elif rally_filter.startswith('<'):
                    passes_rally_filter = pt_rally < int(rally_filter[1:])
                elif rally_filter.startswith('>'):
                    passes_rally_filter = pt_rally > int(rally_filter[1:])
                
                if not passes_rally_filter:
                    if should_debug:
                        print(f"{debug_prefix} | FILTERED: rally_length {pt_rally} does not match {rally_filter}")
                    return
            elif isinstance(rally_filter, int):
                # Exact match
                passes_rally_filter = pt_rally == rally_filter
                if not passes_rally_filter:
                    if should_debug:
                        print(f"{debug_prefix} | FILTERED: rally_length {pt_rally} != {rally_filter}")
                    return
            
            if should_debug and passes_rally_filter:
                print(f"{debug_prefix} | OK rally_length={pt_rally} matches filter={rally_filter}")
        
        # CRITICAL: prev_rally_length filter (for "after X rally" queries)
        prev_rally_filter = filters.get('prev_rally_length')
        if prev_rally_filter is not None:
            pt_prev_rally = point_data_for_metric.get('_prev_rally_length', 0)
            passes_prev_rally_filter = False
            
            if isinstance(prev_rally_filter, (tuple, list)) and len(prev_rally_filter) == 2:
                # Range filter: (min, max) or [min, max]
                min_val, max_val = prev_rally_filter
                passes_prev_rally_filter = min_val <= pt_prev_rally <= max_val
                if not passes_prev_rally_filter:
                    if should_debug:
                        print(f"{debug_prefix} | FILTERED: prev_rally_length {pt_prev_rally} not in range ({min_val}, {max_val})")
                    return
            elif isinstance(prev_rally_filter, str):
                # Comparison filter: ">=5", "<=10", ">3", "<7"
                if prev_rally_filter.startswith('<='):
                    passes_prev_rally_filter = pt_prev_rally <= int(prev_rally_filter[2:])
                elif prev_rally_filter.startswith('>='):
                    passes_prev_rally_filter = pt_prev_rally >= int(prev_rally_filter[2:])
                elif prev_rally_filter.startswith('<'):
                    passes_prev_rally_filter = pt_prev_rally < int(prev_rally_filter[1:])
                elif prev_rally_filter.startswith('>'):
                    passes_prev_rally_filter = pt_prev_rally > int(prev_rally_filter[1:])
                
                if not passes_prev_rally_filter:
                    if should_debug:
                        print(f"{debug_prefix} | FILTERED: prev_rally_length {pt_prev_rally} does not match {prev_rally_filter}")
                    return
            elif isinstance(prev_rally_filter, int):
                # Exact match
                passes_prev_rally_filter = pt_prev_rally == prev_rally_filter
                if not passes_prev_rally_filter:
                    if should_debug:
                        print(f"{debug_prefix} | FILTERED: prev_rally_length {pt_prev_rally} != {prev_rally_filter}")
                    return
            
            if should_debug and passes_prev_rally_filter:
                print(f"{debug_prefix} | OK prev_rally_length={pt_prev_rally} matches filter={prev_rally_filter}")
        
        # REMOVED: point_score filter check
        # This is a TREE-LEVEL filter - already applied during tree traversal!
        # Re-checking here fails because point_data_for_metric has the FULL score string
        # (e.g., "0-0 1-1 0-40") while the filter is just the game score (e.g., "0-40")
        
        # CRITICAL: game_number filter
        game_number_filter = filters.get('game_number') or filters.get('game_number_in_set')
        if game_number_filter is not None:
            pt_game = point_data_for_metric.get('game_number_in_set') or point_data_for_metric.get('game_number')
            if pt_game != game_number_filter:
                if should_debug:
                    print(f"{debug_prefix} | FILTERED: game_number={game_number_filter} != point_game={pt_game}")
                return
            if should_debug:
                print(f"{debug_prefix} | OK game_number={pt_game} matches filter={game_number_filter}")
        
        # DEBUG: Point passed all filters (only show first 3)
        active_filters = {k: v for k, v in filters.items() if v is not None}
        if should_debug:
            print(f"{debug_prefix} | *** PASSED ALL FILTERS: {active_filters} | Will count for metric")
            setattr(self, debug_key, debug_count + 1)
        
        # role filter is handled via player_role override below
        
        # Get config for this metric from CLASS CONSTANT (single source of truth)
        config = TennisChatAgentEmbeddingQALocal.METRIC_CONFIG.get(metric, {'player_role': 'both', 'total_filter': 'always', 'count_filter': 'won'})
        player_role = config['player_role']
        total_filter = config['total_filter']
        count_filter = config['count_filter']
        keywords = config.get('keywords', [])
        exclude_keywords = config.get('exclude_keywords', [])
        
        # Override player_role if role_filter is set (e.g., "as server") - GENERIC
        if role_filter and role_filter in self.ROLE_CONFIG:
            player_role = role_filter
        
        # Helper: check if keywords match
        def keywords_match():
            if not keywords:
                return True
            # Check that at least one keyword matches
            has_keyword = any(kw in point_lower for kw in keywords)
            # Check that NO exclude keywords match
            has_exclude = any(ex in point_lower for ex in exclude_keywords) if exclude_keywords else False
            return has_keyword and not has_exclude
        
        # Helper: check total filter condition
        def passes_total_filter():
            if total_filter == 'always':
                return True
            elif total_filter == 'first_serve':
                return serve_number == 1
            elif total_filter == 'second_serve':
                return serve_number == 2
            elif total_filter == 'on_match':
                return keywords_match()
            return True
        
        # Helper: check count filter condition for a specific player
        def passes_count_filter(player):
            if count_filter == 'always':
                return True
            elif count_filter == 'first_serve_in':
                return serve_number == 1
            elif count_filter == 'second_serve_in':
                return serve_number == 2 and 'double fault' not in point_lower
            elif count_filter == 'won':
                return point_winner and self._names_match_robust(player, point_winner)
            elif count_filter == 'on_match':
                return keywords_match()
            return True
        
        # === UNIFIED TRACKING LOOP - ONE PATH FOR ALL METRICS ===
        for player, player_key in [(player1, 'player1'), (player2, 'player2')]:
            if not player:
                continue
            
            # Determine if this player is relevant for this metric - GENERIC using ROLE_CONFIG
            is_relevant = False
            if player_role == 'both':
                is_relevant = True
            elif player_role == 'performer':
                # Special case: check if player performed the action in any shot
                for shot in actual_shots:
                    shot_desc = shot.get('description', '').lower()
                    shot_player = shot.get('player', '')
                    if self._names_match_robust(player, shot_player) and any(kw in shot_desc for kw in keywords):
                        is_relevant = True
                        break
            else:
                # GENERIC: Use ROLE_CONFIG to determine which player field to check
                role_config = self.ROLE_CONFIG.get(player_role, {})
                player_field = role_config.get('player_field', '')
                if player_field:
                    # Map player_field to actual player value
                    field_to_player = {
                        'server': server,
                        'returner': returner,
                        'point_winner': point_winner,
                        'error_player': error_player
                    }
                    target_player = field_to_player.get(player_field, '')
                    is_relevant = target_player and self._names_match_robust(player, target_player)
            
            if not is_relevant:
                continue
            
            # Check total filter - if passes, increment total
            if passes_total_filter():
                results['per_player_metrics'][metric][player_key]['total'] += 1
                
                # Check count filter - if passes, increment count
                if passes_count_filter(player):
                    results['per_player_metrics'][metric][player_key]['count'] += 1
    
    
    def _analyze_n_dimensional(self, classification: Dict) -> Dict:
        """
        N-DIMENSIONAL TREE ANALYSIS
        
        Handles any depth of filters + any number of grouping dimensions.
        
        Example 5D query:
        "On break points (1), serving to T (2), on Ad court (3), 
         in sets he won (4), compare 1st vs 2nd serve (5) win %"
        """
        # Reset debug counters for this query (fresh start)
        metrics = classification.get('metrics', [])
        for metric in metrics:
            debug_key = f"_metric_filter_debug_{metric}"
            setattr(self, debug_key, 0)
        
        # Reset shot count debug flag
        if hasattr(self, '_shot_count_debug_done'):
            delattr(self, '_shot_count_debug_done')
        
        # Reset error shot type debug count
        if hasattr(self, '_error_shot_debug_count'):
            delattr(self, '_error_shot_debug_count')
        
        # Build the query tree
        tree = self._build_query_tree(classification)
        
        print(f"[TREE] Built with depth={tree['depth']} | Filters: {tree['dimensions']['filters']} | Groups: {tree['dimensions']['groups']} | Metrics: {tree['dimensions']['metrics']}")
        
        # Get all points
        if not hasattr(self, 'point_by_point') or not self.point_by_point:
            return {'error': 'No point-by-point data available'}
        
        points = self.point_by_point
        
        # NO PRE-FILTERING - Tree traversal handles ALL filtering
        print(f"[TREE] Using {len(points)} points")
        
        # Traverse tree
        results = self._traverse_tree(tree, points)
        
        # For debugging: collect points from tree branches with FULL METADATA
        matching_points = []
        
        def _extract_winning_shot_metadata(pt):
            """Extract metadata from the winning shot of a point."""
            point_text = pt.get('point_text', pt.get('description', ''))
            server = pt.get('server', '')
            returner = pt.get('returner', '')
            rally_shots = self._parse_rally_sequence(point_text, server, returner)
            actual_shots = [s for s in rally_shots if s.get('outcome') not in ['FAULT', 'LET']]
            if actual_shots:
                last = actual_shots[-1]
                # Determine shot category from contact_type and intent
                contact_type = last.get('contact_type', 'groundstroke')
                intent = last.get('intent', '')
                # Categorize: groundstroke vs net shot (volley/half_volley/swinging_volley/overhead) vs drop_shot/lob
                if intent in ['drop_shot', 'lob']:
                    shot_category = intent
                elif contact_type in ['volley', 'half_volley', 'swinging_volley', 'overhead']:
                    shot_category = contact_type
                else:
                    shot_category = 'groundstroke'
                return {
                    'winner': last.get('player', '?'),
                    'shot_type': last.get('shot_type', '?'),
                    'shot_modifier': last.get('shot_modifier', '-'),
                    'direction': last.get('direction', '?'),
                    'at_net': last.get('at_net', False),
                    'outcome': last.get('outcome', '?'),
                    'rally_length': len(actual_shots),
                    'contact_type': contact_type,
                    'intent': intent,
                    'shot_category': shot_category
                }
            return {'winner': '?', 'shot_type': '?', 'shot_modifier': '-', 'direction': '?', 'at_net': False, 'outcome': '?', 'rally_length': 0, 'contact_type': '?', 'intent': '', 'shot_category': '?'}
        
        def _extract_situation_info(pt):
            """Extract situation information from point metadata."""
            # Try multiple locations where situation info might be stored
            if '_metadata' in pt and isinstance(pt['_metadata'], dict):
                return pt['_metadata'].get('situation', {})
            elif 'situation' in pt and isinstance(pt['situation'], dict):
                return pt['situation']
            # Fallback: compute from score if available
            elif 'score' in pt:
                score = pt.get('score', '')
                return {
                    'is_break_point': self._is_break_point_score(score),
                    'is_game_point': self._is_game_point_score(score),
                    'is_set_point': self._is_set_point_score(score),
                    'is_match_point': self._is_match_point_score(score),
                    'is_deuce': self._is_deuce_score(score),
                    'is_tiebreak': self._is_tiebreak_point(score)
                }
            return {}
        
        # Helper to filter points based on metric criteria for debug display
        def _filter_points_by_metric(points, metric, player_name=None):
            """
            GENERIC metric-based point filter for debug display.
            Uses METRIC_CONFIG to determine which points to show.
            
            This ensures debug output shows ONLY points where the metric applies
            (e.g., for "aces", show only ace points, not all serve points).
            """
            if not metric or not points:
                return points
            
            # Get metric config from CLASS CONSTANT (single source of truth)
            config = TennisChatAgentEmbeddingQALocal.METRIC_CONFIG.get(metric, {})
            if not config:
                return points
            
            player_role = config.get('player_role', 'both')
            total_filter = config.get('total_filter', 'always')
            count_filter = config.get('count_filter', 'always')
            keywords = config.get('keywords', [])
            
            filtered = []
            for pt in points:
                point_text = pt.get('point_text', pt.get('description', ''))
                point_lower = point_text.lower()
                server = pt.get('server', '')
                returner = pt.get('returner', '')
                
                # Extract point winner from [Point won by: Player] tag
                point_winner = None
                winner_match = re.search(r'\[Point won by:\s*([^\]]+)\]', point_text)
                if winner_match:
                    point_winner = winner_match.group(1).strip()
                
                # Get serve number
                serve_number = 1
                if '2nd serve' in point_lower or 'second serve' in point_lower:
                    serve_number = 2
                
                # GENERIC: Check player role using ROLE_CONFIG
                # CRITICAL: 'both' or 'all' means no player filter - don't apply role filtering
                effective_player_role = player_name if player_name and player_name.lower() not in ('both', 'all') else None
                if player_role != 'both' and effective_player_role:
                    role_config = self.ROLE_CONFIG.get(player_role, {})
                    player_field = role_config.get('player_field', '')
                    
                    # Map player_field to actual player value
                    field_to_player = {
                        'server': server,
                        'returner': returner,
                        'point_winner': point_winner
                    }
                    target_player = field_to_player.get(player_field, '')
                    
                    # If role doesn't match player, skip this point
                    if not target_player or not self._names_match_robust(effective_player_role, target_player):
                        continue
                
                # GENERIC: Check total filter (denominator condition)
                passes_total = False
                if total_filter == 'always':
                    passes_total = True
                elif total_filter == 'first_serve':
                    passes_total = (serve_number == 1)
                elif total_filter == 'second_serve':
                    passes_total = (serve_number == 2)
                elif total_filter == 'on_match':
                    passes_total = any(kw in point_lower for kw in keywords) if keywords else True
                else:
                    passes_total = True
                
                if not passes_total:
                    continue
                
                # GENERIC: Check count filter (numerator condition - what makes it "count")
                matches_metric = False
                if count_filter == 'always':
                    matches_metric = True
                elif count_filter == 'on_match':
                    # Keyword-based metrics (aces, winners, errors, etc.)
                    matches_metric = any(kw in point_lower for kw in keywords) if keywords else False
                elif count_filter == 'won':
                    # Point won by the player
                    # CRITICAL: 'both' or 'all' means no player filter - count all won points
                    effective_player = player_name if player_name and player_name.lower() not in ('both', 'all') else None
                    if effective_player and point_winner:
                        matches_metric = self._names_match_robust(effective_player, point_winner)
                    else:
                        matches_metric = True  # If no player filter, show all won points
                elif count_filter == 'first_serve_in':
                    # First serve in (not a fault)
                    matches_metric = (serve_number == 1)
                elif count_filter == 'second_serve_in':
                    # Second serve in (not a double fault)
                    matches_metric = (serve_number == 2 and 'double fault' not in point_lower)
                else:
                    matches_metric = True
                
                if matches_metric:
                    filtered.append(pt)
            
            return filtered
        
        # UNIFIED POINT EXTRACTION: Get filtered points from tree traversal result
        # This ensures display shows EXACTLY the same points that were analyzed
        def _get_deepest_points(node_results, depth=0):
            """Recursively find points from the DEEPEST node (not first node with points)."""
            indent = "  " * depth
            if not node_results:
                return []
            
            node_type = node_results.get('type', 'unknown')
            
            # For filter nodes, ALWAYS go to children first (they have more filtered points)
            if node_type == 'filter':
                dim = node_results.get('dimension', '?')
                val = node_results.get('value', '?')
                pts_before = node_results.get('points_before', '?')
                pts_after = node_results.get('points_after', '?')
                print(f"{indent}[EXTRACT] Filter {dim}={val}: {pts_before}->{pts_after}")
                
                if 'children' in node_results and node_results['children']:
                    child_points = _get_deepest_points(node_results['children'], depth + 1)
                    if child_points:
                        return child_points
                # Only if no children, use this node's points
                if 'points' in node_results:
                    print(f"{indent}[EXTRACT] Using filter's points: {len(node_results['points'])}")
                    return node_results['points']
            
            # For group nodes, collect from all branches
            elif node_type == 'group' and 'branches' in node_results:
                print(f"{indent}[EXTRACT] Group with {len(node_results['branches'])} branches")
                all_points = []
                for branch_key, branch_data in node_results['branches'].items():
                    if 'points' in branch_data:
                        print(f"{indent}[EXTRACT]   Branch '{branch_key}': {len(branch_data['points'])} points")
                        all_points.extend(branch_data['points'])
                    elif 'results' in branch_data:
                        sub_points = _get_deepest_points(branch_data['results'], depth + 1)
                        all_points.extend(sub_points)
                print(f"{indent}[EXTRACT] Total from group: {len(all_points)}")
                return all_points
            
            # Fallback: if node has 'points' directly
            if 'points' in node_results:
                print(f"{indent}[EXTRACT] Fallback - using direct points: {len(node_results['points'])}")
                return node_results['points']
            
            return []
        
        # Get filtered points from tree result
        print(f"[DEBUG] Starting point extraction from tree (results type: {results.get('type')})")
        filtered_points = _get_deepest_points(results, 0)
        print(f"[DEBUG] Extracted {len(filtered_points)} filtered points from tree")
        
        # === UNIFIED: Collect debug points for each metric (no legacy path) ===
        metrics = classification.get('metrics', [])
        metric_filters_map = classification.get('metric_filters', {})
        matching_points_by_metric = {}
        
        # Get player filter from classification to pass to metric filtering
        player_filter = classification.get('filters', {}).get('player')
        
        # Helper function to filter points with metric-specific filters
        def _filter_points_with_metric_filters(points_list, metric_name, metric_filters_dict, player_name=None):
            """Filter points using metric-specific filters + metric config."""
            if not metric_filters_dict or not points_list:
                return _filter_points_by_metric(points_list, metric_name, player_name)
            
            filtered = []
            for pt in points_list:
                # Apply metric-specific filters first
                serve_number = pt.get('serve_info', {}).get('serve_number', 1) if pt.get('serve_info') else 1
                if '2nd serve' in (pt.get('point_text', pt.get('description', '')) or '').lower():
                    serve_number = 2
                
                # Check serve_number filter
                if metric_filters_dict.get('serve_number') is not None:
                    if serve_number != metric_filters_dict['serve_number']:
                        continue
                
                # REMOVED: situation filter check
                # Situation filtering is done by the TREE, not here.
                # Re-checking causes false negatives because tree uses _check_situation(score)
                # but this code would use metadata.is_break_point which may not be set.
                
                # REMOVED: point_score filter check
                # Point score filtering is done by the TREE, not here.
                
                # Check shot-level filters (direction, shot_type) - CRITICAL for inside-out, DTL, etc.
                shot_type_filter = metric_filters_dict.get('shot_type')
                direction_filter = metric_filters_dict.get('direction')
                
                if shot_type_filter or direction_filter:
                    # Parse rally to check if this point has the required shot characteristics
                    point_text = pt.get('point_text', pt.get('description', ''))
                    server = pt.get('server', '')
                    returner = pt.get('returner', '')
                    rally_shots = self._parse_rally_sequence(point_text, server, returner)
                    actual_shots = [s for s in rally_shots if s.get('outcome') not in ['FAULT', 'LET']]
                    
                    # Check if ANY shot by the filtered player matches the criteria
                    has_matching_shot = False
                    for shot in actual_shots:
                        shot_player = shot.get('player', '')
                        # Only check shots by the filtered player
                        if player_name and not self._names_match_robust(player_name, shot_player):
                            continue
                        
                        shot_type_val = (shot.get('shot_type') or '').lower()
                        shot_direction = shot.get('direction', '')
                        
                        # Check if this shot matches the filters
                        matches = True
                        if shot_type_filter and shot_type_val != shot_type_filter.lower():
                            matches = False
                        if direction_filter and shot_direction != direction_filter:
                            matches = False
                        
                        if matches:
                            has_matching_shot = True
                            break
                    
                    if not has_matching_shot:
                        continue
                
                # Then apply metric config filter WITH player filter
                metric_filtered = _filter_points_by_metric([pt], metric_name, player_name)
                if metric_filtered:
                    filtered.append(pt)
            
            return filtered
        
        # Process EVERY metric through the same path
        for metric_key in (metrics if metrics else [None]):
            # Get metric-specific config if available, otherwise use defaults
            metric_specific = metric_filters_map.get(metric_key, {}) if metric_key else {}
            actual_metric = metric_specific.get('metric', metric_key) if metric_specific else metric_key
            
            # Get player filter for this metric (metric-specific overrides global)
            metric_player_filter = metric_specific.get('filters', {}).get('player', player_filter) if metric_specific else player_filter
            metric_filters_dict = metric_specific.get('filters', {}) if metric_specific else {}
            
            # NOTE: Tree handles all dimensional filtering (situation, set, point_score, etc.)
            # Metric filters should ONLY contain metric-specific requirements (serve_number for first_serve_pct)
            # We do NOT re-check tree dimensions here - the points are already filtered
            
            # Collect points for this metric
            metric_points = []
            
            if results.get('type') == 'group' and 'branches' in results:
                for branch_key, branch_data in results['branches'].items():
                    branch_points = branch_data.get('points', [])
                    if not branch_points and 'results' in branch_data:
                        branch_points = _get_deepest_points(branch_data['results'], 0)
                    
                    branch_label = branch_data.get('label', branch_key)
                    
                    # Filter with metric-specific filters + metric config + player filter
                    if actual_metric:
                        metric_filtered = _filter_points_with_metric_filters(
                            branch_points, actual_metric, metric_filters_dict, metric_player_filter
                        )
                        print(f"[DEBUG] Metric '{metric_key}' Branch '{branch_label}': {len(branch_points)} total -> {len(metric_filtered)} matching")
                    else:
                        metric_filtered = branch_points
                        print(f"[DEBUG] Branch '{branch_label}': {len(branch_points)} points")
                    
                    for pt in metric_filtered:
                        meta = _extract_winning_shot_metadata(pt)
                        situation_info = _extract_situation_info(pt)
                        metric_points.append({
                            'point_number': pt.get('point_number', 0),
                            'server': pt.get('server', ''),
                            'returner': pt.get('returner', ''),
                            'score': pt.get('score', ''),
                            'description': pt.get('description', ''),
                            'group': branch_label,
                            'situation': situation_info,
                            'metric': metric_key,
                            **meta
                        })
            else:
                # Filter-only results
                if actual_metric:
                    metric_filtered = _filter_points_with_metric_filters(
                        filtered_points, actual_metric, metric_filters_dict, metric_player_filter
                    )
                    print(f"[DEBUG] Metric '{metric_key}': {len(filtered_points)} total -> {len(metric_filtered)} matching")
                else:
                    metric_filtered = filtered_points
                    print(f"[DEBUG] No metric filter: {len(filtered_points)} points")
                
                for pt in metric_filtered:
                    meta = _extract_winning_shot_metadata(pt)
                    situation_info = _extract_situation_info(pt)
                    metric_points.append({
                        'point_number': pt.get('point_number', 0),
                        'server': pt.get('server', ''),
                        'returner': pt.get('returner', ''),
                        'score': pt.get('score', ''),
                        'description': pt.get('description', ''),
                        'situation': situation_info,
                        'metric': metric_key,
                        **meta
                    })
            
            if metric_key:
                matching_points_by_metric[metric_key] = metric_points
        
        # Flatten for backward compatibility
        matching_points = []
        for metric_key, points in matching_points_by_metric.items():
            matching_points.extend(points)
        
        print(f"[DEBUG] Final matching_points count: {len(matching_points)}")
        
        # Return structure with per-metric points if available
        return_dict = {
            'tree': tree,
            'results': results,
            'classification': classification,
            'player1': self.player1,
            'player2': self.player2,
            'matching_points': matching_points
        }
        
        # Add per-metric points (always include for shot category breakdown)
        if matching_points_by_metric:
            return_dict['matching_points_by_metric'] = matching_points_by_metric
        
        return return_dict
    
    def _format_n_dimensional_results(self, analysis: Dict) -> str:
        """Format N-dimensional tree analysis results."""
        if 'error' in analysis:
            return f"Unable to perform analysis: {analysis['error']}"
        
        tree = analysis['tree']
        results = analysis['results']
        classification = analysis['classification']
        
        dimensions = tree['dimensions']
        filters = dimensions['filters']
        groups = dimensions['groups']
        metrics = dimensions['metrics']
        
        player1 = analysis['player1']
        player2 = analysis['player2']
        player_filter = classification.get('filters', {}).get('player')
        
        response = f"**Analysis** (Tree Depth: {tree['depth']})\n\n"
        
        # Show filter path
        if filters:
            response += "**Filter Path:**\n"
            for i, (dim, val) in enumerate(filters):
                indent = "  " * i
                response += f"{indent}â””â”€ {dim}: {val}\n"
            response += "\n"
        
        # Format results based on structure
        response += self._format_tree_results(results, groups, metrics, player1, player2, player_filter, classification=classification)
        
        # Add comparison summary if we have group comparison with 2+ groups
        if groups and len(groups) >= 1:
            response += self._add_group_comparison_summary(results, metrics, player1, player2, classification)
        
        # === SHOT CATEGORY BREAKDOWN for point-ending shot outcomes ===
        # When showing counts of winners/errors, break down by shot category (groundstroke vs net shots)
        # Applies to any metric involving point-ending shots (winners, errors, induced errors, etc.)
        matching_points = analysis.get('matching_points', [])
        matching_points_by_metric = analysis.get('matching_points_by_metric', {})
        
        # Generic detection: any metric containing 'winner', 'error', or 'induced' 
        # These are all point-ending shot outcomes that benefit from shot category breakdown
        def is_shot_outcome_metric(m):
            m_lower = m.lower()
            return any(term in m_lower for term in ['winner', 'error', 'induced_fe', 'induced_ue'])
        
        active_breakdown_metric = next((m for m in metrics if is_shot_outcome_metric(m)), None)
        
        if active_breakdown_metric:
            # Use metric-specific points if available (properly filtered), otherwise fall back to all matching_points
            breakdown_points = matching_points_by_metric.get(active_breakdown_metric, matching_points)
            
            if breakdown_points:
                # Count by shot_category
                category_counts = {}
                for pt in breakdown_points:
                    cat = pt.get('shot_category', 'unknown')
                    if cat and cat != '?':
                        category_counts[cat] = category_counts.get(cat, 0) + 1
                
                if category_counts and len(category_counts) > 1:
                    # Only show breakdown if there's variety
                    total = sum(category_counts.values())
                    metric_label = active_breakdown_metric.replace('_', ' ').title()
                    response += f"\n**{metric_label} Breakdown by Shot Type:**\n"
                    response += "| Shot Type | Count | Percentage |\n"
                    response += "|---|---|---|\n"
                    
                    # Sort by count descending
                    for cat, count in sorted(category_counts.items(), key=lambda x: -x[1]):
                        pct = round(100 * count / total, 1) if total > 0 else 0
                        cat_display = cat.replace('_', ' ').title()
                        response += f"| {cat_display} | {count} | {pct}% |\n"
        
        # DEBUG: Show matching points if filtering actually happened
        # Skip if all points returned (no filtering = noise, not useful debug info)
        matching_points_by_metric = analysis.get('matching_points_by_metric')
        total_points = len(self.point_by_point) if hasattr(self, 'point_by_point') else 283
        
        print(f"[DEBUG] matching_points count: {len(matching_points)}, total_points: {total_points}")
        
        # Show debug if:
        # 1. We have matching points
        # 2. AND either filtering reduced the count OR we have grouped results OR we have situation filters
        # CRITICAL: Always show debug for situation queries (break points, game points, etc.) - these are important!
        has_grouping = bool(groups)
        has_filtering = len(matching_points) < total_points
        has_situation = bool(filters and any(f[0] == 'situation' for f in filters))
        
        if matching_points and (has_filtering or has_grouping or has_situation):
            # === GENERIC N-METRIC: Show points grouped by metric ===
            if matching_points_by_metric:
                # Multi-metric query - show points per metric
                response += f"\n\n**DEBUG: Points by Metric:**\n"
                for metric_key, metric_points in matching_points_by_metric.items():
                    metric_specific = classification.get('metric_filters', {}).get(metric_key, {})
                    actual_metric = metric_specific.get('metric', metric_key)
                    metric_filters = metric_specific.get('filters', {})
                    
                    # Build filter description for this metric
                    filter_parts = []
                    for k, v in metric_filters.items():
                        if v is not None:
                            filter_parts.append(f"{k}={v}")
                    filter_str = f" (filters: {', '.join(filter_parts)})" if filter_parts else ""
                    
                    response += f"\n**Metric: {actual_metric}{filter_str}** ({len(metric_points)} points):\n"
                    for i, pt in enumerate(metric_points, 1):
                        response += self._format_debug_point(pt, i)
            else:
                # Single metric - show all points together
                filter_desc = []
                if has_situation:
                    situation_val = next((f[1] for f in filters if f[0] == 'situation'), None)
                    if situation_val:
                        filter_desc.append(f"situation={situation_val}")
                if has_filtering:
                    filter_desc.append("filtered")
                if has_grouping:
                    filter_desc.append("grouped")
                
                filter_str = f" ({', '.join(filter_desc)})" if filter_desc else ""
                total_msg = f"Showing {len(matching_points)} of {total_points} points{filter_str}"
                response += f"\n\n**DEBUG: {total_msg}:**\n"
                for i, pt in enumerate(matching_points, 1):
                    response += self._format_debug_point(pt, i)
        
        return response
    
    def _format_debug_point(self, pt: Dict, index: int) -> str:
        """Format a single debug point for display."""
        response = f"\n{index}. **Point {pt.get('point_number', '?')}** [{pt.get('server', '?')} serving]\n"
        response += f"   Score: {pt.get('score', '?')}\n"
        
        # Show situation information if available
        situation_info = pt.get('situation', {})
        if isinstance(situation_info, dict):
            situation_flags = []
            if situation_info.get('is_break_point'):
                situation_flags.append("BREAK POINT")
            if situation_info.get('is_game_point'):
                situation_flags.append("GAME POINT")
            if situation_info.get('is_set_point'):
                situation_flags.append("SET POINT")
            if situation_info.get('is_match_point'):
                situation_flags.append("MATCH POINT")
            if situation_info.get('is_deuce'):
                situation_flags.append("DEUCE")
            if situation_info.get('is_tiebreak'):
                situation_flags.append("TIEBREAK")
            if situation_flags:
                response += f"   **Situation:** {', '.join(situation_flags)}\n"
        
        # Show FULL extracted metadata (use winning_shot dict if available)
        winner = pt.get('point_winner', pt.get('winner', '?'))
        winning_shot = pt.get('winning_shot', {})
        shot_type = winning_shot.get('shot_type') or pt.get('shot_type', '?')
        shot_mod = winning_shot.get('shot_modifier') or pt.get('shot_modifier', '-')
        direction = winning_shot.get('direction') or pt.get('direction', '?')
        at_net = winning_shot.get('at_net', pt.get('at_net', False))
        outcome = winning_shot.get('outcome') or pt.get('outcome', '?')
        
        # CRITICAL: Recalculate rally_length from source (don't trust stale enriched metadata)
        # The enriched metadata might be outdated if code has changed
        point_text = pt.get('description', '')
        server = pt.get('server', '')
        returner = pt.get('returner', '')
        rally_shots = self._parse_rally_sequence(point_text, server, returner) if point_text else []
        rally_len = self._calculate_rally_length(rally_shots, point_text)
        
        group = pt.get('group', '-')
        
        response += f"   **Winning Shot:** {shot_type}"
        if shot_mod and shot_mod != '-':
            response += f" {shot_mod}"
        response += f" | Direction: {direction}"
        if at_net:
            response += " (AT NET)"
        response += f"\n"
        response += f"   Winner: {winner} | Outcome: {outcome} | Rally: {rally_len} shots"
        if group and group != '-':
            response += f" | Group: {group}"
        response += f"\n"
        response += f"   {pt.get('description', '')}\n"
        
        return response
    
    
    def _is_count_based_query(self, classification: Dict) -> bool:
        """
        Detect if query is asking for counts (how many) rather than percentages.
        Examples: "how many aces", "count of", "number of"
        """
        # Check the actual question text if available
        actual_question = classification.get('actual_question', '') or classification.get('question', '')
        if actual_question:
            question_lower = actual_question.lower()
            count_keywords = ['how many', 'count', 'number of', 'total number']
            if any(kw in question_lower for kw in count_keywords):
                return True
        
        # Check if metric is inherently count-based (aces, double faults always show counts)
        metrics = classification.get('metrics', [])
        count_metrics = ['aces', 'double_faults', 'service_winners', 'winners', 'errors', 
                        'unforced_errors', 'forced_errors', 'break_points']
        if any(m in count_metrics for m in metrics):
            # Only if it's a count query - if asking for win % on aces, show percentages
            if actual_question:
                if 'percentage' not in actual_question.lower() and 'win %' not in actual_question.lower():
                    return True
        
        return False
    
    def _add_group_comparison_summary(self, results: Dict, metrics: list, player1: str, player2: str, classification: Dict = None) -> str:
        """Add a summary comparing metric changes across groups - FULLY DYNAMIC."""
        
        # Extract branches from results
        branches = results.get('branches', {})
        dimension = results.get('dimension', '')
        if not branches:
            # Try to find branches in children
            if results.get('type') == 'filter' and results.get('children'):
                child = results['children']
                if isinstance(child, dict):
                    branches = child.get('branches', {})
                    dimension = child.get('dimension', '')
        
        if not branches or len(branches) < 2:
            return ""
        
        # Get the primary metric being analyzed
        primary_metric = metrics[0] if metrics else 'points_won'
        metric_label = primary_metric.replace('_', ' ').title()
        
        # Detect if this is a count-based query (e.g., "how many aces")
        show_counts_first = classification and self._is_count_based_query(classification)
        
        # SPECIAL CASE: When grouping by PLAYER, each branch IS a player
        # Don't do a cross-comparison, just show each player's total
        if dimension == 'player':
            response = f"\n\n**ðŸ“Š {metric_label} Summary:**\n\n"
            
            for key, branch in branches.items():
                label = branch.get('label', key)
                sub_results = branch.get('results', {})
                per_player = sub_results.get('per_player_metrics', {}).get(primary_metric, {})
                
                if per_player:
                    # Get data for this specific player
                    if label.lower() == player1.lower():
                        player_data = per_player.get('player1', {})
                    elif label.lower() == player2.lower():
                        player_data = per_player.get('player2', {})
                    else:
                        player_data = per_player.get('player1', {}) or per_player.get('player2', {})
                    
                    count = player_data.get('count', 0)
                    total = player_data.get('total', 0)
                    pct = player_data.get('pct', 0)
                    
                    if show_counts_first:
                        response += f"- **{label}**: **{count} {metric_label.lower()}**\n"
                    else:
                        response += f"- **{label}**: {pct}% ({count} of {total})\n"
            
            # Add conclusion comparing the two players
            if len(branches) == 2:
                branch_list = list(branches.values())
                b1, b2 = branch_list[0], branch_list[1]
                label1 = b1.get('label', '')
                label2 = b2.get('label', '')
                
                results1 = b1.get('results', {})
                results2 = b2.get('results', {})
                per_player1 = results1.get('per_player_metrics', {}).get(primary_metric, {})
                per_player2 = results2.get('per_player_metrics', {}).get(primary_metric, {})
                
                # Get count for player 1
                if label1.lower() == player1.lower():
                    count1 = per_player1.get('player1', {}).get('count', 0)
                elif label1.lower() == player2.lower():
                    count1 = per_player1.get('player2', {}).get('count', 0)
                else:
                    count1 = per_player1.get('player1', {}).get('count', 0) or per_player1.get('player2', {}).get('count', 0)
                
                # Get count for player 2
                if label2.lower() == player1.lower():
                    count2 = per_player2.get('player1', {}).get('count', 0)
                elif label2.lower() == player2.lower():
                    count2 = per_player2.get('player2', {}).get('count', 0)
                else:
                    count2 = per_player2.get('player1', {}).get('count', 0) or per_player2.get('player2', {}).get('count', 0)
                
                if show_counts_first and count1 != count2:
                    diff = abs(count1 - count2)
                    winner = label1 if count1 > count2 else label2
                    response += f"\n**ðŸ“Š Conclusion:** {winner} had **{diff} more {metric_label.lower()}**\n"
            
            return response
        
        # NORMAL CASE: Comparing conditions (Set 1 vs Set 2, etc.)
        response = f"\n\n**ðŸ“Š {metric_label} Comparison:**\n\n"
        
        # Collect data for each group
        group_data = []
        for key, branch in branches.items():
            label = branch.get('label', key)
            sub_results = branch.get('results', {})
            
            # Get per-player metrics if available
            per_player = sub_results.get('per_player_metrics', {}).get(primary_metric, {})
            
            if per_player:
                # Use per-player tracking
                p1_data = per_player.get('player1', {})
                p2_data = per_player.get('player2', {})
                group_data.append({
                    'label': label,
                    'p1_value': p1_data.get('pct', p1_data.get('count', 0)),
                    'p2_value': p2_data.get('pct', p2_data.get('count', 0)),
                    'p1_count': p1_data.get('count', p1_data.get('total', 0)),
                    'p2_count': p2_data.get('count', p2_data.get('total', 0)),
                    'p1_total': p1_data.get('total', sub_results.get('total_points', 0)),
                    'p2_total': p2_data.get('total', sub_results.get('total_points', 0)),
                    'is_percentage': 'pct' in p1_data
                })
            else:
                # Use overall win percentages
                group_data.append({
                    'label': label,
                    'p1_value': sub_results.get('player1_pct', 0),
                    'p2_value': sub_results.get('player2_pct', 0),
                    'p1_count': sub_results.get('player1_wins', 0),
                    'p2_count': sub_results.get('player2_wins', 0),
                    'p1_total': sub_results.get('player1_wins', 0),
                    'p2_total': sub_results.get('player2_wins', 0),
                    'is_percentage': True
                })
        
        if len(group_data) >= 2:
            g1, g2 = group_data[0], group_data[1]
            
            # Calculate changes
            p1_change = g1['p1_value'] - g2['p1_value']
            p2_change = g1['p2_value'] - g2['p2_value']
            
            unit = '%' if g1['is_percentage'] else ''
            
            # Format output based on query type
            response += f"**{player1}:**\n"
            if show_counts_first:
                # Show counts prominently for "how many" queries
                response += f"- {g1['label']}: **{g1['p1_count']} {metric_label.lower()}**\n"
                response += f"- {g2['label']}: **{g2['p2_count']} {metric_label.lower()}**\n"
                count_change = g1['p1_count'] - g2['p2_count']
                response += f"- Change: **{count_change:+.0f} {metric_label.lower()}**\n\n"
            else:
                # Show percentages for win rate queries
                response += f"- {g1['label']}: {g1['p1_value']}{unit} ({g1['p1_total']} total)\n"
                response += f"- {g2['label']}: {g2['p1_value']}{unit} ({g2['p2_total']} total)\n"
                response += f"- Change: **{p1_change:+.1f}{unit}**\n\n"
            
            response += f"**{player2}:**\n"
            if show_counts_first:
                # Show counts prominently for "how many" queries
                response += f"- {g1['label']}: **{g1['p2_count']} {metric_label.lower()}**\n"
                response += f"- {g2['label']}: **{g2['p2_count']} {metric_label.lower()}**\n"
                count_change = g1['p2_count'] - g2['p2_count']
                response += f"- Change: **{count_change:+.0f} {metric_label.lower()}**\n\n"
            else:
                # Show percentages for win rate queries
                response += f"- {g1['label']}: {g1['p2_value']}{unit} ({g1['p2_total']} total)\n"
                response += f"- {g2['label']}: {g2['p2_value']}{unit} ({g2['p2_total']} total)\n"
                response += f"- Change: **{p2_change:+.1f}{unit}**\n\n"
            
            # Determine who changed more (bigger drop = more negative change)
            if show_counts_first:
                # For count queries, compare absolute counts
                p1_total_count = g1['p1_count'] + g2['p1_count']
                p2_total_count = g1['p2_count'] + g2['p2_count']
                if p1_total_count > p2_total_count:
                    diff = p1_total_count - p2_total_count
                    response += f"**ðŸ“Š Conclusion:** {player1} had **{diff} more {metric_label.lower()}** overall\n"
                elif p2_total_count > p1_total_count:
                    diff = p2_total_count - p1_total_count
                    response += f"**ðŸ“Š Conclusion:** {player2} had **{diff} more {metric_label.lower()}** overall\n"
                else:
                    response += f"**ðŸ“Š Conclusion:** Both players had equal {metric_label.lower()}\n"
            else:
                # For percentage queries, compare changes
                p1_drop = -p1_change  # Positive means dropped
                p2_drop = -p2_change
                
                if p1_drop > p2_drop + 0.1:  # P1 dropped more
                    response += f"**ðŸ“‰ Conclusion:** {player1}'s {metric_label.lower()} dropped more ({abs(p1_drop - p2_drop):.1f}{unit} greater decline)\n"
                elif p2_drop > p1_drop + 0.1:  # P2 dropped more
                    response += f"**ðŸ“‰ Conclusion:** {player2}'s {metric_label.lower()} dropped more ({abs(p2_drop - p1_drop):.1f}{unit} greater decline)\n"
                else:
                    response += f"**ðŸ“‰ Conclusion:** Both players had similar changes in {metric_label.lower()}\n"
        
        return response
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # UNIFIED METRIC FORMATTING - Uses METRIC_CONFIG.display_type
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    def _format_metric_for_display(self, metric_name: str, results: Dict, 
                                    player1: str, player2: str, player_filter: str = None) -> str:
        """
        Format a single metric using METRIC_CONFIG.display_type.
        
        This is the SINGLE SOURCE OF TRUTH for metric formatting.
        All formatting code should call this instead of duplicating logic.
        
        Args:
            metric_name: Name of the metric (e.g., 'first_serve_pct', 'winners')
            results: Leaf node results containing per_player_metrics and metrics
            player1, player2: Player names
            player_filter: If set, only show this player's data
            
        Returns:
            Formatted string for display
        """
        config = self.METRIC_CONFIG.get(metric_name, {})
        display_type = config.get('display_type', 'count')
        label = config.get('label', metric_name.replace('_', ' ').title())
        
        per_player = results.get('per_player_metrics', {}).get(metric_name, {})
        metrics_data = results.get('metrics', {}).get(metric_name, {})
        
        p1_data = per_player.get('player1', {})
        p2_data = per_player.get('player2', {})
        
        # Handle player filter - only show requested player
        if player_filter and player_filter.lower() not in ('both', 'all'):
            is_p1 = player1 and self._names_match_robust(player_filter, player1)
            player_data = p1_data if is_p1 else p2_data
            player_name = player1 if is_p1 else player2
            
            if display_type == 'per_player_pct':
                if player_data.get('total', 0) > 0:
                    return f"**{label}:** {player_data.get('pct', 0)}% ({player_data.get('count', 0)} of {player_data.get('total', 0)})"
                return f"**{label}:** No data"
            elif display_type == 'count':
                return f"**{label}:** {player_data.get('count', 0)}"
            elif display_type == 'points_won':
                total = results.get('total_points', 0)
                pct = player_data.get('pct', 0)
                return f"**{label}:** {player_data.get('count', 0)} ({pct}% of {total})"
            else:
                return f"**{label}:** {player_data.get('count', 0)}"
        
        # Both players - format depends on display_type
        if display_type == 'per_player_pct':
            # Each player gets their own percentage line
            lines = [f"**{label}:**"]
            if p1_data.get('total', 0) > 0:
                lines.append(f"  - {player1}: {p1_data.get('pct', 0)}% ({p1_data.get('count', 0)} of {p1_data.get('total', 0)})")
            else:
                lines.append(f"  - {player1}: No data (0 attempts)")
            if p2_data.get('total', 0) > 0:
                lines.append(f"  - {player2}: {p2_data.get('pct', 0)}% ({p2_data.get('count', 0)} of {p2_data.get('total', 0)})")
            else:
                lines.append(f"  - {player2}: No data (0 attempts)")
            return "\n".join(lines)
            
        elif display_type == 'aggregate_pct':
            # Combined percentage
            total_count = metrics_data.get('count', 0)
            total_total = metrics_data.get('total', 0)
            if total_total > 0:
                pct = round(100 * total_count / total_total, 1)
                return f"**{label}:** {pct}% ({total_count} of {total_total})"
            return f"**{label}:** 0% (no data)"
            
        elif display_type == 'count':
            # Raw counts per player
            return f"**{label}:** {player1}: {p1_data.get('count', 0)}, {player2}: {p2_data.get('count', 0)}"
            
        elif display_type == 'points_won':
            # Win/loss distribution
            total = results.get('total_points', 0)
            p1_wins = results.get('player1_wins', 0)
            p2_wins = results.get('player2_wins', 0)
            p1_pct = results.get('player1_pct', 0)
            p2_pct = results.get('player2_pct', 0)
            return f"**{label}:** {player1}: {p1_wins} ({p1_pct}%), {player2}: {p2_wins} ({p2_pct}%)"
            
        else:
            # Fallback
            return f"**{label}:** {metrics_data.get('count', 0)}"
    
    def _get_metric_display_type(self, metric_name: str) -> str:
        """Get the display type for a metric from METRIC_CONFIG."""
        config = self.METRIC_CONFIG.get(metric_name, {})
        return config.get('display_type', 'count')
    
    def _get_metric_label(self, metric_name: str) -> str:
        """Get the human-readable label for a metric from METRIC_CONFIG."""
        config = self.METRIC_CONFIG.get(metric_name, {})
        return config.get('label', metric_name.replace('_', ' ').title())
    
    def _format_tree_results(self, results: Dict, groups: list, metrics: list,
                             player1: str, player2: str, player_filter: str, depth: int = 0, classification: Dict = None) -> str:
        """Recursively format tree results."""
        response = ""
        indent = "  " * depth
        
        if results.get('type') == 'filter':
            # Show filter narrowing
            response += f"{indent}**{results['dimension']}={results['value']}**: "
            response += f"{results['points_before']} -> {results['points_after']} points\n"
            
            if results.get('children'):
                response += self._format_tree_results(results['children'], groups, metrics,
                                                     player1, player2, player_filter, depth, classification=classification)
        
        elif results.get('type') == 'group':
            # Show grouping table
            dimension = results['dimension']
            branches = results.get('branches', {})
            
            response += f"\n**Grouped by: {dimension.replace('_', ' ').title()}**\n\n"
            
            # Special handling for PLAYER grouping - each row IS a player
            if dimension == 'player':
                primary_metric = metrics[0] if metrics else 'count'
                metric_label = primary_metric.replace('_', ' ').title()
                
                # Percentage metrics that need to show count/total from per_player_metrics (not points won)
                per_player_pct_metrics = {'first_serve_pct', 'first_serve_win_pct', 'second_serve_pct', 'second_serve_win_pct'}
                
                if primary_metric in per_player_pct_metrics:
                    # For serve percentage metrics, show the metric-specific count/total
                    response += f"| Player | {metric_label} | Count | Total |\n"
                response += "|---|---|---|---|\n"
                
                for val, branch_data in branches.items():
                    label = branch_data['label']  # Player name
                    sub_results = branch_data.get('results', {})
                    
                    if sub_results.get('type') == 'group':
                        response += f"\n**{label}:**\n"
                        response += self._format_tree_results(sub_results, groups[1:] if len(groups) > 1 else [],
                                                             metrics, player1, player2, player_filter, depth + 1, classification=classification)
                    else:
                            # Get this player's metric data from per_player_metrics
                            per_player = sub_results.get('per_player_metrics', {}).get(primary_metric, {})
                            
                            # Determine which player key this branch represents
                            if label.lower() == player1.lower() if player1 else False:
                                player_data = per_player.get('player1', {})
                            else:
                                player_data = per_player.get('player2', {})
                            
                            m_count = player_data.get('count', 0)
                            m_total = player_data.get('total', 0)
                            m_pct = player_data.get('pct', 0)
                            
                            response += f"| **{label}** | {m_pct}% | {m_count} | {m_total} |\n"
                else:
                    # For points_won metric grouped by player (grouped by point_winner):
                    # Each branch count IS that player's points won
                    # Show: Points Won | % of Total (not Win % which would be 100%)
                    
                    # Calculate total points across all branches for percentage
                    total_points_all = sum(b['count'] for b in branches.values())
                    
                    response += f"| Player | Points Won | % of Total |\n"
                    response += "|---|---|---|\n"
                    
                    for val, branch_data in branches.items():
                        label = branch_data['label']  # Player name
                        count = branch_data['count']  # Points WON by this player (since grouped by point_winner)
                        sub_results = branch_data.get('results', {})
                        
                        if sub_results.get('type') == 'group':
                            response += f"\n**{label}:**\n"
                            response += self._format_tree_results(sub_results, groups[1:] if len(groups) > 1 else [],
                                                                 metrics, player1, player2, player_filter, depth + 1, classification=classification)
                        else:
                            # Percentage of total points won
                            pct_of_total = round(count / total_points_all * 100, 1) if total_points_all > 0 else 0
                            response += f"| **{label}** | {count} | {pct_of_total}% |\n"
                
                return response
            
            # Check if we have per-player metrics (for both-player queries on non-player grouping)
            first_branch = next(iter(branches.values()), {})
            first_results = first_branch.get('results', {})
            has_per_player = bool(first_results.get('per_player_metrics'))
            
            # Dynamic per-player table for any metric (when NOT grouping by player)
            # IMPORTANT: Only use per-player table when NO player filter (showing both players)
            # When filtered to single player, use simple format showing just that player's counts
            if has_per_player and metrics and not player_filter:
                primary_metric = metrics[0]
                metric_label = primary_metric.replace('_', ' ').title()
                
                response += f"| {dimension.title()} | {player1} Total | {player1} Won | {player1} % | {player2} Total | {player2} Won | {player2} % |\n"
                response += "|" + "---|" * 7 + "\n"
                
                for val, branch_data in branches.items():
                    label = branch_data['label']
                    sub_results = branch_data.get('results', {})
                    
                    if sub_results.get('type') == 'group':
                        response += f"\n**{label}:**\n"
                        response += self._format_tree_results(sub_results, groups[1:] if len(groups) > 1 else [],
                                                             metrics, player1, player2, player_filter, depth + 1, classification=classification)
                    else:
                        per_player = sub_results.get('per_player_metrics', {}).get(primary_metric, {})
                        p1_data = per_player.get('player1', {})
                        p2_data = per_player.get('player2', {})
                        
                        response += f"| **{label}** | {p1_data.get('total', 0)} | {p1_data.get('count', 0)} | {p1_data.get('pct', 0)}% | {p2_data.get('total', 0)} | {p2_data.get('count', 0)} | {p2_data.get('pct', 0)}% |\n"
                
                return response
            
            # Build table header based on what we're showing
            if 'win_percentage' in metrics or 'points_won' in metrics:
                response += f"| {dimension.title()} | Total | {player1} | {player2} | "
                if player_filter:
                    response += f"{player_filter} Win% |\n"
                else:
                    response += f"P1 Win% |\n"
                response += "|" + "---|" * 5 + "\n"
            else:
                response += f"| {dimension.title()} | Total |"
                for m in metrics:
                    response += f" {m.replace('_', ' ').title()} |"
                response += "\n"
                response += "|" + "---|" * (len(metrics) + 2) + "\n"
            
            for val, branch_data in branches.items():
                label = branch_data['label']
                count = branch_data['count']
                sub_results = branch_data.get('results', {})
                
                # Get leaf data
                if sub_results.get('type') == 'group':
                    # Nested group - recurse
                    response += f"\n**{label}:**\n"
                    response += self._format_tree_results(sub_results, groups[1:] if len(groups) > 1 else [],
                                                         metrics, player1, player2, player_filter, depth + 1, classification=classification)
                else:
                    # Leaf node - show metrics
                    p1_wins = sub_results.get('player1_wins', 0)
                    p2_wins = sub_results.get('player2_wins', 0)
                    p1_pct = sub_results.get('player1_pct', 0)
                    p2_pct = sub_results.get('player2_pct', 0)
                    
                    if 'win_percentage' in metrics or 'points_won' in metrics:
                        pct = p1_pct if (player_filter and player1 and player_filter.lower() in player1.lower()) else p2_pct if player_filter else p1_pct
                        response += f"| **{label}** | {count} | {p1_wins} | {p2_wins} | {pct}% |\n"
                    else:
                        response += f"| **{label}** | {count} |"
                        for m in metrics:
                            m_count = sub_results.get('metrics', {}).get(m, {}).get('count', 0)
                            response += f" {m_count} |"
                        response += "\n"
        
        elif 'total_points' in results:
            # Leaf node directly
            
            # === SHOT-LEVEL RESULTS (when counting individual shots grouped by type) ===
            if 'shot_counts_by_type' in results and results['shot_counts_by_type']:
                shot_counts = results['shot_counts_by_type']
                total_shots = sum(shot_counts.values())
                
                response += f"\n**Shot Counts by Type:**\n"
                response += f"| Shot Type | Count | Percentage |\n"
                response += "|---|---|---|\n"
                
                # Sort by count descending
                for shot_type, count in sorted(shot_counts.items(), key=lambda x: -x[1]):
                    pct = round(100 * count / total_shots, 1) if total_shots > 0 else 0
                    response += f"| **{shot_type.title()}** | {count} | {pct}% |\n"
                
                # Build descriptive total label with filters
                total_label = "Total Shots"
                metric_filters_map = classification.get('metric_filters', {}) if classification else {}
                if 'shot_count' in metric_filters_map:
                    filters = metric_filters_map['shot_count'].get('filters', {})
                    filter_parts = []
                    if filters.get('direction'):
                        filter_parts.append(filters['direction'].replace('_', '-').title())
                    if filters.get('shot_type'):
                        filter_parts.append(filters['shot_type'].title())
                    if filter_parts:
                        total_label = "Total " + ' '.join(filter_parts) + " Shots"
                
                response += f"\n**{total_label}: {total_shots}**\n"
                
                # Calculate ratio if forehand and backhand both present
                if 'forehand' in shot_counts and 'backhand' in shot_counts:
                    fh = shot_counts['forehand']
                    bh = shot_counts['backhand']
                    if bh > 0:
                        ratio = round(fh / bh, 2)
                        response += f"**Forehand to Backhand Ratio: {ratio} : 1**\n"
                
                # Display detailed breakdown by contact_type + intent
                if 'shot_breakdown' in results and results['shot_breakdown']:
                    response += f"\n**Detailed Breakdown by Shot Subtype:**\n"
                    for shot_type, breakdown in results['shot_breakdown'].items():
                        response += f"\n**{shot_type.title()} Breakdown:**\n"
                        response += f"| Subtype | Count |\n"
                        response += "|---|---|\n"
                        
                        # Sort by count descending
                        for subtype, count in sorted(breakdown.items(), key=lambda x: -x[1]):
                            if count > 0:  # Only show non-zero counts
                                response += f"| {subtype.replace('_', ' ').title()} | {count} |\n"
                
                return response
            
            response += f"\n**Results:**\n"
            response += f"- Total Points: {results['total_points']}\n"
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # UNIFIED METRIC FORMATTING using METRIC_CONFIG.display_type
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            metrics_results = results.get('metrics', {})
            per_player = results.get('per_player_metrics', {})
            
            # Format each metric using config-driven display
            for m in metrics:
                if m not in metrics_results and m not in per_player:
                    continue
                    
                display_type = self._get_metric_display_type(m)
                metric_label = self._get_metric_label(m)
                
                # Get data
                m_data = metrics_results.get(m, {})
                p1_data = per_player.get(m, {}).get('player1', {})
                p2_data = per_player.get(m, {}).get('player2', {})
                
                # Handle player filter
                if player_filter and player_filter.lower() not in ('both', 'all'):
                    is_p1 = player1 and self._names_match_robust(player_filter, player1)
                    player_data = p1_data if is_p1 else p2_data
                    
                    if display_type == 'per_player_pct':
                        if player_data.get('total', 0) > 0:
                            response += f"- {metric_label}: {player_data.get('pct', 0)}% ({player_data.get('count', 0)} of {player_data.get('total', 0)})\n"
                        else:
                            response += f"- {metric_label}: No data\n"
                    else:
                        response += f"- {metric_label}: {player_data.get('count', 0)}\n"
                    continue
                
                # Both players - format based on display_type
                if display_type == 'per_player_pct':
                    # Each player gets their own percentage
                    response += f"\n**{metric_label}:**\n"
                    if p1_data.get('total', 0) > 0:
                        response += f"- {player1}: {p1_data.get('pct', 0)}% ({p1_data.get('count', 0)} of {p1_data.get('total', 0)})\n"
                    else:
                        response += f"- {player1}: No data (0 attempts)\n"
                    if p2_data.get('total', 0) > 0:
                        response += f"- {player2}: {p2_data.get('pct', 0)}% ({p2_data.get('count', 0)} of {p2_data.get('total', 0)})\n"
                    else:
                        response += f"- {player2}: No data (0 attempts)\n"
                        
                elif display_type == 'aggregate_pct':
                    # Combined percentage
                    count = m_data.get('count', 0)
                    total = m_data.get('total', 0)
                    if total > 0:
                        pct = round(100 * count / total, 1)
                        response += f"- {metric_label}: {pct}% ({count} of {total})\n"
                    else:
                        response += f"- {metric_label}: 0% (no data)\n"
                        
                elif display_type == 'count':
                    # Raw counts per player
                    response += f"- {metric_label}: {player1}: {p1_data.get('count', 0)}, {player2}: {p2_data.get('count', 0)}\n"
                    
                elif display_type == 'points_won':
                    # Win/loss distribution - show who won more
                    p1_wins = results.get('player1_wins', 0)
                    p2_wins = results.get('player2_wins', 0)
                    p1_pct = results.get('player1_pct', 0)
                    p2_pct = results.get('player2_pct', 0)
                    response += f"\n**{metric_label}:**\n"
                    response += f"- {player1}: {p1_wins} ({p1_pct}%)\n"
                    response += f"- {player2}: {p2_wins} ({p2_pct}%)\n"
                    
                else:
                    # Fallback
                    response += f"- {metric_label}: {m_data.get('count', 0)}\n"
        
        return response
    
    
    
    def _determine_group_key(self, group_by: str, rally_length: int, score: str, point_lower: str, filters: Dict, target_shot_desc: str = '', rally_shots: list = None, metadata: Dict = None) -> str:
        """
        FULLY GENERIC GROUP KEY DETERMINATION using GROUP_CONFIG.
        New groupings can be added to GROUP_CONFIG without code changes!
        """
        # Use metadata if provided (preferred)
        meta = metadata or {}
        
        # Build point_data dict for extraction
        point_data = {
            'rally_length': rally_length,
            'score': score,
            'point_lower': point_lower,
        }
        
        # Use generic extraction method
        group_key = self._extract_group_key(
            group_by=group_by,
            point_data=point_data,
            metadata=meta,
            filters=filters,
            score=score,
            point_lower=point_lower,
            rally_length=rally_length
        )
        
        # If extraction returned None, check if it's a known group_by that needs special handling
        if group_key is None and group_by in self.GROUP_CONFIG:
            # Config exists but extraction failed - return None (point will be skipped)
            return None
        
        # If group_by not in config, this is a NEW grouping request
        # Return None to skip (user needs to add it to GROUP_CONFIG)
        if group_key is None and group_by not in self.GROUP_CONFIG:
            print(f"[WARNING] Unknown group_by '{group_by}' - add to GROUP_CONFIG to enable")
            return None
        
        return group_key
    
    def _check_metric_match(self, metric: str, winning_shot_type: str, point_winner: str, 
                           server: str, player_filter: str, point_data: Dict = None) -> bool:
        """
        GENERIC CONFIG-DRIVEN metric matching.
        Uses METRIC_CONFIG and ROLE_CONFIG - NO hardcoded metric checks!
        """
        # Treat player_filter='both' as no filter (compare all players)
        if player_filter and player_filter.lower() == 'both':
            player_filter = None
        
        # Get metric config - SINGLE SOURCE OF TRUTH
        config = self.METRIC_CONFIG.get(metric, {})
        
        # If no config found, use a generic fallback
        if not config:
            # Check if metric is a winner type
            if 'winner' in metric.lower():
                config = {'player_role': 'winner', 'total_filter': 'always', 'count_filter': 'on_match', 'keywords': ['winner']}
            elif 'error' in metric.lower():
                config = {'player_role': 'error', 'total_filter': 'always', 'count_filter': 'on_match', 'keywords': ['error']}
            else:
                config = {'player_role': 'both', 'total_filter': 'always', 'count_filter': 'won'}
        
        player_role = config.get('player_role', 'both')
        count_filter = config.get('count_filter', 'won')
        total_filter = config.get('total_filter', 'always')
        keywords = config.get('keywords', [])
        
        # Get relevant players using ROLE_CONFIG
        returner = point_data.get('returner', '') if point_data else ''
        error_player = point_data.get('error_player', '') if point_data else ''
        serve_number = point_data.get('serve_number') if point_data else None
        rally_length = point_data.get('rally_length', 0) if point_data else 0
        
        # Determine the relevant player based on player_role - GENERIC using field_to_player mapping
        role_config = self.ROLE_CONFIG.get(player_role, {})
        player_field = role_config.get('player_field', '')
        
        # GENERIC mapping from field name to actual player value
        field_to_player = {
            'server': server,
            'returner': returner,
            'point_winner': point_winner,
            'error_player': error_player
        }
        
        relevant_player = ''
        if player_field and player_field in field_to_player:
            relevant_player = field_to_player[player_field]
        elif player_role == 'both':
            # For 'both', check if player is involved in point at all
            relevant_player = point_winner  # Default to winner for 'both'
        
        # Check player filter - GENERIC using relevant_player
        if player_filter:
            if player_role == 'both':
                # Player filter matches if player won
                if not self._names_match_robust(player_filter, point_winner):
                    return False
            elif relevant_player:
                # Player filter matches the relevant player for this metric's role
                if not self._names_match_robust(player_filter, relevant_player):
                    return False
        
        # Check total_filter (for percentage calculations - which points to include in denominator)
        if total_filter == 'first_serve':
            if serve_number != 1:
                return False
        elif total_filter == 'second_serve':
            if serve_number != 2:
                return False
        
        # Check count_filter (which points to count in numerator) - GENERIC
        if count_filter == 'won':
            # Point must be won by the relevant player
            # For roles like 'server'/'returner': check if they won
            # For 'winner': always counts (they ARE the winner)
            # For 'error': always counts (error occurred)
            # For 'both' with player_filter: check if that player won
            if player_role in ['winner', 'error']:
                pass  # These roles always count for 'won' filter
            elif player_role == 'both' and player_filter:
                if not self._names_match_robust(point_winner, player_filter):
                    return False
            elif relevant_player:
                # For other roles (server, returner), check if they won
                if not self._names_match_robust(point_winner, relevant_player):
                    return False
        
        elif count_filter == 'first_serve_in':
            return serve_number == 1
        
        elif count_filter == 'second_serve_in':
            return serve_number == 2
        
        elif count_filter == 'on_match':
            # Check keywords against winning_shot_type
            if keywords:
                # Normalize winning_shot_type for comparison
                shot_type_lower = winning_shot_type.lower() if winning_shot_type else ''
                
                # Check if WINNER_TYPES should be used
                if 'winner' in keywords:
                    if winning_shot_type not in self.WINNER_TYPES and 'winner' not in shot_type_lower:
                        return False
                elif 'ace' in keywords:
                    if shot_type_lower != 'ace':
                        return False
                elif 'double fault' in keywords:
                    if shot_type_lower != 'double_fault':
                        return False
                elif 'forced error' in keywords:
                    if shot_type_lower != 'forced_error':
                        return False
                elif 'unforced error' in keywords:
                    if shot_type_lower != 'unforced_error':
                        return False
                elif 'error' in keywords:
                    if shot_type_lower not in ['unforced_error', 'forced_error']:
                        return False
                else:
                    # Generic keyword matching
                    if not any(kw.lower() in shot_type_lower for kw in keywords):
                        return False
        
        # Additional metric-specific conditions using config
        # Rally length conditions for rally_winners
        min_rally = config.get('min_rally_length', 0)
        if min_rally > 0 and rally_length < min_rally:
            return False
        
        return True
    
    def _calculate_group_percentages(self, results: Dict, player_filter: str) -> None:
        """Calculate win percentages for each group and find best group."""
        best_pct = -1
        best_group = None
        
        player1 = results['player1']
        player2 = results['player2']
        
        for group_key, group_data in results['groups'].items():
            if group_data['total'] > 0:
                group_data['player1_pct'] = round(100 * group_data['player1_wins'] / group_data['total'], 1)
                group_data['player2_pct'] = round(100 * group_data['player2_wins'] / group_data['total'], 1)
                
                # Track best group for the player filter
                if player_filter:
                    if player1 and player_filter.lower() in player1.lower():
                        if group_data['player1_pct'] > best_pct:
                            best_pct = group_data['player1_pct']
                            best_group = group_key
                    elif player2 and player_filter.lower() in player2.lower():
                        if group_data['player2_pct'] > best_pct:
                            best_pct = group_data['player2_pct']
                            best_group = group_key
            else:
                group_data['player1_pct'] = 0
                group_data['player2_pct'] = 0
        
        if best_group:
            results['best_group_for_player'] = {
                'group': best_group,
                'label': results['groups'][best_group]['label'],
                'win_pct': best_pct,
                'player': player_filter
            }
    
    def _analyze_chain_logic(self, classification: Dict) -> Dict[str, Any]:
        """
        Chain Logic Analysis - Track Shot A leading to Shot B patterns.
        
        Example: "How many times did a backhand slice lead to an unforced error?"
        """
        filters = classification.get('filters', {})
        chain = filters.get('chain_logic', {})
        
        shot_a_raw = chain.get('shot_a')  # Can be string or dict
        shot_b_raw = chain.get('shot_b')  # Can be string or dict
        
        # Convert dict format to list of keywords for flexible matching
        def normalize_shot(shot_data):
            keywords = []
            
            if isinstance(shot_data, dict):
                # Extract all values from dict and split into individual words
                for key in ['shot_type', 'shot_modifier', 'hand', 'direction']:
                    val = shot_data.get(key)
                    if val:
                        # Split multi-word values: "forehand volley" -> ["forehand", "volley"]
                        keywords.extend(val.lower().split())
            elif isinstance(shot_data, str):
                # Split string into individual keywords
                keywords.extend(shot_data.lower().split())
            
            # Remove duplicates while preserving order
            seen = set()
            unique_keywords = []
            for kw in keywords:
                if kw not in seen:
                    seen.add(kw)
                    unique_keywords.append(kw)
            
            return unique_keywords if unique_keywords else None
        
        shot_a_keywords = normalize_shot(shot_a_raw)
        shot_b_keywords = normalize_shot(shot_b_raw)
        
        # CRITICAL: Extract Shot A attributes from chain_logic (for metadata-based matching)
        # "When Federer hit X, did Nadal respond..." -> Shot A player = Federer, Shot B player = Nadal
        shot_a_player = None
        shot_a_shot_type = None
        shot_a_direction = None
        shot_a_depth = None
        shot_a_spin = None
        shot_a_phase = None  # NEW: serve, return, rally
        
        if isinstance(shot_a_raw, dict):
            # Dict format: {player: "X", shot_type: "forehand", direction: "crosscourt", shot_phase: "return"}
            shot_a_player = shot_a_raw.get('player')
            shot_a_shot_type = shot_a_raw.get('shot_type')
            shot_a_direction = shot_a_raw.get('direction')
            shot_a_depth = shot_a_raw.get('depth')
            shot_a_spin = shot_a_raw.get('spin')
            shot_a_phase = shot_a_raw.get('shot_phase')  # NEW
        elif isinstance(shot_a_raw, str):
            # String format: "Federer's crosscourt forehand" - parse it using GROUP_CONFIG
            shot_a_lower = shot_a_raw.lower()
            
            # Extract player name (before "'s" or "s'" or just the first name)
            if "'s " in shot_a_lower or "s' " in shot_a_lower:
                player_match = re.match(r"^([^']+)'s?", shot_a_lower)
                if player_match:
                    shot_a_player = player_match.group(1).strip()
            
            # Extract shot type from GROUP_CONFIG.shot_type
            shot_type_config = self.GROUP_CONFIG.get('shot_type', {})
            shot_type_branches = shot_type_config.get('default_branches', [])
            shot_type_labels = shot_type_config.get('display_labels', {})
            # Check both branch values and display labels
            all_shot_types = list(set(shot_type_branches + list(shot_type_labels.keys())))
            for st in all_shot_types:
                if st.lower() in shot_a_lower:
                    shot_a_shot_type = st
                    break
            
            # Extract direction from GROUP_CONFIG.shot_direction
            direction_config = self.GROUP_CONFIG.get('shot_direction', {})
            direction_branches = direction_config.get('default_branches', [])
            for d in direction_branches:
                # Normalize: check with underscores, hyphens, and spaces
                d_normalized = d.replace('_', ' ').replace('-', ' ')
                if d_normalized in shot_a_lower or d.replace('_', '') in shot_a_lower.replace(' ', '').replace('-', ''):
                    shot_a_direction = d
                    break
            
            # Extract depth from GROUP_CONFIG.depth
            depth_config = self.GROUP_CONFIG.get('depth', {})
            depth_branches = depth_config.get('default_branches', [])
            # Check longest first (to match "very deep" before "deep")
            for depth in sorted(depth_branches, key=len, reverse=True):
                depth_normalized = depth.replace('_', ' ')
                if depth_normalized in shot_a_lower:
                    shot_a_depth = depth
                    break
            
            # Extract spin from GROUP_CONFIG.spin (if it exists)
            spin_config = self.GROUP_CONFIG.get('spin', {})
            spin_branches = spin_config.get('default_branches', [])
            for spin in spin_branches:
                if spin.lower() in shot_a_lower:
                    shot_a_spin = spin
                    break
            
            # NEW: Extract shot_phase (serve, return, rally)
            if 'return' in shot_a_lower:
                shot_a_phase = 'return'
            elif 'serve' in shot_a_lower:
                shot_a_phase = 'serve'
            elif 'rally' in shot_a_lower:
                shot_a_phase = 'rally'
        
        # Collect debug info for user response
        debug_info = []
        debug_info.append(f"Shot A player: {shot_a_player}, Shot B player (responder): {filters.get('player')}")
        debug_info.append(f"Shot A metadata: type={shot_a_shot_type}, dir={shot_a_direction}, depth={shot_a_depth}, phase={shot_a_phase}")
        debug_info.append(f"Shot A keywords (fallback): {shot_a_keywords}, Shot B keywords: {shot_b_keywords}")
        
        # CRITICAL: Parse Shot B for special cases
        # "unforced error from opponent" -> opponent's shot with unforced error outcome
        # "winner" -> current player's winning shot
        shot_b_opponent = False  # Is Shot B by the opponent?
        shot_b_outcome = None    # What outcome to check? (unforced error, forced error, winner)
        
        shot_b_str = ' '.join(shot_b_keywords) if shot_b_keywords else (shot_b_raw if isinstance(shot_b_raw, str) else '')
        shot_b_lower = shot_b_str.lower()
        
        # Check if Shot B is by opponent
        if 'opponent' in shot_b_lower or 'from opponent' in shot_b_lower:
            shot_b_opponent = True
            # Remove "opponent" and "from" from keywords - these are modifiers, not shot descriptors
            shot_b_keywords = [kw for kw in (shot_b_keywords or []) if kw not in ['opponent', 'from']]
        
        # Check for outcome-only Shot B (unforced error, forced error, winner)
        if 'unforced' in shot_b_lower and 'error' in shot_b_lower:
            shot_b_outcome = 'UNFORCED ERROR'
        elif 'forced' in shot_b_lower and 'error' in shot_b_lower:
            shot_b_outcome = 'FORCED ERROR'
        elif 'winner' in shot_b_lower:
            shot_b_outcome = 'WINNER'
        
        # For display purposes
        shot_a_type = ' '.join(shot_a_keywords) if shot_a_keywords else None
        shot_b_type = shot_b_str if shot_b_str else ' '.join(shot_b_keywords) if shot_b_keywords else None
        
        if not shot_a_keywords:
            # Try to detect from query
            query_lower = classification.get('actual_question', '').lower()
            
            # Pattern: "X led to Y" or "X followed by Y"
            if 'led to' in query_lower or 'lead to' in query_lower:
                parts = query_lower.split('led to' if 'led to' in query_lower else 'lead to')
                shot_a_keywords = [parts[0].strip()] if parts[0].strip() else None
            elif 'followed by' in query_lower:
                parts = query_lower.split('followed by')
                shot_a_keywords = [parts[0].strip()] if parts[0].strip() else None
            
            # Update display strings
            shot_a_type = ' '.join(shot_a_keywords) if shot_a_keywords else None
        
        if not shot_a_keywords:
            return {'error': 'Chain logic requires Shot A specification'}
        
        player_filter = filters.get('player')
        set_filter = filters.get('set')
        serve_target_filter = filters.get('serve_target')  # wide, body, t
        shot_type_filter = filters.get('shot_type')  # forehand, backhand, etc.
        
        # SHOT POSITION FILTER: Extract from query/chain_logic
        # "second shot" = position 2 (return), "third shot" = position 3 (serve+1)
        shot_a_position = None
        query_lower = classification.get('actual_question', '').lower()
        
        if 'second shot' in query_lower or 'as his return' in query_lower or 'as her return' in query_lower or 'the return' in query_lower:
            shot_a_position = 2  # Return = shot #2
        elif 'third shot' in query_lower or 'third ball' in query_lower or 'serve+1' in query_lower or 'serve + 1' in query_lower:
            shot_a_position = 3  # Serve + 1 = shot #3
        elif 'first shot' in query_lower or 'the serve' in query_lower:
            shot_a_position = 1  # Serve = shot #1
        elif 'fourth shot' in query_lower:
            shot_a_position = 4
        
        if shot_a_position:
            debug_info.append(f"Shot A position filter: position {shot_a_position}")
        
        if not hasattr(self, 'point_by_point') or not self.point_by_point:
            return {'error': 'No point-by-point data available'}
        
        chain_matches = []
        total_shot_a = 0
        
        for point_data in self.point_by_point:
            point_text = point_data.get('point_text', point_data.get('description', ''))
            score = point_data.get('score', '')
            server = point_data.get('server', '')
            returner = point_data.get('returner', '')
            
            # Extract point winner from [Point won by:] tag (authoritative source)
            point_winner = None
            winner_match = re.search(r'\[Point won by:\s*([^\]]+)\]', point_text)
            if winner_match:
                point_winner = winner_match.group(1).strip()
            
            # Set filter (supports both single value and list)
            if set_filter:
                current_set = self._extract_current_set(score)
                if isinstance(set_filter, (list, tuple)):
                    if current_set not in set_filter:
                        continue
                elif current_set != set_filter:
                    continue
            
            # Parse rally
            rally_shots = self._parse_rally_sequence(point_text, server, returner)
            actual_shots = [s for s in rally_shots if s.get('outcome') != 'FAULT']
            
            # Look for Shot A -> Shot B pattern
            for i, shot in enumerate(actual_shots[:-1]):
                shot_desc = (shot.get('description') or '').lower()
                shot_player = shot.get('player') or ''
                shot_position = shot.get('shot_number')  # USE METADATA (1=serve, 2=return, 3=serve+1, etc.)
                
                # SHOT POSITION FILTER: Skip if not the required position
                if shot_a_position and shot_position and shot_position != shot_a_position:
                    continue
                
                # Check if this is Shot A - Use METADATA-BASED matching first, fallback to keywords
                # Metadata fields are already parsed by _parse_rally_sequence
                shot_a_match = True
                
                # Check shot_type from metadata (e.g., 'forehand', 'backhand')
                if shot_a_shot_type:
                    shot_meta_type = shot.get('shot_type', '').lower() if shot.get('shot_type') else ''
                    shot_a_match = shot_a_match and (shot_a_shot_type.lower() in shot_meta_type or shot_meta_type in shot_a_shot_type.lower())
                
                # Check direction from metadata (e.g., 'crosscourt', 'down_the_line')
                if shot_a_match and shot_a_direction:
                    shot_meta_dir = shot.get('direction', '').lower() if shot.get('direction') else ''
                    # Normalize: 'crosscourt' matches 'cross_court', 'cc', etc.
                    dir_normalized = shot_a_direction.lower().replace('_', '').replace('-', '').replace(' ', '')
                    meta_normalized = shot_meta_dir.replace('_', '').replace('-', '').replace(' ', '')
                    shot_a_match = shot_a_match and (dir_normalized in meta_normalized or meta_normalized in dir_normalized or shot_a_direction.lower() in shot_desc)
                
                # Check depth from metadata
                if shot_a_match and shot_a_depth:
                    shot_meta_depth = shot.get('depth', '').lower() if shot.get('depth') else ''
                    shot_a_match = shot_a_match and (shot_a_depth.lower() in shot_meta_depth or shot_meta_depth in shot_a_depth.lower() or shot_a_depth.lower() in shot_desc)
                
                # Check spin from metadata
                if shot_a_match and shot_a_spin:
                    shot_meta_spin = shot.get('spin', '').lower() if shot.get('spin') else ''
                    shot_a_match = shot_a_match and (shot_a_spin.lower() in shot_meta_spin or shot_meta_spin in shot_a_spin.lower() or shot_a_spin.lower() in shot_desc)
                
                # NEW: Check shot_phase from metadata (serve, return, rally)
                if shot_a_match and shot_a_phase:
                    # shot['outcome'] often includes "return", "serve", etc.
                    shot_outcome = shot.get('outcome', '').lower() if shot.get('outcome') else ''
                    # shot_desc also has phase info like "backhand return"
                    shot_a_match = shot_a_match and (shot_a_phase.lower() in shot_desc or shot_a_phase.lower() in shot_outcome)
                
                # FALLBACK: If no metadata attributes specified, use keyword matching on description
                if not any([shot_a_shot_type, shot_a_direction, shot_a_depth, shot_a_spin, shot_a_phase]) and shot_a_keywords:
                    shot_a_match = all(kw in shot_desc for kw in shot_a_keywords)
                
                if shot_a_match:
                    # Player filter for Shot A (use shot_a_player from chain_logic, NOT top-level player_filter!)
                    # top-level player_filter = who responded (Shot B player)
                    # shot_a_player = who hit Shot A (from chain_logic.shot_a.player)
                    if shot_a_player and not self._names_match_robust(shot_a_player, shot_player):
                        continue
                    
                    # Debug: Log first few Shot A matches with metadata
                    if total_shot_a < 3:
                        shot_meta_info = f"type={shot.get('shot_type')}, dir={shot.get('direction')}, depth={shot.get('depth')}"
                        debug_info.append(f"Shot A match #{total_shot_a+1}: '{shot_desc[:50]}' by {shot_player} | meta: {shot_meta_info}")
                    
                    # Serve target filter (wide, body, t)
                    if serve_target_filter:
                        if serve_target_filter == 'wide':
                            if 'wide' not in shot_desc:
                                continue
                        elif serve_target_filter == 'body':
                            if 'body' not in shot_desc and 'to body' not in shot_desc:
                                continue
                        elif serve_target_filter == 't':
                            if 'down the t' not in shot_desc and 'to t' not in shot_desc:
                                continue
                    
                    total_shot_a += 1
                    
                    # CRITICAL: Determine which shot to check for Shot B
                    # - If Shot B is by SAME player as Shot A → use +2 (opponent hits in between)
                    # - If Shot B is by OPPONENT → use +1 (immediate next shot)
                    is_serve = 'serve' in shot_desc or '1st serve' in shot_desc or '2nd serve' in shot_desc
                    
                    # Determine if we want same player or opponent for Shot B
                    # CRITICAL: If Shot A is by a DIFFERENT player than player_filter, then Shot B is the response
                    # E.g., "When Federer hit crosscourt forehand, how did Nadal respond?"
                    # - shot_a_player = Federer, player_filter = Nadal
                    # - Shot B is by Nadal (opponent of Shot A hitter), so step = 1
                    if shot_a_player and player_filter:
                        # Shot A has explicit player - check if it's the same as player_filter
                        same_player_for_both = self._names_match_robust(shot_a_player, player_filter)
                        # If Shot A is by player_filter, Shot B is also by player_filter (same player pattern)
                        # If Shot A is by opponent, Shot B is by player_filter (response pattern)
                        want_same_player = same_player_for_both and not shot_b_opponent
                    else:
                        # No explicit Shot A player - fall back to old logic
                        want_same_player = player_filter and not shot_b_opponent
                    step = 2 if want_same_player else 1
                    
                    # Special case: serve patterns always use +2 to get serve+1
                    if is_serve and player_filter:
                        step = 2
                    
                    if i + step < len(actual_shots):
                        next_shot = actual_shots[i + step]
                        next_player = next_shot.get('player') or ''
                        next_desc = (next_shot.get('description') or '').lower()
                        next_outcome = (next_shot.get('outcome') or '').lower()
                        
                        # Verify player is correct for same-player patterns
                        if want_same_player and not self._names_match_robust(player_filter, next_player):
                            continue  # Wrong player for same-player pattern
                        
                        # For response patterns (Shot A by different player), verify next shot is by player_filter
                        if not want_same_player and player_filter:
                            if not self._names_match_robust(player_filter, next_player):
                                if total_shot_a < 3:
                                    debug_info.append(f"Response pattern: next_player='{next_player}' != player_filter='{player_filter}' - skipping")
                                continue  # Wrong player for response pattern
                        
                        # Check if Shot B matches
                        # NEW: Handle three cases:
                        # 1. shot_b_outcome set (e.g., "unforced error") - check outcome field
                        # 2. shot_b_opponent set (e.g., "from opponent") - next shot by other player
                        # 3. Regular keywords - check description
                        shot_b_match = False
                        
                        # CASE 1: Outcome-based Shot B (e.g., "unforced error from opponent") - GENERIC
                        if shot_b_outcome:
                            # Check if next shot's outcome matches - GENERIC using keyword from shot_b_outcome
                            outcome_upper = (next_outcome or '').upper()
                            desc_lower = (next_desc or '').lower()
                            
                            # Convert shot_b_outcome to keyword for matching
                            outcome_keyword = shot_b_outcome.lower().replace('_', ' ')
                            shot_b_match = outcome_keyword in outcome_upper.lower() or outcome_keyword in desc_lower
                            
                            # Check if opponent requirement is met
                            if shot_b_match and shot_b_opponent and player_filter:
                                # Shot B should be by the OTHER player (not player_filter)
                                if self._names_match_robust(player_filter, next_player):
                                    shot_b_match = False  # Shot B is by same player, not opponent
                        else:
                            # CASE 2: Regular keyword matching - CONFIG-DRIVEN
                            # Get outcome keywords from GROUP_CONFIG instead of hardcoding
                            outcome_keywords = self.GROUP_CONFIG.get('outcome', {}).get('default_branches', [])
                            shot_type_keywords_b = [kw for kw in (shot_b_keywords or []) if kw not in outcome_keywords]
                            outcome_only_keywords = [kw for kw in (shot_b_keywords or []) if kw in outcome_keywords]
                            
                            # Check shot type keywords (must be in description)
                            shot_type_match = True
                            if shot_type_keywords_b:
                                shot_type_match = all(kw in next_desc for kw in shot_type_keywords_b)
                            
                            # Check outcome keywords (can be in outcome OR description)
                            outcome_match = True
                            if outcome_only_keywords:
                                outcome_match = all(
                                    (kw in next_outcome) or (kw in next_desc)
                                    for kw in outcome_only_keywords
                                )
                            
                            shot_b_match = shot_type_match and outcome_match
                            
                            # Check opponent requirement
                            if shot_b_match and shot_b_opponent and player_filter:
                                if self._names_match_robust(player_filter, next_player):
                                    shot_b_match = False  # Shot B is by same player, not opponent
                            # If NOT opponent mode and player filter exists, Shot B must be by player
                            elif shot_b_match and not shot_b_opponent and player_filter:
                                if not self._names_match_robust(player_filter, next_player):
                                    shot_b_match = False
                                    if total_shot_a < 3:
                                        debug_info.append(f"Shot B rejected: next_player={next_player} != player_filter={player_filter}")
                        
                        # Shot type filter for Shot B (e.g., forehand winner)
                        if shot_b_match and shot_type_filter:
                            if shot_type_filter.lower() not in next_desc:
                                continue
                        
                        if shot_b_match:
                            # Determine if player won the point
                            won = None
                            if point_winner and player_filter:
                                won = self._names_match_robust(player_filter, point_winner)
                            
                            # Debug: Log first few complete sequences
                            if len(chain_matches) < 3:
                                debug_info.append(f"Complete sequence: Shot A='{shot_desc}' -> Shot B='{next_desc}' by {next_player}")
                            
                            # Store Shot B metadata for grouping
                            shot_b_metadata = {
                                'description': next_desc,
                                'outcome': next_outcome,
                                'shot_type': next_shot.get('shot_type'),
                                'direction': next_shot.get('direction'),
                                'depth': next_shot.get('depth'),
                                'spin': next_shot.get('spin')
                            }
                            
                            chain_matches.append({
                                'point': point_text,
                                'point_number': point_data.get('point_number', '?'),
                                'score': score,
                                'server': point_data.get('server', ''),
                                'shot_a': shot_desc,
                                'shot_b': f"{next_desc} ({next_outcome})",
                                'shot_b_metadata': shot_b_metadata,
                                'player_a': shot_player,
                                'player_b': next_player,
                                'shot_a_number': shot_position,
                                'shot_b_number': next_shot.get('shot_number'),
                                'won': won
                            })
                    else:
                        continue  # Not enough shots
        
        # Calculate win percentage for chain sequences
        wins = sum(1 for m in chain_matches if m.get('won') == True)
        total_chain = len(chain_matches)
        win_pct = round(100 * wins / total_chain, 1) if total_chain > 0 else 0
        
        # Add full point information for all matching points to debug info
        debug_info.append(f"\n=== All Matching Points ({len(chain_matches)} total) ===")
        for i, m in enumerate(chain_matches, 1):
            point_num = m.get('point_number', i)
            debug_info.append(f"\n**Point {point_num}:**")
            debug_info.append(m.get('point', 'N/A'))
        
        return {
            'classification': classification,
            'shot_a': shot_a_type,
            'shot_b': shot_b_type,
            'player': player_filter,
            'total_shot_a': total_shot_a,
            'chain_matches': chain_matches,
            'total_chain_sequences': total_chain,
            'wins': wins,
            'win_percentage': win_pct,
            'conversion_rate': round(100 * total_chain / total_shot_a, 1) if total_shot_a > 0 else 0,
            'debug_info': debug_info
        }
    
    def _format_chain_logic_analysis(self, analysis: Dict[str, Any]) -> str:
        """Format chain logic analysis results."""
        if 'error' in analysis:
            return f"Unable to perform chain logic analysis: {analysis['error']}"
        
        shot_a = analysis['shot_a']
        shot_b = analysis['shot_b']
        player = analysis.get('player', 'Player')
        total_a = analysis['total_shot_a']
        matches = analysis['chain_matches']
        total_chain = analysis.get('total_chain_sequences', len(matches))
        wins = analysis.get('wins', 0)
        win_pct = analysis.get('win_percentage', 0)
        rate = analysis['conversion_rate']
        
        # Handle None values
        shot_a_display = shot_a.title() if shot_a else "Unknown Shot"
        shot_b_display = shot_b.title() if shot_b else "Any Response"
        
        # CHECK FOR GROUPING (generic, like tree)
        classification = analysis.get('classification', {})
        group_by_dim = classification.get('group_by')
        
        # If shot_b is None AND group_by exists, group Shot B responses
        if not shot_b and group_by_dim and matches:
            # Map group_by to Shot B metadata field
            field_map = {
                'shot_direction': 'direction',
                'direction': 'direction',
                'shot_type': 'shot_type',
                'depth': 'depth',
                'spin': 'spin'
            }
            shot_b_field = field_map.get(group_by_dim, group_by_dim)
            
            # Group matches by Shot B attribute
            from collections import defaultdict
            grouped = defaultdict(lambda: {'count': 0, 'wins': 0, 'examples': []})
            
            for m in matches:
                shot_b_meta = m.get('shot_b_metadata', {})
                group_value = shot_b_meta.get(shot_b_field)
                
                if not group_value:
                    group_value = 'unknown'
                
                grouped[group_value]['count'] += 1
                if m.get('won'):
                    grouped[group_value]['wins'] += 1
                if len(grouped[group_value]['examples']) < 3:
                    grouped[group_value]['examples'].append(m)
            
            # Format grouped results
            response = f"**Chain Logic Analysis: After {shot_a_display}**\n\n"
            if player:
                response += f"**Player:** {player}\n"
            response += f"**Total {shot_a_display} Shots:** {total_a}\n"
            response += f"**Total Responses Analyzed:** {total_chain} ({rate}% response rate)\n\n"
            
            group_label = group_by_dim.replace('_', ' ').title()
            response += f"**Response Breakdown by {group_label}:**\n\n"
            
            # Sort by count (most frequent first)
            sorted_groups = sorted(grouped.items(), key=lambda x: x[1]['count'], reverse=True)
            
            for group_val, stats in sorted_groups:
                count = stats['count']
                wins = stats['wins']
                pct = round(100 * count / total_chain, 1) if total_chain > 0 else 0
                win_pct_group = round(100 * wins / count, 1) if count > 0 else 0
                
                response += f"**{group_val.title()}:** {count} responses ({pct}%)\n"
                response += f"  - Win %: {win_pct_group}% ({wins}/{count})\n"
                
                # Show 1-2 examples
                for ex in stats['examples'][:2]:
                    won_str = "✅" if ex.get('won') else "❌"
                    response += f"  - {won_str} {ex['score']}: {ex['shot_a']} → {ex['shot_b']}\n"
                response += "\n"
            
            return response
        
        if shot_b:
            response = f"**Chain Logic Analysis: {shot_a_display} → {shot_b_display}**\n\n"
        else:
            response = f"**Chain Logic Analysis: After {shot_a_display}**\n\n"
        
        # Player info below
        if False:  # Dead code marker
            _ = f"OLD {shot_a_display} -> {shot_b.title()}**\n\n"
        
        if player:
            response += f"**Player:** {player}\n"
        
        response += f"**Total {shot_a_display} Shots:** {total_a}\n"
        if shot_b:
            response += f"**Led to {shot_b_display}:** {total_chain} ({rate}% conversion)\n\n"
        # Win percentage section
            response += f"**Win Percentage on {shot_a_display} → {shot_b_display} sequences:**\n"
            response += f"- Points Won: {wins} / {total_chain}\n"
            response += f"- **Win %: {win_pct}%**\n\n"
        else:
            response += f"**Total Responses:** {total_chain} ({rate}% response rate)\n\n"
        
        
        # Examples section
        if False:  # Dead code cleanup marker
            _ = f"OLD {shot_a_display} -> {shot_b.title()} sequences:**\n"
        response += f"- Points Won: {wins} / {total_chain}\n"
        response += f"- **Win %: {win_pct}%**\n\n"
        
        if matches:
            response += f"**Point Citations (All {len(matches)} Points):**\n\n"
            for i, m in enumerate(matches, 1):
                won_str = "âœ… WON" if m.get('won') else "âŒ LOST" if m.get('won') == False else ""
                shot_a_num = m.get('shot_a_number', '?')
                shot_b_num = m.get('shot_b_number', '?')
                point_num = m.get('point_number', i)
                set_num = self._extract_current_set(m.get('score', '')) or '?'
                server = m.get('server', '?')
                score = m.get('score', '?')
                
                response += f"{i}. **Point {point_num}** [Set {set_num} | {server} serving at {score}] {won_str}\n"
                response += f"   ● Shot A (#{shot_a_num}): {m['shot_a']} by {m['player_a']}\n"
                response += f"   ● Shot B (#{shot_b_num}): {m['shot_b']} by {m['player_b']}\n"
                # Show full point description - NO LIMITS
                point_desc = m.get('point', '')
                response += f"   ● Point: {point_desc}\n\n"
        
        # Add debug info if available
        debug_info = analysis.get('debug_info', [])
        if debug_info:
            response += f"**Debug Information:**\n\n"
            for debug_line in debug_info:
                response += f"- {debug_line}\n"
            response += "\n"
        
        return response
    
    # ═══════════════════════════════════════════════════════════════════════════
    # CONSECUTIVE SHOTS ANALYSIS - "3+ forehands in a row"
    # ═══════════════════════════════════════════════════════════════════════════
    
    def _analyze_consecutive_shots(self, classification: Dict[str, Any]) -> Dict[str, Any]:
        """
        Analyze consecutive shot patterns within rallies.
        
        Handles questions like:
        - "How many times did Federer hit 3+ consecutive forehands before winning?"
        - "How often did Nadal hit 5+ crosscourt shots in a row?"
        - "What's the average consecutive backhand count in long rallies?"
        
        Parses rally sequences and counts runs of consecutive shots matching criteria.
        """
        if not self.point_by_point:
            return {'error': 'No point-by-point data available'}
        
        filters = classification.get('filters', {})
        player_filter = filters.get('player')
        
        # Extract consecutive shot criteria from classification
        min_consecutive = classification.get('consecutive_shots_min', 3)
        shot_type_filter = classification.get('sequence_shot_type') or filters.get('shot_type')
        direction_filter = classification.get('sequence_direction') or filters.get('direction')
        require_win = classification.get('point_won_by') == player_filter or 'winning' in classification.get('actual_question', '').lower() or 'won' in classification.get('actual_question', '').lower()
        
        # Collect debug info for user response
        debug_info = []
        debug_info.append(f"Looking for {min_consecutive}+ consecutive shots")
        debug_info.append(f"Player: {player_filter}, Shot type: {shot_type_filter}, Direction: {direction_filter}")
        debug_info.append(f"Require win: {require_win}")
        
        # Results
        matching_points = []
        total_sequences = 0
        max_consecutive = 0
        consecutive_counts = []  # Track all sequence lengths
        debug_count = 0
        DEBUG_ENABLED = False  # Set to True to see detailed matching logs
        
        for point_data in self.point_by_point:
            point_text = point_data.get('point_text', point_data.get('description', ''))
            score = point_data.get('score', '')
            set_num = self._extract_current_set(score) or 1
            # Extract point winner from [Point won by:] tag
            point_winner = None
            winner_match = re.search(r'\[Point won by:\s*([^\]]+)\]', point_text)
            if winner_match:
                point_winner = winner_match.group(1).strip()
            server = point_data.get('server', '')
            returner = point_data.get('returner', '')
            
            # Parse rally sequence
            rally = self._parse_rally_sequence(point_text, server, returner)
            if not rally:
                continue
            
            # TRULY CONSECUTIVE shots for a single player means +2 positions 
            # (because opponent hits in between)
            # Shot at position N, next by same player is at N+2, then N+4, etc.
            # For BOTH players (no player filter), it's just +1 positions
            
            # Debug: show first few rallies
            if DEBUG_ENABLED and debug_count < 3 and len(rally) > 3:
                debug_count += 1
                debug_info.append(f"Rally {debug_count} has {len(rally)} shots:")
                for i, shot in enumerate(rally[:5], 1):
                    debug_info.append(f"  Shot {i}: player={shot.get('player', '?')}, type={shot.get('shot_type', '?')}, desc={shot.get('description', '')[:40]}")
            
            # Helper to check if a shot matches criteria - CONFIG-DRIVEN
            def shot_matches(shot):
                shot_player = shot.get('player', '')
                shot_type = (shot.get('shot_type') or '').lower()
                shot_dir = (shot.get('direction') or '').lower()
                shot_outcome = (shot.get('outcome') or '').lower()
                shot_desc = shot.get('description', '').lower()
                shot_intent = (shot.get('intent') or '').lower()
                shot_contact = (shot.get('contact_type') or '').lower()
                shot_spin = (shot.get('spin') or '').lower()
                shot_depth = (shot.get('depth') or '').lower()
                
                # Player filter
                player_match = not player_filter or self._names_match_robust(player_filter, shot_player)
                if not player_match:
                    return False
                
                # Shot type filter - CONFIG-DRIVEN using GROUP_CONFIG
                type_match = True
                if shot_type_filter:
                    filter_lower = shot_type_filter.lower()
                    # Check outcome using GROUP_CONFIG
                    if filter_lower in self.GROUP_CONFIG.get('outcome', {}).get('default_branches', []):
                        type_match = filter_lower in shot_outcome or filter_lower in shot_desc
                    # Check intent using match_filter_inventory
                    elif filter_lower in self.match_filter_inventory.get('intents', []) or filter_lower.replace(' ', '_') in self.match_filter_inventory.get('intents', []):
                        type_match = (filter_lower.replace(' ', '_') in shot_intent if shot_intent else False) or filter_lower in shot_desc
                    # Check contact type using match_filter_inventory
                    elif filter_lower in self.match_filter_inventory.get('contact_types', []) or filter_lower.replace(' ', '_') in self.match_filter_inventory.get('contact_types', []):
                        type_match = (filter_lower.replace(' ', '_') in shot_contact if shot_contact else False) or filter_lower in shot_desc or (filter_lower.replace('_', ' ') in shot_desc)
                    # Check shot_type using GROUP_CONFIG
                    elif filter_lower in self.GROUP_CONFIG.get('shot_type', {}).get('default_branches', []):
                        type_match = filter_lower in shot_type or filter_lower in shot_desc
                    # Check spin using GROUP_CONFIG
                    elif filter_lower in self.GROUP_CONFIG.get('spin', {}).get('default_branches', []):
                        type_match = filter_lower in shot_spin or filter_lower in shot_desc
                    # Check depth using GROUP_CONFIG
                    elif filter_lower in self.GROUP_CONFIG.get('depth', {}).get('default_branches', []):
                        type_match = filter_lower in shot_depth or filter_lower in shot_desc
                    # Fallback: check all keywords in description
                    else:
                        type_match = all(kw in shot_desc for kw in filter_lower.split())
                
                # Direction filter - CONFIG-DRIVEN using GROUP_CONFIG
                dir_match = True
                if direction_filter:
                    filter_lower = direction_filter.lower()
                    if filter_lower in self.GROUP_CONFIG.get('shot_direction', {}).get('default_branches', []):
                        dir_match = filter_lower.replace(' ', '_') in shot_dir or filter_lower.replace(' ', '') in shot_dir.replace('_', '') or filter_lower in shot_desc
                    else:
                        # Fallback: check all keywords in description
                        dir_match = all(kw in shot_desc for kw in filter_lower.split())
                
                return type_match and dir_match
            
            # Find longest run of TRULY consecutive shots
            # For single player: +2 positions (opponent hits in between)
            # For both players: +1 positions
            step = 2 if player_filter else 1
            
            best_run_in_point = 0
            
            for start_idx in range(len(rally)):
                if not shot_matches(rally[start_idx]):
                    continue
                
                # Count consecutive matching shots from this starting point
                run_length = 1
                current_idx = start_idx
                
                while True:
                    next_idx = current_idx + step
                    if next_idx >= len(rally):
                        break
                    if not shot_matches(rally[next_idx]):
                        break
                    run_length += 1
                    current_idx = next_idx
                
                best_run_in_point = max(best_run_in_point, run_length)
            
            # Debug: show when we find enough matching shots
            if DEBUG_ENABLED and debug_count <= 3 and best_run_in_point >= min_consecutive:
                debug_info.append(f"Found {best_run_in_point} {shot_type_filter or 'shots'} by {player_filter} in this rally")
            
            # Record if this point had a qualifying sequence
            if best_run_in_point >= min_consecutive:
                # Check win requirement
                player_won = False
                if player_filter and point_winner:
                    player_won = self._names_match_robust(player_filter, point_winner)
                
                if not require_win or player_won:
                    total_sequences += 1
                    max_consecutive = max(max_consecutive, best_run_in_point)
                    consecutive_counts.append(best_run_in_point)
                    
                    matching_points.append({
                        'point_number': point_data.get('point_number', '?'),
                        'point': point_text,
                        'score': score,
                        'set': set_num,
                        'server': point_data.get('server', '?'),
                        'point_winner': point_winner,
                        'consecutive_count': best_run_in_point,
                        'won': player_won,
                        'rally_length': len(rally)
                    })
        
        # Calculate stats
        avg_consecutive = round(sum(consecutive_counts) / len(consecutive_counts), 1) if consecutive_counts else 0
        wins = sum(1 for m in matching_points if m.get('won'))
        win_pct = round(100 * wins / total_sequences, 1) if total_sequences > 0 else 0
        
        # Add full point information for all matching points to debug info
        debug_info.append(f"\n=== All Matching Points ({len(matching_points)} total) ===")
        for i, m in enumerate(matching_points, 1):
            point_num = m.get('point_number', '?')
            debug_info.append(f"\n**Point {point_num}:**")
            debug_info.append(m.get('point', 'N/A'))
        
        return {
            'classification': classification,
            'player': player_filter,
            'shot_type': shot_type_filter,
            'direction': direction_filter,
            'min_consecutive': min_consecutive,
            'require_win': require_win,
            'total_sequences': total_sequences,
            'max_consecutive': max_consecutive,
            'avg_consecutive': avg_consecutive,
            'wins': wins,
            'win_percentage': win_pct,
            'matching_points': matching_points,
            'debug_info': debug_info
        }
    
    def _analyze_multi_step_pattern(self, classification: Dict[str, Any]) -> Dict[str, Any]:
        """
        Analyze multi-step shot patterns (A -> B -> C or more).
        
        Handles questions like:
        - "How many points ended: forehand -> approach -> volley -> winner?"
        - "When did Federer hit slice -> approach -> volley?"
        - "How often did rallies go forehand -> forehand -> backhand?"
        
        Extends chain logic to 3+ step sequences.
        """
        if not self.point_by_point:
            return {'error': 'No point-by-point data available'}
        
        filters = classification.get('filters', {})
        player_filter = filters.get('player')
        
        # Extract pattern from classification
        pattern = classification.get('multi_step_pattern', [])
        if not pattern:
            return {'error': 'No multi-step pattern specified'}
        
        # Collect debug info for user response
        debug_info = []
        debug_info.append(f"Looking for pattern: {' -> '.join(pattern)}")
        debug_info.append(f"Player filter: {player_filter or 'Both players'}")
        
        # Results
        matching_points = []
        total_matches = 0
        debug_windows = 0
        DEBUG_ENABLED = False  # Set to True to see detailed matching logs
        
        for point_data in self.point_by_point:
            point_text = point_data.get('point_text', point_data.get('description', ''))
            score = point_data.get('score', '')
            set_num = self._extract_current_set(score) or 1
            # Extract point winner from [Point won by:] tag
            point_winner = None
            winner_match = re.search(r'\[Point won by:\s*([^\]]+)\]', point_text)
            if winner_match:
                point_winner = winner_match.group(1).strip()
            server = point_data.get('server', '')
            returner = point_data.get('returner', '')
            
            # Parse rally sequence
            rally = self._parse_rally_sequence(point_text, server, returner)
            
            # CRITICAL: Determine if pattern should be checked for ONE player or BOTH players
            # Examples:
            # - "forehand approach -> volley winner" → tactical sequence, same player only (step=2)
            # - "crosscourt -> crosscourt -> down-the-line" → could be same or alternating
            
            # If player_filter specified → only check that player's pattern (step=2)
            # If tactical sequence (approach/volley/winner) → only same player (step=2)
            # Otherwise → check BOTH same-player (step=2) AND alternating (step=1)
            
            is_tactical_sequence = any('approach' in p.lower() or 'volley' in p.lower() or 'winner' in p.lower() for p in pattern)
            
            # Determine which step patterns to check
            if player_filter or is_tactical_sequence:
                step_patterns = [2]  # Only same player
            else:
                step_patterns = [2, 1]  # Try both: same player first, then alternating
            
            # Track matches for each pattern type
            same_player_matches = []
            alternating_matches = []
            
            for step in step_patterns:
                required_rally_length = 1 + (len(pattern) - 1) * step
                
                if len(rally) < required_rally_length:
                    continue
                
                # Slide through rally looking for pattern match with correct step
                max_start = len(rally) - required_rally_length + 1
                for start_idx in range(max_start):
                    # Build window using correct step
                    window_indices = [start_idx + i * step for i in range(len(pattern))]
                    if window_indices[-1] >= len(rally):
                        continue
                    window = [rally[idx] for idx in window_indices]
                    
                    # For same-player patterns (step=2), verify ALL shots are by the same player
                    if step == 2:
                        first_player = window[0].get('player', '')
                        if not all(self._names_match_robust(first_player, shot.get('player', '')) for shot in window):
                            continue  # Different players in sequence, skip
                
                # Debug: show first few windows
                if DEBUG_ENABLED and debug_windows < 1:
                    debug_windows += 1
                    debug_info.append(f"Window {debug_windows}: {len(window)} shots from {len(rally)}-shot rally")
                    for j, s in enumerate(window):
                        debug_info.append(f"  Step {j+1}: type={s.get('shot_type')}, intent={s.get('intent')}, contact={s.get('contact_type')}, outcome={s.get('outcome')}")
                        debug_info.append(f"           desc='{s.get('description', '')[:80]}'")
                
                # Check if window matches pattern
                match = True
                match_details = []
                
                for i, (shot, pattern_step) in enumerate(zip(window, pattern)):
                    shot_player = shot.get('player', '')
                    shot_type = (shot.get('shot_type') or '').lower()
                    shot_dir = (shot.get('direction') or '').lower()
                    shot_outcome = (shot.get('outcome') or '').lower()
                    shot_desc = shot.get('description', '').lower()
                    shot_intent = (shot.get('intent') or '').lower()  # NEW: approach, drop_shot, lob
                    shot_contact = (shot.get('contact_type') or '').lower()  # NEW: volley, groundstroke
                    
                    # Parse pattern step (can be "forehand", "crosscourt forehand", "winner", etc.)
                    step_lower = pattern_step.lower()
                    
                    # Check for player constraint (first shot often has player)
                    step_player = None
                    if player_filter and i == 0:
                        step_player = player_filter
                    
                    # CONFIG-DRIVEN MATCHING - Check if pattern step matches this shot
                    # All possible shot attributes come from config
                    step_keywords = step_lower.split()
                    
                    # Build config-driven category lookups (normalize to lowercase)
                    cfg_shot_types = [s.lower() for s in self.GROUP_CONFIG.get('shot_type', {}).get('default_branches', [])]
                    cfg_outcomes = [o.lower() for o in self.GROUP_CONFIG.get('outcome', {}).get('default_branches', [])]
                    cfg_directions = [d.lower() for d in self.GROUP_CONFIG.get('shot_direction', {}).get('default_branches', [])]
                    cfg_modifiers = [m.lower() for m in self.GROUP_CONFIG.get('shot_modifier', {}).get('default_branches', [])]
                    cfg_spins = [s.lower() for s in self.GROUP_CONFIG.get('spin', {}).get('default_branches', [])]
                    cfg_contacts = [c.lower() for c in self.match_filter_inventory.get('contact_types', [])]
                    cfg_intents = [i.lower() for i in self.match_filter_inventory.get('intents', [])]
                    cfg_depths = [d.lower() for d in self.GROUP_CONFIG.get('depth', {}).get('default_branches', [])]
                    
                    # Get ALL shot fields for matching
                    shot_spin = (shot.get('spin') or '').lower()
                    shot_depth = (shot.get('depth') or '').lower()
                    
                    def keyword_in_shot(kw):
                        """CONFIG-DRIVEN: Check keyword against appropriate shot field based on config category"""
                        kw = kw.lower().strip()
                        kw_norm = kw.replace('-', '_').replace(' ', '_')
                        
                        # Determine category from config and check appropriate field
                        # 1. Shot type (forehand, backhand) -> shot_type field
                        if kw in cfg_shot_types or kw_norm in cfg_shot_types:
                            return kw in shot_type or kw_norm in shot_type
                        
                        # 2. Outcome (winner, error, ace) -> outcome field
                        if kw in cfg_outcomes or kw_norm in cfg_outcomes:
                            return kw in shot_outcome or kw_norm in shot_outcome
                        
                        # 3. Direction (crosscourt, down_the_line) -> direction field
                        if kw in cfg_directions or kw_norm in cfg_directions:
                            dir_norm = shot_dir.replace('-', '_').replace(' ', '_')
                            return kw_norm in dir_norm or kw in shot_dir or kw.replace('_', ' ') in shot_desc
                        
                        # 4. Modifier/Intent (approach, volley, drop_shot, slice) -> intent OR contact OR description
                        if kw in cfg_modifiers or kw_norm in cfg_modifiers:
                            return (kw in shot_intent or kw_norm in shot_intent or
                                    kw in shot_contact or kw_norm in shot_contact or
                                    kw in shot_desc or kw.replace('_', ' ') in shot_desc)
                        
                        # 5. Contact type (volley, overhead, groundstroke) -> contact_type field
                        if kw in cfg_contacts or kw_norm in cfg_contacts:
                            return kw in shot_contact or kw_norm in shot_contact or kw in shot_desc
                        
                        # 6. Intent (approach, drop_shot, lob) -> intent field
                        if kw in cfg_intents or kw_norm in cfg_intents:
                            return kw in shot_intent or kw_norm in shot_intent or kw in shot_desc
                        
                        # 7. Spin (slice, topspin, flat) -> spin field
                        if kw in cfg_spins or kw_norm in cfg_spins:
                            return kw in shot_spin or kw_norm in shot_spin or kw in shot_desc
                        
                        # 8. Depth (shallow, deep, very_deep) -> depth field
                        if kw in cfg_depths or kw_norm in cfg_depths:
                            return kw in shot_depth or kw_norm in shot_depth or kw in shot_desc
                        
                        # Fallback: check description for anything not in config
                        return kw in shot_desc or kw.replace('_', ' ') in shot_desc
                    
                    # ALL keywords in pattern step must match this ONE shot
                    step_match = all(keyword_in_shot(kw) for kw in step_keywords)
                    
                    # Debug: Show when we find a match for ANY pattern step
                    if step_match and len(step_keywords) > 1:
                        print(f"[PATTERN-MATCH] Step {i+1} '{step_lower}' MATCHED shot: type='{shot_type}', intent='{shot_intent}', contact='{shot_contact}', outcome='{shot_outcome}'")
                        print(f"  Desc: '{shot_desc[:60]}'")
                    
                    # Player check for first step
                    if step_player and not self._names_match_robust(step_player, shot_player):
                        step_match = False
                    
                    if not step_match:
                        # Debug: Show when step 2+ fails after step 1 matched
                        if i > 0 and len(step_keywords) > 1:
                            print(f"[PATTERN-FAIL] Step {i+1} '{step_lower}' FAILED vs shot: type='{shot_type}', intent='{shot_intent}', contact='{shot_contact}', outcome='{shot_outcome}'")
                            print(f"  Desc: '{shot_desc[:60]}'")
                            kw_results = [(kw, keyword_in_shot(kw)) for kw in step_keywords]
                            print(f"  Keywords: {kw_results}")
                        match = False
                        break
                    
                    match_details.append({
                        'shot_num': shot.get('shot_number'),
                        'player': shot_player,
                        'description': shot.get('description', '')[:50]
                    })
                
                    if match:
                        player_won = False
                        if player_filter and point_winner:
                            player_won = self._names_match_robust(player_filter, point_winner)
                        
                        match_data = {
                            'point_number': point_data.get('point_number', '?'),
                            'point': point_text,
                            'score': score,
                            'set': set_num,
                            'server': point_data.get('server', '?'),
                            'point_winner': point_winner,
                            'match_details': match_details,
                            'won': player_won,
                            'rally_length': len(rally),
                            'pattern_type': 'same_player' if step == 2 else 'alternating'
                        }
                        
                        # Store in appropriate list
                        if step == 2:
                            same_player_matches.append(match_data)
                        else:
                            alternating_matches.append(match_data)
                        break  # Only count once per point (for this step pattern)
            
            # Combine matches (avoid duplicates if point matched both patterns)
            seen_points = set()
            for match in same_player_matches + alternating_matches:
                point_num = match['point_number']
                if point_num not in seen_points:
                    matching_points.append(match)
                    seen_points.add(point_num)
                    total_matches += 1
        
        # Calculate stats
        wins = sum(1 for m in matching_points if m.get('won'))
        win_pct = round(100 * wins / total_matches, 1) if total_matches > 0 else 0
        
        # Add pattern type breakdown if we checked both
        if len(same_player_matches) > 0 and len(alternating_matches) > 0:
            debug_info.append(f"\n=== Pattern Match Breakdown ===")
            debug_info.append(f"Same Player Pattern (step=2): {len(same_player_matches)} points")
            debug_info.append(f"Alternating Players Pattern (step=1): {len(alternating_matches)} points")
            debug_info.append(f"Total Unique Points: {len(matching_points)}")
        
        # Add full point information for all matching points to debug info
        debug_info.append(f"\n=== All Matching Points ({len(matching_points)} total) ===")
        for i, m in enumerate(matching_points, 1):
            point_num = m.get('point_number', '?')
            pattern_type = m.get('pattern_type', 'unknown')
            debug_info.append(f"\n**Point {point_num}** [{pattern_type}]:")
            debug_info.append(m.get('point', 'N/A'))
        
        return {
            'classification': classification,
            'player': player_filter,
            'pattern': pattern,
            'total_matches': total_matches,
            'same_player_matches': len(same_player_matches),
            'alternating_matches': len(alternating_matches),
            'wins': wins,
            'win_percentage': win_pct,
            'matching_points': matching_points,
            'debug_info': debug_info
        }
    
    def _prefilter_points_by_shot_attributes(self, classification: Dict[str, Any]) -> List[Dict]:
        """
        Pre-filter points by shot-level attributes before passing to narrative.
        
        Filters points that contain specific shot characteristics:
        - shot_type: forehand, backhand, volley, etc.
        - direction: crosscourt, down_the_line, etc.
        - spin: slice, topspin, flat
        - outcome: winner, error, etc.
        
        Returns list of matching point descriptions for focused narrative synthesis.
        """
        if not self.point_by_point:
            return []
        
        filters = classification.get('filters', {})
        
        # CONFIG-DRIVEN: Extract ALL possible shot attributes from GROUP_CONFIG and match_filter_inventory
        # Get all config categories
        cfg_outcomes = [o.lower() for o in self.GROUP_CONFIG.get('outcome', {}).get('default_branches', [])]
        
        # Extract attributes (check both filters and top-level classification)
        shot_type = filters.get('shot_type') or classification.get('shot_type')
        direction = filters.get('direction') or classification.get('direction')
        spin = filters.get('spin') or classification.get('spin')
        outcome = filters.get('outcome') or classification.get('outcome')
        intent = filters.get('intent') or classification.get('intent')
        contact_type = filters.get('contact_type') or classification.get('contact_type')
        depth = filters.get('depth') or classification.get('depth')  # NEW: shallow, deep, very_deep
        location = filters.get('location') or classification.get('location')  # NEW: baseline, mid_court, net, service_line
        shot_modifier = filters.get('shot_modifier') or classification.get('shot_modifier')  # NEW: slice, volley, drop_shot, approach
        player_filter = filters.get('player')
        
        # CONFIG-DRIVEN: Extract outcome from metrics_parsed using config
        # Query like "crosscourt forehand winners" might parse "winners" as a metric, not outcome
        metrics_parsed = classification.get('metrics_parsed', [])
        for metric_info in metrics_parsed:
            metric = metric_info.get('metric', '').lower()
            if not outcome:
                # Check if metric matches any outcome in config
                for cfg_outcome in cfg_outcomes:
                    if cfg_outcome in metric or metric in cfg_outcome:
                        outcome = cfg_outcome
                        print(f"[SHOT-PREFILTER] Extracted '{outcome}' outcome from metric '{metric_info.get('metric')}' (config-driven)")
                        break
        
        # CONFIG-DRIVEN: Fallback - Check question text for outcome keywords from config
        if not outcome:
            question = classification.get('actual_question', '') or ''
            question_lower = question.lower()
            # Check each outcome in config
            for cfg_outcome in cfg_outcomes:
                if cfg_outcome.replace('_', ' ') in question_lower or cfg_outcome in question_lower:
                    outcome = cfg_outcome
                    print(f"[SHOT-PREFILTER] Extracted '{outcome}' outcome from question text (config-driven)")
                    break
        
        # If no shot attributes to filter on, return empty (use normal narrative)
        if not any([shot_type, direction, spin, outcome, intent, contact_type, depth, location, shot_modifier]):
            return []
        
        # Collect debug info for user response
        debug_info = []
        debug_info.append(f"Filtering points by: player={player_filter}, shot_type={shot_type}, dir={direction}, spin={spin}, outcome={outcome}, intent={intent}, contact={contact_type}, depth={depth}, location={location}, modifier={shot_modifier}")
        
        matching_points = []
        
        for point_data in self.point_by_point:
            point_text = point_data.get('point_text', point_data.get('description', ''))
            server = point_data.get('server', '')
            returner = point_data.get('returner', '')
            
            # Parse rally to check shot attributes
            rally = self._parse_rally_sequence(point_text, server, returner)
            
            # Check if any shot in rally matches criteria - CONFIG-DRIVEN
            point_matches = False
            for shot in rally:
                shot_player = shot.get('player', '')
                s_type = (shot.get('shot_type') or '').lower()
                s_dir = (shot.get('direction') or '').lower()
                s_spin = (shot.get('spin') or '').lower()
                s_outcome = (shot.get('outcome') or '').lower()
                s_desc = shot.get('description', '').lower()
                s_intent = (shot.get('intent') or '').lower()
                s_contact = (shot.get('contact_type') or '').lower()
                s_depth = (shot.get('depth') or '').lower()
                
                # Player filter
                if player_filter and not self._names_match_robust(player_filter, shot_player):
                    continue
                
                # Check all specified attributes - CONFIG-DRIVEN using GROUP_CONFIG and match_filter_inventory
                # Shot type filter
                type_match = True
                if shot_type:
                    filter_lower = shot_type.lower()
                    # Check outcome using GROUP_CONFIG
                    if filter_lower in self.GROUP_CONFIG.get('outcome', {}).get('default_branches', []):
                        type_match = filter_lower in s_outcome or filter_lower in s_desc
                    # Check intent using match_filter_inventory
                    elif filter_lower in self.match_filter_inventory.get('intents', []) or filter_lower.replace(' ', '_') in self.match_filter_inventory.get('intents', []):
                        type_match = (filter_lower.replace(' ', '_') in s_intent if s_intent else False) or filter_lower in s_desc
                    # Check contact type using match_filter_inventory
                    elif filter_lower in self.match_filter_inventory.get('contact_types', []) or filter_lower.replace(' ', '_') in self.match_filter_inventory.get('contact_types', []):
                        type_match = (filter_lower.replace(' ', '_') in s_contact if s_contact else False) or filter_lower in s_desc or (filter_lower.replace('_', ' ') in s_desc)
                    # Check shot_type using GROUP_CONFIG
                    elif filter_lower in self.GROUP_CONFIG.get('shot_type', {}).get('default_branches', []):
                        type_match = filter_lower in s_type or filter_lower in s_desc
                    # Fallback: check all keywords in description
                    else:
                        type_match = all(kw in s_desc for kw in filter_lower.split())
                
                # Direction filter - CONFIG-DRIVEN using GROUP_CONFIG
                dir_match = True
                if direction:
                    filter_lower = direction.lower()
                    if filter_lower in self.GROUP_CONFIG.get('shot_direction', {}).get('default_branches', []):
                        dir_match = filter_lower.replace(' ', '_') in s_dir or filter_lower.replace(' ', '') in s_dir.replace('_', '') or filter_lower in s_desc
                    else:
                        # Fallback: check all keywords in description
                        dir_match = all(kw in s_desc for kw in filter_lower.split())
                
                # Spin filter - CONFIG-DRIVEN using GROUP_CONFIG
                spin_match = True
                if spin:
                    filter_lower = spin.lower()
                    if filter_lower in self.GROUP_CONFIG.get('spin', {}).get('default_branches', []):
                        spin_match = filter_lower in s_spin or filter_lower in s_desc
                    else:
                        spin_match = all(kw in s_desc for kw in filter_lower.split())
                
                # Outcome filter - CONFIG-DRIVEN using GROUP_CONFIG
                outcome_match = True
                if outcome:
                    filter_lower = outcome.lower()
                    if filter_lower in self.GROUP_CONFIG.get('outcome', {}).get('default_branches', []):
                        outcome_match = filter_lower in s_outcome or filter_lower in s_desc
                    else:
                        outcome_match = all(kw in s_desc for kw in filter_lower.split())
                
                # Intent filter - CONFIG-DRIVEN using match_filter_inventory
                intent_match = True
                if intent:
                    filter_lower = intent.lower()
                    if filter_lower in self.match_filter_inventory.get('intents', []) or filter_lower.replace(' ', '_') in self.match_filter_inventory.get('intents', []):
                        intent_match = (filter_lower.replace(' ', '_') in s_intent if s_intent else False) or filter_lower in s_desc
                    else:
                        intent_match = all(kw in s_desc for kw in filter_lower.split())
                
                # Contact type filter - CONFIG-DRIVEN using match_filter_inventory
                contact_match = True
                if contact_type:
                    filter_lower = contact_type.lower()
                    if filter_lower in self.match_filter_inventory.get('contact_types', []) or filter_lower.replace(' ', '_') in self.match_filter_inventory.get('contact_types', []):
                        contact_match = (filter_lower.replace(' ', '_') in s_contact if s_contact else False) or filter_lower in s_desc or (filter_lower.replace('_', ' ') in s_desc)
                    else:
                        contact_match = all(kw in s_desc for kw in filter_lower.split())
                
                # Depth filter - CONFIG-DRIVEN using GROUP_CONFIG
                depth_match = True
                if depth:
                    filter_lower = depth.lower()
                    if filter_lower in self.GROUP_CONFIG.get('depth', {}).get('default_branches', []):
                        depth_match = filter_lower in s_depth or filter_lower in s_desc
                    else:
                        depth_match = all(kw in s_desc for kw in filter_lower.split())
                
                # Location filter - CONFIG-DRIVEN using match_filter_inventory
                location_match = True
                if location:
                    filter_lower = location.lower()
                    s_location = (shot.get('location') or '').lower()
                    if filter_lower in self.match_filter_inventory.get('locations', []) or filter_lower.replace(' ', '_') in self.match_filter_inventory.get('locations', []):
                        location_match = (filter_lower.replace(' ', '_') in s_location if s_location else False) or filter_lower in s_desc
                    else:
                        location_match = all(kw in s_desc for kw in filter_lower.split())
                
                # Shot modifier filter - CONFIG-DRIVEN using GROUP_CONFIG
                modifier_match = True
                if shot_modifier:
                    filter_lower = shot_modifier.lower()
                    # Modifiers can appear in multiple fields: intent, contact, or description
                    if filter_lower in self.GROUP_CONFIG.get('shot_modifier', {}).get('default_branches', []):
                        modifier_match = (filter_lower in s_intent or filter_lower in s_contact or 
                                         filter_lower in s_desc or filter_lower.replace('_', ' ') in s_desc)
                    else:
                        modifier_match = all(kw in s_desc for kw in filter_lower.split())
                
                if type_match and dir_match and spin_match and outcome_match and intent_match and contact_match and depth_match and location_match and modifier_match:
                    point_matches = True
                    break
            
            if point_matches:
                # Extract point winner
                point_winner = None
                winner_match = re.search(r'\[Point won by:\s*([^\]]+)\]', point_text)
                if winner_match:
                    point_winner = winner_match.group(1).strip()
                
                matching_points.append({
                    'point': point_text,
                    'point_number': point_data.get('point_number', '?'),
                    'score': point_data.get('score', ''),
                    'set': self._extract_current_set(point_data.get('score', '')) or 1,
                    'winner': point_winner or ''
                })
                
                # NO LIMIT - show ALL matching points in debug
        
        debug_info.append(f"Found {len(matching_points)} matching points")
        
        # Add full point information for all matching points to debug info
        debug_info.append(f"\n=== All Matching Points ({len(matching_points)} total) ===")
        for i, m in enumerate(matching_points, 1):
            point_num = m.get('point_number', '?')
            debug_info.append(f"\n**Point {point_num}:**")
            debug_info.append(m.get('point', 'N/A'))
        
        # Store debug info in last_prefilter_debug for caller to append
        self._last_prefilter_debug = debug_info
        
        return matching_points
    
    def _format_prefiltered_narrative_context(self, matching_points: List[Dict], classification: Dict) -> str:
        """Format pre-filtered points into narrative context for LLM."""
        if not matching_points:
            return ""
        
        filters = classification.get('filters', {})
        shot_type = filters.get('shot_type') or classification.get('shot_type')
        direction = filters.get('direction') or classification.get('direction')
        player = filters.get('player')
        
        # Build header
        desc_parts = []
        if player:
            desc_parts.append(player)
        if direction:
            desc_parts.append(direction.replace('_', ' '))
        if shot_type:
            desc_parts.append(shot_type)
        
        header = f"Points containing {' '.join(desc_parts) if desc_parts else 'specified shot attributes'}:"
        
        context = f"{header}\n\n"
        for i, p in enumerate(matching_points, 1):
            point_num = p.get('point_number', '?')
            won_by = f" (won by {p['winner']})" if p.get('winner') else ""
            context += f"{i}. **Point {point_num}** [{p['score']}]{won_by}: {p['point']}\n\n"
        
        return context
    
    def _format_multi_step_pattern_analysis(self, analysis: Dict[str, Any]) -> str:
        """Format multi-step pattern analysis results."""
        if 'error' in analysis:
            return f"Unable to perform multi-step pattern analysis: {analysis['error']}"
        
        player = analysis.get('player', 'Player')
        pattern = analysis.get('pattern', [])
        total = analysis.get('total_matches', 0)
        wins = analysis.get('wins', 0)
        win_pct = analysis.get('win_percentage', 0)
        matches = analysis.get('matching_points', [])
        
        pattern_str = ' -> '.join(pattern)
        
        response = f"**Multi-Step Pattern Analysis: {pattern_str}**\n\n"
        
        if player:
            response += f"**Player:** {player}\n"
        
        response += f"**Pattern Found:** {total} times\n\n"
        
        response += f"**Win Statistics:**\n"
        response += f"- Points Won: {wins} / {total}\n"
        response += f"- **Win %: {win_pct}%**\n\n"
        
        if matches:
            response += f"**Point Citations (All {len(matches)} Points):**\n\n"
            for i, m in enumerate(matches, 1):
                won_str = "◆ WIN" if m.get('won') else "◆ LOSS"
                point_num = m.get('point_number', '?')
                set_num = m.get('set', '?')
                server = m.get('server', '?')
                score = m.get('score', '?')
                
                response += f"{i}. **Point {point_num}** [Set {set_num} | {server} serving at {score}] {won_str}\n"
                response += f"   ● Pattern: {pattern_str} (rally length: {m['rally_length']} shots)\n"
                response += f"   ● Won by: {m.get('point_winner', '?')}\n"
                
                # Show matched shots
                if m.get('match_details'):
                    response += f"   ● Matched shots:\n"
                    for j, detail in enumerate(m['match_details'], 1):
                        response += f"      {j}. {detail.get('player', '?')}: {detail.get('description', '?')}\n"
                
                # Show full point description - NO LIMITS
                point_desc = m.get('point', '')
                response += f"   ● Point: {point_desc}\n\n"
        
        # Add debug info if available
        debug_info = analysis.get('debug_info', [])
        if debug_info:
            response += f"**Debug Information:**\n\n"
            for debug_line in debug_info:
                response += f"- {debug_line}\n"
                response += "\n"
        
        return response
    
    def _format_multi_step_pattern_analysis(self, analysis: Dict[str, Any]) -> str:
        """Format multi-step pattern analysis results."""
        if 'error' in analysis:
            return f"Unable to perform multi-step pattern analysis: {analysis['error']}"
        
        pattern = analysis.get('pattern', [])
        player = analysis.get('player')
        total = analysis.get('total_matches', 0)
        wins = analysis.get('wins', 0)
        win_pct = analysis.get('win_percentage', 0)
        matches = analysis.get('matching_points', [])
        
        pattern_str = " → ".join(pattern)
        
        response = f"**Multi-Step Pattern Analysis: {pattern_str}**\n\n"
        
        if player:
            response += f"**Player:** {player}\n"
        
        response += f"**Pattern Matches Found:** {total}\n"
        response += f"**Points Won:** {wins} / {total}\n"
        response += f"**Win %:** {win_pct}%\n\n"
        
        if matches:
            response += f"**Point Citations (All {len(matches)} Points):**\n\n"
            for i, m in enumerate(matches, 1):
                won_str = "â—† WIN" if m.get('won') else "â—‡ LOSS"
                point_num = m.get('point_number', '?')
                set_num = m.get('set', '?')
                server = m.get('server', '?')
                score = m.get('score', '?')
                
                response += f"{i}. **Point {point_num}** [Set {set_num} | {server} serving at {score}] {won_str}\n"
                response += f"   â—Ź Pattern: {pattern_str} (rally length: {m['rally_length']} shots)\n"
                response += f"   â—Ź Won by: {m.get('point_winner', '?')}\n"
                
                # Show matched shots
                if m.get('match_details'):
                    response += f"   â—Ź Matched shots:\n"
                    for j, detail in enumerate(m['match_details'], 1):
                        response += f"      {j}. {detail.get('player', '?')}: {detail.get('description', '?')}\n"
                
                # Show full point description - NO LIMITS
                point_desc = m.get('point', '')
                response += f"   ● Point: {point_desc}\n\n"
        
        # Add debug info if available
        debug_info = analysis.get('debug_info', [])
        if debug_info:
            response += f"**Debug Information:**\n\n"
            for debug_line in debug_info:
                response += f"- {debug_line}\n"
                response += "\n"
        
        return response
    
    def _format_consecutive_shots_analysis(self, analysis: Dict[str, Any]) -> str:
        """Format consecutive shots analysis results."""
        if 'error' in analysis:
            return f"Unable to perform consecutive shots analysis: {analysis['error']}"
        
        player = analysis.get('player', 'Player')
        shot_type = analysis.get('shot_type', 'shot')
        direction = analysis.get('direction')
        min_consec = analysis.get('min_consecutive', 3)
        require_win = analysis.get('require_win', False)
        
        total = analysis.get('total_sequences', 0)
        max_consec = analysis.get('max_consecutive', 0)
        avg_consec = analysis.get('avg_consecutive', 0)
        wins = analysis.get('wins', 0)
        win_pct = analysis.get('win_percentage', 0)
        matches = analysis.get('matching_points', [])
        
        # Build description
        shot_desc = shot_type.title() if shot_type else "Shot"
        if direction:
            shot_desc = f"{direction.replace('_', ' ').title()} {shot_desc}"
        
        win_clause = " Before Winning" if require_win else ""
        
        response = f"**Consecutive {shot_desc}s Analysis ({min_consec}+{win_clause})**\n\n"
        
        if player:
            response += f"**Player:** {player}\n"
        
        response += f"**Minimum Consecutive:** {min_consec}\n"
        response += f"**Total Qualifying Sequences:** {total}\n"
        response += f"**Longest Streak:** {max_consec} consecutive\n"
        response += f"**Average Streak Length:** {avg_consec}\n\n"
        
        response += f"**Win Statistics:**\n"
        response += f"- Points Won: {wins} / {total}\n"
        response += f"- **Win %: {win_pct}%**\n\n"
        
        if matches:
            response += f"**Point Citations (All {len(matches)} Points):**\n\n"
            for i, m in enumerate(matches, 1):
                won_str = "◆ WIN" if m.get('won') else "◆ LOSS"
                point_num = m.get('point_number', '?')
                set_num = m.get('set', '?')
                server = m.get('server', '?')
                score = m.get('score', '?')
                
                response += f"{i}. **Point {point_num}** [Set {set_num} | {server} serving at {score}] {won_str}\n"
                response += f"   ● {m['consecutive_count']} consecutive {shot_desc}s (rally length: {m['rally_length']} shots)\n"
                response += f"   ● Won by: {m.get('point_winner', '?')}\n"
                
                # Show full point description - NO LIMITS
                point_desc = m.get('point', '')
                response += f"   ● Point: {point_desc}\n\n"
        
        # Add debug info if available
        debug_info = analysis.get('debug_info', [])
        if debug_info:
            response += f"**Debug Information:**\n\n"
            for debug_line in debug_info:
                response += f"- {debug_line}\n"
            response += "\n"
        
        return response
    
    def _format_grouped_analysis(self, analysis: Dict[str, Any]) -> str:
        """
        Format grouped analysis results - PURELY VARIABLE-DRIVEN.
        
        Uses classification variables to determine output format:
        - group_by: determines grouping dimension (sets, rally length, court side, etc.)
        - metrics: determines what we're counting (errors, winners, points_won, etc.)
        - player_filter: single player focus vs both players
        - shot_type: adds shot context to labels
        """
        classification = analysis['classification']
        filters = classification['filters']
        group_by = analysis['group_by']
        groups = analysis['groups']
        metrics = classification.get('metrics', [])
        
        # Metrics where win % is MEANINGLESS (outcome is inherent)
        # Winners/Aces = always won the point
        # Errors/Double Faults = always lost the point (use class constant)
        show_win_pct = not any(m in self.SELF_EVIDENT_OUTCOME_METRICS for m in metrics)
        
        player1 = analysis.get('player1', 'Player 1')
        player2 = analysis.get('player2', 'Player 2')
        player_filter = filters.get('player')
        shot_type = filters.get('shot_type') or filters.get('shot_base')
        
        # === BUILD LABELS FROM VARIABLES ===
        metric_name = metrics[0].replace('_', ' ').title() if metrics else 'Points Won'
        shot_desc = f"{shot_type.title()} " if shot_type else ""
        group_label = group_by.replace('_', ' ').title() if group_by else 'Category'
        
        # Title combines: [Shot] [Metric] by [Group]
        title = f"{shot_desc}{metric_name} by {group_label}"
        
        response = f"**{title}**\n\n"
        
        # === SHOW ACTIVE FILTERS ===
        if player_filter:
            response += f"**Player:** {player_filter}\n"
        if shot_type:
            response += f"**Shot Type:** {shot_type.title()}\n"
        if metrics:
            response += f"**Metric:** {metric_name}\n"
        response += f"**Total Points Analyzed:** {analysis['total_points']}\n\n"
        
        # === BUILD TABLE FROM VARIABLES ===
        # Determine if single player focus or both players
        is_single_player = bool(player_filter)
        
        # Determine who is the focus player for win % (returner for serve_direction queries)
        focus_player = None
        if player_filter:
            focus_player = player_filter
            is_player1 = player1 and player_filter.lower() in player1.lower()
        
        # GENERIC: Get display type from GROUP_CONFIG
        group_config = self._get_group_config(group_by)
        display_type = group_config.get('display_type', 'default') if group_config else 'default'
        
        # Format table header based on display_type - GENERIC
        if display_type == 'role_based':
            # Role-based grouping (e.g., serve_direction shows returner perspective)
            role_label = group_label.replace('_', ' ').title()
            response += f"**{role_label} Breakdown:**\n\n"
            if show_win_pct:
                response += f"| {group_label.replace('_', ' ').title()} | Total | {focus_player or 'Returner'} Won | {focus_player or 'Returner'} Lost | Win % |\n"
                response += f"|-----------|-------|------|------|-------|\n"
            else:
                response += f"| {group_label.replace('_', ' ').title()} | {player1} | {player2} |\n"
                response += f"|-----------|-------|-------|\n"
        elif display_type == 'player':
            # Player grouping - each group IS a player
            response += f"**{shot_desc}{metric_name} by {group_label}:**\n\n"
            if show_win_pct:
                response += f"| {group_label} | Total | Won | Lost | Win % |\n"
                response += f"|-----|-------|-----|------|-------|\n"
            else:
                response += f"| {group_label} | Count |\n"
                response += f"|-----|-------|\n"
        elif is_single_player:
            response += f"**{shot_desc}{metric_name} by {group_label}:**\n\n"
            if show_win_pct:
                response += f"| {group_label} | Total | Won | Lost | Win % |\n"
                response += f"|-----|-------|-----|------|-------|\n"
            else:
                response += f"| {group_label} | Count |\n"
                response += f"|-----|-------|\n"
        else:
            response += f"**{shot_desc}{metric_name} by {group_label}:**\n\n"
            if show_win_pct:
                response += f"| {group_label} | Total | {player1} | {player2} | {player1} % |\n"
                response += f"|-----|-------|-----|-----|-------|\n"
            else:
                response += f"| {group_label} | {player1} | {player2} |\n"
                response += f"|-----|-------|-------|\n"
        
        # === ITERATE GROUPS ===
        group_keys = ['group_a', 'group_b'] if 'group_a' in groups else list(groups.keys())
        group_data_list = []  # Store for finding most frequent
        
        for group_key in group_keys:
            if group_key not in groups:
                continue
            group_data = groups[group_key]
            label = group_data.get('label', group_key)
            total = group_data.get('total', 0)
            
            # Dynamically access metric-specific counts (e.g., player1_winners, player1_aces, etc.)
            # Fallback to player1_wins for points won or when no specific metric tracking
            metric_key = metrics[0] if metrics else 'wins'
            p1_wins = group_data.get(f'player1_{metric_key}', group_data.get('player1_wins', 0))
            p2_wins = group_data.get(f'player2_{metric_key}', group_data.get('player2_wins', 0))
            
            # GENERIC: Handle player display type - each group IS a player
            if display_type == 'player':
                if group_key == 'player1':
                    won = p1_wins  # This group is player1, use their count
                    lost = p2_wins  # Will be 0
                elif group_key == 'player2':
                    won = p2_wins  # This group is player2, use their count
                    lost = p1_wins  # Will be 0
                else:
                    won = p1_wins
                    lost = p2_wins
                
                # CRITICAL: For win_percentage metric with player grouping, calculate against MATCH total
                # NOT branch total (branch only contains won points, giving 100%)
                # Use total_points from analysis results (grand total across all branches)
                if 'win_percentage' in metrics:
                    match_total = analysis.get('total_points', 0)
                    if match_total == 0:
                        # Fallback: sum all branch totals
                        match_total = sum(g.get('total', 0) for g in groups.values())
                    win_pct = round(100 * won / match_total, 1) if match_total > 0 else 0
                else:
                    # For other metrics, use branch total
                    win_pct = round(100 * won / total, 1) if total > 0 else 0
            # Calculate win % for focus player
            elif is_single_player and is_player1:
                won = p1_wins
                lost = total - p1_wins
                win_pct = round(100 * p1_wins / total, 1) if total > 0 else 0
            elif is_single_player:
                won = p2_wins
                lost = total - p2_wins
                win_pct = round(100 * p2_wins / total, 1) if total > 0 else 0
            else:
                won = p1_wins
                lost = p2_wins
                win_pct = round(100 * p1_wins / total, 1) if total > 0 else 0
            
            group_data_list.append({
                'key': group_key, 'label': label, 'total': total, 
                'won': won, 'lost': lost, 'win_pct': win_pct
            })
            
            # Format row based on whether we're showing win %
            if is_single_player and show_win_pct:
                response += f"| **{label}** | {total} | {won} | {lost} | **{win_pct}%** |\n"
            elif is_single_player and not show_win_pct:
                response += f"| **{label}** | {won} |\n"
            elif not is_single_player and show_win_pct:
                response += f"| **{label}** | {total} | {won} | {lost} | **{win_pct}%** |\n"
            elif group_by == 'player' and not show_win_pct:
                # For player grouping without win %, show just the count for THAT player
                response += f"| **{label}** | {won} |\n"
            else:  # Other groupings, both players, no win %
                response += f"| **{label}** | {won} | {lost} |\n"
        
        # === ANSWER SECTION ===
        if group_data_list:
            response += f"\n**Answer:**\n"
            
            # Find most frequent (highest total)
            most_frequent = max(group_data_list, key=lambda x: x['total'])
            
            response += f"ðŸ“Š **Most Frequent:** {most_frequent['label']} ({most_frequent['total']} total, {most_frequent['total']/analysis['total_points']*100:.0f}% of analyzed points)\n"
            
            # Only show win % insights if relevant
            if show_win_pct:
                # Find highest win %
                highest_win_pct = max(group_data_list, key=lambda x: x['win_pct'])
                
                # Find lowest win %
                lowest_win_pct = min(group_data_list, key=lambda x: x['win_pct'] if x['total'] > 0 else 100)
                
                response += f"ðŸŽ¯ **Success Rate vs {most_frequent['label']}:** {most_frequent['win_pct']}% ({most_frequent['won']} won, {most_frequent['lost']} lost)\n\n"
                
                if highest_win_pct['key'] != most_frequent['key']:
                    response += f"âœ… **Best Success:** vs {highest_win_pct['label']} ({highest_win_pct['win_pct']}%)\n"
                if lowest_win_pct['key'] != most_frequent['key'] and lowest_win_pct['total'] > 0:
                    response += f"âš ï¸ **Worst Success:** vs {lowest_win_pct['label']} ({lowest_win_pct['win_pct']}%)\n"
            else:
                # For self-evident metrics, just show the counts
                response += f"ðŸŽ¯ **{metric_name} at {most_frequent['label']}:** {most_frequent['won']}\n\n"
            
            # For 2-group comparisons (like set_groups), also show ratio
            if len(group_data_list) == 2:
                val_a = group_data_list[0]['won']
                val_b = group_data_list[1]['won']
                if val_a > 0:
                    ratio = val_b / val_a
                    if ratio >= 2:
                        response += f"\nâœ… **More than doubled!** ({val_a} -> {val_b}, **{ratio:.1f}x**)\n"
                    elif ratio > 1:
                        response += f"\nðŸ“ˆ +{((ratio-1)*100):.0f}% change ({val_a} -> {val_b})\n"
                    elif ratio < 1:
                        response += f"\nðŸ“‰ -{((1-ratio)*100):.0f}% change ({val_a} -> {val_b})\n"
        
        # === EXAMPLES (optional) ===
        for group_key in group_keys:
            if group_key not in groups:
                continue
            examples = groups[group_key].get('examples', [])
            if examples:
                label = groups[group_key].get('label', group_key)
                response += f"\n**{label} Examples:**\n"
                for ex in examples[:2]:
                    response += f"- Point {ex.get('point', '?')}: {ex.get('excerpt', '')}\n"
        
        # === DEBUG: SHOW MATCHING POINTS BY GROUP (only if filtering happened) ===
        total_points = len(self.point_by_point) if hasattr(self, 'point_by_point') else 283
        total_in_groups = sum(len(groups.get(gk, {}).get('matching_points', [])) for gk in group_keys if gk in groups)
        
        # Only show debug if filtering actually reduced the count
        if total_in_groups > 0 and total_in_groups < total_points:
            response += f"\n\n**DEBUG: Matching Points by {group_label} ({total_in_groups} of {total_points} filtered):**\n"
            for group_key in group_keys:
                if group_key not in groups:
                    continue
                group_data = groups[group_key]
                label = group_data.get('label', group_key)
                matching_points = group_data.get('matching_points', [])
                
                if matching_points:
                    total_msg = f"{len(matching_points)} points"
                    response += f"\n**{label}: {total_msg}**\n"
                for i, pt in enumerate(matching_points, 1):
                    response += f"{i}. Point {pt.get('point_number', '?')} [{pt.get('server', '?')} serving] "
                    winner = pt.get('point_winner', pt.get('winner', '?'))
                    outcome = pt.get('outcome', '?')
                    
                    # CRITICAL: Recalculate rally_length from source (don't trust stale enriched metadata)
                    point_text = pt.get('description', '')
                    server = pt.get('server', '')
                    returner = pt.get('returner', '')
                    rally_shots = self._parse_rally_sequence(point_text, server, returner) if point_text else []
                    rally_len = self._calculate_rally_length(rally_shots, point_text)
                    
                    response += f"Score: {pt.get('score', '?')} | Winner: {winner} | "
                    response += f"Outcome: {outcome} | Rally: {rally_len} shots\n"
                    response += f"   {pt.get('description', '')}\n"
        
        return response
    
    def _detect_question_intent(self, question: str, classification: Dict) -> Dict:
        """
        Detect the intent behind the question to guide response formatting.
        Returns hints about what format the user likely expects.
        """
        question_lower = question.lower()
        
        intent = {
            'wants_count': False,      # "how many", "count", "number of"
            'wants_percentage': False,  # "percentage", "win rate", "% of"
            'wants_comparison': False,  # "compared to", "vs", "better than"
            'wants_trend': False,       # "over time", "throughout", "by set"
            'wants_breakdown': False,   # "breakdown", "by", "grouped by"
            'is_simple_lookup': False,  # "who won", "what was the score"
            'primary_format': 'auto'    # Let LLM decide
        }
        
        # Count-based queries
        if any(kw in question_lower for kw in ['how many', 'count', 'number of', 'total number', 'total aces', 'total winners']):
            intent['wants_count'] = True
            intent['primary_format'] = 'count'
        
        # Percentage-based queries
        if any(kw in question_lower for kw in ['percentage', 'win rate', 'win %', '% of', 'rate of', 'efficiency']):
            intent['wants_percentage'] = True
            intent['primary_format'] = 'percentage'
        
        # Comparison queries
        if any(kw in question_lower for kw in ['compared to', ' vs ', 'versus', 'better than', 'worse than', 'difference between']):
            intent['wants_comparison'] = True
            if intent['primary_format'] == 'auto':
                intent['primary_format'] = 'comparison'
        
        # Trend/time-based queries
        if any(kw in question_lower for kw in ['over time', 'throughout', 'by set', 'across sets', 'trend', 'changed']):
            intent['wants_trend'] = True
        
        # Breakdown queries
        if any(kw in question_lower for kw in ['breakdown', 'grouped by', 'by direction', 'by court', 'split by']):
            intent['wants_breakdown'] = True
        
        # Simple lookups
        if any(kw in question_lower for kw in ['who won', 'what was the score', 'final score', 'who served']):
            intent['is_simple_lookup'] = True
            intent['primary_format'] = 'simple'
        
        # Metric-specific hints
        metrics = classification.get('metrics', [])
        if metrics:
            metric = metrics[0]
            if metric in ['aces', 'double_faults', 'winners', 'errors', 'unforced_errors']:
                # These are naturally count-based unless asking for rate
                if not intent['wants_percentage']:
                    intent['wants_count'] = True
                    intent['primary_format'] = 'count'
        
        return intent
    
    def _synthesize_with_narrative(self, question: str, data_response: str, classification: Dict) -> str:
        """
        Combine calculated data with narrative context for insightful answers.
        
        CRITICAL HIERARCHY:
        1. Calculated data (data_response) = SOURCE OF TRUTH for ALL numbers/statistics
        2. Narrative context = Additional insight/context ONLY (never use numbers from here)
        3. LLM synthesizes: Present calculated numbers clearly + add tactical insight
        
        IMPROVED: Gives LLM freedom to format data appropriately based on question intent.
        
        This method:
        1. Detects what format the user likely expects (count vs percentage vs comparison)
        2. Passes raw data + formatting hints to LLM
        3. Lets LLM decide the best presentation format
        4. Retrieves narrative context for insight
        """
        filters = classification.get('filters', {})
        metrics = classification.get('metrics', [])
        
        # === GENERIC N-METRIC: Check if metrics are related for synthesis ===
        synthesize_related = classification.get('synthesize_related_metrics', False)
        metric_context_type = classification.get('metric_context_type')
        
        if synthesize_related:
            print(f"[SYNTHESIS] Related metrics detected (context: {metric_context_type}) - will synthesize together")
        
        # DETECT QUESTION INTENT
        intent = self._detect_question_intent(question, classification)
        print(f"[SYNTHESIS] Question intent: {intent['primary_format']}")
        
        # Build context-aware search query for narrative retrieval
        search_terms = []
        if filters.get('player'):
            search_terms.append(filters['player'])
        if filters.get('shot_type'):
            search_terms.append(filters['shot_type'])
        
        # For related metrics, use context type; otherwise use first metric
        if synthesize_related and metric_context_type:
            search_terms.append(metric_context_type)
        elif metrics:
            # For multi-metric, include all metrics
            for metric in metrics:
                metric_filters = classification.get('metric_filters', {}).get(metric, {})
                actual_metric = metric_filters.get('metric', metric)
                search_terms.append(actual_metric.replace('_', ' '))
        
        # Get set info if comparing sets
        set_a = filters.get('set_group_a', [])
        set_b = filters.get('set_group_b', [])
        if set_a:
            search_terms.append(f"Set {set_a[0]}")
        if set_b:
            search_terms.append(f"Set {set_b[0]}")
        
        narrative_query = " ".join(search_terms) if search_terms else question
        
        # Retrieve relevant narrative chunks
        print(f"[SYNTHESIS] Retrieving narrative for: {narrative_query}")
        relevant_chunks = self.retrieve_relevant_chunks(narrative_query, top_k=5)
        
        narrative_context = ""
        if relevant_chunks:
            narrative_context = "\n\n".join([chunk.get('text', chunk) if isinstance(chunk, dict) else str(chunk) 
                                             for chunk in relevant_chunks[:5]])
        
        # BUILD FORMATTING GUIDANCE based on intent
        format_guidance = self._build_format_guidance(intent, metrics)
        
        # EXTRACT DEBUG SECTION - Keep in response but don't print to terminal
        # The debug section will show in the UI response, but we don't spam terminal with point lists
        debug_section = ""
        if "**DEBUG:" in data_response:
            debug_idx = data_response.find("**DEBUG:")
            debug_section = data_response[debug_idx:]
            data_for_llm = data_response[:debug_idx].strip()
            
            # Extract point count for terminal log (but don't print the actual points)
            import re
            point_count_match = re.search(r'Showing (\d+) of (\d+)', debug_section)
            if point_count_match:
                shown_points = int(point_count_match.group(1))
                total_points = int(point_count_match.group(2))
                # Removed console print - points only shown to user on screen
        else:
            data_for_llm = data_response
        
        # If question asks specifically about MATCH score/result, add it to the data
        # Be careful: "who won" alone is too broad (e.g., "who won more points")
        question_lower = question.lower()
        score_terms = ['final score', 'match score', 'who won the match', 'match result', 'match outcome']
        
        # More specific check: "score" alone only triggers if asking about "the score" or "final"
        asks_about_score = (
            any(term in question_lower for term in score_terms) or
            ('what was the score' in question_lower) or
            ('what is the score' in question_lower)
        )
        
        if asks_about_score:
            if hasattr(self, 'match_score') and self.match_score:
                data_for_llm += f"\n\n**Match Score:** {self.match_score}"
                print(f"[SYNTHESIS] Added match score to data: {self.match_score}")
        
        # Note: Match duration is typically in narrative context, not calculated data
        # The LLM should extract it from narrative if available
        
        # Use LLM to synthesize data + narrative into insight with FORMATTING FREEDOM
        synthesis_prompt = f"""You are a tennis analyst answering analytical questions using calculated match data.

âš ï¸ **ABSOLUTE RULE:** This is an ANALYTICAL QUESTION requiring NUMBERS. You MUST use ONLY the numbers from the CALCULATED DATA section below. DO NOT use ANY numbers, statistics, or counts from the narrative context. The narrative is for CONTEXT and INSIGHT only.

**USER'S QUESTION:** {question}

**QUESTION INTENT:** {intent['primary_format']}
{format_guidance}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸ“Š **CALCULATED DATA (SOURCE OF TRUTH - USE THESE NUMBERS ONLY):**
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{data_for_llm}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ“– **NARRATIVE CONTEXT (for insight/context ONLY - DO NOT extract numbers from here):**
{narrative_context if narrative_context else "No additional context available."}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**YOUR TASK:**

1. **ANSWER WITH CALCULATED DATA NUMBERS ONLY:**
   - Extract ALL numbers (counts, percentages, etc.) from the CALCULATED DATA section above
   - NEVER use numbers from the narrative context (they may be outdated or incorrect)
   - Format the numbers in the way that best answers the user's question{f"   - **RELATED METRICS:** If the question asks about multiple related metrics (e.g., 'first serve % and first serve win %'), synthesize them together in a cohesive answer that shows how they relate to each other." if synthesize_related else ""}

2. **PRESENT THE ANSWER CLEARLY:**
   - If asking "how many" -> Lead with the COUNT (e.g., "Sinner hit **33 winners**, Medvedev hit **29 winners**")
   - If asking "percentage" -> Lead with the PERCENTAGE
   - If asking "comparison" -> Show side-by-side comparison with numbers from calculated data
   - If asking about "final score" or "match score" -> Include the Match Score from the calculated data section
   - If asking about "how long" or "duration" -> Look for this information in the narrative context (it's not in calculated data){f"   - **MULTI-METRIC:** If multiple metrics are provided, present them together showing their relationship (e.g., 'First serve % was X%, and on those first serves, win % was Y%')" if synthesize_related else ""}
   - Use tables, bullets, or plain text - whatever is clearest

3. **ADD BRIEF TACTICAL INSIGHT (2-3 sentences):**
   - Use the narrative context to understand WHY or add strategic perspective
   - But still reference only calculated data numbers in your insight
   - Example: "Sinner's 33 winners suggest an aggressive baseline approach..."{f"   - **RELATED METRICS INSIGHT:** When multiple related metrics are provided, explain how they relate (e.g., 'A high first serve % combined with a strong first serve win % indicates effective serving')" if synthesize_related else ""}
   - **EXCEPTION:** Match duration/time is NOT in calculated data - you may extract this from narrative context if the question asks for it

**FORBIDDEN:**
- âŒ Using any numbers from the narrative context
- âŒ Contradicting the calculated data
- âŒ Showing percentages when they asked for counts
- âŒ Answering a different question than what was asked
- âŒ **NEVER mention "win rate" or "win percentage" for winners, aces, errors, or double faults**
  (Winners/aces are always won points, errors/DFs are always lost points - stating this is redundant)

Format in markdown."""

        try:
            # Get model config from classification (if available)
            model_config = classification.get('_model_config', {})
            model_name = model_config.get('model_name', self.model if hasattr(self, 'model') else 'gemini-2.5-flash')
            temperature = model_config.get('temperature', 0.7)
            
            if self.llm_provider == "gemini":
                import google.generativeai as genai
                
                # Configure generation (3.0 Flash has built-in reasoning capabilities)
                # Use simple dict for generation config
                gen_config = {"temperature": temperature}
                
                try:
                    model = genai.GenerativeModel(model_name)
                    response = model.generate_content(synthesis_prompt, generation_config=gen_config)
                    llm_response = response.text.strip()
                except Exception as e:
                    # If 3 Flash not available, fallback to 2.5 Flash
                    if ("3-flash" in model_name.lower() or "3.0-flash" in model_name.lower()) and ("not found" in str(e).lower() or "404" in str(e)):
                        print(f"[SYNTHESIS] Model {model_name} not available, falling back to 2.5 Flash")
                        fallback_model = genai.GenerativeModel(self.model_25_flash)
                        response = fallback_model.generate_content(synthesis_prompt, generation_config=gen_config)
                        llm_response = response.text.strip()
                    else:
                        raise  # Re-raise if it's a different error
            else:
                # Fallback to default for non-Gemini
                model = genai.GenerativeModel('gemini-2.5-flash')
                response = model.generate_content(synthesis_prompt)
                llm_response = response.text.strip()
            
            # PREPEND VAGUE TERM INTERPRETATION (Step E: Disclose interpretation)
            if classification.get('_vague_term'):
                interpretation = classification.get('_vague_interpretation', '')
                vague_metrics = classification.get('_vague_metrics', [])
                context = classification.get('_vague_context', 'default')
                disclosure = f"*Interpreting '{classification['_vague_term']}' ({context} context): {interpretation}*\n*Metrics analyzed: {', '.join(vague_metrics)}*\n\n"
                llm_response = disclosure + llm_response
            
            # APPEND DEBUG SECTION so user can verify the data
            if debug_section:
                llm_response += "\n\n---\n\n" + debug_section
            
            return llm_response
        except Exception as e:
            print(f"[SYNTHESIS] LLM error: {e}, returning data only")
            return data_response
    
    def _build_format_guidance(self, intent: Dict, metrics: list) -> str:
        """Build specific formatting guidance based on detected intent."""
        guidance_parts = []
        
        if intent['wants_count']:
            guidance_parts.append("-> User wants COUNTS (raw numbers). Show counts prominently, not percentages.")
        
        if intent['wants_percentage']:
            guidance_parts.append("-> User wants PERCENTAGES/RATES. Calculate and show percentages clearly.")
        
        if intent['wants_comparison']:
            guidance_parts.append("-> User wants COMPARISON. Show side-by-side and state who was better/worse.")
        
        if intent['wants_trend']:
            guidance_parts.append("-> User wants TREND over time. Show progression across sets/games.")
        
        if intent['wants_breakdown']:
            guidance_parts.append("-> User wants BREAKDOWN by category. Show grouped/categorized data.")
        
        if intent['is_simple_lookup']:
            guidance_parts.append("-> Simple lookup question. Give a direct, brief answer.")
        
        if metrics:
            metric_name = metrics[0].replace('_', ' ').title()
            guidance_parts.append(f"-> Primary metric: {metric_name}")
        
        if not guidance_parts:
            guidance_parts.append("-> Use your judgment on the best format to answer this question.")
        
        return "\n".join(guidance_parts)
    
    def _sort_chunks_chronologically(self, chunks: List[Dict]) -> List[Dict]:
        """
        Sort chunks by their first point number to preserve chronological flow.
        
        FAISS retrieves by semantic similarity, which ignores temporal order.
        For narrative/momentum queries, chronological order is critical to understanding flow.
        """
        import re
        
        def extract_min_point_number(chunk_text: str) -> int:
            """Extract the minimum point number from chunk text"""
            # Find all "Point X:" or "Point X [" patterns
            matches = re.findall(r'Point (\d+)[\[:]', chunk_text)
            if matches:
                return min(map(int, matches))
            # If no point numbers found, push to end
            return 999999
        
        # Sort chunks by minimum point number
        sorted_chunks = sorted(chunks, key=lambda c: extract_min_point_number(c.get('text', '')))
        
        return sorted_chunks
    
    def _handle_narrative_query(self, question: str, classification: Dict, top_k: int = None) -> str:
        """
        Handle narrative queries using NL retrieval + LLM synthesis.
        
        For questions like:
        - "What happened in Set 3?"
        - "Provide a strategic summary"
        - "Tell the parallel journey of both players"
        
        NEW: Supports shot-level pre-filtering for questions like:
        - "Show me all backhand slice down-the-line winners"
        - "Find points with forehand volleys"
        """
        # === NEW: Check if question needs shot-level pre-filtering ===
        filters = classification.get('filters', {})
        question_lower = question.lower()
        
        # CONFIG-DRIVEN: Check for ALL possible shot attributes from GROUP_CONFIG and match_filter_inventory
        # Attributes from GROUP_CONFIG: shot_type, direction, spin, outcome, depth, shot_modifier
        # Attributes from match_filter_inventory: intent, contact_type, location
        has_shot_attributes = any([
            filters.get('shot_type'),
            classification.get('shot_type'),
            filters.get('direction'),
            classification.get('direction'),
            filters.get('spin'),
            classification.get('spin'),
            filters.get('outcome'),
            classification.get('outcome'),
            filters.get('depth'),
            classification.get('depth'),
            filters.get('shot_modifier'),
            classification.get('shot_modifier'),
            filters.get('intent'),
            classification.get('intent'),
            filters.get('contact_type'),
            classification.get('contact_type'),
            filters.get('location'),
            classification.get('location')
        ])
        
        # Also check attributes that were moved to top-level by schema repair
        has_toplevel_shot_attrs = any([
            classification.get('filters', {}).get('shot_type'),
            classification.get('filters', {}).get('direction'),
            classification.get('filters', {}).get('spin'),
            classification.get('filters', {}).get('outcome'),
            classification.get('filters', {}).get('depth'),
            classification.get('filters', {}).get('shot_modifier'),
            classification.get('filters', {}).get('intent'),
            classification.get('filters', {}).get('contact_type'),
            classification.get('filters', {}).get('location')
        ])
        
        needs_shot_filter = has_shot_attributes or has_toplevel_shot_attrs
        
        if needs_shot_filter and self.point_by_point:
            print("[NARRATIVE] Using shot-level pre-filtering for specific shot query...")
            matching_points = self._prefilter_points_by_shot_attributes(classification)
            
            if matching_points:
                # Use pre-filtered context instead of chunk retrieval
                prefiltered_context = self._format_prefiltered_narrative_context(matching_points, classification)
                print(f"[NARRATIVE] Pre-filtered to {len(matching_points)} points with matching shots")
                
                # Synthesize with focused context
                answer = self._synthesize_narrative_with_context(question, prefiltered_context, classification, matching_points)
                
                # Append debug info (matching points) AFTER narrative synthesis
                if hasattr(self, '_last_prefilter_debug') and self._last_prefilter_debug:
                    answer += "\n\n" + "\n".join(self._last_prefilter_debug)
                    self._last_prefilter_debug = None  # Clear after use
                
                return answer
            else:
                print("[NARRATIVE] No points matched shot filters, falling back to chunk retrieval")
        
        print("[NARRATIVE] Retrieving relevant context from NL file...")
        
        # Determine appropriate chunk count for narrative
        if top_k is None:
            top_k = self._determine_optimal_chunk_count(question)
            top_k = max(top_k, 8)  # Narratives need more context
        
        # Retrieve relevant chunks
        relevant_chunks = self.retrieve_relevant_chunks(question, top_k)
        
        if not relevant_chunks:
            return "I couldn't find relevant information to answer your question."
        
        # CRITICAL: Sort chunks chronologically for momentum/flow questions
        # FAISS retrieves by similarity, but narratives need temporal order
        question_lower = question.lower()
        needs_chronological_order = any(kw in question_lower for kw in [
            'momentum', 'flow', 'story', 'how did', 'what happened',
            'turning point', 'shift', 'changed', 'evolved', 'unfolded',
            'from start', 'from beginning', 'throughout', 'progression',
            'journey', 'narrative', 'sequence', 'chronological',
            'get away', 'come back', 'comeback', 'rally', 'surge',
            'decline', 'drop off', 'improve', 'deteriorate'
        ])
        
        if needs_chronological_order:
            print("[NARRATIVE] Sorting chunks chronologically for temporal flow...")
            relevant_chunks = self._sort_chunks_chronologically(relevant_chunks)
        
        print(f"[NARRATIVE] Retrieved {len(relevant_chunks)} chunks, generating synthesis...")
        
        # Build context from retrieved chunks
        context_pieces = [chunk['text'] for chunk in relevant_chunks]
        context_text = "\n\n---\n\n".join(context_pieces)
        
        # Build match overview for context
        match_overview = ""
        total_points = 283  # default
        if hasattr(self, 'match_stats_summary') and self.match_stats_summary:
            stats = self.match_stats_summary
            total_points = stats.get('total_points', 283)
            match_overview = f"""
MATCH DATA AVAILABLE:
- Total Points: {total_points} (complete point-by-point records)
- Players: {stats.get('players', 'N/A')}
- Match Score: {stats.get('match_score', 'N/A')}
- Every point includes: shot types, directions, depths, outcomes, rally lengths, score context
"""
        
        enhanced_prompt = f"""You are analyzing a tennis match with COMPLETE point-by-point data.
{match_overview}

âš ï¸ CRITICAL - DATA AVAILABILITY:
The match file contains ALL {total_points} points with:
- Full shot-by-shot descriptions for every point
- Every serve placement, rally sequence, and outcome
- Score context and situation (break points, game points, etc.)
- Player actions and shot selections

The context below is RETRIEVED from this complete dataset. Work with what you have.

QUESTION: {question}

RELEVANT ANALYSIS FROM MATCH DATA:
{context_text}

Instructions:
- Answer using the provided match analysis
- For strategic/tactical questions, draw insights from the patterns and data shown
- If the retrieved context doesn't fully answer the question, provide insights based on what IS shown
- **ABSOLUTELY FORBIDDEN**: Never say "point-by-point data is not available" or "data doesn't include point-by-point narratives" - this is factually incorrect. ALL point data exists in the system.
- Provide specific, detailed answers based on the context

Answer:"""
        
        # Use LLM to synthesize narrative answer with appropriate model
        try:
            # Get model config from classification (if available)
            model_config = classification.get('_model_config', {})
            model_name = model_config.get('model_name', self.model)
            temperature = model_config.get('temperature', 0.7)
            
            if self.llm_provider == "gemini":
                import google.generativeai as genai
                
                # Configure generation (3.0 Flash has built-in reasoning capabilities)
                # Use simple dict for generation config
                gen_config = {"temperature": temperature}
                
                try:
                    model = genai.GenerativeModel(model_name)
                    response = model.generate_content(enhanced_prompt, generation_config=gen_config)
                    answer = response.text
                except Exception as e:
                    # If 3 Flash not available, fallback to 2.5 Flash
                    if ("3-flash" in model_name.lower() or "3.0-flash" in model_name.lower()) and ("not found" in str(e).lower() or "404" in str(e)):
                        print(f"[NARRATIVE] Model {model_name} not available, falling back to 2.5 Flash")
                        fallback_model = genai.GenerativeModel(self.model_25_flash)
                        response = fallback_model.generate_content(enhanced_prompt, generation_config=gen_config)
                        answer = response.text
                    else:
                        raise  # Re-raise if it's a different error
            else:
                # For non-Gemini, use standard method
                answer = self.answer_query_with_llm(question, relevant_chunks)
                
        except Exception as e:
            print(f"[NARRATIVE] Error in LLM synthesis: {e}")
            answer = self.answer_query_with_llm(question, relevant_chunks)
        
        # CRITICAL: If answer cites specific point numbers, show those points in debug
        # This ensures transparency and verifiability when narrative answers reference specific plays
        self._extract_and_show_cited_points(answer)
        
        return answer
    
    def _synthesize_narrative_with_context(self, question: str, context: str, classification: Dict, matching_points: List[Dict] = None) -> str:
        """
        Synthesize narrative answer using pre-filtered shot-level context.
        
        This is a lighter version of _handle_narrative_query for when we already
        have focused context from shot-level pre-filtering.
        """
        filters = classification.get('filters', {})
        player = filters.get('player', 'the player')
        
        # Count points from context if matching_points not provided
        num_points = len(matching_points) if matching_points else len([line for line in context.split('\n') if line.strip().startswith('**Point')])
        
        prompt = f"""Based on the following point-by-point data, answer this question:

**Question:** {question}

**Relevant Points:**
{context}

Instructions:
- **LIST ALL {num_points} MATCHING POINTS** - Do NOT summarize or condense
- **ALWAYS cite point numbers** (e.g., "Point 5", "Point 12") for EVERY point you mention
- Show the exact count: "There are {num_points} matching points"
- List each point with its point number and score
- Provide tactical context if relevant
- **CRITICAL: The count must match the number of points provided above ({num_points} points)**

Answer:"""
        
        try:
            if self.llm_provider == "gemini":
                import google.generativeai as genai
                model = genai.GenerativeModel(self.model)
                response = model.generate_content(prompt)
                return response.text
            elif self.llm_provider == "claude":
                import anthropic
                client = anthropic.Anthropic(api_key=self.api_key)
                response = client.messages.create(
                    model=self.model,
                    max_tokens=2000,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.content[0].text
            elif self.llm_provider == "openai":
                from openai import OpenAI
                client = OpenAI(api_key=self.api_key)
                response = client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.7
                )
                return response.choices[0].message.content
        except Exception as e:
            print(f"[SHOT-PREFILTER] Error in synthesis: {e}")
            return f"Found {len(context.split('**'))-1} matching points. See context above for details."
    
    # =========================================================================
    # QUERY PLAN ARCHITECTURE
    # =========================================================================
    # Instead of monolithic routing, LLM generates a structured query plan:
    #   - Multiple operations (tree, narrative, or hybrid)
    #   - Each operation is independent with its own filters/metrics
    #   - Synthesis instructions combine results
    # =========================================================================
    
    def _should_use_query_plan(self, question: str, classification: Dict, llm_parse: Dict) -> bool:
        """
        Determine if the query should use Query Plan architecture.
        
        PHILOSOPHY: Use the CLASSIFICATION to determine complexity.
        - Simple queries → let existing narrative routing infrastructure handle it
        - Complex queries (comparisons, multi-operation) → Query Plan
        
        The existing narrative routing handles chunk selection, prioritization, etc.
        Query Plan is for when we need MULTIPLE operations or tree filtering.
        """
        question_lower = question.lower()
        
        # Extract classification fields (the classification ALREADY knows the complexity)
        query_type = classification.get('query_type', 'narrative')
        analysis_type = classification.get('analysis_type', '')
        metric_clarity = classification.get('metric_clarity', 'vague')
        
        # Extract metrics
        metrics = classification.get('metrics', [])
        
        # Comparison structures that REQUIRE Query Plan (parallel operations)
        set_comparison = classification.get('set_comparison') or {}
        situation_comparison = classification.get('situation_comparison')
        
        # Grouping complexity
        group_by = classification.get('group_by', '')
        secondary_group_by = classification.get('secondary_group_by', '')
        n_dimensional = classification.get('n_dimensional', False)
        
        # Filters that need tree processing
        filters = classification.get('filters', {})
        situation = filters.get('situation') or classification.get('situation')
        set_filter = filters.get('set') or classification.get('set_filter')
        
        # Chain/momentum queries
        chain_logic = classification.get('chain_logic')
        
        # ═══════════════════════════════════════════════════════════════════════
        # SAFETY NET #1: Temporal patterns that ALWAYS need Query Plan
        # (Even if classification misses the filter, we catch it here)
        # ═══════════════════════════════════════════════════════════════════════
        temporal_indicators = [
            'after set', 'before set', 'later in the match', 'early in the match',
            'as the match went on', 'as the match progressed', 'by the end',
            'late in the match', 'early match', 'late match',
            'in sets 3', 'in sets 4', 'in sets 1', 'sets 3-5', 'sets 4-5',
            'first two sets', 'last two sets', 'final two sets',
            'from set 1 to set 5', 'across sets', 'over the course',
            'did he change', 'did she change', 'did they change',
            'did he improve', 'did she improve', 'improvement',
            'adjustment', 'tactical shift', 'strategy change'
        ]
        has_temporal_pattern = any(ind in question_lower for ind in temporal_indicators)
        
        # ═══════════════════════════════════════════════════════════════════════
        # SAFETY NET #2: Shot-level queries ALWAYS need Query Plan
        # CONFIG-DRIVEN: Check if grouping by any SHOT_LEVEL_FIELD (not hardcoded keywords!)
        # ═══════════════════════════════════════════════════════════════════════
        is_shot_level_grouping = group_by in self.SHOT_LEVEL_FIELDS
        
        # Also check if ANY shot-level field exists in classification (not as a filter, but as context)
        has_shot_level_context = any([
            classification.get(field) for field in self.SHOT_LEVEL_FIELDS
        ])
        
        # ═══════════════════════════════════════════════════════════════════════
        # REQUIRE Query Plan - these NEED multiple operations or tree filtering
        # ═══════════════════════════════════════════════════════════════════════
        
        # 1. Set comparisons (early vs late, set A vs set B)
        has_set_comparison = bool(set_comparison.get('set_a') or set_comparison.get('set_b'))
        
        # 2. Situation comparisons
        has_situation_comparison = bool(situation_comparison)
        
        # 3. Multi-dimensional analysis
        is_multi_dimensional = n_dimensional or (group_by and secondary_group_by)
        
        # 4. Complex analysis types that need structure
        # NOTE: 'chain' is EXCLUDED - it has its own implementation in _analyze_chain_logic
        # Query Plan doesn't have chain operation support, so let legacy routing handle it
        complex_analysis_types = ['2d_cross_tab', 'momentum']
        is_complex_analysis = analysis_type in complex_analysis_types
        
        # 5. Comparison with specific filter (needs tree)
        # e.g., "Compare break point performance in Set 1 vs Set 5"
        is_filtered_comparison = (
            analysis_type == 'comparison' and
            (situation or set_filter) and
            has_set_comparison
        )
        
        # ═══════════════════════════════════════════════════════════════════════
        # SKIP Query Plan - let narrative infrastructure handle these
        # ═══════════════════════════════════════════════════════════════════════
        
        # Pure narrative questions (strategic, tactical, descriptive)
        # BUT NOT if there's a temporal pattern (needs filtering)
        is_pure_narrative = (
            query_type == 'narrative' and 
            not situation and 
            not set_filter and
            not has_temporal_pattern  # Safety net!
        )
        
        # Simple analytical with clear metric and no comparisons
        is_simple_analytical = (
            query_type == 'analytical' and
            metric_clarity == 'clear' and
            not has_set_comparison and
            not has_situation_comparison and
            not is_multi_dimensional and
            not has_temporal_pattern and  # Safety net!
            analysis_type in ('count', 'percentage', '', None)
        )
        
        # ═══════════════════════════════════════════════════════════════════════
        # DECISION
        # ═══════════════════════════════════════════════════════════════════════
        
        # Check if this is a one-shot question (serve/return/winner/error) - these are tree-capable
        is_one_shot_question = any(
            self.METRIC_CONFIG.get(m, {}).get('player_role') in self.ONE_SHOT_TYPES
            for m in metrics
        )
        
        # Chain queries have their own implementation - DON'T use Query Plan
        is_chain_query = analysis_type == 'chain' or classification.get('filters', {}).get('chain_logic')
        
        # Consecutive shot queries have their own implementation - DON'T use Query Plan
        has_consecutive_keywords = (
            'consecutive' in question_lower or
            'in a row' in question_lower or
            'in-a-row' in question_lower or
            re.search(r'\d+\+?\s*(straight|consecutive)', question_lower) or
            re.search(r'(hit|hitting|had)\s+\d+\+?\s*(fore|back|cross|down)', question_lower)
        )
        has_consecutive_filters = (
            classification.get('consecutive_shots_min') or
            filters.get('consecutive_shots_min') or
            filters.get('sequence_shot_type')
        )
        is_consecutive_query = has_consecutive_keywords or has_consecutive_filters
        
        # Multi-step pattern queries have their own implementation - DON'T use Query Plan
        # Normalize arrows (Unicode → to ASCII ->)
        question_normalized = question.replace('→', '->').replace('→', '->')
        question_lower_normalized = question_normalized.lower()
        
        # Check if LLM detected nested pattern in chain_logic
        chain_logic = classification.get('chain_logic') or filters.get('chain_logic')
        has_nested_pattern = False
        if chain_logic and isinstance(chain_logic, dict):
            shot_b = chain_logic.get('shot_b')
            if shot_b and isinstance(shot_b, dict) and 'next_shot' in shot_b:
                has_nested_pattern = True
        
        has_multistep_keywords = (
            '->' in question_lower_normalized or
            ' then ' in question_lower_normalized or
            'sequence' in question_lower_normalized or
            re.search(r'(forehand|backhand|volley|slice|approach|crosscourt|down.the.line)\s*(,|then|->|followed by)\s*(forehand|backhand|volley|slice|approach|crosscourt|down.the.line|winner|error)', question_lower_normalized)
        )
        is_multistep_query = has_nested_pattern or (has_multistep_keywords and '->' in question_normalized)
        
        # Shot pre-filtering queries have shot-level attributes but NO grouping
        # E.g., "When Nadal hit a forehand down-the-line, what % did he win?"
        # These need _prefilter_points_by_shot_attributes to filter by shot attributes
        has_shot_attributes = any([
            filters.get('shot_type'),
            classification.get('shot_type'),
            filters.get('direction'),
            classification.get('direction'),
            filters.get('spin'),
            classification.get('spin'),
            filters.get('outcome')
        ])
        
        # Check top-level shot attributes (moved by schema repair)
        has_toplevel_shot_attrs = any([
            classification.get('filters', {}).get('shot_type'),
            classification.get('filters', {}).get('direction'),
            classification.get('filters', {}).get('spin'),
            classification.get('filters', {}).get('shot_modifier')
        ])
        
        # Shot prefilter query = has shot attributes but NOT chain/consecutive/multi-step
        is_shot_prefilter_query = (has_shot_attributes or has_toplevel_shot_attrs) and not (is_chain_query or is_consecutive_query or is_multistep_query)
        
        # CRITICAL: Exclude ALL shot parser queries - they have dedicated handlers
        is_shot_parser_query = (
            is_chain_query or 
            is_consecutive_query or 
            is_multistep_query or 
            is_shot_prefilter_query
        )
        
        needs_query_plan = (
            has_set_comparison or
            has_situation_comparison or
            is_multi_dimensional or
            is_complex_analysis or
            is_filtered_comparison or
            has_temporal_pattern or         # Safety net #1: temporal
            is_shot_level_grouping or       # Safety net #2: shot-level grouping (CONFIG-DRIVEN)
            has_shot_level_context or       # Safety net #3: shot-level context exists
            is_one_shot_question            # Safety net #4: one-shot types need tree grouping
        ) and not is_shot_parser_query  # EXCLUDE all shot parser queries
        
        skip_query_plan = is_pure_narrative or is_simple_analytical or is_shot_parser_query
        
        # Final decision: use Query Plan unless we're confident it's simple
        should_use = needs_query_plan or (not skip_query_plan)
        
        if should_use:
            reasons = []
            if has_set_comparison: reasons.append("set_comparison")
            if has_situation_comparison: reasons.append("situation_comparison")
            if is_multi_dimensional: reasons.append("multi_dimensional")
            if is_complex_analysis: reasons.append(f"complex_analysis({analysis_type})")
            if is_filtered_comparison: reasons.append("filtered_comparison")
            if has_temporal_pattern: reasons.append("temporal_pattern")
            if is_shot_level_grouping: reasons.append(f"shot_level_grouping({group_by})")
            if has_shot_level_context: reasons.append("shot_level_context")
            if not reasons: reasons.append("non-trivial")
            print(f"[QUERY-PLAN] Using Query Plan ({', '.join(reasons)})")
        else:
            if is_chain_query:
                print(f"[QUERY-PLAN] Skipping Query Plan (chain query -> _analyze_chain_logic)")
            elif is_consecutive_query:
                print(f"[QUERY-PLAN] Skipping Query Plan (consecutive shots query -> _analyze_consecutive_shots)")
            elif is_multistep_query:
                print(f"[QUERY-PLAN] Skipping Query Plan (multi-step pattern query -> _analyze_multi_step_pattern)")
            elif is_shot_prefilter_query:
                print(f"[QUERY-PLAN] Skipping Query Plan (shot pre-filtering query -> _prefilter_points_by_shot_attributes)")
            elif is_pure_narrative:
                print(f"[QUERY-PLAN] Skipping Query Plan (pure narrative -> existing routing)")
            elif is_simple_analytical:
                print(f"[QUERY-PLAN] Skipping Query Plan (simple analytical -> existing routing)")
        
        return should_use
    
    def _generate_query_plan(self, question: str, classification: Dict) -> Dict:
        """
        Generate a Query Plan for the question.
        
        The Query Plan allows:
        - Multiple independent operations (tree, narrative)
        - Each operation has its own filters and metrics
        - Operations can reference results from previous operations
        - Explicit synthesis instructions
        
        Returns:
            {
                "query_plan": [
                    {"id": "A", "route": "tree", "filters": {...}, "metrics": [...]},
                    {"id": "B", "route": "narrative", "point_source": "A", "chunk_retrieval": true}
                ],
                "synthesis_instructions": "..."
            }
        """
        import json
        
        player1 = self.player1 or "Player 1"
        player2 = self.player2 or "Player 2"
        
        # Build supported metrics list from config
        supported_metrics = ', '.join(sorted(self.TREE_SUPPORTED_METRICS))
        supported_filters = ', '.join(sorted(self.TREE_LEVEL_DIMENSIONS))
        
        prompt = """You are a tennis data query planner. Your ONLY job is to route questions correctly.

PLAYERS: {player1} vs {player2}

╔══════════════════════════════════════════════════════════════════════════════════════════╗
║                    THE FUNDAMENTAL ROUTING RULE                                          ║
╠══════════════════════════════════════════════════════════════════════════════════════════╣
║  SHOT-LEVEL attributes (direction, shot_type, depth) → NARRATIVE (data in NL chunks)     ║
║  POINT-LEVEL attributes (set, situation, serve_number, role) → TREE (computed on fly)    ║
║  BOTH shot-level AND point-level → HYBRID (tree filters, then narrative analyzes)        ║
╚══════════════════════════════════════════════════════════════════════════════════════════╝

════════════════════════════════════════════════════════════════════════════════════════════
SHOT-LEVEL ATTRIBUTES (TREE CANNOT HANDLE - MUST USE NARRATIVE)
════════════════════════════════════════════════════════════════════════════════════════════
These are attributes of individual SHOTS within rallies. Tree has NO access to these.
Data lives in pre-computed NL file chunks (SHOTDIR, SHOTS, NETPTS sections).

• direction: crosscourt, down_the_line, inside_out, inside_in, down_the_middle
• shot_type: forehand, backhand, volley, overhead, drop_shot, slice  
• shot_modifier: slice, volley, drop_shot, approach, lob
• depth: shallow, deep, very_deep
• spin: topspin, slice, flat
• net_play: approaches, volleys, points at net

KEYWORD DETECTION → NARRATIVE:
- "crosscourt", "down the line", "DTL", "inside-out", "inside-in", "down the middle"
- "forehand", "backhand" (when asking about counts/patterns, not winners/errors)
- "volley", "approach", "net point", "came to net"
- "drop shot", "lob", "slice" (shot types)
- "pattern", "placement", "direction"

════════════════════════════════════════════════════════════════════════════════════════════
POINT-LEVEL ATTRIBUTES (NARRATIVE CANNOT FILTER - MUST USE TREE)
════════════════════════════════════════════════════════════════════════════════════════════
These are attributes of POINTS (not shots). Tree filters/aggregates these.

• set: 1, 2, 3, 4, 5
• situation: break_point, game_point, deuce, set_point, match_point, tiebreak
• serve_number: 1 (first serve), 2 (second serve)
• role: server, returner
• court_side: deuce, ad
• rally_length: numeric (1, 2, 3, ... or >=7, <=3)
• prev_rally_length: for "after X" questions
• point_score: "30-30", "15-40", "40-15", etc.
• point_number_range: [1, 100] for temporal segments

KEYWORD DETECTION → TREE:
- "Set 3", "in the 4th set", "sets 4 and 5"
- "break point", "game point", "deuce", "set point", "match point"
- "first serve", "second serve", "2nd serve", "1st serve"
- "when serving", "when returning", "serve games", "return games"
- "at 30-30", "at 15-40", "when ahead", "when behind"
- "long rallies", "short rallies", "rallies of 7+"
- "first 100 points", "last 50 points"

════════════════════════════════════════════════════════════════════════════════════════════
CRITICAL: TREE METADATA ATTRIBUTES - USE PURE TREE FOR ALL COUNTING/DISTRIBUTION
════════════════════════════════════════════════════════════════════════════════════════════
ANY attribute stored in tree metadata MUST use TREE operations for counting/math.
NEVER use narrative/LLM counting for data that exists in tree metadata.

TREE METADATA ATTRIBUTES (use group_by for distribution questions):
• return_depth: shallow, deep, very_deep (return shot - one per return point)
• serve_target / serve_direction: T, wide, body (serve - one per serve point)
• serve_number: 1st, 2nd (which serve was in play)
• winning_shot_type: forehand, backhand, volley, etc. (shot that ended the point)
• winning_shot_direction: crosscourt, DTL, etc. (direction of winning shot)
• winning_shot_outcome: winner, unforced_error, forced_error, ace, double_fault
• court_side: deuce, ad
• serve_plus_one_type: forehand, backhand, none (shot after serve)

KEYWORD DETECTION → TREE WITH GROUP_BY (deterministic counting):
- "return depth distribution" → group_by=return_depth
- "serve target %" → group_by=serve_target  
- "winning shot type breakdown" → group_by=winning_shot_type
- "direction of winners" → filters={{outcome: winner}}, group_by=winning_shot_direction

IMPORTANT DISTINCTION - Rally shots vs Point-metadata shots:
- "forehand depth in rallies" = NARRATIVE (many forehands per point, requires parsing)
- "return depth" = TREE (exactly one return per point, in metadata)
- "winning shot direction" = TREE (exactly one winning shot per point, in metadata)
- "rally forehand direction" = NARRATIVE (many forehands per point, requires parsing)

════════════════════════════════════════════════════════════════════════════════════════════
TREE METRICS (what tree can compute)
════════════════════════════════════════════════════════════════════════════════════════════
{supported_metrics}

════════════════════════════════════════════════════════════════════════════════════════════
NL FILE SECTIONS (what narrative chunks contain)
════════════════════════════════════════════════════════════════════════════════════════════
• OVERVIEW STATISTICS: Total aces, double faults, winners, errors, final score
• SERVE1/SERVE2: Detailed serve stats (by court, by outcome) per player
• RETURN1/RETURN2: Detailed return stats per player  
• KEY POINTS: Break point, game point, deuce stats
• SHOTS1/SHOTS2: Shot TYPE totals (forehand count, backhand count, volleys)
• SHOTDIR1/SHOTDIR2: Shot DIRECTION with WIN% (crosscourt, DTL, inside-out, inside-in)
• NETPTS1/NETPTS2: Net approach statistics
• POINT-BY-POINT: Full descriptions for qualitative analysis

════════════════════════════════════════════════════════════════════════════════════════════
COMPLETE ROUTING TABLE - MEMORIZE THIS
════════════════════════════════════════════════════════════════════════════════════════════

┌─────────────────────────────────────────┬───────────┬─────────────────────────────────────┐
│ QUESTION TYPE                           │ ROUTE     │ CHUNK/FILTER                        │
├─────────────────────────────────────────┼───────────┼─────────────────────────────────────┤
│ SHOT DIRECTION                          │           │                                     │
│ "most successful forehand pattern"      │ NARRATIVE │ chunk: "forehand direction win %"   │
│ "crosscourt vs DTL"                     │ NARRATIVE │ chunk: "crosscourt down the line"   │
│ "inside-out winners"                    │ NARRATIVE │ chunk: "inside-out winners"         │
│ "direction breakdown"                   │ NARRATIVE │ chunk: "shot direction breakdown"   │
├─────────────────────────────────────────┼───────────┼─────────────────────────────────────┤
│ SHOT TYPE COUNTS                        │           │                                     │
│ "how many forehands"                    │ NARRATIVE │ chunk: "forehand total shots"       │
│ "forehand vs backhand"                  │ NARRATIVE │ chunk: "forehand backhand shots"    │
│ "total shots hit"                       │ NARRATIVE │ chunk: "shot totals"                │
├─────────────────────────────────────────┼───────────┼─────────────────────────────────────┤
│ NET PLAY                                │           │                                     │
│ "net approaches"                        │ NARRATIVE │ chunk: "net approaches"             │
│ "volley win %"                          │ NARRATIVE │ chunk: "volley net points won"      │
│ "times at net"                          │ NARRATIVE │ chunk: "net points statistics"      │
├─────────────────────────────────────────┼───────────┼─────────────────────────────────────┤
│ MATCH TOTALS                            │           │                                     │
│ "total aces", "total winners"           │ NARRATIVE │ chunk: "overview statistics"        │
│ "final score", "who won"                │ NARRATIVE │ chunk: "match overview"             │
├─────────────────────────────────────────┼───────────┼─────────────────────────────────────┤
│ SET-FILTERED                            │           │                                     │
│ "points in Set 3"                       │ TREE      │ filter: set=3                       │
│ "which set best"                        │ TREE      │ filters: set=1,2,3,4,5 (compare)    │
│ "Set 4 vs Set 5"                        │ TREE      │ filters: set=4, set=5               │
├─────────────────────────────────────────┼───────────┼─────────────────────────────────────┤
│ SITUATION-FILTERED                      │           │                                     │
│ "break point conversion"                │ TREE      │ filter: situation=break_point       │
│ "at deuce"                              │ TREE      │ filter: situation=deuce             │
│ "game points saved"                     │ TREE      │ filter: situation=game_point        │
├─────────────────────────────────────────┼───────────┼─────────────────────────────────────┤
│ SERVE-FILTERED                          │           │                                     │
│ "2nd serve win %"                       │ TREE      │ filter: serve_number=2              │
│ "aces on 1st serve"                     │ TREE      │ filter: serve_number=1              │
├─────────────────────────────────────────┼───────────┼─────────────────────────────────────┤
│ ROLE-FILTERED                           │           │                                     │
│ "return points won"                     │ TREE      │ filter: role=returner               │
│ "serve games"                           │ TREE      │ filter: role=server                 │
├─────────────────────────────────────────┼───────────┼─────────────────────────────────────┤
│ RALLY-FILTERED                          │           │                                     │
│ "long rally (7+) win %"                 │ TREE      │ filter: rally_length>=7             │
│ "short rally performance"               │ TREE      │ filter: rally_length<=3             │
├─────────────────────────────────────────┼───────────┼─────────────────────────────────────┤
│ SEQUENTIAL/MOMENTUM (prev point)        │           │                                     │
│ "after long rallies"                    │ TREE      │ filter: prev_rally_length>=7        │
│ "following a break"                     │ TREE      │ filter: (use prev game context)     │
│ "after winning X"                       │ TREE      │ filter: prev_point_result           │
├─────────────────────────────────────────┼───────────┼─────────────────────────────────────┤
│ QUALITATIVE MOMENTUM                    │           │                                     │
│ "turning point", "momentum shift"       │ NARRATIVE │ chunk: "momentum turning points"    │
│ "tactics", "strategy"                   │ NARRATIVE │ chunk: "tactics strategy"           │
├─────────────────────────────────────────┼───────────┼─────────────────────────────────────┤
│ HYBRID (point filter + shot analysis)   │           │                                     │
│ "forehand pattern in Set 3"             │ HYBRID    │ tree: set=3, narrative: point_source│
│ "tactics at break points"               │ HYBRID    │ tree: situation=bp, narrative: desc │
│ "serve placement at deuce"              │ HYBRID    │ tree: situation=deuce, narr: serve  │
└─────────────────────────────────────────┴───────────┴─────────────────────────────────────┘

════════════════════════════════════════════════════════════════════════════════════════════
QUERY PLAN JSON FORMAT
════════════════════════════════════════════════════════════════════════════════════════════
{{
  "query_plan": [
    {{
      "id": "A",
      "route": "tree" | "narrative" | "clarify",
      "filters": {{}},           // tree: ONLY point-level filters
      "metrics": [],             // tree: ONLY supported metrics
      "group_by": "return_depth" | "serve_target" | "player" | null,  // tree: for COUNTING/DISTRIBUTION questions
      "chunk_retrieval": true,   // narrative: ALWAYS true
      "chunk_query": "...",      // narrative: REQUIRED - keywords to find right chunks
      "point_source": "A",       // hybrid: use filtered points from tree op
      "top_k": 15                // narrative: chunks to retrieve
    }}
  ],
  "synthesis_instructions": "..."
}}

════════════════════════════════════════════════════════════════════════════════════════════
CRITICAL DECISION RULES
════════════════════════════════════════════════════════════════════════════════════════════

RULE 1: Check for SHOT-LEVEL keywords first:
  - crosscourt, down the line, DTL, inside-out, inside-in → NARRATIVE
  - forehand/backhand totals, shot counts, patterns → NARRATIVE  
  - net approaches, volleys, times at net → NARRATIVE
  
RULE 2: Check for POINT-LEVEL keywords:
  - Set X, situation, break point, deuce, serve number → TREE
  - role (server/returner), rally length, point score → TREE
  
RULE 3: If BOTH shot-level AND point-level keywords → HYBRID
  - Tree operation first to filter points
  - Narrative operation with point_source to analyze

RULE 4: For narrative ops, ALWAYS set:
  - chunk_retrieval: true
  - chunk_query: descriptive keywords matching NL section content
  
RULE 5: For tree comparison questions:
  - Create SEPARATE tree operation for EACH entity being compared
  - "Set 3 vs Set 5" → TWO ops with set=3 and set=5
  - "break point vs deuce" → TWO ops with different situations

RULE 6: For NARRATIVE comparison questions (shot directions, patterns, tactics):
  - Create SEPARATE narrative operation for EACH direction/pattern being compared
  - "inside-out vs inside-in vs DTL" → THREE narrative ops, each with specific chunk_query
  - Each op should target the specific direction's statistics
  - This allows proper retrieval and comparison like tree does

RULE 7: When asking about "most successful" or "best" pattern:
  - This is a COMPARISON question requiring data for ALL patterns
  - Generate separate narrative ops for each pattern to retrieve ALL relevant stats
  - The synthesis can then determine which is "most successful"

RULE 8: CRITICAL - Distinguish QUALITATIVE momentum vs SEQUENTIAL momentum:
  - QUALITATIVE (NARRATIVE): "What was the turning point?", "momentum shift", "when did X take control?"
    → Looking for strategic/psychological analysis of match flow
  - SEQUENTIAL (TREE): "after long rallies", "following a break", "immediately after X"
    → Statistical analysis using prev_rally_length, prev_point_result filters
  - Keywords: "after", "following", "immediately after", "in response to" → TREE with prev_* filters

RULE 9: CRITICAL - IF DATA EXISTS IN TREE METADATA, USE TREE (NOT NARRATIVE/LLM COUNTING):
  - For ANY counting/distribution/math question, check if the attribute is in tree metadata
  - Tree metadata attributes: return_depth, serve_target, serve_number, winning_shot_*, court_side, serve_plus_one_type
  - Questions about these → Use PURE TREE with group_by for DETERMINISTIC counts
  - Example: {{"route": "tree", "filters": {{"role": "returner"}}, "group_by": "return_depth", "metrics": ["win_percentage"]}}
  - NO LLM COUNTING - tree metadata provides exact numbers
  
RULE 9b: ONLY use HYBRID/NARRATIVE when data is NOT in tree metadata:
  - Rally shot patterns NOT in metadata: forehand/backhand patterns during rallies, shot sequences
  - These require parsing point descriptions because tree doesn't store every shot in a rally
  - Tree stores: serve, return, winning shot (in metadata) ✅
  - Tree does NOT store: 2nd rally shot, 3rd rally shot, etc. ❌
  - Example hybrid: "forehand crosscourt patterns in rallies" → tree filters + narrative analyzes rally descriptions

RULE 10: CRITICAL - Handling ANY "*_group*" Fields in Classification:
  - NEVER use ANY field name containing "_group" as a filter dimension
  - Valid filter fields are ONLY: {supported_filters}
  - TRANSLATION RULES:
    
    A. situation_group_a / situation_group_b (comparisons):
       - situation_group_a="break_point" → Op A: filters={{"situation": "break_point"}}
       - situation_group_b="non_break_point" → Op B: filters={{"situation": "non_break_point"}}
       - NOT filters={{"situation_group_a": ...}} or filters={{"situation_group_b": ...}}
    
    B. set_group_a / set_group_b (set comparisons):
       - set_group_a=[1, 2] → Op A: filters={{"set": [1, 2]}}
       - set_group_b=[3, 4, 5] → Op B: filters={{"set": [3, 4, 5]}}
       - NOT filters={{"set_group_a": ...}} or filters={{"set_group_b": ...}}
    
    C. situation_group (multiple situations):
       - situation_group=["break_point", "deuce"] → filters={{"situation": ["break_point", "deuce"]}}
       - NOT filters={{"situation_group": ...}}
  
  - REMEMBER: Extract the VALUES from *_group* fields and use the base dimension name (set, situation, etc.)

RULE 11: CRITICAL - ALWAYS Include Player Filter in Tree Operations:
  - If "player" is specified in classification (e.g., "player": "Jannik Sinner" or "Daniil Medvedev"), you MUST include it in EVERY tree operation filter
  - This applies to ALL query types: analytical, hybrid, narrative with tree filtering
  - Example: If player="Daniil Medvedev" and you're filtering to sets [3,4,5], the filter MUST be {{"set": [3,4,5], "player": "Daniil Medvedev"}}
  - The ONLY exception is when player="both" (comparing both players) → then do NOT include player in filters
  - DO NOT filter player in tree operations if player="both" - the tree will aggregate by player automatically

RULE 12: CRITICAL - MULTI-DIMENSIONAL GROUPING - SPLIT OPERATIONS:
  - When classification has secondary_group_by or tertiary_group_by with point-level values, CREATE SEPARATE OPERATIONS
  - For serve_number: Create 2 ops (serve_number=1, serve_number=2)
  - For player (when comparing "both"): Create 2 ops for each player name
  - Each operation should have the SAME group_by but DIFFERENT filters for the secondary dimension
  - Example: group_by="return_depth", secondary_group_by="serve_number"
    → Op A: filters={{{{role: returner, serve_number: 1}}}}, group_by="return_depth"
    → Op B: filters={{{{role: returner, serve_number: 2}}}}, group_by="return_depth"
  - Example: group_by="return_depth", secondary_group_by="serve_number", tertiary_group_by="player", player="both"
    → 4 ops: each player × each serve_number, all with group_by="return_depth"

════════════════════════════════════════════════════════════════════════════════════════════
EXAMPLES - COPY THESE PATTERNS
════════════════════════════════════════════════════════════════════════════════════════════

Q: "Who won more break points?"
{{
  "query_plan": [
    {{"id": "A", "route": "tree", "filters": {{"situation": "break_point"}}, "metrics": ["points_won", "win_percentage"]}}
  ],
  "synthesis_instructions": "Report break point stats directly from A"
}}

Q: "Who performed better at deuce or at break points?"
EXPLANATION: This compares 2 situations. Must create 2 operations.
{{
  "query_plan": [
    {{"id": "A", "route": "tree", "filters": {{"situation": "deuce"}}, "metrics": ["win_percentage", "points_won"]}},
    {{"id": "B", "route": "tree", "filters": {{"situation": "break_point"}}, "metrics": ["win_percentage", "points_won"]}}
  ],
  "synthesis_instructions": "Compare win% at deuce (A) vs break points (B) for both players. Identify who performed better in each situation."
}}

Q: "What shot patterns did Sinner use on break points?"
{{
  "query_plan": [
    {{"id": "A", "route": "tree", "filters": {{"situation": "break_point"}}, "metrics": []}},
    {{"id": "B", "route": "narrative", "point_source": "A", "filters": {{"situation": "break_point"}}, "chunk_retrieval": true}}
  ],
  "synthesis_instructions": "Use A to identify break points, then B analyzes shot patterns in those points using both the point data and break point chunks"
}}

Q: "Points won at 30-30 and deuce combined?"
{{
  "query_plan": [
    {{"id": "A", "route": "tree", "filters": {{"point_score": "30-30"}}, "metrics": ["points_won"]}},
    {{"id": "B", "route": "tree", "filters": {{"situation": "deuce"}}, "metrics": ["points_won"]}}
  ],
  "synthesis_instructions": "Combine points from A and B, report total per player"
}}

Q: "How did the match flow change across sets?"
EXPLANATION: Qualitative momentum question asking for narrative/strategic analysis.
{{
  "query_plan": [
    {{"id": "A", "route": "narrative", "chunk_retrieval": true, "chunk_query": "match flow momentum across sets"}}
  ],
  "synthesis_instructions": "Describe match flow evolution from narrative context"
}}

Q: "How did Sinner perform after winning long rallies?" or "Did Medvedev serve worse after long rallies?"
EXPLANATION: Sequential momentum - asking about performance FOLLOWING a specific type of point. Use prev_rally_length filter (TREE).
{{
  "query_plan": [
    {{"id": "A", "route": "tree", "op_type": "tree_aggregate", "filters": {{"prev_rally_length": ">=7"}}, "metrics": ["win_percentage", "winners", "unforced_errors"]}}
  ],
  "synthesis_instructions": "Report performance on points that followed long rallies (7+ shots), comparing both players"
}}

Q: "Who won more points immediately after losing long rallies?" or "Performance following breaks?"
EXPLANATION: Sequential patterns - use TREE's temporal filters (prev_rally_length, prev_point_result).
{{
  "query_plan": [
    {{"id": "A", "route": "tree", "op_type": "tree_aggregate", "filters": {{"prev_rally_length": ">=7"}}, "metrics": ["points_won", "win_percentage"]}}
  ],
  "synthesis_instructions": "Analyze points following long rallies to identify sequential momentum patterns"
}}

Q: "On break points, what was the 2nd serve win% and what tactics were used?"
{{
  "query_plan": [
    {{"id": "A", "route": "tree", "op_type": "tree_aggregate", "filters": {{"situation": "break_point", "serve_number": 2}}, "metrics": ["win_percentage"]}},
    {{"id": "B", "route": "narrative", "op_type": "narrative_describe", "point_source": "A", "filters": {{"situation": "break_point"}}, "chunk_retrieval": true, "chunk_query": "break point tactics"}}
  ],
  "synthesis_instructions": "Report 2nd serve win% from A, then describe tactics from B"
}}

Q: "What were the turning points in Set 3?" or "What were the mini momentum shifts in Set 4?"
EXPLANATION: Set-specific narrative questions need tree filtering first, then narrative analysis with filtered chunk retrieval.
{{
  "query_plan": [
    {{"id": "A", "route": "tree", "op_type": "tree_filter_only", "filters": {{"set": 3}}, "metrics": []}},
    {{"id": "B", "route": "narrative", "op_type": "narrative_timeline", "point_source": "A", "filters": {{"set": 3}}, "chunk_retrieval": true, "chunk_query": "turning points momentum shifts Set 3"}}
  ],
  "synthesis_instructions": "Use A to filter to Set 3 points only, then B analyzes turning points/momentum shifts within that set using both the points and Set 3 chunks"
}}

Q: "Compare Sinner on break points vs on set points"
{{
  "query_plan": [
    {{"id": "A", "route": "tree", "op_type": "tree_aggregate", "filters": {{"situation": "break_point"}}, "metrics": ["points_won", "win_percentage"]}},
    {{"id": "B", "route": "tree", "op_type": "tree_aggregate", "filters": {{"situation": "set_point"}}, "metrics": ["points_won", "win_percentage"]}}
  ],
  "synthesis_instructions": "Compare A (break points) vs B (set points) side by side. Note if either has insufficient data."
}}

Q: "Who was more effective?"
{{
  "query_plan": [
    {{"id": "A", "route": "clarify", "clarify_question": "When you say 'effective', do you mean: (1) win percentage overall, (2) winners vs errors ratio, (3) performance on big points, or (4) something else?"}}
  ],
  "synthesis_instructions": "Ask user for clarification before proceeding"
}}

Q: "How did momentum shift after the 3rd set?"
{{
  "query_plan": [
    {{"id": "A", "route": "tree", "op_type": "tree_aggregate", "filters": {{"set": 4}}, "metrics": ["points_won", "win_percentage"]}},
    {{"id": "B", "route": "tree", "op_type": "tree_aggregate", "filters": {{"set": 5}}, "metrics": ["points_won", "win_percentage"]}},
    {{"id": "C", "route": "narrative", "op_type": "narrative_timeline", "chunk_retrieval": true, "chunk_query": "momentum shift sets 4 and 5"}}
  ],
  "synthesis_instructions": "Use A and B for stats in sets 4-5, use C for narrative about momentum shift"
}}

Q: "Did either player get hot on serve for a stretch (like 12/14 points)?"
EXPLANATION: Streak/stretch questions need ALL points for sequential analysis + comprehensive chunks.
{{
  "query_plan": [
    {{"id": "A", "route": "tree", "op_type": "tree_filter_only", "filters": {{}}, "metrics": []}},
    {{"id": "B", "route": "narrative", "op_type": "narrative_timeline", "point_source": "A", "chunk_retrieval": true, "chunk_query": "serving streaks hot stretches momentum runs", "top_k": 18}}
  ],
  "synthesis_instructions": "Use A to get ALL points in sequence, then B analyzes for consecutive/near-consecutive winning patterns on serve. Identify any stretches where a player won 10+ of 12-15 points while serving."
}}

Q: "Who won more points in rallies of 7+ shots?"
PARSED CLASSIFICATION: {{"filters": {{"rally_length": ">=7"}}, "metrics": ["points_won"], "group_by": "player"}}
EXPLANATION: Classification already detected rally_length filter - USE IT in the tree operation!
{{
  "query_plan": [
    {{"id": "A", "route": "tree", "op_type": "tree_aggregate", "filters": {{"rally_length": ">=7"}}, "metrics": ["points_won"]}}
  ],
  "synthesis_instructions": "Report points won by each player in rallies of 7+ shots from operation A."
}}

Q: "Who won more points immediately after long rallies (7+ shots)?"
EXPLANATION: "immediately after" = use prev_rally_length filter! The current point follows a point where rally>=7.
{{
  "query_plan": [
    {{"id": "A", "route": "tree", "op_type": "tree_aggregate", "filters": {{"prev_rally_length": ">=7"}}, "metrics": ["points_won"]}}
  ],
  "synthesis_instructions": "Report points won by each player on points that immediately followed rallies of 7+ shots."
}}

Q: "When did Medvedev's level drop the most: Set 3, 4, or 5?"
EXPLANATION: This is a COMPARISON question asking about 3 sets. Must create 3 separate tree operations.
{{
  "query_plan": [
    {{"id": "A", "route": "tree", "filters": {{"set": 3}}, "metrics": ["points_won", "win_percentage", "unforced_errors"]}},
    {{"id": "B", "route": "tree", "filters": {{"set": 4}}, "metrics": ["points_won", "win_percentage", "unforced_errors"]}},
    {{"id": "C", "route": "tree", "filters": {{"set": 5}}, "metrics": ["points_won", "win_percentage", "unforced_errors"]}}
  ],
  "synthesis_instructions": "Compare Medvedev's win% across sets 3, 4, 5. Identify which set had LOWEST win% or HIGHEST errors = biggest drop. Present as comparison table showing all 3 sets."
}}

Q: "Did Sinner improve more on serve or on return after Set 2?"
{{
  "query_plan": [
    {{"id": "A", "route": "tree", "filters": {{"set": 3, "role": "server"}}, "metrics": ["win_percentage", "points_won"]}},
    {{"id": "B", "route": "tree", "filters": {{"set": 3, "role": "returner"}}, "metrics": ["win_percentage", "points_won"]}},
    {{"id": "C", "route": "tree", "filters": {{"set": 4, "role": "server"}}, "metrics": ["win_percentage", "points_won"]}},
    {{"id": "D", "route": "tree", "filters": {{"set": 4, "role": "returner"}}, "metrics": ["win_percentage", "points_won"]}},
    {{"id": "E", "route": "tree", "filters": {{"set": 5, "role": "server"}}, "metrics": ["win_percentage", "points_won"]}},
    {{"id": "F", "route": "tree", "filters": {{"set": 5, "role": "returner"}}, "metrics": ["win_percentage", "points_won"]}}
  ],
  "synthesis_instructions": "Compare Sinner's serve performance (A, C, E) vs return performance (B, D, F) across sets 3-5. Calculate improvement trends for each role."
}}

Q: "First 100 points vs last 100 points - what changed most?"
{{
  "query_plan": [
    {{"id": "A", "route": "tree", "filters": {{"point_number_range": [1, 100]}}, "metrics": ["points_won", "win_percentage", "aces", "unforced_errors"]}},
    {{"id": "B", "route": "tree", "filters": {{"point_number_range": [184, 283]}}, "metrics": ["points_won", "win_percentage", "aces", "unforced_errors"]}}
  ],
  "synthesis_instructions": "Compare early match (A) vs late match (B) stats. Identify biggest differences in win%, aces, errors for each player."
}}

Q: "Did Medvedev stop going down the line late in the match?"
PARSED CLASSIFICATION: {{"player": "Daniil Medvedev", "direction": "down_the_line", "set_comparison": {{"set_a": [1, 2], "set_b": [3, 4, 5]}}}}
EXPLANATION: Hybrid query - tree filters to player's points in each set group, narrative analyzes down-the-line shots in those points.
CRITICAL: Player "Daniil Medvedev" MUST be included in tree filters (RULE 11)!
{{
  "query_plan": [
    {{"id": "A", "route": "tree", "op_type": "tree_filter_only", "filters": {{"set": [1, 2], "player": "Daniil Medvedev"}}, "metrics": []}},
    {{"id": "B", "route": "narrative", "op_type": "narrative_describe", "point_source": "A", "chunk_retrieval": true, "chunk_query": "down the line shots direction"}},
    {{"id": "C", "route": "tree", "op_type": "tree_filter_only", "filters": {{"set": [3, 4, 5], "player": "Daniil Medvedev"}}, "metrics": []}},
    {{"id": "D", "route": "narrative", "op_type": "narrative_describe", "point_source": "C", "chunk_retrieval": true, "chunk_query": "down the line shots direction"}}
  ],
  "synthesis_instructions": "Operation A filters to Medvedev's points in Sets 1-2. B analyzes down-the-line shots in those points. C filters to Sets 3-5. D analyzes down-the-line in those. Compare frequency/patterns between early vs late sets."
}}

Q: "What was the return depth distribution?"
PARSED CLASSIFICATION: {{"filters": {{"role": "returner"}}, "group_by": "return_depth"}}
EXPLANATION: COUNTING/DISTRIBUTION question about return_depth (one-shot-per-point). Use TREE grouping for deterministic counts.
CRITICAL: return_depth is in tree metadata - use group_by for accurate counting!
{{
  "query_plan": [
    {{"id": "A", "route": "tree", "op_type": "tree_aggregate", "filters": {{"role": "returner"}}, "group_by": "return_depth", "metrics": ["points_won", "win_percentage"]}}
  ],
  "synthesis_instructions": "Tree operation A filters to return points and groups by return_depth (shallow/deep/very_deep). Use the per-branch win rates to answer the distribution question."
}}

Q: "What was Nadal's return depth distribution against Federer's 1st and 2nd serves?"
PARSED CLASSIFICATION: {{"player": "Rafael Nadal", "group_by": "return_depth", "role": "returner"}}
EXPLANATION: Return depth DISTRIBUTION question. Use TREE grouping by return_depth for deterministic counts. Separate operations for 1st vs 2nd serve.
CRITICAL: return_depth is in tree metadata - DO NOT use narrative for counting!
{{
  "query_plan": [
    {{"id": "A", "route": "tree", "op_type": "tree_aggregate", "filters": {{"role": "returner", "serve_number": 1, "player": "Rafael Nadal"}}, "group_by": "return_depth", "metrics": ["points_won", "win_percentage"]}},
    {{"id": "B", "route": "tree", "op_type": "tree_aggregate", "filters": {{"role": "returner", "serve_number": 2, "player": "Rafael Nadal"}}, "group_by": "return_depth", "metrics": ["points_won", "win_percentage"]}}
  ],
  "synthesis_instructions": "Operation A groups Nadal's 1st serve returns by depth (shallow/deep/very_deep). Operation B does same for 2nd serves. Report distribution and win rates for each depth zone against each serve type."
}}

Q: "What direction did Nadal hit his winners?"
PARSED CLASSIFICATION: {{"player": "Rafael Nadal", "group_by": "winning_shot_direction", "outcome": "winner"}}
EXPLANATION: Winning shot direction DISTRIBUTION. Use TREE grouping - winning_shot_direction is in tree metadata!
CRITICAL: DO NOT use narrative - tree has exact counts per direction.
{{
  "query_plan": [
    {{"id": "A", "route": "tree", "op_type": "tree_aggregate", "filters": {{"player": "Rafael Nadal", "outcome": "winner"}}, "group_by": "winning_shot_direction", "metrics": ["points_won"]}}
  ],
  "synthesis_instructions": "Tree groups Nadal's winners by direction (crosscourt/DTL/inside-out/inside-in). Report count and % for each direction."
}}

Q: "What was Sinner's most successful forehand pattern during rallies (inside-out, inside-in, DTL)?"
PARSED CLASSIFICATION: {{"group_by": "direction", "shot_type": "forehand", "player": "Jannik Sinner"}}
EXPLANATION: RALLY forehand direction patterns - this asks about ALL forehands during rallies (not just winning shots).
This data is pre-computed and stored in SHOTDIR chunks. Use narrative with chunk_retrieval.
IMPORTANT: This is DIFFERENT from "direction of Sinner's forehand winners" (which would use tree + winning_shot_direction).
{{
  "query_plan": [
    {{"id": "A", "route": "narrative", "op_type": "narrative_describe", "chunk_retrieval": true, "chunk_query": "Sinner forehand direction inside-out inside-in down the line win percentage points won", "top_k": 15}}
  ],
  "synthesis_instructions": "Find SHOTDIR1 chunk with forehand win percentages by direction for ALL rally forehands. Compare inside-out, inside-in, and down the line win rates. Report which pattern was most successful (highest win %)."
}}

Q: "How many crosscourt winners did each player hit?"
PARSED CLASSIFICATION: {{"metrics": ["winners"], "filters": {{"direction": "crosscourt"}}, "group_by": "player"}}
EXPLANATION: Direction + outcome query - data is in SHOTDIR chunks with breakdowns by direction and outcome.
{{
  "query_plan": [
    {{"id": "A", "route": "narrative", "op_type": "narrative_describe", "chunk_retrieval": true, "chunk_query": "crosscourt winners shot direction forehand backhand", "top_k": 15}}
  ],
  "synthesis_instructions": "Find SHOTDIR chunks for both players. Extract crosscourt winner counts for each. Sum forehand + backhand crosscourt winners per player."
}}

Q: "Compare Sinner's forehand vs backhand effectiveness"
PARSED CLASSIFICATION: {{"group_by": "shot_type", "player": "Jannik Sinner"}}
EXPLANATION: Shot type comparison - data is in SHOTS chunks with win percentages per shot type.
{{
  "query_plan": [
    {{"id": "A", "route": "narrative", "op_type": "narrative_describe", "chunk_retrieval": true, "chunk_query": "Sinner forehand backhand win percentage points won effectiveness", "top_k": 15}}
  ],
  "synthesis_instructions": "Find SHOTS1 chunk with Sinner's shot statistics. Compare forehand vs backhand win percentages, winners, and errors."
}}

Q: "Which direction did Medvedev hit most winners from?"
PARSED CLASSIFICATION: {{"group_by": "direction", "metrics": ["winners"], "player": "Daniil Medvedev"}}
EXPLANATION: Direction grouping for winners - data is in SHOTDIR2 chunk with winner counts by direction.
{{
  "query_plan": [
    {{"id": "A", "route": "narrative", "op_type": "narrative_describe", "chunk_retrieval": true, "chunk_query": "Medvedev shot direction winners crosscourt down the line inside-out", "top_k": 15}}
  ],
  "synthesis_instructions": "Find SHOTDIR2 chunk. Extract winner counts per direction (crosscourt, DTL, inside-out, etc.). Report which direction had most winners."
}}

Q: "How did Sinner perform on clutch points?"
PARSED CLASSIFICATION: {{"situation_group": ["break_point", "deuce", "set_point", "match_point"]}}
EXPLANATION: "Clutch" maps to multiple situations. Create ops for EACH situation and combine.
{{
  "query_plan": [
    {{"id": "A", "route": "tree", "filters": {{"situation": "break_point"}}, "metrics": ["points_won", "win_percentage"]}},
    {{"id": "B", "route": "tree", "filters": {{"situation": "deuce"}}, "metrics": ["points_won", "win_percentage"]}},
    {{"id": "C", "route": "tree", "filters": {{"situation": "set_point"}}, "metrics": ["points_won", "win_percentage"]}},
    {{"id": "D", "route": "tree", "filters": {{"situation": "match_point"}}, "metrics": ["points_won", "win_percentage"]}}
  ],
  "synthesis_instructions": "Combine results from all clutch situations (A=break points, B=deuce, C=set points, D=match points). Report total combined win % across all clutch moments."
}}

Q: "Which serve target was most effective for Sinner?"
PARSED CLASSIFICATION: {{"group_by": "serve_target", "role": "server", "metrics": ["win_percentage"]}}
EXPLANATION: Ranking query - compare multiple targets. Create op for EACH target, then rank.
{{
  "query_plan": [
    {{"id": "A", "route": "tree", "filters": {{"role": "server", "serve_target": "wide"}}, "metrics": ["win_percentage", "points_won"]}},
    {{"id": "B", "route": "tree", "filters": {{"role": "server", "serve_target": "T"}}, "metrics": ["win_percentage", "points_won"]}},
    {{"id": "C", "route": "tree", "filters": {{"role": "server", "serve_target": "body"}}, "metrics": ["win_percentage", "points_won"]}}
  ],
  "synthesis_instructions": "Compare win % for each serve target (A=wide, B=T, C=body). RANK from highest to lowest win %. Report most effective target."
}}

Q: "Did Sinner perform better on big points than Medvedev?"
PARSED CLASSIFICATION: {{"situation_group": ["break_point", "game_point", "set_point", "match_point"], "group_by": "player"}}
EXPLANATION: "Big points" = pressure situations combined. Compare both players across these.
{{
  "query_plan": [
    {{"id": "A", "route": "tree", "filters": {{"situation": "break_point"}}, "metrics": ["win_percentage"]}},
    {{"id": "B", "route": "tree", "filters": {{"situation": "game_point"}}, "metrics": ["win_percentage"]}},
    {{"id": "C", "route": "tree", "filters": {{"situation": "set_point"}}, "metrics": ["win_percentage"]}},
    {{"id": "D", "route": "tree", "filters": {{"situation": "deuce"}}, "metrics": ["win_percentage"]}}
  ],
  "synthesis_instructions": "For each player, combine win% across all big point situations (break points, game points, set points, deuce). Compare Sinner vs Medvedev overall big-point performance."
}}

IMPORTANT: 'player' is NOT a tree filter! Use 'role' (server/returner) instead. The tree knows who served/returned each point.
IMPORTANT: If group_by is NOT in TREE_LEVEL_DIMENSIONS ({supported_filters}), it's shot-level → use HYBRID or narrative with chunks!
IMPORTANT: For direction questions, data may be in SHOTDIR chunks (use chunk_retrieval) OR need point description analysis (use hybrid).
IMPORTANT: Use point_source to pass filtered points TO narrative for shot-level analysis from point descriptions!

USER QUESTION: {question}

PARSED CLASSIFICATION (use this information when creating the query plan):
{classification_json}

CRITICAL: Use the filters, metrics, and groupings from PARSED CLASSIFICATION in your query plan operations!
- If rally_length filter exists, include it in tree operation filters
- If set filter exists, include it in tree operation filters
- If metrics were parsed, use those metrics in tree operations
- If player is set, consider whether to use player grouping
- If situation/role filters exist, include them

Return ONLY valid JSON (no markdown, no explanation):"""

        # Format the classification for the LLM - include ALL fields that affect routing
        import json
        filters = classification.get('filters', {})
        classification_json = json.dumps({
            # Core query structure
            'filters': filters,
            'metrics': classification.get('metrics', []),
            'metric_filters': classification.get('metric_filters', {}),
            'player': filters.get('player'),  # Now always in filters after normalization
            'query_category': classification.get('query_category'),
            'analysis_type': classification.get('analysis_type'),
            
            # Grouping (all dimensions)
            'group_by': classification.get('group_by'),
            'secondary_group_by': classification.get('secondary_group_by'),
            'tertiary_group_by': classification.get('tertiary_group_by'),
            'n_dimensional': classification.get('n_dimensional'),
            
            # Shot-level fields (trigger narrative/hybrid)
            'shot_type': classification.get('shot_type') or filters.get('shot_type'),
            'direction': classification.get('direction') or filters.get('direction'),
            'shot_modifier': classification.get('shot_modifier') or filters.get('shot_modifier'),
            
            # Multi-entity comparisons
            'situation_group': filters.get('situation_group'),
            'set_group_a': filters.get('set_group_a'),
            'set_group_b': filters.get('set_group_b'),
            'situation_group_a': filters.get('situation_group_a'),
            'situation_group_b': filters.get('situation_group_b'),
            
            # Other context
            'rally_length': filters.get('rally_length'),
            'set': filters.get('set'),
            'chain_logic': filters.get('chain_logic'),
        }, indent=2)
        
        prompt = prompt.format(
            player1=player1,
            player2=player2,
            supported_metrics=supported_metrics,
            supported_filters=supported_filters,
            question=question,
            classification_json=classification_json
        )

        try:
            import google.generativeai as genai
            model = genai.GenerativeModel(self.model_25_flash)  # Fast model for planning
            response = model.generate_content(prompt, generation_config={"temperature": 0.3})
            
            response_text = response.text.strip()
            # Clean markdown if present
            if response_text.startswith("```"):
                response_text = response_text.split("```")[1]
                if response_text.startswith("json"):
                    response_text = response_text[4:]
                response_text = response_text.strip()
            
            query_plan = json.loads(response_text)
            
            # Check if plan is garbage (all empty filters/no chunk_query for narrative)
            ops = query_plan.get('query_plan', [])
            is_garbage = all(
                (not op.get('filters') and not op.get('chunk_query') and not op.get('metrics') and not op.get('chunk_retrieval'))
                for op in ops
            ) if ops else True
            
            if is_garbage:
                print(f"[QUERY-PLAN] Generated garbage (empty ops) -> using fallback")
                return self._fallback_query_plan(question, classification)
            
            print(f"[QUERY-PLAN] Generated plan with {len(ops)} operations")
            return query_plan
            
        except Exception as e:
            print(f"[QUERY-PLAN] Error generating plan: {e}")
            # Fallback: simple single-operation plan based on classification
            return self._fallback_query_plan(question, classification)
    
    def _validate_query_plan(self, query_plan: Dict, question: str = "") -> tuple:
        """
        Validate a query plan for correctness before execution.
        
        Checks:
        1. Dependencies exist (point_source references valid op)
        2. Routes/types are valid
        3. Filters use TREE_LEVEL_DIMENSIONS
        4. Metrics are in TREE_SUPPORTED_METRICS
        5. Total operations within limit
        6. CRITICAL: Narrative ops have grounding (chunk_query OR point_source)
        7. CRITICAL: Comparison questions have multiple ops
        
        Returns: (is_valid, errors_list)
        """
        errors = []
        warnings = []
        operations = query_plan.get('query_plan', [])
        
        if not operations:
            errors.append("No operations in query plan")
            return False, errors
        
        # Max operations limit (safety guard against runaway plans only)
        MAX_OPERATIONS = 20  # High limit - let LLM generate what it needs
        if len(operations) > MAX_OPERATIONS:
            errors.append(f"Too many operations ({len(operations)} > {MAX_OPERATIONS})")
        
        # Track operation IDs
        defined_ops = set()
        tree_ops_count = 0
        narrative_ops_count = 0
        
        for op in operations:
            op_id = op.get('id', '')
            route = op.get('route', '')
            
            # Check route is valid
            valid_routes = {'tree', 'narrative', 'clarify'}
            if route not in valid_routes:
                errors.append(f"Op {op_id}: Invalid route '{route}' (must be {valid_routes})")
            
            # Track defined ops and counts
            defined_ops.add(op_id)
            if route == 'tree':
                tree_ops_count += 1
            elif route == 'narrative':
                narrative_ops_count += 1
            
            # Check tree-specific validation
            if route == 'tree':
                # Check filters use valid dimensions
                filters = op.get('filters', {})
                for dim in filters.keys():
                    # Skip 'player' - it's context, not a filter dimension
                    if dim == 'player':
                        continue
                    # Normalize: "sets" -> "set" for validation
                    normalized_dim = 'set' if dim == 'sets' else dim
                    if normalized_dim not in self.TREE_LEVEL_DIMENSIONS:
                        errors.append(f"Op {op_id}: Filter '{dim}' not in TREE_LEVEL_DIMENSIONS")
                
                # Check metrics are supported
                metrics = op.get('metrics', [])
                for metric in metrics:
                    if metric not in self.TREE_SUPPORTED_METRICS:
                        errors.append(f"Op {op_id}: Metric '{metric}' not in TREE_SUPPORTED_METRICS")
                    
                    # Check metric requirements can be met
                    if metric in self.METRIC_REQUIREMENTS:
                        req = self.METRIC_REQUIREMENTS[metric]
                        if req.get('fallback') == 'narrative':
                            # This metric may not be reliable from tree
                            warnings.append(f"Op {op_id}: Metric '{metric}' may need narrative fallback")
            
            # Check narrative-specific validation
            if route == 'narrative':
                point_source = op.get('point_source')
                chunk_query = op.get('chunk_query')
                chunk_retrieval = op.get('chunk_retrieval', False)
                
                # CRITICAL FIX #1: Narrative must have grounding
                # Every narrative op MUST have either:
                # - chunk_query (for standalone narrative retrieval)
                # - point_source (for hybrid analysis of filtered points)
                has_chunk_grounding = chunk_retrieval and chunk_query
                has_point_grounding = point_source is not None
                
                if not has_chunk_grounding and not has_point_grounding:
                    errors.append(f"Op {op_id}: Narrative MUST have chunk_query OR point_source (no grounding = hallucination risk)")
                
                # Check point_source references valid op
                if point_source and point_source not in defined_ops:
                    errors.append(f"Op {op_id}: point_source '{point_source}' references undefined operation")
        
        # CRITICAL FIX #3: Comparison questions should have multiple ops
        if question:
            question_lower = question.lower()
            comparison_indicators = [
                'compare', ' vs ', 'versus', 'better than', 'worse than',
                'difference between', 'compared to', 'or ', ' vs.'
            ]
            is_comparison_question = any(ind in question_lower for ind in comparison_indicators)
            
            # If comparison language but only one tree op, warn
            # (Could be valid for player comparisons which are handled by group_by)
            if is_comparison_question and tree_ops_count == 1 and narrative_ops_count == 0:
                # Check if it's a player comparison (which uses group_by, not multiple ops)
                is_player_comparison = any(word in question_lower for word in [
                    'each player', 'both players', 'who ', 'which player'
                ])
                if not is_player_comparison:
                    warnings.append(f"Comparison question but only 1 tree op - may need multiple ops for proper comparison")
        
        # === SHOT-LEVEL AGGREGATION WARNING ===
        # Detect if question asks to aggregate shot-level data (group by direction/shot_type)
        # These questions are fundamentally unsupported by tree - need precomputed narrative stats
        shot_level_grouping_detected = False
        for op in operations:
            route = op.get('route')
            filters = op.get('filters', {})
            
            # Check if any op tries to use shot-level fields as filters (which tree can't handle)
            for field in self.SHOT_LEVEL_FIELDS:
                if field in filters:
                    shot_level_grouping_detected = True
                    break
        
        if shot_level_grouping_detected or 'most successful' in question.lower() or 'best pattern' in question.lower():
            # Check if question asks for ranking/comparison of shot patterns
            pattern_comparison_terms = ['most successful', 'best pattern', 'which pattern', 'better', 'more effective']
            if any(term in question.lower() for term in pattern_comparison_terms):
                warnings.append(
                    "⚠️ SHOT-LEVEL AGGREGATION: This question requires counting/ranking individual shots by direction/type. "
                    "The tree cannot aggregate shot-level data (only point-level). "
                    "Answer will rely on precomputed stats from narrative chunks or qualitative analysis from point descriptions. "
                    "If narrative chunks don't contain the specific breakdown, the answer may be incomplete or inferred from examples."
                )
        
        # Combine errors and warnings
        all_issues = errors + warnings
        
        # Valid if no hard errors (warnings are OK)
        is_valid = len(errors) == 0
        return is_valid, all_issues
    
    def _fallback_query_plan(self, question: str, classification: Dict) -> Dict:
        """
        Fallback query plan when LLM planning fails.
        Uses classification signals GENERICALLY - no hardcoded keywords.
        """
        filters = classification.get('filters', {})
        metrics = classification.get('metrics', ['points_won'])
        group_by = classification.get('group_by')
        secondary_group_by = classification.get('secondary_group_by')
        tertiary_group_by = classification.get('tertiary_group_by')
        
        # Find the FIRST tree-level group_by dimension (for tree operations)
        # Check primary, then secondary, then tertiary
        # NORMALIZE: "depth" → "return_depth" for return questions (schema inconsistency fix)
        is_return_question = filters.get('role') == 'returner' or classification.get('role') == 'returner'
        
        tree_group_by = None
        for gb in [group_by, secondary_group_by, tertiary_group_by]:
            if not gb:
                continue
            
            # NORMALIZE: "depth" → "return_depth" for return questions
            if gb == 'depth' and is_return_question:
                gb = 'return_depth'
                print(f"[FALLBACK] Normalized group_by 'depth' -> 'return_depth' (return question)")
            
            if gb in self.TREE_LEVEL_DIMENSIONS:
                tree_group_by = gb
                print(f"[FALLBACK] Found tree-level group_by: '{gb}'")
                break
        
        shot_type = classification.get('shot_type') or filters.get('shot_type')
        direction = classification.get('direction') or filters.get('direction')
        shot_modifier = classification.get('shot_modifier') or filters.get('shot_modifier')
        
        # SHOT-LEVEL = group_by is NOT in TREE_LEVEL_DIMENSIONS (use config, not hardcoded lists!)
        # These are shot-level attributes that require analyzing point descriptions
        
        # Normalize group_by: "sets" -> "set" (plural to singular for dimension check)
        normalized_group_by = group_by
        if group_by == 'sets':
            normalized_group_by = 'set'
        
        # Check if group_by is a shot-level attribute (not in tree dimensions)
        is_grouping_shot_level = normalized_group_by and normalized_group_by not in self.TREE_LEVEL_DIMENSIONS
        
        # Check if any shot attributes are specified
        has_shot_attributes = any([shot_type, direction, shot_modifier])
        
        is_shot_level = is_grouping_shot_level or has_shot_attributes
        
        if is_shot_level:
            # CRITICAL: Shot-level groupings need HYBRID approach:
            # 1. Tree filters to relevant points (e.g., role=returner for return_depth)
            # 2. Narrative analyzes point descriptions to extract shot-level data
            
            tree_filters = {k: v for k, v in filters.items() if k in self.TREE_LEVEL_DIMENSIONS and v}
            
            # For shot-level groupings, we ALWAYS need point data for analysis
            # HYBRID: tree filter (even if empty) + narrative analysis
            print(f"[FALLBACK] Shot-level grouping '{group_by}' NOT in TREE_LEVEL_DIMENSIONS")
            print(f"[FALLBACK] Routing to HYBRID (tree filter + narrative analysis)")
            return {
                "query_plan": [
                    {"id": "A", "route": "tree", "filters": tree_filters or {}, "metrics": []},
                    {"id": "B", "route": "narrative", "point_source": "A", "chunk_retrieval": False}
                ],
                "synthesis_instructions": f"Analyze the filtered points from A. Extract {group_by or 'shot-level data'} from point descriptions and compute win percentages. Answer the question."
            }
        
        # Check if any filters are NOT in tree dimensions → narrative
        # IGNORE spurious filters that LLM sometimes adds (handedness, etc.)
        IGNORED_FILTERS = {'handedness', 'hand', 'handed'}  # These should never be filters
        non_tree_filters = [k for k in filters.keys() 
                           if k not in self.TREE_LEVEL_DIMENSIONS 
                           and k not in IGNORED_FILTERS
                           and filters[k]]
        if non_tree_filters:
            print(f"[FALLBACK] Non-tree filters {non_tree_filters} -> narrative")
            return {
                "query_plan": [
                    {"id": "A", "route": "narrative", "chunk_retrieval": True, 
                     "chunk_query": question, "top_k": 12}
                ],
                "synthesis_instructions": "Answer from narrative context"
            }
        
        # DEFAULT: TREE with valid filters only
        tree_filters = {k: v for k, v in filters.items() 
                       if v is not None and k in self.TREE_LEVEL_DIMENSIONS}
        
        # Include group_by if it's a tree-level dimension (deterministic counting!)
        tree_op = {"id": "A", "route": "tree", "filters": tree_filters, "metrics": metrics}
        if tree_group_by:
            tree_op["group_by"] = tree_group_by
            print(f"[FALLBACK-DEFAULT] Including group_by='{tree_group_by}' in tree operation")
        
        return {
            "query_plan": [tree_op],
            "synthesis_instructions": "Report stats from tree analysis with grouping"
            }
    
    def _execute_query_plan(self, question: str, query_plan: Dict, classification: Dict, top_k: int = None) -> str:
        """
        Execute a Query Plan and synthesize results.
        
        Steps:
        1. Check for clarify operations first (return early)
        2. Execute each operation in order
        3. Store structured results by operation ID
        4. Use synthesis instructions to combine into final answer
        
        Each operation result includes:
        - operation_id, filters_applied, n_points, results (metrics/context)
        - confidence: high/medium/low
        - limitations: any caveats about the data
        """
        # Determine optimal chunk count if not provided
        if top_k is None:
            top_k = self._determine_optimal_chunk_count(question)
            # Ensure minimum for query plan operations
            top_k = max(top_k, 8)
        operations = query_plan.get('query_plan', [])
        synthesis_instructions = query_plan.get('synthesis_instructions', '')
        
        if not operations:
            return "No operations in query plan."
        
        # VALIDATE PLAN before execution (pass question for comparison detection)
        is_valid, validation_errors = self._validate_query_plan(query_plan, question)
        if not is_valid:
            print(f"[QUERY-PLAN] Validation failed: {validation_errors}")
            # Try to regenerate once
            print("[QUERY-PLAN] Attempting to regenerate plan...")
            query_plan = self._fallback_query_plan(question, classification)
            operations = query_plan.get('query_plan', [])
            synthesis_instructions = query_plan.get('synthesis_instructions', '')
        elif validation_errors:
            # Warnings only
            print(f"[QUERY-PLAN] Validation warnings: {validation_errors}")
        
        # Check for clarify operations first
        for op in operations:
            if op.get('route') == 'clarify':
                clarify_question = op.get('clarify_question', 'Could you please clarify your question?')
                print(f"[QUERY-PLAN] Clarification needed: {clarify_question}")
                return f"I'd like to give you an accurate answer. {clarify_question}"
        
        print(f"[QUERY-PLAN] Executing {len(operations)} operations...")
        
        # Store structured results and filtered points by operation ID
        results = {}
        filtered_points_by_id = {}
        
        for op in operations:
            op_id = op.get('id', 'unknown')
            route = op.get('route', 'tree')
            op_type = op.get('op_type', route)  # Default to route if no op_type
            
            print(f"[QUERY-PLAN] Executing operation {op_id} ({route}, type={op_type})...")
            
            if route == 'tree':
                # ENSURE group_by is in operation if classification has it (LLM sometimes forgets)
                if 'group_by' not in op:
                    # Check if classification has a tree-level group_by
                    for gb_field in ['group_by', 'secondary_group_by', 'tertiary_group_by']:
                        gb_value = classification.get(gb_field)
                        if not gb_value:
                            continue
                        
                        # Normalize "depth" → "return_depth" for return questions
                        is_return = op.get('filters', {}).get('role') == 'returner' or classification.get('role') == 'returner'
                        if gb_value == 'depth' and is_return:
                            gb_value = 'return_depth'
                        
                        if gb_value in self.TREE_LEVEL_DIMENSIONS:
                            op['group_by'] = gb_value
                            print(f"[QUERY-PLAN] Added missing group_by='{gb_value}' to operation {op_id}")
                            break
                
                result, points = self._execute_tree_operation(op, classification)
                
                # Add structured metadata
                result['operation_id'] = op_id
                result['op_type'] = op_type
                # Use config thresholds for confidence
                thresholds = self.SAMPLE_SIZE_THRESHOLDS
                result['confidence'] = (
                    'high' if len(points) >= thresholds['high_confidence'] else 
                    ('medium' if len(points) >= thresholds['medium_confidence'] else 'low')
                )
                result['limitations'] = []
                if len(points) < thresholds['medium_confidence']:
                    result['limitations'].append(f"Small sample size ({len(points)} points)")
                if not result.get('per_player_metrics'):
                    result['limitations'].append("No metrics computed")
                
                results[op_id] = result
                filtered_points_by_id[op_id] = points
                
            elif route == 'narrative':
                # Get point source if specified
                point_source = op.get('point_source')
                source_points = filtered_points_by_id.get(point_source, []) if point_source else []
                
                # CRITICAL FIX #2: Abort hybrid narrative when tree returns 0 points
                # This prevents confident answers based on unrelated match-wide data
                if point_source and len(source_points) == 0:
                    print(f"[QUERY-PLAN] ABORT: Narrative op {op_id} has point_source={point_source} but 0 points matched filters")
                    result = {
                        'operation_id': op_id,
                        'op_type': op_type,
                        'aborted': True,
                        'abort_reason': f"No points matched filters from source operation {point_source}",
                        'point_texts': [],
                        'chunks': [],
                        'confidence': 'none',
                        'limitations': [f"ABORTED: No data available for this filter combination"]
                    }
                    results[op_id] = result
                    continue  # Skip to next operation - do NOT execute narrative
                
                # Use operation-specific top_k if provided, otherwise use query-level top_k
                op_top_k = op.get('top_k', top_k)
                result = self._execute_narrative_operation(op, classification, source_points, op_top_k)
                
                # Add structured metadata
                result['operation_id'] = op_id
                result['op_type'] = op_type
                result['confidence'] = 'high' if (source_points or result.get('chunks')) else 'low'
                result['limitations'] = []
                if point_source and not source_points:
                    result['limitations'].append(f"No points from source operation {point_source}")
                if op.get('chunk_retrieval') and not result.get('chunks'):
                    result['limitations'].append("No relevant chunks found")
                
                results[op_id] = result
        
        # Synthesize results
        print("[QUERY-PLAN] Synthesizing results...")
        answer = self._synthesize_query_plan_results(question, results, filtered_points_by_id, synthesis_instructions, classification)
        
        return answer
    
    def _execute_tree_operation(self, operation: Dict, classification: Dict) -> tuple:
        """
        Execute a tree operation: filter points and compute metrics.
        
        Uses existing _apply_dimension_filter for GENERIC filtering - no hardcoded dimensions.
        
        Returns: (result_dict, filtered_points_list)
        """
        filters = operation.get('filters', {})
        metrics = operation.get('metrics', ['points_won'])
        
        if not hasattr(self, 'point_by_point') or not self.point_by_point:
            return {"error": "No point data available"}, []
        
        # Start with all points
        filtered_points = list(self.point_by_point)
        
        # Build a temporary classification for _apply_dimension_filter
        temp_classification = dict(classification)
        # CRITICAL: Get player context from original classification for role filtering
        # But DON'T put player in operation filters - that breaks metric computation for grouped queries
        original_filters = classification.get('filters', {})
        player_context = filters.get('player') or original_filters.get('player') or classification.get('player')
        
        # ORIGINAL DESIGN: Strip 'player' from filters - it's context for role resolution, not a filter
        # The role filter (server/returner) uses player_context to determine WHO should be in that role
        # Having player in BOTH filters AND classification causes double-filtering with different logic
        if 'player' in filters:
            print(f"[TREE-OP] Moving player='{filters.get('player')}' from filters to classification context")
        filters = {k: v for k, v in filters.items() if k != 'player'}
        
        # Set operation filters but preserve player at classification level for role filtering
        temp_classification['filters'] = filters
        temp_classification['player'] = player_context  # Top-level for role filter access
        
        # Apply each filter using the existing generic filter method
        for dim, value in filters.items():
            if value is None:
                continue
            
            # Use existing _apply_dimension_filter - it handles ALL dimension types from config
            filtered_points = self._apply_dimension_filter(
                filtered_points, dim, value, temp_classification
            )
        
        print(f"[TREE-OP] Filtered {len(filtered_points)} points with filters: {filters}")
        
        # DEBUG: Print serve_number filter stats if it was used
        if 'serve_number' in filters and hasattr(self, '_serve_debug'):
            debug = self._serve_debug
            print(f"[SERVE-DEBUG] 2nd serves found: {debug['total']}, empty_text: {debug['empty_text']}")
            print(f"[SERVE-DEBUG] By server: {debug['by_server']}")
            delattr(self, '_serve_debug')  # Reset for next query
        
        # Build classification for metric computation
        temp_classification['metrics'] = metrics
        
        # For tree-level dimensions, allow tree grouping
        # These are dimensions that exist in tree metadata (no rally parsing needed)
        # Use TREE_LEVEL_DIMENSIONS constant (defined at class level)
        
        # Collect ALL group_by dimensions that are tree-level
        # NORMALIZE: "depth" → "return_depth" for return questions (schema inconsistency fix)
        is_return_question = filters.get('role') == 'returner' or classification.get('role') == 'returner'
        
        group_by_dimensions = []
        for gb_field in ['group_by', 'secondary_group_by', 'tertiary_group_by']:
            gb_value = classification.get(gb_field)
            if not gb_value:
                continue
            
            # NORMALIZE: "depth" → "return_depth" for return questions
            if gb_value == 'depth' and is_return_question:
                gb_value = 'return_depth'
                print(f"[TREE-OP] Normalized group_by 'depth' -> 'return_depth' (return question)")
            
            if gb_value in self.TREE_LEVEL_DIMENSIONS:
                group_by_dimensions.append(gb_value)
        
        if group_by_dimensions:
            # Use primary tree-level group_by for the main grouping
            temp_classification['group_by'] = group_by_dimensions[0]
            # Store all dimensions for multi-dimensional analysis
            temp_classification['all_group_by'] = group_by_dimensions
            print(f"[TREE-OP] Using tree grouping for dimensions: {group_by_dimensions}")
        else:
            temp_classification['group_by'] = None
        
        # Use existing _compute_leaf_metrics - it's GENERIC and handles ALL metrics via config
        # NO HARDCODING - the config defines how each metric is computed
        computed_results = self._compute_leaf_metrics(filtered_points, temp_classification)
        
        # Return the computed results directly with minimal formatting
        # Let synthesis handle the display - we just provide the data
        result = {
            'filters': filters,
            'total_points': len(filtered_points),
            'per_player_metrics': computed_results['per_player_metrics'],  # Generic structure for ALL metrics
            'player1_name': self.player1,
            'player2_name': self.player2,
        }
        
        # Include grouping data if present (for distribution queries)
        if 'grouped_by' in computed_results:
            result['grouped_by'] = computed_results['grouped_by']
            result['groups'] = computed_results['groups']
            print(f"[TREE-OP] Returning grouped results: {len(computed_results['groups'])} groups by {computed_results['grouped_by']}")
        
        return result, filtered_points
    
    def _execute_narrative_operation(self, operation: Dict, classification: Dict, source_points: list, top_k: int = None) -> Dict:
        """
        Execute a narrative operation: analyze points and/or retrieve chunks.
        
        Args:
            operation: The operation definition
            classification: Query classification
            source_points: Points from a previous tree operation (if point_source specified)
            top_k: Number of chunks to retrieve
        
        Returns: result dict with 'context' and optionally 'chunks'
        """
        chunk_retrieval = operation.get('chunk_retrieval', False)
        chunk_query = operation.get('chunk_query', '')
        
        result = {
            'source_points_count': len(source_points),
            'point_texts': [],
            'chunks': []
        }
        
        # Build point context if we have source points
        if source_points:
            for pt in source_points:
                point_num = pt.get('point_number', '?')
                server = pt.get('server', '?')
                returner = pt.get('returner', '?')
                score = pt.get('score', '?')
                description = pt.get('point_text', pt.get('description', 'No description'))
                point_winner = pt.get('point_winner', '?')
                
                point_text = f"Point {point_num} [Server: {server} | Score: {score}]:\n{description}\n[Point won by: {point_winner}]"
                result['point_texts'].append(point_text)
        
        # Retrieve chunks if requested
        if chunk_retrieval:
            # Determine optimal chunk count if not provided
            if top_k is None:
                query_for_chunks = chunk_query or classification.get('original_question', '')
                top_k = self._determine_optimal_chunk_count(query_for_chunks)
                # Narratives need more context - ensure minimum
                top_k = max(top_k, 8)
            else:
                query_for_chunks = chunk_query or classification.get('original_question', '')
            
            # CRITICAL: Enhance query with filter information to ensure proper filtering
            # If operation has filters (e.g., set=3), explicitly add them to the query
            operation_filters = operation.get('filters', {})
            if operation_filters:
                filter_parts = []
                if 'set' in operation_filters:
                    filter_parts.append(f"Set {operation_filters['set']}")
                if 'situation' in operation_filters:
                    filter_parts.append(operation_filters['situation'].replace('_', ' '))
                # Add other relevant filters as needed
                
                if filter_parts:
                    enhanced_query = f"{query_for_chunks} {' '.join(filter_parts)}"
                    query_for_chunks = enhanced_query
                    print(f"[NARRATIVE-OP] Enhanced query with filters: {filter_parts}")
            
            if hasattr(self, 'retrieve_relevant_chunks'):
                # Pass operation filters to chunk retrieval for proper filtering
                chunks = self.retrieve_relevant_chunks(query_for_chunks, top_k=top_k, filters=operation_filters)
                result['chunks'] = chunks
                print(f"[NARRATIVE-OP] Retrieved {len(chunks)} chunks (top_k={top_k}, filters={operation_filters})")
        
        return result
    
    def _compute_point_aggregations(self, points: list, classification: Dict) -> str:
        """
        GENERIC aggregation of ALL points - extracts shot-level data and computes statistics.
        
        This is the KEY to handling large point sets: instead of passing raw descriptions
        to the LLM, we extract and aggregate the data programmatically.
        
        Returns a formatted string with all computed statistics.
        """
        import re
        from collections import defaultdict
        
        if not points:
            return "No points to analyze."
        
        # Initialize aggregation structures
        stats_by_set = defaultdict(lambda: {
            'total_points': 0,
            'return_depths': defaultdict(int),  # very_deep, deep, shallow, unspecified
            'serve_targets': defaultdict(int),  # wide, T, body
            'shot_directions': defaultdict(int),  # crosscourt, down_the_line, middle
            'outcomes': defaultdict(int),  # winner, unforced_error, forced_error, ace
            'rally_lengths': [],
            'points_won': {'player1': 0, 'player2': 0},
        })
        
        player1 = self.player1
        player2 = self.player2
        
        # Process EVERY point
        for pt in points:
            set_num = pt.get('set_number', pt.get('set', 1)) or 1
            description = pt.get('point_text', pt.get('description', ''))
            desc_lower = description.lower()
            server = pt.get('server', '')
            returner = pt.get('returner', '')
            point_winner = pt.get('point_winner', '')
            
            stats = stats_by_set[set_num]
            stats['total_points'] += 1
            
            # Track point winner
            if point_winner:
                if self._names_match_robust(player1, point_winner):
                    stats['points_won']['player1'] += 1
                elif self._names_match_robust(player2, point_winner):
                    stats['points_won']['player2'] += 1
            
            # Extract return depth from description (e.g., "return down the middle (very deep)")
            depth_match = re.search(r'return[^;]*\((very deep|deep|shallow)\)', desc_lower)
            if depth_match:
                depth = depth_match.group(1).replace(' ', '_')
                stats['return_depths'][depth] += 1
            elif 'return' in desc_lower:
                stats['return_depths']['unspecified'] += 1
            
            # Extract serve target (e.g., "1st serve wide", "2nd serve down the T")
            serve_match = re.search(r'(?:1st|2nd)\s+serve\s+(wide|down the t|to body|body)', desc_lower)
            if serve_match:
                target = serve_match.group(1)
                if 'wide' in target:
                    stats['serve_targets']['wide'] += 1
                elif 't' in target:
                    stats['serve_targets']['T'] += 1
                elif 'body' in target:
                    stats['serve_targets']['body'] += 1
            
            # Extract outcomes
            if 'ace' in desc_lower:
                stats['outcomes']['ace'] += 1
            if 'winner' in desc_lower and 'service winner' not in desc_lower:
                stats['outcomes']['winner'] += 1
            # CRITICAL: Check unforced FIRST to avoid 'forced error' matching inside 'unforced error'
            if 'unforced error' in desc_lower:
                stats['outcomes']['unforced_error'] += 1
            elif 'forced error' in desc_lower:
                stats['outcomes']['forced_error'] += 1
            if 'double fault' in desc_lower:
                stats['outcomes']['double_fault'] += 1
            
            # Track rally length
            rally_len = pt.get('rally_length', 0)
            if rally_len:
                stats['rally_lengths'].append(rally_len)
        
        # Build formatted output
        output_parts = [f"=== COMPLETE ANALYSIS OF ALL {len(points)} POINTS ===\n"]
        
        for set_num in sorted(stats_by_set.keys()):
            stats = stats_by_set[set_num]
            output_parts.append(f"\n--- SET {set_num} ({stats['total_points']} points) ---")
            
            # Points won
            p1_wins = stats['points_won']['player1']
            p2_wins = stats['points_won']['player2']
            output_parts.append(f"Points won: {player1}: {p1_wins}, {player2}: {p2_wins}")
            
            # Return depths (if any recorded)
            if any(stats['return_depths'].values()):
                depths = stats['return_depths']
                output_parts.append(f"Return depths: very_deep={depths['very_deep']}, deep={depths['deep']}, shallow={depths['shallow']}, unspecified={depths['unspecified']}")
            
            # Serve targets (if any recorded)
            if any(stats['serve_targets'].values()):
                targets = stats['serve_targets']
                output_parts.append(f"Serve targets: wide={targets['wide']}, T={targets['T']}, body={targets['body']}")
            
            # Outcomes
            if any(stats['outcomes'].values()):
                outcomes = stats['outcomes']
                output_parts.append(f"Outcomes: aces={outcomes['ace']}, winners={outcomes['winner']}, UE={outcomes['unforced_error']}, FE={outcomes['forced_error']}, DF={outcomes['double_fault']}")
            
            # Rally length stats
            if stats['rally_lengths']:
                avg_rally = sum(stats['rally_lengths']) / len(stats['rally_lengths'])
                output_parts.append(f"Avg rally length: {avg_rally:.1f} shots")
        
        return "\n".join(output_parts)
    
    def _synthesize_query_plan_results(self, question: str, results: Dict, filtered_points_by_id: Dict, synthesis_instructions: str, classification: Dict) -> str:
        """
        Synthesize results from all operations into a final answer.
        
        Uses LLM to combine tree stats and narrative context based on synthesis instructions.
        Includes structured metadata: confidence, limitations from each operation.
        """
        # Build context for synthesis with structured metadata
        context_parts = []
        all_points = []
        all_limitations = []
        
        # Track if any operations were aborted
        aborted_ops = []
        
        for op_id, result in results.items():
            if isinstance(result, dict):
                # Check for aborted operations first
                if result.get('aborted'):
                    aborted_ops.append(op_id)
                    context_parts.append(f"\n=== Operation {op_id} (ABORTED) ===")
                    context_parts.append(f"Reason: {result.get('abort_reason', 'No data matched filters')}")
                    all_limitations.append(f"Op {op_id}: ABORTED - {result.get('abort_reason', 'insufficient data')}")
                    continue  # Skip to next operation
                
                # Extract structured metadata
                confidence = result.get('confidence', 'unknown')
                limitations = result.get('limitations', [])
                op_type = result.get('op_type', 'unknown')
                
                if limitations:
                    all_limitations.extend([f"Op {op_id}: {lim}" for lim in limitations])
                
                if 'per_player_metrics' in result:
                    # Tree operation result - uses GENERIC per_player_metrics structure
                    context_parts.append(f"=== Operation {op_id} (Tree, {op_type}) ===")
                    context_parts.append(f"Filters: {result.get('filters', {})}")
                    context_parts.append(f"Total points: {result.get('total_points', 0)}")
                    
                    # Display metrics in a readable format
                    player1 = result.get('player1_name', 'Player 1')
                    player2 = result.get('player2_name', 'Player 2')
                    
                    # Get total points for clarity
                    total_points_in_category = result.get('total_points', 0)
                    
                    # ============================================================
                    # GROUPED RESULTS: Display distribution by dimension
                    # ============================================================
                    grouped_by = result.get('grouped_by')
                    groups = result.get('groups', {})
                    
                    if grouped_by and groups:
                        context_parts.append(f"\n*** DISTRIBUTION BY {grouped_by.upper()} ***")
                        for group_value, group_data in sorted(groups.items()):
                            count = group_data.get('count', 0)
                            p1_wins = group_data.get('player1_wins', 0)
                            p2_wins = group_data.get('player2_wins', 0)
                            p1_pct = group_data.get('player1_pct', 0)
                            p2_pct = group_data.get('player2_pct', 0)
                            
                            context_parts.append(f"  {group_value}: {count} points")
                            context_parts.append(f"    {player1} won: {p1_wins} ({p1_pct}%)")
                            context_parts.append(f"    {player2} won: {p2_wins} ({p2_pct}%)")
                        context_parts.append("")
                    
                    # ============================================================
                    # OVERALL METRICS (always shown)
                    # ============================================================
                    for metric, player_data in result.get('per_player_metrics', {}).items():
                        p1_count = player_data.get('player1', {}).get('count', 0)
                        p1_total = player_data.get('player1', {}).get('total', 0)
                        p2_count = player_data.get('player2', {}).get('count', 0)
                        p2_total = player_data.get('player2', {}).get('total', 0)
                        
                        # Check display_type from METRIC_CONFIG to determine formatting
                        metric_config = self.METRIC_CONFIG.get(metric, {})
                        display_type = metric_config.get('display_type', 'percentage')
                        
                        # CRITICAL: For points_won-type metrics (display_type='points_won'), make it explicit these are WINS
                        # These represent absolute win counts with per-player denominators for percentages
                        points_won_metrics = ['points_won', 'win_percentage', 'return_points_won', 
                                             'break_points_won', 'break_points_saved', 'deuce_points_won']
                        
                        if display_type == 'count':
                            # Count metrics (aces, errors, winners) - just show raw counts, no denominators
                            context_parts.append(f"{metric}:")
                            context_parts.append(f"  {player1}: {p1_count}")
                            context_parts.append(f"  {player2}: {p2_count}")
                        elif metric in points_won_metrics:
                            # Points won metrics - use per-player totals for percentage calculation
                            # total_points_in_category is the sum across both players and should NOT be used as denominator
                            context_parts.append(f"Points WON by each player (total {total_points_in_category} points in this category):")
                            context_parts.append(f"  {player1}: {p1_count} won out of {p1_total} ({round(100*p1_count/p1_total,1) if p1_total > 0 else 0}%)")
                            context_parts.append(f"  {player2}: {p2_count} won out of {p2_total} ({round(100*p2_count/p2_total,1) if p2_total > 0 else 0}%)")
                        else:
                            # Percentage metrics - show with denominators
                            context_parts.append(f"{metric}:")
                            context_parts.append(f"  {player1}: {p1_count} (out of {p1_total})")
                            context_parts.append(f"  {player2}: {p2_count} (out of {p2_total})")
                    
                    if limitations:
                        context_parts.append(f"Limitations: {', '.join(limitations)}")
                    
                    # Collect filtered points from this operation
                    # NOTE: May contain duplicates across operations (e.g., Op A: all break points, Op B: subset with 7+ shots)
                    # Deduplication happens before debug display
                    points = filtered_points_by_id.get(op_id, [])
                    all_points.extend(points)
                    
                elif 'point_texts' in result:
                    # Narrative operation result
                    context_parts.append(f"\n=== Operation {op_id} (Narrative, {op_type}) ===")
                    context_parts.append(f"Source points analyzed: {result.get('source_points_count', 0)}")
                    
                    # CRITICAL FIX: Include point_texts from narrative operation for hybrid queries
                    # These are the filtered points that need shot-level analysis
                    if result.get('point_texts'):
                        num_points = len(result['point_texts'])
                        context_parts.append(f"\nFiltered Point Descriptions ({num_points} points):")
                        # NO SAMPLING - Include ALL points for maximum accuracy
                        # User preference: accuracy > speed/cost
                        context_parts.extend(result['point_texts'])
                    
                    if result.get('chunks'):
                        context_parts.append("\nRetrieved Reference Chunks:")
                        # For SHOTDIR chunks, include full content (win percentages are in detailed breakdown)
                        for chunk in result['chunks'][:5]:  # Show up to 5 chunks
                            chunk_text = chunk.get('text', chunk.get('content', ''))
                            chunk_section = chunk.get('metadata', {}).get('section', '')
                            
                            # SHOTDIR chunks contain detailed breakdowns with win percentages - include full text
                            if 'shotdir' in chunk_section.lower():
                                context_parts.append(f"  [{chunk_section}]:")
                                context_parts.append(chunk_text)
                            else:
                                # Other chunks can be truncated
                                context_parts.append(f"  - {chunk_text[:1500]}..." if len(chunk_text) > 1500 else f"  - {chunk_text}")
                    
                    if limitations:
                        context_parts.append(f"Limitations: {', '.join(limitations)}")
        
        # Build final context
        final_context = "\n".join(context_parts)
        
        # Add point texts for synthesis
        point_context = ""
        aggregated_stats = ""
        
        if all_points:
            # Check if tree operations already provided grouped results
            has_tree_grouping = any(
                result.get('grouped_by') and result.get('groups')
                for result in results.values()
                if isinstance(result, dict)
            )
            
            # ONLY compute aggregations for questions that NEED full point analysis:
            # - Trend analysis (changes across sets) without tree grouping
            # - Shot-level pattern questions (depth, placement, directions) that DON'T have tree grouping
            # Simple metric questions (aces, winners, win%) use tree stats directly
            # Set-based questions now use tree grouping (not full point analysis)
            
            analysis_type = classification.get('analysis_type', '')
            group_by = classification.get('group_by', '')
            question_lower = question.lower()
            
            needs_full_analysis = (
                analysis_type == 'trend' or
                # REMOVED: group_by in ('sets', 'set') - now handled by tree grouping
                'depth' in question_lower or
                'placement' in question_lower or
                'direction' in question_lower or
                'pattern' in question_lower or
                'constant' in question_lower or  # "was it constant?"
                'change' in question_lower or    # "did X change?"
                'evolve' in question_lower or
                'throughout' in question_lower
            )
            
            # If tree already grouped the results, skip full point analysis
            if has_tree_grouping:
                needs_full_analysis = False
                print(f"[SYNTHESIS] Skipping full point analysis - tree provided grouped results")
            
            if needs_full_analysis and len(all_points) > 10:
                aggregated_stats = self._compute_point_aggregations(all_points, classification)
                print(f"[SYNTHESIS] Full point analysis for trend/pattern question")
            
            # Only pass point descriptions if we don't have tree grouping
            # When tree has grouped results, the LLM uses those - no need for raw descriptions
            if not has_tree_grouping:
                # NO SAMPLING - Pass ALL points for maximum accuracy
                # User preference: accuracy > speed
                point_texts = []
                for pt in all_points:
                    point_num = pt.get('point_number', '?')
                    server = pt.get('server', '?')
                    score = pt.get('score', '?')
                    set_num = pt.get('set_number', pt.get('set', '?'))
                    description = pt.get('point_text', pt.get('description', ''))
                    point_winner = pt.get('point_winner', '?')
                    point_texts.append(f"Point {point_num} [Set {set_num} | {server} serving at {score}]: {description} [Won by: {point_winner}]")
                point_context = "\n\n".join(point_texts)
                print(f"[SYNTHESIS] Passing ALL {len(all_points)} point descriptions to LLM (no sampling)")
            else:
                print(f"[SYNTHESIS] Skipping point descriptions - using tree grouped results only")
        
        # Build limitations summary for LLM
        limitations_text = "\n".join(all_limitations) if all_limitations else "None"
        
        # CRITICAL: Check if all operations were aborted or yielded no data
        # If so, return a clear "insufficient data" message instead of hallucinating
        if aborted_ops:
            non_aborted_results = [r for op_id, r in results.items() if not r.get('aborted')]
            if not non_aborted_results:
                # ALL operations were aborted - cannot answer
                abort_reasons = [results[op_id].get('abort_reason', 'No data') for op_id in aborted_ops]
                return f"I cannot answer this question with the available data.\n\n**Reason:** {'; '.join(set(abort_reasons))}\n\nThis typically happens when the filters in your question (e.g., specific set, situation, or shot type combination) don't match any points in the match data. Try broadening your question or asking about a different filter combination."
            elif not all_points and not any(r.get('chunks') for r in non_aborted_results if isinstance(r, dict)):
                # Some ops ran but yielded no usable data
                return f"I found limited data for this query.\n\n**Issue:** {limitations_text}\n\nThe specific combination of filters may not have enough data points for reliable analysis. Consider asking about broader conditions or different metrics."
        
        # Synthesize with LLM
        prompt = f"""You are a tennis analyst synthesizing query results.

QUESTION: {question}

SYNTHESIS INSTRUCTIONS: {synthesis_instructions}

OPERATION RESULTS:
{final_context}

LIMITATIONS/CAVEATS:
{limitations_text}

AGGREGATED STATISTICS (computed from ALL points):
{aggregated_stats if aggregated_stats else "(No aggregated stats)"}

FULL POINT DETAILS ({len(all_points) if all_points else 0} points - NO SAMPLING):
{point_context if point_context else "(No point details)"}

Based on the operation results and AGGREGATED STATISTICS, provide a clear answer to the question.
CRITICAL: Use the AGGREGATED STATISTICS for your analysis - they cover ALL filtered points.

DATA SOURCE HIERARCHY (CRITICAL):
1. For shot-level questions (forehand/backhand, direction, etc.) with point-level filters (Set X, break points):
   - PRIMARY SOURCE: "Filtered Point Descriptions" from narrative operations
   - Analyze these point descriptions to count forehands, shot directions, etc.
   - DO NOT use match-wide totals from reference chunks
   
2. For point-level metrics (points won, win %, aces, double faults):
   - PRIMARY SOURCE: Tree operation results with exact counts
   - NEVER calculate these yourself
   - CRITICAL: When you see "Player1 won: X (out of Y total points)", X is the number WON, not the total number of points in that category
   - LANGUAGE PRECISION FOR SITUATION POINTS (CRITICAL):
     * NEVER say "Player won X set points" or "Player won X break points"
     * In tennis, "winning a set point" means CONVERTING it - you can only win 3 set points max in best-of-5
     * The data shows who won POINTS THAT OCCURRED during set point situations (mix of for/against)
     * ALWAYS say: "Player won X of Y points in [situation] situations" or "X points when [situation] was at stake"
     * CORRECT: "Sinner won 6 of 8 points when a set point was at stake"
     * WRONG: "Sinner won 6 set points" (impossible - sounds like 6 conversions)
   
3. Reference chunks are SUPPLEMENTARY context only
   - If a chunk says "Match-wide totals" but the question asks about Set 3, DO NOT use that chunk
   - Acknowledge when data is limited to filtered points

RULES (CRITICAL):
- Use EXACT numbers from tree operations - NEVER calculate or estimate numbers yourself
- If you need a number that's not in the tree results, say "not available from data"
- For hybrid queries: Analyze the "Filtered Point Descriptions" to extract shot-level data
- Reference specific points when relevant (by point number)
- Provide tactical insight for PATTERNS only, not for inventing statistics
- If any operation has low confidence or small data size, explicitly mention this caveat
- If data size < 7 points, avoid strong tactical claims like "dominated" or "struggled"
- Be concise but complete
- SURFACE NEGATIVE EVIDENCE: If no meaningful difference is observed, SAY SO explicitly
  - "No significant difference was observed between X and Y"
  - "The data shows similar performance in both conditions"
  - Silence ≠ neutrality — explicitly state when there's nothing notable
- SET POINT / BREAK POINT LANGUAGE (CRITICAL):
  - You CANNOT win more than 3 set points in a best-of-5 match (one per set)
  - When you see "Sinner won 6 (out of 8)" for set_point situation:
    * This means: 6 of 8 points that occurred DURING set point situations
    * NOT: 6 set point conversions (impossible)
  - ALWAYS phrase as: "won X of Y points when [situation] was at stake"
  - NEVER phrase as: "won X set points" or "won X break points"
- SITUATION LANGUAGE: For questions about "big points" or multiple situations combined:
  - Say "won X of Y points in [situation] situations" not "won X [situation]"
  - Example: "Sinner won 6 of 8 points in set point situations" (correct)
  - NOT: "Sinner won 6 set points" (misleading - sounds like conversions)

FORBIDDEN:
- Do NOT calculate percentages yourself - only report what tree operations computed
- Do NOT invent counts - if winners/errors not in tree results, say "detailed breakdown not available"
- Do NOT extrapolate from small data sets to general patterns
- Do NOT use match-wide totals when the question asks about a specific set/situation
- Do NOT imply differences when the data shows none - be honest about null results

Answer:"""

        try:
            model_config = classification.get('_model_config', {})
            model_name = model_config.get('model_name', self.model)
            
            import google.generativeai as genai
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt, generation_config={"temperature": 0.7})
            answer = response.text
            
        except Exception as e:
            print(f"[SYNTHESIS] Error: {e}")
            # Fallback: just return the raw results
            answer = f"Query Plan Results:\n{final_context}"
        
        # Add debug section showing filtered points (controlled by DEBUG flag)
        if self.DEBUG_SHOW_POINTS and all_points:
            # CRITICAL: Deduplicate points by point_number (multi-op plans can have overlapping filters)
            # Example: Op A filters to "break points in Sets 4-5" (6 points)
            #          Op B filters to "break points in Sets 4-5 with 7+ shots" (3 points)
            # Without dedup, we'd show 9 points (6 + 3 with duplicates)
            seen_points = {}
            for pt in all_points:
                point_num = pt.get('point_number')
                if point_num and point_num not in seen_points:
                    seen_points[point_num] = pt
            
            unique_points = list(seen_points.values())
            
            debug_section = f"\n\n**DEBUG: Filtered Points ({len(unique_points)} unique)**\n"
            if len(all_points) > len(unique_points):
                debug_section += f"*(Deduplicated from {len(all_points)} total across operations)*\n"
            
            # NO SAMPLING - Show ALL unique points for maximum transparency
            for i, pt in enumerate(unique_points, 1):
                debug_section += self._format_debug_point(pt, i)
            answer += debug_section
        elif all_points and not self.DEBUG_SHOW_POINTS:
            # Production mode: deduplicate and show count
            seen_points = set(pt.get('point_number') for pt in all_points if pt.get('point_number'))
            unique_count = len(seen_points)
            answer += f"\n\n*Based on {unique_count} filtered points.*"
        
        return answer
    
    def _check_hybrid_routing(self, question: str, classification: Dict, filters: Dict) -> Dict:
        """
        Check if query needs hybrid routing (tree filter → narrative analysis).
        
        Hybrid is needed when:
        1. Query has tree-filterable conditions that aren't pre-computed with shot stats
        2. AND requires shot-level analysis (directions, patterns, etc.)
        3. OR multiple metrics_parsed entries need separate tree filtering (LLM synthesizes)
        
        Returns:
            Dict with 'needs_hybrid', 'reason', 'tree_filters', 'shot_trigger', 'multi_metric_filters'
        """
        question_lower = question.lower()
        
        # === CONDITION 0: MULTIPLE METRICS_PARSED WITH DIFFERENT TREE FILTERS ===
        # When LLM parses "X and Y combined" into multiple entries, each needs separate tree filtering
        # Then narrative LLM synthesizes the combined results
        metric_filters = classification.get('metric_filters', {})
        if len(metric_filters) > 1:
            # Collect tree-level filters from each metric (use class config)
            multi_filter_sets = []
            
            for metric_key, metric_data in metric_filters.items():
                mf = metric_data.get('filters', {})
                # Check for tree-level filters using class config
                tree_filters_for_metric = {}
                for dim in self.TREE_LEVEL_DIMENSIONS:
                    # Check if this metric has this dimension filter
                    if mf.get(dim):
                        tree_filters_for_metric[dim] = mf[dim]
                
                # Store metric key with its filters
                if tree_filters_for_metric:
                    multi_filter_sets.append({
                        'metric_key': metric_key,
                        'filters': tree_filters_for_metric
                    })
            
            # If multiple metrics have tree filters, trigger hybrid
            if len(multi_filter_sets) > 1:
                return {
                    'needs_hybrid': True,
                    'reason': f"Multiple metrics_parsed entries ({len(multi_filter_sets)}) need separate tree filtering → narrative synthesis",
                    'tree_filters': {},  # Will use multi_metric_filters instead
                    'shot_trigger': 'multi_metric',
                    'multi_metric_filters': multi_filter_sets
                }
        
        # === FILTERS THAT NEED HYBRID WHEN COMBINED WITH SHOT QUESTIONS ===
        # These filters are NEVER pre-computed with shot direction/pattern breakdowns
        # Use class config for tree-level dimensions
        ALWAYS_HYBRID_FILTERS = {
            dim: filters.get(dim) for dim in self.TREE_LEVEL_DIMENSIONS
            if filters.get(dim) is not None
        }
        
        # Situation needs hybrid when asking about shot DIRECTIONS (not just winners/errors)
        # NL has "winners at break points" but NOT "crosscourt at break points"
        situation_filter = filters.get('situation')
        
        # === DETECT SHOT-LEVEL QUESTION (CONFIG-DRIVEN) ===
        # These indicate we need to analyze shots, not just point outcomes
        
        # Build direction terms from GROUP_CONFIG
        direction_config = self.GROUP_CONFIG.get('shot_direction', {}).get('default_branches', [])
        shot_direction_terms = []
        for d in direction_config:
            shot_direction_terms.append(d.lower())
            shot_direction_terms.append(d.lower().replace('_', ' '))
            shot_direction_terms.append(d.lower().replace('_', '-'))
        # Add common aliases
        shot_direction_terms.extend(['dtl', 'cc', 'middle'])
        
        # Build shot type terms from GROUP_CONFIG
        shot_type_config = self.GROUP_CONFIG.get('shot_type', {}).get('default_branches', [])
        shot_type_terms = []
        for s in shot_type_config:
            shot_type_terms.append(s.lower())
            shot_type_terms.append(s.lower().replace('_', ' '))
        
        # Pattern and counting keywords (these are semantic, not from config)
        shot_pattern_keywords = [
            'shot pattern', 'shot sequence', 'rally pattern',
            'what shots', 'which shots', 'shot selection',
            'shot breakdown', 'shot distribution'
        ]
        
        shot_counting_keywords = [
            'how many shots', 'shot count', 'total shots'
        ]
        # Add shot counting with shot types from config: "forehand shots", "backhand shots"
        for st in shot_type_terms:
            shot_counting_keywords.append(f'{st} shots')
        
        has_direction_question = any(kw in question_lower for kw in shot_direction_terms)
        has_pattern_question = any(kw in question_lower for kw in shot_pattern_keywords)
        has_shot_counting = any(kw in question_lower for kw in shot_counting_keywords)
        
        is_shot_question = has_direction_question or has_pattern_question or has_shot_counting
        
        # Determine which trigger caused the shot question
        shot_trigger = None
        if has_direction_question:
            shot_trigger = 'direction'
        elif has_pattern_question:
            shot_trigger = 'pattern'
        elif has_shot_counting:
            shot_trigger = 'counting'
        
        # === CHECK FOR HYBRID CONDITIONS ===
        active_hybrid_filters = {k: v for k, v in ALWAYS_HYBRID_FILTERS.items() if v is not None}
        
        # Extract metrics from classification
        metrics = classification.get('metrics', [])
        
        # NEW: If the question is about ONE-SHOT types (serve/return/winner/error),
        # ALL shot attributes (direction, depth, type) are tree-capable - no hybrid needed
        is_one_shot_question = any(
            self.METRIC_CONFIG.get(m, {}).get('player_role') in self.ONE_SHOT_TYPES
            for m in metrics
        )
        
        # Condition 1: Always-hybrid filter + shot question
        # BUT SKIP if it's a one-shot question (those are tree-capable)
        if active_hybrid_filters and is_shot_question and not is_one_shot_question:
            return {
                'needs_hybrid': True,
                'reason': f"Filter {list(active_hybrid_filters.keys())} + shot {shot_trigger} not pre-computed",
                'tree_filters': active_hybrid_filters,
                'shot_trigger': shot_trigger
            }
        
        # Condition 2: Situation + shot direction (situation stats exist, but not with directions)
        # BUT SKIP if it's a one-shot question (those are tree-capable)
        if situation_filter and has_direction_question and not is_one_shot_question:
            return {
                'needs_hybrid': True,
                'reason': f"Situation '{situation_filter}' + shot direction not pre-computed",
                'tree_filters': {'situation': situation_filter},
                'shot_trigger': 'direction'
            }
        
        # Condition 3: QUALITATIVE ANALYSIS on filtered points
        # Questions asking "how", "who handled", "composure", "resilience", etc. on specific point subsets
        # These need tree filtering for precision, then LLM for narrative analysis
        # NOTE: Keywords must be specific enough to avoid false positives
        qualitative_keywords = [
            # Mental/pressure
            'held up better', 'handled better', 'composure', 'resilience', 'mental strength',
            'under pressure', 'clutch', 'recovered', 'pressure points',
            # Momentum/turning points (specific phrases, not just "shift")
            'momentum', 'momentum shift', 'momentum swing', 'turning point', 'turning points',
            'mini turning', 'shifted momentum', 'key moment', 'key moments', 'pivotal',
            'decisive', 'critical point', 'critical moment',
            # Narrative requests
            'what happened', 'tell me about', 'describe', 'explain', 'story of', 'narrative',
            # Tactical analysis
            'how did', 'tactics', 'tactical', 'strategy', 'approach', 'responded', 'game plan',
            # Pattern/adaptation
            'adapted', 'adjusted', 'changed approach', 'pattern', 'trend'
        ]
        
        has_qualitative_question = any(kw in question_lower for kw in qualitative_keywords)
        
        # Check for ANY tree-level filter (not just situation/point_score)
        # Use active_hybrid_filters which already collected all tree-level filters
        active_tree_filters = active_hybrid_filters if active_hybrid_filters else {}
        if not active_tree_filters:
            # Also check common narrative filters: situation, point_score, set
            for dim in ['situation', 'point_score', 'set', 'serve_number', 'role']:
                if filters.get(dim):
                    active_tree_filters[dim] = filters[dim]
        
        if has_qualitative_question and active_tree_filters:
            return {
                'needs_hybrid': True,
                'reason': f"Qualitative analysis with filters {list(active_tree_filters.keys())} needs tree filter + narrative synthesis",
                'tree_filters': active_tree_filters,
                'shot_trigger': 'qualitative'
            }
        
        return {'needs_hybrid': False, 'reason': None, 'tree_filters': {}, 'shot_trigger': None}
    
    def _handle_hybrid_query(self, question: str, classification: Dict, hybrid_result: Dict, top_k: int = None) -> str:
        """
        Handle hybrid queries: Use tree to filter points, then narrative to analyze shots.
        
        Steps:
        1. Use tree to filter to matching points (guarantees completeness)
        2. Extract point texts from filtered points
        3. Pass filtered point texts to LLM for shot-level analysis
        4. Show cited points in debug
        
        For multi-metric queries (e.g., "30-30 and deuce combined"):
        - Filter points for EACH metric's filters separately
        - Combine all filtered points
        - Let narrative LLM synthesize the combined analysis
        """
        print("[HYBRID] Step 1: Filtering points using tree...")
        
        if not hasattr(self, 'point_by_point') or not self.point_by_point:
            print("[HYBRID] ERROR: point_by_point data not available")
            return self._handle_narrative_query(question, classification, top_k)
        
        # === MULTI-METRIC HANDLING ===
        # When multiple metrics_parsed entries have different tree filters,
        # filter for EACH separately and combine results
        multi_metric_filters = hybrid_result.get('multi_metric_filters')
        if multi_metric_filters and len(multi_metric_filters) > 1:
            print(f"[HYBRID] Multi-metric mode: {len(multi_metric_filters)} filter sets")
            all_filtered_points = {}  # point_number -> (point, metric_keys)
            
            for mf_entry in multi_metric_filters:
                metric_key = mf_entry['metric_key']
                mf_filters = mf_entry['filters']
                print(f"[HYBRID]   Filtering for metric '{metric_key}' with filters: {mf_filters}")
                
                for pt in self.point_by_point:
                    include = True
                    
                    # Apply each filter in this metric's filter set
                    for dim, value in mf_filters.items():
                        if not include:
                            break
                        
                        if dim == 'set':
                            pt_set = pt.get('set_number') or pt.get('_metadata', {}).get('set_number')
                            if pt_set != value:
                                include = False
                        
                        elif dim == 'situation':
                            pt_situation = pt.get('situation', {})
                            if isinstance(pt_situation, dict):
                                pt_situation_type = pt_situation.get('type', '')
                            else:
                                pt_situation_type = str(pt_situation)
                            is_situation = (
                                pt_situation_type == value or
                                pt.get(f'is_{value}', False) or
                                pt.get('_metadata', {}).get(f'is_{value}', False)
                            )
                            if not is_situation:
                                include = False
                        
                        elif dim == 'point_score':
                            pt_score = pt.get('point_score') or pt.get('_metadata', {}).get('point_score', '')
                            normalized_pt = self._normalize_point_score(pt_score)
                            normalized_filter = self._normalize_point_score(value)
                            if normalized_pt != normalized_filter:
                                include = False
                        
                        elif dim == 'rally_length':
                            pt_rally = pt.get('rally_length') or pt.get('_metadata', {}).get('rally_length', 0)
                            if isinstance(value, (tuple, list)) and len(value) == 2:
                                min_val, max_val = value
                                if not (min_val <= pt_rally <= max_val):
                                    include = False
                            elif isinstance(value, int):
                                if pt_rally != value:
                                    include = False
                    
                    if include:
                        pt_num = pt.get('point_number')
                        if pt_num not in all_filtered_points:
                            all_filtered_points[pt_num] = (pt, [metric_key])
                        else:
                            all_filtered_points[pt_num][1].append(metric_key)
            
            # Convert to list
            filtered_points = [entry[0] for entry in all_filtered_points.values()]
            print(f"[HYBRID] Combined: {len(filtered_points)} unique points from {len(multi_metric_filters)} filter sets")
            
            # Now continue with standard hybrid flow using combined points
            # (skip the single-filter logic below)
            return self._finish_hybrid_query(question, classification, filtered_points, top_k, hybrid_result)
        
        # === SINGLE FILTER SET (original logic) ===
        tree_filters = hybrid_result.get('tree_filters', {})
        
        # Filter points using tree logic
        filtered_points = []
        filters = classification.get('filters', {})
        
        for pt in self.point_by_point:
            include = True
            
            # Apply set filter
            if tree_filters.get('set'):
                pt_set = pt.get('set_number') or pt.get('_metadata', {}).get('set_number')
                if pt_set != tree_filters['set']:
                    include = False
            
            # Apply situation filter
            if include and tree_filters.get('situation'):
                situation = tree_filters['situation']
                pt_situation = pt.get('situation', {})
                if isinstance(pt_situation, dict):
                    pt_situation_type = pt_situation.get('type', '')
                else:
                    pt_situation_type = str(pt_situation)
                
                # Also check boolean flags
                is_situation = (
                    pt_situation_type == situation or
                    pt.get(f'is_{situation}', False) or
                    pt.get('_metadata', {}).get(f'is_{situation}', False)
                )
                if not is_situation:
                    include = False
            
            # Apply point_score filter (supports single value OR list of values)
            if include and tree_filters.get('point_score'):
                pt_score = pt.get('point_score') or pt.get('_metadata', {}).get('point_score', '')
                normalized_pt = self._normalize_point_score(pt_score)
                
                filter_value = tree_filters['point_score']
                if isinstance(filter_value, list):
                    # OR logic: point matches if it matches ANY score in the list
                    normalized_filters = [self._normalize_point_score(s) for s in filter_value]
                    if normalized_pt not in normalized_filters:
                        include = False
                else:
                    # Single value: exact match
                    normalized_filter = self._normalize_point_score(filter_value)
                    if normalized_pt != normalized_filter:
                        include = False
            
            # Apply rally_length filter
            if include and tree_filters.get('rally_length'):
                pt_rally = pt.get('rally_length') or pt.get('_metadata', {}).get('rally_length', 0)
                rally_filter = tree_filters['rally_length']
                
                if isinstance(rally_filter, (tuple, list)) and len(rally_filter) == 2:
                    # Range filter: (min, max) or [min, max]
                    min_val, max_val = rally_filter
                    if not (min_val <= pt_rally <= max_val):
                        include = False
                elif isinstance(rally_filter, str):
                    if rally_filter.startswith('<='):
                        if pt_rally > int(rally_filter[2:]):
                            include = False
                    elif rally_filter.startswith('>='):
                        if pt_rally < int(rally_filter[2:]):
                            include = False
                    elif rally_filter.startswith('<'):
                        if pt_rally >= int(rally_filter[1:]):
                            include = False
                    elif rally_filter.startswith('>'):
                        if pt_rally <= int(rally_filter[1:]):
                            include = False
                elif isinstance(rally_filter, int):
                    if pt_rally != rally_filter:
                        include = False
            
            # Apply game_number filter
            if include and tree_filters.get('game_number'):
                pt_game = pt.get('game_number_in_set') or pt.get('_metadata', {}).get('game_number_in_set')
                if pt_game != tree_filters['game_number']:
                    include = False
            
            if include:
                filtered_points.append(pt)
        
        print(f"[HYBRID] Step 2: Filtered to {len(filtered_points)} points (from {len(self.point_by_point)} total)")
        
        # Continue with common hybrid logic
        return self._finish_hybrid_query(question, classification, filtered_points, top_k, hybrid_result)
    
    def _finish_hybrid_query(self, question: str, classification: Dict, filtered_points: list, top_k: int, hybrid_result: Dict) -> str:
        """
        Complete hybrid query: Build context from filtered points and send to LLM for narrative synthesis.
        
        Called by _handle_hybrid_query after points are filtered (single or multi-filter modes).
        """
        tree_filters = hybrid_result.get('tree_filters', {})
        
        if not filtered_points:
            filter_desc = ", ".join([f"{k}={v}" for k, v in tree_filters.items()]) or "specified filters"
            return f"No points found matching the filters: {filter_desc}"
        
        # Build context from filtered point texts
        print("[HYBRID] Step 3: Building context from filtered points...")
        
        point_texts = []
        for pt in filtered_points:
            point_num = pt.get('point_number', '?')
            server = pt.get('server', '?')
            returner = pt.get('returner', '?')
            score = pt.get('score', '?')
            description = pt.get('point_text', pt.get('description', 'No description'))
            point_winner = pt.get('point_winner', '?')
            
            point_text = f"Point {point_num} [Server: {server} | Returner: {returner} | Score: {score}]:\n{description}\n[Point won by: {point_winner}]"
            point_texts.append(point_text)
        
        context_text = "\n\n".join(point_texts)
        
        # ALSO retrieve relevant chunks for qualitative analysis
        # The NL file may have pre-analyzed narrative (turning points, momentum shifts)
        chunk_context = ""
        if hybrid_result.get('shot_trigger') == 'qualitative' and hasattr(self, 'retrieve_relevant_chunks'):
            print("[HYBRID] Step 3b: Also retrieving relevant NL chunks for qualitative context...")
            # Use filters to ensure chunks are from the right subset (e.g., Set 3)
            chunks = self.retrieve_relevant_chunks(question, top_k=10, filters=tree_filters)
            if chunks:
                chunk_texts = []
                for chunk in chunks[:5]:
                    chunk_text = chunk.get('text', '')
                    chunk_section = chunk.get('metadata', {}).get('section', '')
                    # SHOTDIR chunks need full content for win percentages
                    if 'shotdir' in chunk_section.lower():
                        chunk_texts.append(chunk_text)
                    else:
                        chunk_texts.append(chunk_text[:2000] if len(chunk_text) > 2000 else chunk_text)
                chunk_context = "\n\nPRE-ANALYZED NARRATIVE CONTEXT:\n" + "\n---\n".join(chunk_texts)
                print(f"[HYBRID] Retrieved {len(chunks)} chunks for additional context")
        
        # Build prompt for LLM
        # Handle multi-metric case description
        multi_metric_filters = hybrid_result.get('multi_metric_filters')
        if multi_metric_filters:
            filter_description = " + ".join([f"{mf['metric_key']}({', '.join(f'{k}={v}' for k,v in mf['filters'].items())})" for mf in multi_metric_filters])
        else:
            filter_description = ", ".join([f"{k}={v}" for k, v in tree_filters.items()])
        
        prompt = f"""You are analyzing tennis match data. The following {len(filtered_points)} points have been filtered from the match based on: {filter_description}

QUESTION: {question}

FILTERED POINTS DATA:
{context_text}
{chunk_context}

Instructions:
- Analyze ONLY the points shown above (they are the complete set matching the filter)
- Count shots, directions, patterns as asked
- When referencing specific points, use their point numbers (e.g., "Point 45", "Points 23 and 67")
- Be precise with counts since you have the complete filtered dataset
- For shot directions, look for: crosscourt, down the line, inside-out, inside-in, down the middle
- If points came from MULTIPLE filter conditions (e.g., "30-30 AND deuce combined"), synthesize analysis across all conditions
- For narrative/qualitative questions (momentum, turning points, etc.), also use the PRE-ANALYZED NARRATIVE CONTEXT if provided

Answer:"""

        print("[HYBRID] Step 4: Sending to LLM for analysis...")
        
        # Use LLM to analyze
        try:
            model_config = classification.get('_model_config', {})
            model_name = model_config.get('model_name', self.model)
            temperature = model_config.get('temperature', 0.7)
            
            if self.llm_provider == "gemini":
                import google.generativeai as genai
                gen_config = {"temperature": temperature}
                
                try:
                    model = genai.GenerativeModel(model_name)
                    response = model.generate_content(prompt, generation_config=gen_config)
                    answer = response.text
                except Exception as e:
                    if "3-flash" in model_name.lower() and ("not found" in str(e).lower() or "404" in str(e)):
                        fallback_model = genai.GenerativeModel(self.model_25_flash)
                        response = fallback_model.generate_content(prompt, generation_config=gen_config)
                        answer = response.text
                    else:
                        raise
            else:
                # Fallback for non-Gemini
                answer = self._call_llm_simple(prompt)
        except Exception as e:
            print(f"[HYBRID] LLM error: {e}")
            answer = f"Error analyzing filtered points: {e}"
        
        # CRITICAL: Show cited points in debug (console)
        self._extract_and_show_cited_points(answer)
        
        # Removed console print - point information only shown to user on screen
        
        # CRITICAL: Append point details to ANSWER so user can see them in UI (not just console)
        # Reuse existing _format_debug_point function for consistency
        if filtered_points:
            filter_desc = filter_description or "specified filters"
            debug_section = f"\n\n**DEBUG: Points by Metric:**\n"
            debug_section += f"**Filter: {filter_desc} ({len(filtered_points)} points)**\n"
            for i, pt in enumerate(filtered_points, 1):
                debug_section += self._format_debug_point(pt, i)
            answer = answer + debug_section
        
        return answer
    
    def _extract_and_show_cited_points(self, answer: str):
        """
        Extract point numbers cited in narrative answer and display full point details.
        
        If the LLM answer references specific point numbers (e.g., "Point 23", "points 45 and 67"),
        extract those points from the PBP data and show them in debug output for verification.
        
        This ensures transparency when narrative answers cite specific plays - user sees full points
        just like analytical path shows matching_points.
        """
        import re
        
        # Pattern to match point number references:
        # "Point 23", "point 145", "Points 23, 45", "points 23 and 67", etc.
        pattern = r'\bpoints?\s+(\d+(?:\s*(?:,|and)\s*\d+)*)'
        matches = re.findall(pattern, answer, re.IGNORECASE)
        
        if not matches:
            return  # No point numbers cited
        
        # Extract all unique point numbers from matches
        cited_point_numbers = set()
        for match in matches:
            # Split on comma and 'and', extract digits
            nums = re.findall(r'\d+', match)
            cited_point_numbers.update(int(n) for n in nums)
        
        if not cited_point_numbers:
            return
        
        # Sort for display
        cited_point_numbers = sorted(cited_point_numbers)
        
        # Removed console print - point information only shown to user on screen
        
        # Look up points in point_by_point data
        if not hasattr(self, 'point_by_point') or not self.point_by_point:
            # Removed console print - point information only shown to user on screen
            return
        
        found_points = []
        for pt in self.point_by_point:
            point_num = pt.get('point_number')
            if point_num in cited_point_numbers:
                found_points.append(pt)
        
        if not found_points:
            # Removed console print - point information only shown to user on screen
            return
        
        # Removed console print - point information only shown to user on screen
        
        print("=" * 120)
    
    def _convert_rally_category_to_filter(self, category: str):
        """
        Convert rally_length_category value to rally_length filter.
        
        Examples:
            "0-4" -> (0, 4) or "<=4"
            "1-3" -> (1, 3)
            "4-6" -> (4, 6)
            "7-9" -> (7, 9)
            "10+" -> ">=10"
        
        Returns:
            tuple (min, max) for range filters, or string for comparison filters
        """
        if not category:
            return None
        
        category = str(category).strip()
        
        # Handle "X+" format (e.g., "10+")
        if category.endswith('+'):
            try:
                min_val = int(category[:-1])
                return f'>={min_val}'
            except ValueError:
                return None
        
        # Handle "X-Y" format (e.g., "0-4", "1-3", "4-6", "7-9")
        if '-' in category or '–' in category:
            # Split on hyphen or en-dash
            parts = category.replace('–', '-').split('-')
            if len(parts) == 2:
                try:
                    min_val = int(parts[0].strip())
                    max_val = int(parts[1].strip())
                    return (min_val, max_val)
                except ValueError:
                    return None
        
        # Handle single number (exact match)
        try:
            return int(category)
        except ValueError:
            return None
    
    def _extract_current_set(self, score: str) -> int:
        """
        Extract current set number from score string.
        
        Handles multiple formats:
        - "Djokovic 0-0 1-2" (name + sets + games) â†' Set 1
        - "Djokovic 1-0 0-0" (name + sets + games) -> Set 2
        - "0-0 1-2 15-30" (sets + games + points) -> Set 1
        - "2-1 3-2 40-30" (sets + games + points) -> Set 4
        """
        import re
        
        # Find all X-X patterns
        patterns = re.findall(r'(\d+)-(\d+)', score)
        
        if not patterns:
            return None
        
        # First X-X pattern that could be a set score (typically 0-0 to 3-2 range)
        for p1, p2 in patterns:
            p1_int, p2_int = int(p1), int(p2)
            # Set scores are typically 0-3 range, games can be 0-7+
            # If both are â‰¤ 3, it's likely the set score
            if p1_int <= 3 and p2_int <= 3:
                return p1_int + p2_int + 1
        
        # Fallback: use first pattern (may be inaccurate for some formats)
        p1, p2 = patterns[0]
        return int(p1) + int(p2) + 1
    
    def _is_break_point_score(self, score_str: str) -> bool:
        """
        Determine if a score represents a break point for the returner.
        Break point = returner has chance to win the game (win the break).
        
        Score format in point-by-point: "X-Y A-B C-D" where:
        - X-Y = Sets (from server's perspective)
        - A-B = Games (from server's perspective)  
        - C-D = Points in current game (server points - returner points)
        
        Break point scenarios (from SERVER's perspective, meaning RETURNER has BP):
        - 0-40 (three break points)
        - 15-40 (two break points)
        - 30-40 (one break point)
        - 40-AD (advantage returner = break point)
        """
        import re
        # Extract just the points portion (last part of score)
        parts = score_str.strip().split()
        if not parts:
            return False
        
        # Get the points score (should be last element like "30-40" or "40-AD")
        points_part = parts[-1] if parts else ""
        
        # Handle various formats
        points_match = re.match(r'(\d+|AD)-(\d+|AD)', points_part, re.IGNORECASE)
        if not points_match:
            return False
        
        server_points = points_match.group(1).upper()
        returner_points = points_match.group(2).upper()
        
        # Break point for returner (server facing break point):
        # - 0-40, 15-40, 30-40 (server trailing by potential game loss)
        # - 40-AD (advantage to returner)
        break_point_scores = [
            ('0', '40'), ('15', '40'), ('30', '40'),
            ('40', 'AD')
        ]
        
        return (server_points, returner_points) in break_point_scores
    
    def _is_game_point_score(self, score_str: str) -> bool:
        """
        Determine if server has game point (about to win their service game).
        """
        import re
        parts = score_str.strip().split()
        if not parts:
            return False
        
        points_part = parts[-1] if parts else ""
        points_match = re.match(r'(\d+|AD)-(\d+|AD)', points_part, re.IGNORECASE)
        if not points_match:
            return False
        
        server_points = points_match.group(1).upper()
        returner_points = points_match.group(2).upper()
        
        # Game point for server:
        # - 40-0, 40-15, 40-30 (server at 40, returner not)
        # - AD-40 (advantage to server)
        game_point_scores = [
            ('40', '0'), ('40', '15'), ('40', '30'),
            ('AD', '40')
        ]
        
        return (server_points, returner_points) in game_point_scores
    
    def _is_grand_slam(self) -> bool:
        """Check if the current match is a Grand Slam tournament."""
        if not self.tournament:
            return False
        
        grand_slams = [
            'Australian Open',
            'French Open',
            'Wimbledon',
            'US Open',
            'Roland Garros',  # Alternate name
        ]
        
        tournament_lower = self.tournament.lower()
        return any(slam.lower() in tournament_lower for slam in grand_slams)
    
    def _get_tiebreak_threshold(self, set_number: int) -> int:
        """
        Get the point threshold for winning a tiebreak based on set number and tournament.
        
        Args:
            set_number: Current set number (1-5)
        
        Returns:
            7 for standard tiebreaks, 10 for 5th set super tiebreaks in Grand Slams
        """
        # Grand Slam 5th set (or 3rd set for best-of-3) uses 10-point tiebreak
        if self._is_grand_slam() and set_number >= 5:
            return 10
        
        # Standard tiebreak
        return 7
    
    def _parse_tiebreak_score(self, score_str: str) -> tuple:
        """
        Parse tiebreak score from score string.
        
        Args:
            score_str: Full score string like "2-2 6-6 5-4"
        
        Returns:
            Tuple of (server_points, returner_points) or (None, None) if not a tiebreak
        """
        import re
        parts = score_str.strip().split()
        
        if len(parts) < 2:
            return (None, None)
        
        # Check if games are 6-6 (tiebreak)
        game_match = re.match(r'(\d+)-(\d+)', parts[1])
        if not game_match:
            return (None, None)
        
        games_server = int(game_match.group(1))
        games_returner = int(game_match.group(2))
        
        # Must be 6-6 for tiebreak
        if not (games_server == 6 and games_returner == 6):
            return (None, None)
        
        # Parse tiebreak points (last part)
        if len(parts) < 3:
            return (None, None)
        
        points_match = re.match(r'(\d+)-(\d+)', parts[-1])
        if not points_match:
            return (None, None)
        
        try:
            server_tb_points = int(points_match.group(1))
            returner_tb_points = int(points_match.group(2))
            return (server_tb_points, returner_tb_points)
        except:
            return (None, None)
    
    def _is_deuce_score(self, score_str: str) -> bool:
        """Determine if score is at deuce (40-40)."""
        import re
        parts = score_str.strip().split()
        if not parts:
            return False
        
        points_part = parts[-1] if parts else ""
        return points_part.upper() in ['40-40', 'DEUCE']
    
    def _is_set_point_score(self, score_str: str) -> bool:
        """
        Determine if a score represents a set point.
        Set point = player has chance to win the current set.
        
        Score format: "X-Y A-B C-D" where:
        - X-Y = Sets (from server's perspective)
        - A-B = Games (from server's perspective)
        - C-D = Points in current game (server points - returner points) OR tiebreak points
        
        Set point scenarios:
        1. Server serving for set: Game score is 5-X (X < 5) AND game point (40-0, 40-15, 40-30, AD-40)
        2. Returner serving for set: Game score is X-5 (X < 5) AND break point (0-40, 15-40, 30-40, 40-AD)
        3. Tiebreak: At 6-6 in games AND one player has 6+ points (or 9+ for super tiebreak) AND is leading by 1+
        """
        import re
        if not score_str:
            return False
        
        parts = score_str.strip().split()
        if len(parts) < 2:
            return False
        
        # Extract game score (second part, e.g., "5-3" or "6-6")
        game_match = re.match(r'(\d+)-(\d+)', parts[1] if len(parts) > 1 else '')
        if not game_match:
            return False
        
        games_server = int(game_match.group(1))
        games_returner = int(game_match.group(2))
        
        # Check if in tiebreak (6-6 only - 7-6 or 6-7 means set is over)
        if games_server == 6 and games_returner == 6:
            # Parse tiebreak score
            server_tb_pts, returner_tb_pts = self._parse_tiebreak_score(score_str)
            
            if server_tb_pts is None or returner_tb_pts is None:
                # Can't parse tiebreak score, assume no set point
                return False
            
            # Get the set number to determine tiebreak threshold
            set_number = self._extract_current_set(score_str)
            threshold = self._get_tiebreak_threshold(set_number)
            
            # Set point if:
            # - Server has threshold-1 points (e.g., 6 for standard, 9 for super) AND is leading
            # - Returner has threshold-1 points AND is leading
            # OR either player has threshold+ points and is leading by 1+
            
            # Server set point: has threshold-1+ points AND leading by 1+
            if server_tb_pts >= (threshold - 1) and server_tb_pts > returner_tb_pts:
                return True
            
            # Returner set point: has threshold-1+ points AND leading by 1+
            if returner_tb_pts >= (threshold - 1) and returner_tb_pts > server_tb_pts:
                return True
            
            return False
        
        # Check if server is serving for set (5-X where X < 5)
        if games_server == 5 and games_returner < 5:
            # Check if server has game point
            return self._is_game_point_score(score_str)
        
        # Check if returner is serving for set (X-5 where X < 5)
        if games_returner == 5 and games_server < 5:
            # Check if returner has game point (which is break point for server)
            return self._is_break_point_score(score_str)
        
        return False
    
    def _is_match_point_score(self, score_str: str) -> bool:
        """
        Determine if a score represents a match point.
        Match point = player has chance to win the entire match.
        
        Score format: "X-Y A-B C-D" where:
        - X-Y = Sets (from server's perspective)
        - A-B = Games (from server's perspective)
        - C-D = Points in current game (server points - returner points) OR tiebreak points
        
        Match point scenarios:
        1. Best of 3: Player up 2-0 in sets AND has set point
        2. Best of 5: Player up 3-0 or 3-1 in sets AND has set point
        3. Any format: Player up by 1 set in final set AND has set point
        """
        import re
        if not score_str:
            return False
        
        parts = score_str.strip().split()
        if len(parts) < 1:
            return False
        
        # Extract set score (first part, e.g., "2-0" or "3-1")
        set_match = re.match(r'(\d+)-(\d+)', parts[0])
        if not set_match:
            return False
        
        sets_server = int(set_match.group(1))
        sets_returner = int(set_match.group(2))
        
        # Determine if this is a potential match point
        # Match point requires:
        # 1. Player is up by enough sets to win on next set, AND
        # 2. That player has set point in current set
        
        # Server can win match if:
        # - Best of 3: Up 2-0 (needs 1 more set) OR up 1-0 in final set (set 3)
        # - Best of 5: Up 3-0 or 3-1 (needs 1 more set) OR up 2-1 in final set (set 5)
        server_can_win = False
        if sets_server == 2 and sets_returner == 0:  # Best of 3, up 2-0
            server_can_win = True
        elif sets_server == 3 and sets_returner <= 1:  # Best of 5, up 3-0 or 3-1
            server_can_win = True
        elif sets_server == 1 and sets_returner == 0 and len(parts) > 1:  # Final set, up 1-0
            # Check if this is set 3 (best of 3) or set 5 (best of 5)
            # We can't determine format from score alone, but if it's the final set and they're up, it's MP
            server_can_win = True
        
        # Returner can win match if:
        # - Best of 3: Up 0-2 (needs 1 more set) OR up 0-1 in final set (set 3)
        # - Best of 5: Up 0-3 or 1-3 (needs 1 more set) OR up 1-2 in final set (set 5)
        returner_can_win = False
        if sets_returner == 2 and sets_server == 0:  # Best of 3, up 0-2
            returner_can_win = True
        elif sets_returner == 3 and sets_server <= 1:  # Best of 5, up 0-3 or 1-3
            returner_can_win = True
        elif sets_returner == 1 and sets_server == 0 and len(parts) > 1:  # Final set, up 0-1
            returner_can_win = True
        
        # Check if either player can win AND has set point
        # (Use the fixed _is_set_point_score which now handles tiebreaks correctly)
        if (server_can_win or returner_can_win) and self._is_set_point_score(score_str):
            return True
        
        return False
    
    def _llm_parse_query(self, question: str) -> Dict[str, Any]:
        """
        Use LLM to parse query into structured classification.
        
        This is the FIRST step - LLM understands the query structure before taxonomy routing.
        
        Returns structured JSON with:
        - player: Which player is being asked about
        - shot_type: backhand, forehand, serve, etc.
        - shot_modifier: slice, topspin, drop shot, etc.
        - metric: winners, unforced_errors, aces, etc.
        - situation: break_point, game_point, deuce, etc.
        - set_filter: specific set number or None
        - set_comparison: {set_a: [1], set_b: [3]} for comparisons
        - direction: crosscourt, down_the_line, etc.
        - query_type: analytical, comparative, narrative
        - actual_question: What the user really wants to know
        """
        import json
        
        player1 = self.player1 or "Player 1"
        player2 = self.player2 or "Player 2"
        
        # Build match context including set winners
        match_context = f"{player1} vs {player2}"
        if hasattr(self, 'match_score') and self.match_score:
            match_context += f"\nMatch Score: {self.match_score}"
            
            # Add which sets each player won
            if hasattr(self, 'set_winners') and self.set_winners:
                p1_sets_won = self._get_sets_won_by_player(player1)
                p2_sets_won = self._get_sets_won_by_player(player2)
                if p1_sets_won:
                    match_context += f"\n{player1} won sets: {p1_sets_won}"
                if p2_sets_won:
                    match_context += f"\n{player2} won sets: {p2_sets_won}"
        
        # === ADD FILTER INVENTORY - CRITICAL FOR GROUNDED QUERIES ===
        # LLM now knows EXACTLY what values exist in this match
        filter_inventory_text = ""
        if hasattr(self, 'match_filter_inventory') and self.match_filter_inventory:
            inv = self.match_filter_inventory
            filter_inventory_text = f"""
AVAILABLE FILTERS IN THIS MATCH (use ONLY these values):

=== NEW TAXONOMY (PRIMARY - USE THESE) ===
- Shot Phases: {inv.get('shot_phases', [])} (serve, return, rally, net)
- Contact Types: {inv.get('contact_types', [])} (groundstroke, volley, half_volley, swinging_volley, overhead)
- Spins: {inv.get('spins', [])} (slice, flat, topspin)
- Intents: {inv.get('intents', [])} (approach, drop_shot, lob, passing_shot, winner_attempt)
- Locations: {inv.get('locations', [])} (baseline, mid_court, net, service_line)

=== CORE DIMENSIONS ===
- Shot Types: {inv.get('shot_types', [])} (forehand, backhand, serve) - NOTE: overhead/smash is a contact_type, not shot_type
- Directions: {inv.get('directions', [])} (crosscourt, down_the_line, inside_out, inside_in, down_the_middle)
- Serve Targets: {inv.get('serve_targets', [])} (wide, body, t)
- Depths: {inv.get('depths', [])} (shallow, deep, very_deep)
- Outcomes: {inv.get('outcomes', [])} (winner, unforced_error, forced_error, ace, etc.)

=== LEGACY (backward compatibility - prefer new taxonomy above) ===
- Modifiers (LEGACY): {inv.get('shot_modifiers', [])} - Use contact_types/spins/intents instead
- Court Positions (LEGACY): {inv.get('court_positions', [])} - Use locations instead
- Net Play Types (LEGACY): {inv.get('net_play_types', [])} - Derive from location=net + contact_type

=== OTHER FILTERS ===
- Court Sides: {inv.get('court_sides', [])}
- Sets Played: {inv.get('sets_played', [])}
- Rally Categories: {inv.get('rally_categories', [])}
- Serve+1 Shot Types: {inv.get('serve_plus_one_shot_types', [])}
- Pressure Levels: {inv.get('pressure_levels', [])}
- Players: {inv.get('players', [])}
"""
            if hasattr(self, 'match_stats_summary') and self.match_stats_summary:
                stats = self.match_stats_summary
                filter_inventory_text += f"""
MATCH STATS SUMMARY:
- Total Points: {stats.get('total_points', 0)}
- Total Shots: {stats.get('total_shots', 0)}
- Aces: {stats.get('aces', 0)}
- Double Faults: {stats.get('double_faults', 0)}
- Winners: {stats.get('winners', 0)}
- Unforced Errors: {stats.get('unforced_errors', 0)}

COMPREHENSIVE ALIAS MAPPINGS (system auto-normalizes):
- Directions: cc/xc/cross-court = crosscourt, dtl/line = down_the_line, dtm = down_the_middle, io = inside_out, ii = inside_in
- Shot Types: fh = forehand, bh = backhand, sv = serve, ret = return, oh = overhead, smash = overhead
- Modifiers: chip/underspin = slice, vb/vol = volley, ds/dropshot = drop_shot, app = approach, sv = swinging_volley, hv = half_volley
- Depths: short = shallow
- Outcomes: wnr/w = winner, ue/unforced = unforced_error, fe/forced = forced_error, df = double_fault
- Serve Targets (CONTEXT: for serves only): "down the t"/"center"/"middle" -> t, "out wide" -> wide, "to body"/"at body"/"jam" -> body

IMPORTANT CONTACT TYPE MAPPINGS:
- "smash" / "smashes" / "overhead" -> contact_type: "overhead" (NOT shot_type)
- Overheads/smashes use shot_type: "forehand" or "backhand" (the stroke used), contact_type: "overhead"

CRITICAL CONTEXT-DEPENDENT MAPPINGS:
- "down the middle" / "center" / "middle" has TWO different meanings:
  1. For GROUNDSTROKES (direction): "down_the_middle" (rally shot direction)
  2. For SERVES (serve_target): "t" (serve to the T / center of service box)
  
- When user asks about SERVES: "serves down the middle" / "serves to center" -> serve_target: "t"
- When user asks about RALLY SHOTS: "forehand down the middle" -> direction: "down_the_middle"
- Context is KEY - look at whether it's about serves or groundstrokes

ALIAS MAPPING RULES:
- ALWAYS map user phrases to the inventory values listed above
- Use context (serves vs groundstrokes) to determine correct mapping
- Prioritize exact inventory matches over aliases

HIERARCHIES (superset filters include all subsets):
- 'volley' matches: volley, swinging_volley, half_volley, drop_volley
- 'net_shot' matches: all volleys + overhead
- 'errors' matches: unforced_error, forced_error, double_fault
"""
        
        parse_prompt = f"""You are a tennis query parser. Parse this question into structured JSON.

MATCH CONTEXT:
{match_context}
{filter_inventory_text}
QUESTION: {question}

Return ONLY valid JSON (no markdown, no explanation) with these fields:
{{
  "player": "name of player being asked about, or 'both' or null",
  
  // === NEW TAXONOMY (PRIMARY - use these for cleaner queries) ===
  "shot_phase": "serve|return|rally|net|null - tactical phase of the shot",
  "contact_type": "groundstroke|volley|half_volley|swinging_volley|overhead|null - how ball is struck",
  "spin": "slice|flat|topspin|null - ball rotation",
  "intent": "approach|drop_shot|lob|passing_shot|winner_attempt|null - tactical purpose",
  "location": "baseline|mid_court|net|service_line|null - court position",
  
  // === LEGACY FIELDS (for backward compatibility, prefer new taxonomy above) ===
  "shot_type": "forehand|backhand|serve|null - base stroke type. NOTE: overhead/smash is NOT a shot_type, use contact_type: overhead",
  "shot_modifier": "DEPRECATED - use contact_type/spin/intent instead. slice|topspin|flat|approach|volley|null",
  
  // === METRICS (N-metric support) ===
  // GENERIC: Each sub-question gets its OWN COMPLETE filter set
  // The LLM decides what filters each metric needs - code doesn't know about specific metrics
  "metrics_parsed": [
    // Array of metric objects - ONE per distinct question/metric in the query
    // EACH metric has its OWN filters - they are INDEPENDENT, not inherited
    {{
      "metric": "the metric name - use BASE metric names like: first_serve_pct, first_serve_win_pct, win_percentage, winners, aces, double_faults, unforced_errors, forced_errors, points_won, etc. NEVER use compound names like 'ace_percentage' or 'winner_percentage' - use 'aces' or 'winners' and the system calculates percentage",
      "filters": {{
        // COMPLETE filter set for THIS metric only - include ALL relevant filters
        // CRITICAL: first_serve_pct needs serve_number=null (ALL serves) to calculate percentage correctly
        // first_serve_win_pct needs serve_number=1 (only first serves that went in)
        "serve_number": "1|2|null - Use 1 for first_serve_win_pct, null for first_serve_pct",
        "role": "server|returner|null", 
        "situation": "break_point|game_point|etc|null",
        "shot_type": "forehand|backhand|serve|null",
        "direction": "crosscourt|down_the_line|null",
        "court_zone": "net|baseline|null",
        "depth": "shallow|deep|null"
        // ... any other filter this specific metric needs
      }},
      "context": "serve|return|rally|net|situation|null - for grouping related metrics"
    }}
  ],
  // LEGACY (kept for backward compatibility, prefer metrics_parsed above)
  "metric": "primary metric for simple single-metric queries",
  "secondary_metric": "DEPRECATED - use metrics_parsed instead",
  "situation": "break_point|game_point|set_point|match_point|deuce|tiebreak|null",
  "situation_comparison": {{"situation_a": "tiebreak", "situation_b": "non_tiebreak"}} or null - for comparing tiebreak vs rest of match",
  "role": "server|returner|null - when asking about a player in a specific role",
  "serve_number": "1 for 1st serve, 2 for 2nd serve, or null for both. CRITICAL: first_serve_pct MUST be null (needs ALL serves), first_serve_win_pct MUST be 1",
  "serve_target": "wide|body|t|null - specific serve direction as filter",
  "court_side": "deuce|ad|null - specific court side as filter",
  "court_zone": "net|baseline|null - CRITICAL: Use 'net' for 'net points' queries, NOT shot_type volley!",
  "set_filter": "single set number (1-5) or null",
  "set_comparison": {{"set_a": [list of sets for first group], "set_b": [list of sets for second group]}},
  
  // === RALLY LENGTH HANDLING (CRITICAL!) ===
  // DO NOT use rally_length_category in filters! It's ONLY for grouping.
  // For filtering by rally length:
  //   - "when rally was 0-4 shots" â†' metrics_parsed: [{{"filters": {{"rally_length_range": "0-4"}}}}]
  //   - "when rally was 5+ shots" â†' metrics_parsed: [{{"filters": {{"rally_length_range": "5+"}}}}]
  //   - "when rally was exactly 7 shots" â†' metrics_parsed: [{{"filters": {{"rally_length": 7}}}}]
  // For grouping by rally length:
  //   - "short vs long rallies" â†' group_by: "rally_length_category"
  //   - "points by rally length" â†' group_by: "rally_length_category"
  
  "group_by": "sets|set_groups|rally_length_category|court_side|serve_number|serve_direction|shot_direction|return_depth|shot_type|shot_modifier|spin|court_position|depth|outcome|shot_number|game_outcome|player|situation|pressure_level|serve_plus_one_type|net_play_type|null",
  "secondary_group_by": "for 2D analysis - same options as group_by, or null",
  "tertiary_group_by": "for 3D analysis - same options as group_by, or null (rarely needed)",
  "n_dimensional": "true if query has 3+ combined dimensions (filters + groups), else false",
  "direction": "crosscourt|down_the_line|inside_out|inside_in|down_the_middle|null",
  "depth": "shallow|deep|very_deep|null",
  "chain_logic": {{"shot_a": "string OR dict with keys: player/shot_type/direction/depth/spin", "shot_b": "string or dict or null"}} or null - for chain patterns. Use DICT format when shot has player+attributes.,
  "analysis_type": "count|percentage|comparison|ratio|trend|2d_cross_tab|chain|momentum|null",
  "query_type": "analytical|narrative - 'analytical' if clear calculable metric, 'narrative' if vague/strategic question",
  "metric_clarity": "clear|vague - 'clear' if the question specifies exactly what to measure (e.g., 'ace count', 'first serve %'), 'vague' if unclear (e.g., 'how did serves change?', 'forehand effectiveness')",
  "actual_question": "brief restatement of what user wants to know"
}}

CRITICAL RULES:
0. **NEW TAXONOMY USAGE**: 
   - For "net play" / "at the net" / "volleys": set location: "net" and contact_type: "volley" (NOT shot_modifier)
   - For "approach shots": set intent: "approach" (NOT shot_modifier)
   - For "drop shots": set intent: "drop_shot" (NOT shot_type)
   - For "slice forehand": set shot_type: "forehand" AND spin: "slice" (NOT shot_modifier)
   - For "topspin backhand": set shot_type: "backhand" AND spin: "topspin"
   - The new taxonomy separates concerns: shot_type (what), contact_type (how), spin (rotation), intent (why), location (where)
   - DERIVE net play from location + contact_type, don't use legacy net_play_types

1. **METRIC CLARITY CHECK**: If the question is vague about WHAT to measure (e.g., "How did serves change?" - change in what?), set:
   - metric_clarity: "vague"
   - query_type: "narrative"
   Even if it seems analytical, vague questions need narrative context to answer properly.
   Examples of VAGUE: "How did X's serves change?", "Did serving improve?", "Forehand effectiveness", "Performance on break points"
   Examples of CLEAR: "First serve win %", "Ace count", "Break point conversion %", "Forehand winner count"

2. **NET POINTS**: When query asks about "net points", set location: "net" and metric: "net_points_won". Do NOT set shot_type: "volley"!
3. When comparing "sets he won vs sets he lost", ALWAYS populate BOTH set_a AND set_b
4. **COMPARISON DETECTION**: If query contains "compared to", "vs", "versus", "on X vs Y", "X vs Y", comparing ONE dimension's values:
   - Use group_by (NOT metrics_parsed)
   - That dimension goes ONLY in group_by, NOT in filters
   - Leave the filter as null
   - Examples:
   - "Ad Court compared to Deuce Court" -> {{"group_by": "court_side", "court_side": null}}
   - "T vs Wide vs Body" -> {{"group_by": "serve_direction", "serve_target": null}}
   - "Forehand vs Backhand winners" -> {{"group_by": "shot_type", "shot_type": null, "metric": "winners"}}
   - "Sinner's forehand vs backhand errors" -> {{"player": "Jannik Sinner", "group_by": "shot_type", "shot_type": null, "metric": "errors"}}
   - "Errors on forehand vs backhand" -> {{"group_by": "shot_type", "shot_type": null, "metric": "errors"}}
   - "Crosscourt vs Down the Line" -> {{"group_by": "shot_direction", "direction": null}}
   - "1st serve vs 2nd serve" -> {{"group_by": "serve_number", "serve_number": null}}
   - "Shallow vs Deep returns" -> {{"group_by": "return_depth", "depth": null}}
   - "Short vs Long rallies" -> {{"group_by": "rally_length_category"}}
   - DO NOT use metrics_parsed for these - use group_by!
5. For ratio questions (winners to errors), set analysis_type: "ratio"
6. For trend questions (across sets), set analysis_type: "trend"
7. For 2D analysis (direction ratio in sets won vs lost), use BOTH group_by AND secondary_group_by
8. For "when serving/returning", set role: "server" or "returner"
9. For complex queries with 3+ conditions (e.g., "on break points, serving to T, on Ad court"), set n_dimensional: true
10. Each filter (serve_target, court_side, situation, etc.) NARROWS the data - use as many as mentioned in the query UNLESS it's a comparison (see rule 4)
11. **BOTH PLAYERS DETECTION**: When query asks about "each player", "both players", "each", "which player", "who", "compare players", "player comparison", or similar terms indicating comparison of both players, ALWAYS set:
   - player: "both"
   - group_by: "player"
   Examples:
   - "How many winners did each player have?" -> {{"player": "both", "group_by": "player", "metric": "winners"}}
   - "How many winners did each have?" -> {{"player": "both", "group_by": "player", "metric": "winners"}}
   - "Compare aces for both players" -> {{"player": "both", "group_by": "player", "metric": "aces"}}
   - "Which player hit more forehand winners?" -> {{"player": "both", "group_by": "player", "shot_type": "forehand", "metric": "winners"}}
   - "Who had more break points saved?" -> {{"player": "both", "group_by": "player", "situation": "break_point", "metric": "points_won"}}
   - "Aces by player" -> {{"player": "both", "group_by": "player", "metric": "aces"}}

EXAMPLES BY ANALYSIS TYPE:

COUNTING:
- "How many aces?" â†' {{"metric": "aces", "analysis_type": "count"}}
- "Forehand winners in Set 3" â†' {{"shot_type": "forehand", "metric": "winners", "set_filter": 3}}

RALLY LENGTH (CRITICAL - Filter vs Group):
**FILTER** (when filtering to specific rally length range):
- "In Set 5, who won more points when the rally was 0-4 shots?" â†' {{
    "player": "both",
    "group_by": "player",
    "set_filter": 5,
    "metrics_parsed": [{{"metric": "points_won", "filters": {{"rally_length_range": "0-4"}}}}],
    "analysis_type": "comparison"
  }}
- "Who won more when rally was 5+ shots?" â†' {{
    "player": "both",
    "group_by": "player",
    "metrics_parsed": [{{"metric": "points_won", "filters": {{"rally_length_range": "5+"}}}}]
  }}
**GROUP** (when comparing rally length categories):
- "Short vs long rallies win %" â†' {{"group_by": "rally_length_category", "metric": "win_percentage"}}
- "Points by rally length" â†' {{"group_by": "rally_length_category"}}

GROUPING/COMPARISON (CRITICAL - dimension being compared goes in group_by, NOT filter):
- "T vs Wide serves" -> {{"group_by": "serve_direction", "serve_target": null}}
- "T vs Wide vs Body" -> {{"group_by": "serve_direction", "serve_target": null}}
- "Forehand vs Backhand winners" -> {{"group_by": "shot_type", "shot_type": null, "metric": "winners"}}
- "Sinner's forehand vs backhand winners" -> {{"player": "Jannik Sinner", "group_by": "shot_type", "shot_type": null, "metric": "winners"}}
- "How many forehand winners did Sinner hit compared to backhand winners?" -> {{"player": "Jannik Sinner", "group_by": "shot_type", "shot_type": null, "metric": "winners"}}
- "How many unforced errors did Sinner make on forehand vs backhand?" -> {{"player": "Jannik Sinner", "group_by": "shot_type", "shot_type": null, "metric": "unforced_errors"}}
- "Forehand errors vs backhand errors" -> {{"group_by": "shot_type", "shot_type": null, "metric": "errors"}}
- "Forced errors on forehand vs backhand" -> {{"group_by": "shot_type", "shot_type": null, "metric": "forced_errors"}}
- "Crosscourt vs Down the Line" -> {{"group_by": "shot_direction", "direction": null}}
- "1st serve vs 2nd serve win %" -> {{"group_by": "serve_number", "serve_number": null, "metric": "win_percentage"}}
- "Shallow vs Deep vs Very Deep returns" -> {{"group_by": "return_depth", "depth": null}}
- "Ad Court compared to Deuce Court" -> {{"group_by": "court_side", "court_side": null}}
- "Points by rally length" -> {{"group_by": "rally_length_category"}}
- "Stats in service games won vs lost" -> {{"group_by": "game_outcome", "role": "server"}}
- "Which player hit more aces?" -> {{"player": "both", "group_by": "player", "metric": "aces"}}
- "Who used body serves more?" -> {{"player": "both", "group_by": "player", "serve_target": "body", "metric": "count"}}

SET COMPARISON:
- "Errors in Set 1 vs Set 3" -> {{"set_comparison": {{"set_a": [1], "set_b": [3]}}}}
- "In the sets X won vs the sets X lost" -> Use the MATCH CONTEXT to determine which specific sets X won/lost, then set set_a and set_b accordingly
  Example: If Player A won sets [2, 3, 5] and lost sets [1, 4], then:
  - "Player A's stats in sets he won vs sets he lost" -> {{"player": "Player A", "set_comparison": {{"set_a": [2, 3, 5], "set_b": [1, 4]}}}}

SITUATION COMPARISON:
- "Net points in tiebreaks compared to rest of match" â†' {{"court_zone": "net", "metric": "net_points_won", "group_by": "situation", "situation_comparison": {{"situation_a": "tiebreak", "situation_b": "non_tiebreak"}}}}
- "Break points vs non-break points" â†' {{"group_by": "situation", "situation_comparison": {{"situation_a": "break_point", "situation_b": "non_break_point"}}}}

GAME-STATE TO POINT_SCORE MAPPING (CRITICAL!):
- "After losing the first point on serve" = points at 0-15 â†' {{"point_score": "0-15", "role": "server"}}
- "After winning the first point on serve" = points at 15-0 â†' {{"point_score": "15-0", "role": "server"}}
- "After going down 0-30" = points at 0-30 â†' {{"point_score": "0-30"}}
- "After going up 30-0" = points at 30-0 â†' {{"point_score": "30-0"}}
- "At deuce" = points at 40-40 â†' {{"point_score": "40-40"}}
Example: "Who won more points after losing the first point of the game on serve?"
â†' {{"metrics_parsed": [{{"metric": "points_won", "filters": {{"point_score": "0-15", "role": "server"}}}}], "query_type": "analytical"}}

MULTI-METRIC QUERIES (N metrics in one question - GENERIC FOR ALL METRIC TYPES):
**CRITICAL DISTINCTION:**
- Use "metrics_parsed" for DIFFERENT metrics or UNRELATED filters (e.g., "aces AND double faults")
- Use "group_by" for SAME metric with different values of ONE dimension (e.g., "forehand VS backhand winners")
- Keywords: "vs"/"compared to"/"versus" â†' group_by | "and"/"plus"/"also" â†' metrics_parsed

**COMBINED CONDITIONS (same metric, different filters - CRITICAL!):**
When query says "X and Y combined", "X plus Y", "both X and Y":
- Create MULTIPLE metrics_parsed entries for the SAME metric with DIFFERENT filters
- The tree will traverse for EACH entry and combine results
- "Points at 30-30 and deuce combined" â†' {{
    "metrics_parsed": [
      {{"metric": "points_won", "filters": {{"point_score": "30-30"}}, "context": "situation"}},
      {{"metric": "points_won", "filters": {{"situation": "deuce"}}, "context": "situation"}}
    ],
    "analysis_type": "count"
  }}
- "Winners in Set 1 and Set 5" â†' {{
    "metrics_parsed": [
      {{"metric": "winners", "filters": {{"set": 1}}}},
      {{"metric": "winners", "filters": {{"set": 5}}}}
    ]
  }}
- "Break points and game points combined" â†' {{
    "metrics_parsed": [
      {{"metric": "points_won", "filters": {{"situation": "break_point"}}}},
      {{"metric": "points_won", "filters": {{"situation": "game_point"}}}}
    ]
  }}

- "First serve % and first serve win %" â†' {{
    "metrics_parsed": [
      {{"metric": "first_serve_pct", "filters": {{"role": "server"}}, "context": "serve"}},
      {{"metric": "first_serve_win_pct", "filters": {{"role": "server", "serve_number": 1}}, "context": "serve"}}
    ]
  }}
  **CRITICAL RULE FOR first_serve_pct:**
  - first_serve_pct = (first serves IN) / (ALL serve attempts)
  - It needs ALL serves (both serve_number=1 AND serve_number=2) to calculate the denominator
  - DO NOT set serve_number filter for first_serve_pct - it must be null/omitted
  - first_serve_win_pct DOES need serve_number=1 because it's win % ON first serves that went in
- "Aces and double faults" -> {{
    "metrics_parsed": [
      {{"metric": "aces", "filters": {{"role": "server"}}, "context": "serve"}},
      {{"metric": "double_faults", "filters": {{"role": "server"}}, "context": "serve"}}
    ]
  }}
- "Break point save % and conversion %" -> {{
    "metrics_parsed": [
      {{"metric": "win_percentage", "filters": {{"situation": "break_point", "role": "server"}}, "context": "situation"}},
      {{"metric": "win_percentage", "filters": {{"situation": "break_point", "role": "returner"}}, "context": "situation"}}
    ]
  }}
- "Net points won and baseline winners" -> {{
    "metrics_parsed": [
      {{"metric": "points_won", "filters": {{"court_zone": "net"}}, "context": "net"}},
      {{"metric": "winners", "filters": {{"court_zone": "baseline"}}, "context": "rally"}}
    ]
  }}
- "Set 1 aces plus Set 3 aces" -> {{
    "metrics_parsed": [
      {{"metric": "aces", "filters": {{"set": 1}}, "context": "serve"}},
      {{"metric": "aces", "filters": {{"set": 3}}, "context": "serve"}}
    ]
  }}
- "Game point winners and break point winners" -> {{
    "metrics_parsed": [
      {{"metric": "winners", "filters": {{"situation": "game_point"}}, "context": "situation"}},
      {{"metric": "winners", "filters": {{"situation": "break_point"}}, "context": "situation"}}
    ]
  }}
- GENERIC: Each metric has its OWN complete filter set - works for ANY filter type (serve_number, situation, shot_type, direction, court_zone, court_side, set, depth, serve_target, role, etc.)
- Code doesn't know about specific metrics - LLM decides what filters each metric needs
- Related metrics (same context) will be synthesized together in the answer

RATIO ANALYSIS:
- "Winners to errors ratio" -> {{"metric": "winners", "secondary_metric": "errors", "analysis_type": "ratio"}}
- "Winners to unforced errors ratio" -> {{"metric": "winners", "secondary_metric": "unforced_errors", "analysis_type": "ratio"}}

TREND ANALYSIS:
- "How did serve % change across sets?" -> {{"metric": "first_serve_pct", "analysis_type": "trend"}}

2D CROSS-TAB:
- "IO vs DTL ratio in sets won vs lost" -> {{"group_by": "shot_direction", "secondary_group_by": "set_groups", "analysis_type": "2d_cross_tab"}}

ROLE-BASED:
- "When serving, break point saves" -> {{"role": "server", "situation": "break_point"}}
- "As returner, deep returns" -> {{"role": "returner", "group_by": "return_depth"}}
- **CRITICAL - SERVE EFFECTIVENESS vs SERVE SHOTS:**
  - "Serve effectiveness" / "serve win %" / "points won on serve" -> {{"role": "server", "metric": "win_percentage"}} (NO shot_type!)
  - "How many aces?" -> {{"metric": "aces"}} (NO shot_type needed - aces are detected by outcome)
  - "Forehand winners" -> {{"shot_type": "forehand", "metric": "winners"}} (shot_type IS the winning shot)
  - Do NOT set shot_type: "serve" for serve effectiveness - that filters to only aces/double faults!
  
- **CRITICAL - SERVE TARGET FILTER (DO NOT HALLUCINATE):**
  - "First serve percentage" / "Second serve won percentage" -> {{"serve_target": null}} (NO serve_target filter!)
  - "Serve effectiveness" / "Serve win %" -> {{"serve_target": null}} (NO serve_target filter!)
  - ONLY set serve_target if question EXPLICITLY mentions: "wide", "body", "to T", "down the T", "to the middle"
  - Examples that SHOULD have serve_target:
    * "First serve percentage to T" -> {{"serve_target": "t"}}
    * "Wide serve win percentage" -> {{"serve_target": "wide"}}
  - Examples that should NOT have serve_target:
    * "First serve percentage" -> {{"serve_target": null}}
    * "Second serve won percentage" -> {{"serve_target": null}}
    * "Serve effectiveness" -> {{"serve_target": null}}
  - DO NOT add serve_target for general serve questions! The system will block it anyway, but don't waste tokens.

CHAIN LOGIC (A â†' B):
⚠️ CRITICAL: Use DICT format for shot_a/shot_b when shot has player or multiple attributes (more accurate):
- Simple: "Backhand slice led to unforced error" â†' {{"chain_logic": {{"shot_a": "backhand slice", "shot_b": "unforced error"}}, "analysis_type": "chain"}}
- With player+attributes (DICT): "When Federer hit crosscourt forehand, did Nadal respond..." â†' {{"chain_logic": {{"shot_a": {{"player": "Roger Federer", "shot_type": "forehand", "direction": "crosscourt"}}, "shot_b": null}}, "analysis_type": "chain", "player": "Rafael Nadal"}}
- With depth (DICT): "After Nadal hit deep backhand, what did Federer do?" â†' {{"chain_logic": {{"shot_a": {{"player": "Rafael Nadal", "shot_type": "backhand", "depth": "deep"}}, "shot_b": null}}, "analysis_type": "chain", "player": "Roger Federer"}}
- Reverse: "Before the winner, what shot did Federer hit?" â†' {{"chain_logic": {{"shot_a": null, "shot_b": "winner"}}, "analysis_type": "chain", "player": "Roger Federer"}}

SEQUENTIAL/TEMPORAL QUERIES (CRITICAL - "after", "following", "next"):
⚠️ Questions asking about "immediately after X rally" use **prev_rally_length_range** filter - tree CAN handle this!
- "Points immediately after long rallies (7+ shots)" → {{"metrics_parsed": [{{"metric": "points_won", "filters": {{"prev_rally_length_range": "7+"}}}}], "query_type": "analytical"}}
- "Performance after short rallies (1-4)" → {{"metrics_parsed": [{{"metric": "win_percentage", "filters": {{"prev_rally_length_range": "1-4"}}}}], "query_type": "analytical"}}
- "After double faults" → {{"query_type": "narrative", "note": "prev_point_outcome filter not yet implemented"}}

NEW TAXONOMY EXAMPLES:
- "Forehand slice winners" -> {{"shot_type": "forehand", "spin": "slice", "metric": "winners"}}
- "Volley winners at net" -> {{"contact_type": "volley", "location": "net", "metric": "winners"}}
- "Approach shot effectiveness" -> {{"intent": "approach", "metric": "win_percentage"}}
- "Drop shot winners" -> {{"intent": "drop_shot", "metric": "winners"}}
- "Passing shot success rate" -> {{"intent": "passing_shot", "metric": "win_percentage"}}
- "Topspin forehand crosscourt" -> {{"shot_type": "forehand", "spin": "topspin", "direction": "crosscourt"}}
- "Slice backhand down the line" -> {{"shot_type": "backhand", "spin": "slice", "direction": "down_the_line"}}
- "Net play by contact type" -> {{"location": "net", "group_by": "contact_type"}}
- "Groundstroke vs volley winners" -> {{"group_by": "contact_type", "metric": "winners"}}

MOMENTUM ANALYSIS:
- "Momentum after break points" -> {{"analysis_type": "momentum", "situation": "break_point"}}
- "Did aggression increase after breaks?" -> {{"analysis_type": "momentum"}}
- "Carry-over effect after winning break" -> {{"analysis_type": "momentum"}}

QUERY_TYPE CLASSIFICATION:
- **analytical**: Questions asking for specific counts, percentages, or metrics that can be directly calculated
  Examples: 
  - "How many winners?"
  - "What was the ace count?" 
  - "Break point conversion %"
  - "Serve % in Set 1 vs Set 3" (has clear metric: serve %)
  - "Winners in sets won vs lost" (has clear metric: winners)
  
- **narrative**: Questions about strategy, tactics, patterns, behavior, "change", or questions with vague/unclear metrics
  Examples:
  - "What was the tactical approach?"
  - "Did they play more aggressively after winning a break point?" (vague metric: "aggressive")
  - "How did momentum shift?"
  - "Tell the story of Set 3"
  - "Did X change after Y?" (vague: change in what?)
  - "Performance on break points" (vague: performance = win %? aggression? shot selection?)
  
KEY DISTINCTION:
- **Clear, calculable metric** -> analytical (e.g., "ace count", "first serve %", "winner count")
- **Vague concept or strategic question** -> narrative (e.g., "aggression", "momentum", "effectiveness", "performance")
- When in doubt: if the metric isn't a direct count/percentage -> narrative

METRIC CLARITY CHECK:
- **clear_metric**: The question specifies EXACTLY what to count/measure
  Examples: "first serve win %", "ace count", "break point conversion", "forehand winners"
- **vague_metric**: The question asks about something but doesn't specify what metric
  Examples: "How did first serves change?", "Did serving improve?", "Forehand effectiveness", "Performance on break points"
  -> If vague_metric -> default to query_type: "narrative"

N-DIMENSIONAL (complex multi-filter + multi-group):
- "On break points, serving to T, Ad court, in sets won - 1st vs 2nd serve win %" -> {{
    "situation": "break_point",
    "serve_target": "t", 
    "court_side": "ad",
    "set_comparison": {{"set_a": [1, 3], "set_b": [2]}},
    "group_by": "serve_number",
    "n_dimensional": true
  }}
- "In tiebreaks, on 2nd serves, compare forehand vs backhand return effectiveness by court side" -> {{
    "situation": "tiebreak",
    "serve_number": 2,
    "group_by": "shot_type",
    "secondary_group_by": "court_side",
    "n_dimensional": true
  }}
- "How many net points in tiebreaks compared to rest of match?" -> {{
    "player": "Roger Federer",
    "court_zone": "net",
    "metric": "net_points_won",
    "group_by": "situation",
    "situation_comparison": {{"situation_a": "tiebreak", "situation_b": "non_tiebreak"}}
  }}
- "On break points, T vs Wide vs Body" -> {{
    "situation": "break_point",
    "group_by": "serve_direction",
    "serve_target": null
  }}
- "In Set 5, Ad Court vs Deuce Court win %" -> {{
    "set_filter": 5,
    "group_by": "court_side",
    "court_side": null,
    "metric": "win_percentage"
  }}

Return ONLY the JSON:"""

        try:
            # ALWAYS use gemini-2.5-flash for query parsing
            import google.generativeai as genai
            model = genai.GenerativeModel('gemini-2.5-flash')
            response = model.generate_content(parse_prompt)
            response_text = response.text.strip()
            
            # Clean up response - remove markdown code blocks if present
            if response_text.startswith("```"):
                response_text = response_text.split("```")[1]
                if response_text.startswith("json"):
                    response_text = response_text[4:]
                response_text = response_text.strip()
            
            # Parse JSON
            parsed = json.loads(response_text)
            print(f"[LLM-PARSE] Parsed query: {json.dumps(parsed, indent=2)}")
            return parsed
            
        except Exception as e:
            print(f"[LLM-PARSE] Error parsing query: {e}")
            return None
    
    def _normalize_and_validate_classification(self, classification: Dict) -> Dict:
        """
        GATEKEEPER FUNCTION: Enforce canonical field placement.
        
        This ensures all fields live in their correct locations:
        - Tree dimensions → classification['filters']
        - Shot-level fields → classification (top-level) or metric_filters (NOT filters)
        - Grouping fields → classification (top-level only)
        - Comparison structures → classification (top-level only)
        
        Returns classification with repairs applied + adds 'schema_repairs' for debugging.
        """
        repairs = []
        warnings = []
        
        # Ensure filters dict exists
        if 'filters' not in classification:
            classification['filters'] = {}
            repairs.append("Created missing filters dict")
        
        filters = classification['filters']
        
        # ═══════════════════════════════════════════════════════════════════════
        # RULE A: Tree dimensions MUST be in filters (if they exist anywhere)
        # ═══════════════════════════════════════════════════════════════════════
        for dim in self.TREE_LEVEL_DIMENSIONS:
            # Check if dimension is at top-level but not in filters
            if dim in classification and dim not in ['player']:  # player handled separately
                value = classification[dim]
                if value is not None:
                    # Move to filters
                    if dim not in filters or filters[dim] != value:
                        filters[dim] = value
                        repairs.append(f"Moved '{dim}={value}' into filters")
        
        # Special handling for player (only if not "both")
        player = classification.get('player')
        if player and player not in ['both', None, '']:
            if 'player' not in filters or filters['player'] != player:
                filters['player'] = player
                repairs.append(f"Moved 'player={player}' into filters")
        elif player == 'both' and 'player' in filters:
            # Remove player from filters if it's "both" (tree aggregates automatically)
            del filters['player']
            repairs.append("Removed 'player=both' from filters (tree will aggregate)")
        
        # ═══════════════════════════════════════════════════════════════════════
        # RULE B: Shot-level fields must NOT be in filters
        # ═══════════════════════════════════════════════════════════════════════
        for field in self.SHOT_LEVEL_FIELDS:
            if field in filters:
                value = filters[field]
                del filters[field]
                # Move to top-level (unless it's already there)
                if field not in classification:
                    classification[field] = value
                repairs.append(f"Removed shot-level '{field}' from filters -> moved to top-level")
        
        # ═══════════════════════════════════════════════════════════════════════
        # RULE C: Grouping fields must NOT be in filters
        # ═══════════════════════════════════════════════════════════════════════
        for field in self.GROUPING_FIELDS:
            if field in filters:
                value = filters[field]
                del filters[field]
                if field not in classification:
                    classification[field] = value
                repairs.append(f"Moved grouping field '{field}' from filters to top-level")
        
        # ═══════════════════════════════════════════════════════════════════════
        # RULE D: Comparison structures must NOT be in filters
        # ═══════════════════════════════════════════════════════════════════════
        for field in self.COMPARISON_FIELDS:
            if field in filters:
                value = filters[field]
                del filters[field]
                if field not in classification:
                    classification[field] = value
                repairs.append(f"Moved comparison field '{field}' from filters to top-level")
        
        # ═══════════════════════════════════════════════════════════════════════
        # VALIDATION: Check filters only contain tree dimensions
        # ═══════════════════════════════════════════════════════════════════════
        for key in list(filters.keys()):
            if key not in self.TREE_LEVEL_DIMENSIONS:
                warnings.append(f"Unknown filter '{key}' not in TREE_LEVEL_DIMENSIONS - leaving in place")
        
        # Update filters
        classification['filters'] = filters
        
        # Add repair log for debugging
        if repairs or warnings:
            classification['_schema_repairs'] = {
                'repairs': repairs,
                'warnings': warnings
            }
            
            # Print for immediate debugging
            if repairs:
                print(f"[SCHEMA-REPAIR] Applied {len(repairs)} fix(es):")
                for repair in repairs:
                    print(f"  - {repair}")
            if warnings:
                print(f"[SCHEMA-WARNING] {len(warnings)} warning(s):")
                for warning in warnings:
                    print(f"  - {warning}")
        
        return classification
    
    def _apply_llm_parse_to_classification(self, classification: Dict, llm_parse: Dict, original_question: str = None) -> Dict:
        """Apply LLM parsing results to the classification."""
        if not llm_parse:
            return classification
        
        # CRITICAL: Sanitize string "null" values to actual None
        # LLM sometimes returns "null" as a string instead of JSON null
        def sanitize_null(value):
            if isinstance(value, str) and value.lower() == 'null':
                return None
            return value
        
        # Sanitize all values in llm_parse
        for key in list(llm_parse.keys()):
            llm_parse[key] = sanitize_null(llm_parse[key])
        
        # CRITICAL: Detect which dimensions are being used for grouping
        # If a dimension is in group_by, it should NOT be in filters
        grouped_dimensions = set()
        group_by_to_filter_map = {
            'court_side': 'court_side',
            'serve_direction': 'serve_target',
            'shot_direction': 'direction',
            'shot_type': 'shot_type',
            'serve_number': 'serve_number',
            'return_depth': 'depth',
            'rally_length_category': None,  # No corresponding filter
            'player': None,  # Special handling
            'game_outcome': None,  # No corresponding filter
            'sets': None,  # No corresponding filter
        }
        
        if llm_parse.get('group_by'):
            group_by = llm_parse['group_by']
            filter_key = group_by_to_filter_map.get(group_by)
            if filter_key:
                grouped_dimensions.add(filter_key)
        
        # Also check secondary and tertiary group_by
        if llm_parse.get('secondary_group_by'):
            filter_key = group_by_to_filter_map.get(llm_parse['secondary_group_by'])
            if filter_key:
                grouped_dimensions.add(filter_key)
        
        if llm_parse.get('tertiary_group_by'):
            filter_key = group_by_to_filter_map.get(llm_parse['tertiary_group_by'])
            if filter_key:
                grouped_dimensions.add(filter_key)
        
        # Update filters from LLM parse
        filters = classification.get('filters', {})
        
        # CRITICAL: Remove any dimensions from filters that are being grouped
        # (These may have been added by _classify_query before LLM parse)
        for dim in grouped_dimensions:
            if dim in filters:
                del filters[dim]
                print(f"[LLM-PARSE] Removed '{dim}' from filters because it's being grouped for comparison")
        
        # Check if this is a chain logic query
        is_chain_query = llm_parse.get('analysis_type') == 'chain' or llm_parse.get('chain_logic')
        
        # For chain queries, remove shot characteristics from filters (they're in chain_logic)
        if is_chain_query:
            chain_related_filters = ['shot_type', 'shot_modifier', 'shot_base', 'shot_number', 'direction']
            for f in chain_related_filters:
                if f in filters:
                    del filters[f]
                    print(f"[LLM-PARSE] Removed '{f}' from filters because it's a chain query (characteristics are in chain_logic)")
        
        if llm_parse.get('player'):
            filters['player'] = llm_parse['player']
        
        # Skip shot_type/shot_modifier for chain queries (they're in chain_logic structure)
        # Skip shot_type if it's being grouped (e.g., "Forehand vs Backhand")
        if llm_parse.get('shot_type') and 'shot_type' not in grouped_dimensions and not is_chain_query:
            filters['shot_type'] = llm_parse['shot_type']
            # Also set shot_base for compatibility
            shot_type = llm_parse['shot_type']
            if shot_type in ['forehand', 'backhand']:
                filters['shot_base'] = shot_type
        
        if llm_parse.get('shot_modifier') and not is_chain_query:
            filters['shot_modifier'] = llm_parse['shot_modifier']
        
        # CRITICAL: Only add/update situation if LLM actually detected one AND NOT doing situation comparison
        # When doing situation_comparison (tiebreak vs rest), situation is used for GROUPING, not filtering
        # DON'T overwrite existing situation detection from _detect_filters_mcp with null/None
        if llm_parse.get('situation') and not llm_parse.get('situation_comparison'):
            llm_situation = llm_parse['situation']
            
            # CRITICAL: Check if LLM misidentified a point_score as a situation
            # Point scores look like "30-30", "15-40", "40-AD" (not valid situations)
            # Valid situations are: break_point, game_point, deuce, set_point, match_point, tiebreak
            valid_situations = set(self.SITUATION_CONFIG.keys())
            
            if llm_situation not in valid_situations:
                # Check if it looks like a point score using config-based validation
                if self._is_valid_point_score(llm_situation):
                    # It's a point score, not a situation!
                    filters['point_score'] = self._normalize_point_score(llm_situation)
                    print(f"[LLM-PARSE] LLM incorrectly set situation='{llm_situation}' - converted to point_score='{filters['point_score']}'")
                else:
                    # Unknown situation - only set if we don't have point_score
                    # (LLM often confuses point scores like "30-30" with situations like "even_score")
                    if filters.get('point_score'):
                        print(f"[LLM-PARSE] Ignoring unknown situation '{llm_situation}' - already have point_score='{filters['point_score']}'")
                    else:
                        print(f"[LLM-PARSE] WARNING: Unknown situation '{llm_situation}' (not in SITUATION_CONFIG) - setting anyway")
                        filters['situation'] = llm_situation
            else:
                # Valid situation
                print(f"[LLM-PARSE] Updating situation filter from taxonomy '{filters.get('situation')}' to LLM '{llm_situation}'")
                filters['situation'] = llm_situation
        elif filters.get('situation'):
            print(f"[LLM-PARSE] Keeping taxonomy-detected situation '{filters['situation']}' (LLM returned: {llm_parse.get('situation')})")
        # If LLM returned null but we already detected one, keep it
        # (Don't let LLM null overwrite good taxonomy detection)
        
        # === PRESERVE point_score FROM TAXONOMY DETECTION ===
        # If _detect_filters_mcp already detected a point_score, don't let LLM override with None
        if filters.get('point_score') and not llm_parse.get('point_score'):
            print(f"[LLM-PARSE] Keeping taxonomy-detected point_score '{filters['point_score']}' (LLM returned: {llm_parse.get('point_score')})")
        
        if llm_parse.get('set_filter'):
            filters['set'] = llm_parse['set_filter']
        
        # Skip direction if it's being grouped (e.g., "Crosscourt vs Down the Line")
        if llm_parse.get('direction') and 'direction' not in grouped_dimensions:
            filters['direction'] = llm_parse['direction']
        
        # Handle serve_number (1st serve vs 2nd serve)
        # Skip if it's being grouped (e.g., "1st serve vs 2nd serve win %")
        if llm_parse.get('serve_number') and 'serve_number' not in grouped_dimensions:
            filters['serve_number'] = llm_parse['serve_number']
        
        classification['filters'] = filters
        
        # === GENERIC N-METRIC SUPPORT ===
        # Each metric has its OWN COMPLETE filter set - code doesn't know about specific metrics
        # LLM decides what filters each metric needs
        metrics_parsed = llm_parse.get('metrics_parsed', [])
        
        if metrics_parsed:
            # GENERIC: Each metric has its own complete filter set from LLM
            classification['metrics'] = []
            classification['metric_filters'] = {}  # Store COMPLETE per-metric filters
            
            for i, mp in enumerate(metrics_parsed):
                metric_name = mp.get('metric')
                if not metric_name:
                    continue
                
                # CRITICAL: Map invalid metric names to correct base metrics FIRST
                # LLM might return "ace_percentage" instead of "aces", etc.
                # ALSO map "shots" -> "shot_count" (shots = individual shots in rallies, not points)
                metric_name_map = {
                    'shots': 'shot_count',  # CRITICAL: "shots" means count individual shots, not points
                    'shots_hit': 'shot_count',  # LLM sometimes returns this variant
                    'shots_count': 'shot_count',  # LLM sometimes returns this variant (with 's')
                    'total_shots': 'shot_count',  # LLM sometimes returns this variant
                    'shot': 'shot_count',  # Singular form
                    'ace_percentage': 'aces',
                    'ace_pct': 'aces',
                    'winner_percentage': 'winners',
                    'winner_pct': 'winners',
                    'error_percentage': 'unforced_errors',
                    'error_pct': 'unforced_errors',
                    'double_fault_percentage': 'double_faults',
                    'double_fault_pct': 'double_faults',
                    'game_win_percentage': 'service_games_held',
                    'service_game_percentage': 'service_games_held',
                    'service_game_win_percentage': 'service_games_held',
                }
                # CRITICAL: "count" with context="rally" means count individual shots
                # Also: "count" with shot_type filter means count individual shots (even if context is missing)
                context = mp.get('context', '')
                metric_filters_check = mp.get('filters', {})
                if metric_name == 'count':
                    if context == 'rally':
                        print(f"[LLM-PARSE] Mapping 'count' with context='rally' -> 'shot_count' (count individual shots)")
                        metric_name = 'shot_count'
                    elif 'shot_type' in metric_filters_check:
                        # Fallback: if counting by shot_type, it's clearly a shot-level query
                        print(f"[LLM-PARSE] Mapping 'count' with shot_type filter -> 'shot_count' (count individual shots by type)")
                        metric_name = 'shot_count'
                elif metric_name in metric_name_map:
                    print(f"[LLM-PARSE] Mapping '{metric_name}' -> '{metric_name_map[metric_name]}' (use base metric names)")
                    metric_name = metric_name_map[metric_name]
                
                # Generate unique key if same metric appears multiple times with different filters
                # e.g., win_percentage for server vs win_percentage for returner
                metric_key = metric_name
                if metric_key in classification['metric_filters']:
                    metric_key = f"{metric_name}_{i}"
                
                classification['metrics'].append(metric_key)
                
                # Store COMPLETE filter set for this metric (LLM decides everything)
                metric_filters = mp.get('filters', {})
                
                # CRITICAL: Before removing tree-dimension filters, check if 'situation' is actually a point_score
                # LLM often returns "30-30" as situation instead of point_score
                metric_situation = metric_filters.get('situation')
                if metric_situation and self._is_valid_point_score(str(metric_situation)):
                    # It's a point_score! Convert and set at TOP LEVEL so tree uses it
                    normalized_score = self._normalize_point_score(str(metric_situation))
                    print(f"[LLM-PARSE] Converting metric situation '{metric_situation}' to TOP-LEVEL point_score='{normalized_score}'")
                    filters['point_score'] = normalized_score  # Set at TOP LEVEL for tree
                    del metric_filters['situation']  # Remove from metric filters
                
                # CRITICAL: PROMOTE tree-dimension filters to top-level BEFORE removing from metric filters
                # These will be applied during tree traversal, not at metric level
                # Re-checking them causes false negatives when metadata isn't populated
                for dim in self.TREE_LEVEL_DIMENSIONS:
                    if dim in metric_filters and metric_filters[dim] is not None:
                        value = metric_filters[dim]
                        # Type coercion for integer fields (LLM often returns strings)
                        if dim in ('serve_number', 'set', 'game_number', 'game_number_in_set'):
                            try:
                                value = int(value)
                            except (ValueError, TypeError):
                                pass
                        # PROMOTE to top-level filters (if not already set)
                        if not filters.get(dim):
                            filters[dim] = value
                            print(f"[LLM-PARSE] Promoted '{dim}={value}' to top-level filters for tree use")
                        print(f"[LLM-PARSE] Removing '{dim}={metric_filters[dim]}' from metric filters (tree dimension)")
                        del metric_filters[dim]
                
                # CRITICAL: Merge top-level filters into metric-specific filters
                # BUT: DON'T merge filters that will be used as tree dimensions (they're filtered in the tree)
                # Tree dimensions: situation, set, point_score, serve_target, court_side, court_zone, rally_length, role
                # Re-checking them at metric level causes false negatives when metadata isn't populated
                
                # Only merge 'player' - it's not a tree dimension (except when used for grouping)
                player_value = llm_parse.get('player')
                if player_value and 'player' not in metric_filters:
                    metric_filters['player'] = player_value
                    print(f"[LLM-PARSE] Merging top-level 'player={player_value}' into metric filters")
                
                # DON'T merge: situation, set, point_score, serve_target, court_side, role, etc.
                # Those are tree dimensions and will be filtered during tree traversal
                
                # CRITICAL: Type coercion for serve_number (LLM might return string)
                if 'serve_number' in metric_filters and metric_filters['serve_number'] is not None:
                    try:
                        metric_filters['serve_number'] = int(metric_filters['serve_number'])
                    except (ValueError, TypeError):
                        pass
                
                # CRITICAL: first_serve_pct should NOT have serve_number filter
                # It needs ALL serve attempts (1st and 2nd) to calculate percentage
                if metric_name == 'first_serve_pct' and 'serve_number' in metric_filters:
                    print(f"[LLM-PARSE] WARNING: Removing serve_number filter from first_serve_pct (needs ALL serves)")
                    del metric_filters['serve_number']
                
                # CRITICAL: Validate and fix situation filters in metric_filters
                # LLM often returns point scores like "30-30" as situations
                valid_situations = set(self.SITUATION_CONFIG.keys())
                metric_situation = metric_filters.get('situation')
                if metric_situation and metric_situation.lower() not in valid_situations:
                    if self._is_valid_point_score(metric_situation):
                        # It's a point_score, not a situation
                        print(f"[LLM-PARSE] Metric '{metric_key}': Converting invalid situation '{metric_situation}' to point_score")
                        metric_filters['point_score'] = self._normalize_point_score(metric_situation)
                        del metric_filters['situation']
                    elif filters.get('point_score'):
                        # If we have point_score at top level, don't use unknown situation
                        print(f"[LLM-PARSE] Metric '{metric_key}': Ignoring unknown situation '{metric_situation}' (have point_score)")
                        del metric_filters['situation']
                    else:
                        print(f"[LLM-PARSE] WARNING: Metric '{metric_key}' has unknown situation '{metric_situation}'")
                
                # CRITICAL: Convert rally_length_range or rally_length_category to rally_length filter
                # LLM should parse "rally was 0-4 shots" as rally_length_range='0-4' (new)
                # But might still use rally_length_category='0-4' (legacy) - handle both
                # MUST DO THIS BEFORE saving to metric_filters!
                if 'rally_length_range' in metric_filters:
                    range_spec = metric_filters['rally_length_range']
                    if range_spec:
                        rally_filter = self._convert_rally_category_to_filter(range_spec)
                        if rally_filter:
                            metric_filters['rally_length'] = rally_filter
                            print(f"[LLM-PARSE] Converted rally_length_range='{range_spec}' to rally_length={rally_filter}")
                        del metric_filters['rally_length_range']
                elif 'rally_length_category' in metric_filters:
                    # Legacy - should only happen if LLM didn't follow new instructions
                    category = metric_filters['rally_length_category']
                    if category:
                        rally_filter = self._convert_rally_category_to_filter(category)
                        if rally_filter:
                            metric_filters['rally_length'] = rally_filter
                            print(f"[LLM-PARSE] LEGACY: Converted rally_length_category='{category}' to rally_length={rally_filter}")
                        del metric_filters['rally_length_category']
                
                # CRITICAL: Convert prev_rally_length_range to prev_rally_length filter (for "after X rally" queries)
                if 'prev_rally_length_range' in metric_filters:
                    range_spec = metric_filters['prev_rally_length_range']
                    if range_spec:
                        prev_rally_filter = self._convert_rally_category_to_filter(range_spec)
                        if prev_rally_filter:
                            metric_filters['prev_rally_length'] = prev_rally_filter
                            print(f"[LLM-PARSE] Converted prev_rally_length_range='{range_spec}' to prev_rally_length={prev_rally_filter}")
                        del metric_filters['prev_rally_length_range']
                
                # Log what filters this metric has
                filter_str = ', '.join(f"{k}={v}" for k, v in metric_filters.items() if v is not None)
                print(f"[LLM-PARSE] Metric '{metric_key}' with filters: {{{filter_str}}}")
                
                # NOW save the metric_filters with converted values
                classification['metric_filters'][metric_key] = {
                    'metric': metric_name,  # Original metric name
                    'filters': metric_filters,  # Complete filter set for THIS metric (with conversions applied)
                    'context': mp.get('context'),  # For synthesis grouping
                }
            
            # CRITICAL: If metrics_parsed has different shot_type filters, remove global shot_type filter
            # Global filter would conflict with per-metric filters (e.g., one metric for forehand, one for backhand)
            shot_types_in_metrics = set()
            for mp in metrics_parsed:
                metric_filters = mp.get('filters', {})
                if 'shot_type' in metric_filters:
                    shot_types_in_metrics.add(metric_filters['shot_type'])
            
            if len(shot_types_in_metrics) > 1:
                # Multiple different shot_type filters - remove global filter
                if 'shot_type' in filters:
                    removed_shot_type = filters.pop('shot_type')
                    print(f"[LLM-PARSE] Removed global shot_type='{removed_shot_type}' filter (metrics_parsed has multiple shot_type filters: {shot_types_in_metrics})")
                if 'shot_base' in filters:
                    removed_shot_base = filters.pop('shot_base')
                    print(f"[LLM-PARSE] Removed global shot_base='{removed_shot_base}' filter (metrics_parsed has multiple shot_type filters)")
                # Update classification filters after removal
                classification['filters'] = filters
            
            # Check if metrics are related (same context) for narrative synthesis
            contexts = set(mp.get('context') for mp in metrics_parsed if mp.get('context'))
            if len(contexts) == 1 and len(metrics_parsed) > 1:
                classification['synthesize_related_metrics'] = True
                classification['metric_context_type'] = list(contexts)[0]
                print(f"[LLM-PARSE] Related metrics detected (context: {list(contexts)[0]}) - will synthesize in narrative")
            
            # CRITICAL: If we have ONLY ONE metric, promote its filters to top-level filters
            # This ensures the tree uses them for filtering (e.g., rally_length, serve_number)
            if len(classification['metric_filters']) == 1:
                single_metric_key = list(classification['metric_filters'].keys())[0]
                single_metric_filters = classification['metric_filters'][single_metric_key]['filters']
                
                # Promote tree-level dimensions to top-level (use config, not hardcoded list!)
                for filter_key in self.TREE_LEVEL_DIMENSIONS:
                    if filter_key in single_metric_filters and single_metric_filters[filter_key] is not None:
                        # Don't overwrite if already set at top level
                        if not filters.get(filter_key):
                            filters[filter_key] = single_metric_filters[filter_key]
                            print(f"[LLM-PARSE] Promoted single-metric filter '{filter_key}={single_metric_filters[filter_key]}' to top-level for tree use")
                
                # Update classification
                classification['filters'] = filters
        else:
            # UNIFIED: Convert single metric to metrics_parsed format for consistent processing
            # This eliminates duplication and ensures all metrics go through the same logic
            if llm_parse.get('metric') or llm_parse.get('secondary_metric'):
                print(f"[LLM-PARSE] Converting single metric to metrics_parsed format for unified processing")
                metrics_to_add = []
                
                # Primary metric
                if llm_parse.get('metric'):
                    llm_metric = llm_parse['metric']
                    print(f"[LLM-PARSE-DEBUG] Raw metric from LLM: '{llm_metric}' (type: {type(llm_metric).__name__}, repr: {repr(llm_metric)})")
                    
                    # CRITICAL: If metric='count' AND group_by='shot_type', it means count individual shots
                    if llm_metric == 'count' and llm_parse.get('group_by') == 'shot_type':
                        print(f"[LLM-PARSE] Detected 'count' with group_by='shot_type' -> treating as shot_count (count individual shots)")
                        llm_metric = 'shot_count'
                    
                    metrics_to_add.append({
                        'metric': llm_metric,
                        'filters': {},
                        'context': llm_parse.get('context')
                    })
                
                # Secondary metric (if any)
                if llm_parse.get('secondary_metric'):
                    secondary = llm_parse['secondary_metric']
                    metrics_to_add.append({
                        'metric': secondary,
                        'filters': {},
                        'context': llm_parse.get('context')
                    })
                    print(f"[LLM-PARSE] Added secondary metric: {secondary}")
                
                # Convert to metrics_parsed and reprocess through unified path
                llm_parse['metrics_parsed'] = metrics_to_add
                # Recursive call to process through unified metrics_parsed path
                # This ensures all mappings happen in one place
                return self._apply_llm_parse_to_classification(classification, llm_parse, original_question)
        
        # === GENERIC: Transform metrics based on action verbs (create/cause/induce) ===
        # When asking "how many errors did X create/cause/induce", we want the INDUCED version
        # The player mentioned CAUSED the error (opponent made it), not made the error themselves
        if original_question:
            q_lower = original_question.lower()
            # Note: 'force/forced/forcing' removed - too ambiguous with 'forced error'
            action_verbs = ['create', 'created', 'creating', 'cause', 'caused', 'causing',  
                           'induce', 'induced', 'inducing', 'generate', 'generated', 
                           'draw', 'drew', 'drawing', 'elicit', 'elicited']
            matched_verbs = [v for v in action_verbs if v in q_lower]
            has_action_verb = len(matched_verbs) > 0
            
            if has_action_verb:
                # GENERIC: Map error metrics to their induced counterparts
                # The pattern: X_errors -> induced_X_errors (player caused opponent's error)
                metric_transforms = {
                    'forced_errors': 'induced_forced_errors',
                    # Add more transforms as needed (e.g., if we track 'induced_unforced_errors' someday)
                }
                
                current_metrics = classification.get('metrics', [])
                transformed = False
                for i, metric in enumerate(current_metrics):
                    if metric in metric_transforms:
                        new_metric = metric_transforms[metric]
                        current_metrics[i] = new_metric
                        transformed = True
                        print(f"[LLM-PARSE] Action verb detected {matched_verbs} - Transforming metric '{metric}' to '{new_metric}'")
                
                # Also transform in metric_filters if using metrics_parsed
                if 'metric_filters' in classification and transformed:
                    for key, mf in classification['metric_filters'].items():
                        old_metric = mf.get('metric')
                        if old_metric in metric_transforms:
                            new_metric = metric_transforms[old_metric]
                            mf['metric'] = new_metric
                            print(f"[LLM-PARSE] Also transformed metric_filter '{key}': '{old_metric}' to '{new_metric}'")
        
        # === GENERIC: Add shot_count for shot-level queries ===
        # When asking about individual shots (not points), need shot_count as denominator
        # Matches the same patterns as rule-based detection in _detect_metrics
        if original_question:
            q_lower = original_question.lower()
            
            # Check for shot-level query patterns (consistent with _detect_metrics line 7849)
            shot_level_patterns = ['how many shot', 'total shot', 'shot count', 
                                  'number of shot', 'percentage of shot', 
                                  'percent of shot', '% of shot']
            is_shot_query = any(phrase in q_lower for phrase in shot_level_patterns)
            
            # Also check for "percentage...shots" pattern (with words in between)
            is_shot_percentage = (('percentage' in q_lower or 'percent' in q_lower or '%' in q_lower) and 
                                 ('shots' in q_lower or 'shot' in q_lower))
            
            # "success rate" for shots = winners / total shots for that direction/type
            # Patterns: "crosscourt success rate", "down-the-line shot success rate", "forehand success rate"
            # Use config for direction and shot type terms
            direction_config = self.GROUP_CONFIG.get('direction', {}).get('default_branches', [])
            shot_type_config = self.GROUP_CONFIG.get('shot_type', {}).get('default_branches', [])
            # Build search terms (include both underscore and space/hyphen versions)
            direction_terms = []
            for d in direction_config:
                direction_terms.append(d.lower())
                direction_terms.append(d.lower().replace('_', ' '))
                direction_terms.append(d.lower().replace('_', '-'))
            shot_type_terms = [s.lower() for s in shot_type_config] if shot_type_config else []
            is_shot_success_rate = 'success rate' in q_lower and any(term in q_lower for term in direction_terms + shot_type_terms + ['shot'])
            
            if is_shot_query or is_shot_percentage or is_shot_success_rate:
                current_metrics = classification.get('metrics', [])
                if 'shot_count' not in current_metrics:
                    current_metrics.append('shot_count')
                    print(f"[LLM-PARSE] Detected shot-level query -> Adding 'shot_count' for denominator")
                
                # For shot success rate: keep win_percentage (points won when using that direction)
                # No transformation needed - win_percentage with direction filter is correct
        
        # Update query category
        if llm_parse.get('query_type'):
            classification['query_category'] = llm_parse['query_type']
        
        # CRITICAL: Game-state chain queries MUST go to narrative (LLM often misclassifies)
        # These require tracking within-game progression (0-15, 15-0, etc.)
        is_game_state_query = False
        
        # Check 1: LLM returned game_state_scenario in filters (we can't handle this analytically)
        # Handle case where metrics_parsed might be None (use 'or []' to ensure we get a list)
        for mp in (llm_parse.get('metrics_parsed') or []):
            metric_filters = mp.get('filters', {})
            if 'game_state_scenario' in metric_filters:
                is_game_state_query = True
                print(f"[LLM-PARSE] LLM returned game_state_scenario='{metric_filters['game_state_scenario']}' -> Overriding to narrative")
                break
        
        # Check 2: Pattern-based detection from original question
        if not is_game_state_query and original_question:
            import re
            q_lower = original_question.lower()
            game_state_patterns = [
                r'after\s+(?:losing|winning)\s+(?:the\s+)?(?:first|second|third|opening)\s+point',
                r'after\s+(?:losing|winning)\s+(?:the\s+)?first\s+\d+\s+points?',
                r'after\s+(?:going|falling|getting)\s+(?:up|down|behind|ahead)\s*(?:\d+-\d+)?',
                r'after\s+(?:starting|beginning)\s+(?:\d+-\d+)',
                r'from\s+(?:\d+-\d+)\s+(?:down|behind|up|ahead)',
                r'games?\s+(?:where|when)\s+(?:server|returner)\s+(?:lost|won)\s+(?:the\s+)?first',
                r'when\s+(?:down|up|behind|ahead)\s+(?:\d+-\d+|0-15|15-0|0-30|30-0|0-40|40-0)',
            ]
            is_game_state_query = any(re.search(pattern, q_lower) for pattern in game_state_patterns)
        
        # REMOVED: Game-state chain override to narrative
        # Tree CAN handle these queries with proper game-level metadata:
        #   - _point_in_game, _server_lost_first_point, etc.
        # Previously this was forcing to narrative which then generated clarify operations
        if is_game_state_query:
            print(f"[LLM-PARSE] GAME-STATE query detected (tree CAN handle via game metadata)")
            # Keep as analytical - tree uses enriched game-state fields
        
        # CRITICAL: Override to narrative if metric is vague
        # BUT: If we have specific filters (point_score, situation, set, etc.), keep analytical
        # because the filters indicate a countable/analytical query even if phrasing is vague
        metric_clarity = llm_parse.get('metric_clarity')
        if metric_clarity == 'vague':
            filters = classification.get('filters', {})
            # Use config for tree-level dimensions instead of hardcoding
            # These specific filters indicate an analytical query even with vague phrasing
            has_specific_filter = any(filters.get(f) for f in self.TREE_LEVEL_DIMENSIONS)
            
            if has_specific_filter:
                detected_filters = [f"{f}={filters[f]}" for f in self.TREE_LEVEL_DIMENSIONS if filters.get(f)]
                print(f"[LLM-PARSE] Metric clarity is VAGUE but has specific filters: {', '.join(detected_filters)}")
                print(f"[LLM-PARSE]   -> Keeping analytical route (filters indicate countable query)")
            else:
                print(f"[LLM-PARSE] Metric clarity is VAGUE and no specific filters -> Overriding to narrative route")
                classification['query_category'] = 'narrative'
        
        # CRITICAL: Shot direction success rate -> narrative (too complex for tree analysis)
        if original_question and 'success rate' in original_question.lower():
            direction_config = self.GROUP_CONFIG.get('direction', {}).get('default_branches', [])
            direction_terms = []
            for d in direction_config:
                direction_terms.extend([d.lower(), d.lower().replace('_', ' '), d.lower().replace('_', '-')])
            if any(term in original_question.lower() for term in direction_terms + ['shot']):
                print(f"[LLM-PARSE] Shot direction success rate question -> Overriding to narrative route")
                classification['query_category'] = 'narrative'
        
        # === GENERIC: Detect role from keywords for ANY situation ===
        # This applies to break points, game points, set points, match points, deuce, etc.
        # - save/saved/face/faced/defend = role=server (defending the point/situation)
        # - convert/converted/conversion/create/created/opportunity = role=returner (attacking/capitalizing)
        situation = classification.get('filters', {}).get('situation')
        if situation and not classification.get('filters', {}).get('role'):
            # Get question text for keyword detection
            question_text = original_question or llm_parse.get('actual_question', '') or classification.get('raw_query', '')
            question_lower = question_text.lower() if question_text else ''
            
            # GENERIC: Check for role-indicating keywords in the question
            has_defensive_kw = any(kw in question_lower for kw in ['save', 'saved', 'saving', 'face', 'faced', 'facing', 'defend', 'defended', 'defending'])
            has_offensive_kw = any(kw in question_lower for kw in ['convert', 'converted', 'conversion', 'create', 'created', 'opportunity', 'opportunities', 'capitalize'])
            
            if has_defensive_kw and has_offensive_kw:
                # Both perspectives mentioned - don't set role, show both
                print(f"[LLM-PARSE] Situation '{situation}' with BOTH defensive and offensive keywords - leaving role=None (will show both perspectives)")
            elif has_defensive_kw:
                classification['filters']['role'] = 'server'
                print(f"[LLM-PARSE] Situation '{situation}' with defensive keywords -> role='server'")
            elif has_offensive_kw:
                classification['filters']['role'] = 'returner'
                print(f"[LLM-PARSE] Situation '{situation}' with offensive keywords -> role='returner'")
            else:
                # No specific keywords - leave role unset (will show the situation regardless of role)
                print(f"[LLM-PARSE] Situation '{situation}' without role keywords - leaving role=None")
        
        # CRITICAL: Questions about "returnable" serves must always go to narrative
        if original_question and 'returnable' in original_question.lower():
            print(f"[LLM-PARSE] Question contains 'returnable' -> Overriding to narrative route")
            classification['query_category'] = 'narrative'
        
        # CRITICAL: Questions asking about "shots" descriptively must go to narrative
        # But quantitative shot queries (ratio, count, percentage) should be analytical
        # EXCEPTION: Rally length patterns (e.g., "0-4 shots", "rally was 5 shots") are about
        # rally LENGTH metadata, not individual shot counting - these stay analytical/hybrid
        if original_question:
            q_lower = original_question.lower()
            if (' shot' in q_lower or q_lower.startswith('shot')):
                # Check if this is a rally length pattern (NOT individual shot counting)
                import re
                rally_length_patterns = [
                    r'\d+[-–]\d+\s*shots',  # "0-4 shots", "5-10 shots"
                    r'\d+\+?\s*shots?\s*(?:rally|rallies)',  # "5+ shot rally"
                    r'rally\s+(?:was|were|of|with)\s+\d+',  # "rally was 5 shots"
                    r'when\s+(?:the\s+)?rally\s+(?:was|is)\s+\d+',  # "when rally was 4"
                ]
                is_rally_length = any(re.search(pattern, q_lower) for pattern in rally_length_patterns)
                
                if is_rally_length:
                    print(f"[LLM-PARSE] Rally length pattern detected ('{q_lower[:50]}...') - keeping analytical/hybrid route")
                else:
                    # Allow analytical if:
                    # 1. About winners/errors/outcomes
                    # 2. About shot counts/ratios/percentages/rates
                    # 3. About "who won more points"
                    is_quantitative = any(kw in q_lower for kw in [
                        'winner', 'winners', 'error', 'errors', 'winning shot',
                        'ratio', 'percentage', 'percent', 'how many', 'count', 
                        'total', 'number of', 'shot count', 'rate', 'success',
                        'won more', 'win more', 'who won'
                    ])
                    if not is_quantitative:
                        print(f"[LLM-PARSE] Question asks about 'shots' descriptively (not quantitative) -> Overriding to narrative route")
                        classification['query_category'] = 'narrative'
        
        # Handle group_by from LLM (e.g., 'sets' for per-set breakdown)
        # CRITICAL: Do NOT apply group_by='player' for overall win% queries
        # When asking "overall win percentage for both players", we want:
        # - Sinner: 142 / 282 total points = 50.4%
        # - Medvedev: 140 / 282 total points = 49.6%
        # NOT per-player branches where each player wins 100% of "their" points
        if llm_parse.get('group_by'):
            llm_group_by = llm_parse['group_by']
            
            # Check if this is an overall percentage query that should NOT be grouped by player
            player_filter = classification.get('filters', {}).get('player', '')
            is_both_players = player_filter and str(player_filter).lower() == 'both'
            metrics = classification.get('metrics', [])
            role_filter = classification.get('filters', {}).get('role')
            
            # Special case: Don't apply group_by='player' for overall win_percentage/points_won queries
            # These queries want match totals, not per-player branches
            overall_pct_metrics = ['win_percentage', 'points_won']
            is_overall_pct_query = is_both_players and any(m in metrics for m in overall_pct_metrics) and not role_filter
            
            if llm_group_by == 'player' and is_overall_pct_query:
                print(f"[LLM-PARSE] Ignoring group_by='player' for overall win% query (want match totals, not per-player branches)")
            else:
                classification['group_by'] = llm_group_by
        
        # Handle secondary_group_by for 2D analysis
        if llm_parse.get('secondary_group_by'):
            classification['secondary_group_by'] = llm_parse['secondary_group_by']
        
        # Handle set comparison
        if llm_parse.get('set_comparison'):
            classification['set_comparison'] = llm_parse['set_comparison']  # CRITICAL: Pass to _should_use_query_plan
            classification['group_by'] = 'set_groups'
            classification['filters']['set_group_a'] = llm_parse['set_comparison'].get('set_a', [])
            classification['filters']['set_group_b'] = llm_parse['set_comparison'].get('set_b', [])
        
        # Handle situation comparison (tiebreak vs rest of match)
        if llm_parse.get('situation_comparison'):
            classification['situation_comparison'] = llm_parse['situation_comparison']  # CRITICAL: Pass to _should_use_query_plan
            classification['group_by'] = 'situation'
            situation_a = llm_parse['situation_comparison'].get('situation_a')
            situation_b = llm_parse['situation_comparison'].get('situation_b')
            # Store for later use in grouping logic
            classification['filters']['situation_group_a'] = situation_a
            classification['filters']['situation_group_b'] = situation_b
            # CRITICAL: Remove any situation filter that was set by _classify_query
            # When doing comparison, situation is for GROUPING, not filtering!
            if 'situation' in classification['filters']:
                del classification['filters']['situation']
                print(f"[LLM-PARSE] Removed 'situation' filter - using for grouping instead")
            print(f"[LLM-PARSE] Set situation comparison: {situation_a} vs {situation_b}")
        
        # Handle role filter (server/returner)
        if llm_parse.get('role'):
            classification['filters']['role'] = llm_parse['role']
        
        # Handle depth filter
        # Skip if it's being grouped (e.g., "Shallow vs Deep returns")
        if llm_parse.get('depth') and 'depth' not in grouped_dimensions:
            classification['filters']['depth'] = llm_parse['depth']
        
        # Handle query_type and metric_clarity for routing decisions
        if llm_parse.get('query_type'):
            classification['query_type'] = llm_parse['query_type']
        if llm_parse.get('metric_clarity'):
            classification['metric_clarity'] = llm_parse['metric_clarity']
        
        # Handle analysis_type for specialized routing
        if llm_parse.get('analysis_type'):
            classification['analysis_type'] = llm_parse['analysis_type']
        
        # Handle ratio_metrics for ratio analysis
        if llm_parse.get('analysis_type') == 'ratio' and llm_parse.get('metric') and llm_parse.get('secondary_metric'):
            classification['ratio_metrics'] = [llm_parse['metric'], llm_parse['secondary_metric']]
        
        # CRITICAL: Add court_zone filter for net queries
        # Priority: 1) Explicit court_zone from LLM, 2) Infer from net_points_won metric, 3) Infer from domain
        if llm_parse.get('court_zone'):
            classification['filters']['court_zone'] = llm_parse['court_zone']
            print(f"[LLM-PARSE] Set 'court_zone: {llm_parse['court_zone']}' from LLM parse")
            # Remove conflicting shot_type if it's volley (net zone is broader)
            if classification['filters'].get('shot_type') == 'volley':
                del classification['filters']['shot_type']
                print(f"[LLM-PARSE] Removed 'shot_type: volley' because court_zone is set")
        elif llm_parse.get('metric') == 'net_points_won' or classification.get('domain') == 'net':
            classification['filters']['court_zone'] = 'net'
            print(f"[LLM-PARSE] Added 'court_zone: net' filter for net points query")
        
        # Handle chain logic for "Shot A led to Shot B" queries
        if llm_parse.get('chain_logic'):
            classification['filters']['chain_logic'] = llm_parse['chain_logic']
            classification['analysis_type'] = 'chain'
        
        # Handle tertiary_group_by for 3D analysis
        if llm_parse.get('tertiary_group_by'):
            classification['tertiary_group_by'] = llm_parse['tertiary_group_by']
        
        # Handle n_dimensional flag
        if llm_parse.get('n_dimensional'):
            classification['n_dimensional'] = llm_parse['n_dimensional']
        
        # Handle serve_target filter (from LLM)
        # BUT: skip if serve_target is being grouped (for comparisons like "T vs Wide")
        # CRITICAL: Only add serve_target if explicitly mentioned in the question
        # The LLM frequently hallucinates serve targets for general serve/return questions
        # AGGRESSIVE SAFEGUARD: Block serve_target unless explicitly mentioned
        if llm_parse.get('serve_target') and 'serve_target' not in grouped_dimensions:
            # Check if question explicitly mentions serve direction/target
            if original_question:
                q_lower = original_question.lower()
                
                # STRICT CHECK: Only allow serve_target if question EXPLICITLY mentions direction/target
                # Must be clear terms like "to T", "wide", "body", etc.
                serve_target_keywords = [
                    'wide', 'body', 
                    'down the t', 'to the t', 't serve', 'serve t', 'serves to t',
                    'down the middle', 'to the middle', 'to middle',
                    'serve wide', 'serve body', 'serves wide', 'serves body',
                    'served wide', 'served to', 'served to the',
                    'targeting', 'targeted',
                    'center', 'middle'  # Only if clearly about serves
                ]
                
                has_explicit_target = any(kw in q_lower for kw in serve_target_keywords)
                
                # Apply filter ONLY if explicit target is mentioned
                if has_explicit_target:
                    classification['filters']['serve_target'] = llm_parse['serve_target']
                    print(f"[LLM-PARSE] [ALLOWED] Applying serve_target='{llm_parse['serve_target']}' - explicitly mentioned")
                else:
                    print(f"[LLM-PARSE] [BLOCKED] Ignoring LLM's serve_target='{llm_parse['serve_target']}' - "
                          f"NOT explicitly mentioned in question: '{original_question}'")
                    # Explicitly remove if somehow already set
                    classification['filters'].pop('serve_target', None)
            else:
                # No original question to check - be conservative, don't trust LLM
                print(f"[LLM-PARSE] [BLOCKED] Ignoring LLM's serve_target='{llm_parse['serve_target']}' - "
                      f"no original question to validate")
                classification['filters'].pop('serve_target', None)
        
        # Handle court_side filter (from LLM)
        # BUT: skip if court_side is being grouped (for comparisons like "Ad Court vs Deuce Court")
        if llm_parse.get('court_side') and 'court_side' not in grouped_dimensions:
            classification['filters']['court_side'] = llm_parse['court_side']
        
        # Store actual question for answer formatting
        if llm_parse.get('actual_question'):
            classification['actual_question'] = llm_parse['actual_question']
        
        # === POST-PROCESSING: Fix metric hallucinations ===
        # If asking about break points, remove incorrect metrics like 'aces' or 'games_lost'
        if classification['filters'].get('situation') == 'break_point':
            metrics = classification.get('metrics', [])
            # Remove inappropriate metrics that LLM might have hallucinated
            inappropriate_for_bp = ['aces', 'games_lost', 'games_won']
            metrics = [m for m in metrics if m not in inappropriate_for_bp]
            # Default to points_won if we removed everything
            classification['metrics'] = metrics if metrics else ['points_won']
            print(f"[LLM-PARSE] Cleaned metrics for break_point situation: {classification['metrics']}")
        
        # === POST-PROCESSING: Fix first_serve_pct calculation ===
        # First serve percentage = (first serves IN) / (total serve attempts)
        # CRITICAL: We need ALL serve attempts, NOT just serve_number=1 points
        # serve_number=1 = points where first serve went IN
        # serve_number=2 = points where first serve was a FAULT (had to use 2nd serve)
        # So total = serve_number=1 + serve_number=2, count = serve_number=1
        metrics = classification.get('metrics', [])
        
        # CRITICAL: For secondary metrics, preserve serve_number context
        # If asking about "first serve percentage and first serve win percentage",
        # the serve_number filter should be removed for first_serve_pct but KEPT for win_percentage
        # Solution: Store metric-specific filters instead of global filter removal
        classification.setdefault('metric_specific_filters', {})
        
        if 'first_serve_pct' in metrics:
            # Remove serve_target filter (first serve % is global across all targets)
            if classification['filters'].get('serve_target'):
                print(f"[LLM-PARSE] Removing serve_target filter for first_serve_pct (global metric)")
                del classification['filters']['serve_target']
            
            # Remove shot_number if it was incorrectly set (shot_number is rally position, not serve attempt)
            if classification['filters'].get('shot_number'):
                print(f"[LLM-PARSE] Removing shot_number filter for first_serve_pct")
                del classification['filters']['shot_number']
            
            # CRITICAL: Store the serve_number filter before removing it
            # Other metrics (like win_percentage) might need it
            serve_number_filter = classification['filters'].get('serve_number')
            if serve_number_filter:
                print(f"[LLM-PARSE] Storing serve_number={serve_number_filter} for non-first_serve_pct metrics")
                classification['metric_specific_filters']['serve_number'] = serve_number_filter
            
            # Remove serve_number filter for first_serve_pct
            # We need ALL serve attempts (both 1st and 2nd serve points) to calculate the percentage correctly
            # The tracking logic will count serve_number=1 as "in" and everything as "total"
            if classification['filters'].get('serve_number'):
                print(f"[LLM-PARSE] Removing serve_number filter for first_serve_pct (need ALL serve attempts)")
                del classification['filters']['serve_number']
            
            print(f"[LLM-PARSE] first_serve_pct: Will count serve_number=1 as IN / all serves as total")
        
        # === POST-PROCESSING: Fix "break serve" vs "break point" confusion ===
        # CRITICAL: "break points" (situation) vs "breaks of serve" (games) are DIFFERENT!
        # - "break points" = points in break point situation (situation filter)
        # - "breaks", "break serve", "games broken" = games won on opponent's serve (games_lost metric)
        
        # Use original question if available, otherwise fall back to LLM's rephrased version
        question_lower = (original_question or llm_parse.get('actual_question') or '').lower()
        
        # FIRST: Check if this is clearly about break POINTS (situation), not games
        is_break_point_query = 'break point' in question_lower or 'breakpoint' in question_lower or 'break points' in question_lower
        
        # SECOND: Only check for break serve patterns if NOT a break point query
        is_break_serve_query = False
        if not is_break_point_query:
            # These patterns indicate break of serve (games), not break points (situation)
            break_serve_patterns = [
                'break serve', 'break of serve', 'breaks of serve',
                'games broken', 'break.*game', 'game.*break',
                'resulted in break', 'resulted in breaks'
            ]
            # Use regex matching for patterns
            import re
            for pattern in break_serve_patterns:
                if re.search(pattern, question_lower):
                    is_break_serve_query = True
                    print(f"[LLM-PARSE] Detected 'break serve' (games) query: pattern='{pattern}'")
                    break
        
        if is_break_point_query:
            # This is about break POINTS (situation), ensure filters are correct
            print(f"[LLM-PARSE] Detected 'break point' (situation) query")
            # Ensure situation is set correctly if LLM missed it
            if not classification['filters'].get('situation'):
                classification['filters']['situation'] = 'break_point'
                print(f"[LLM-PARSE] Set situation='break_point' (was missing)")
            
            # Ensure metric is appropriate for break points
            metrics = classification.get('metrics', [])
            if 'games_lost' in metrics or 'breaks' in metrics:
                print(f"[LLM-PARSE] Removing game metrics {metrics} for break_point situation")
                metrics = [m for m in metrics if m not in ['games_lost', 'breaks', 'games_won']]
                classification['metrics'] = metrics if metrics else ['points_won']
        elif is_break_serve_query:
            # This is about breaks of serve (games), NOT break points
            # Ensure situation is NOT set to break_point
            if classification['filters'].get('situation') == 'break_point':
                print(f"[LLM-PARSE] Fixing 'break serve' query: removing incorrect situation=break_point")
                classification['filters']['situation'] = None
            # Fix incorrect metric like "breaks_of_serve"
            if 'breaks_of_serve' in metrics:
                metrics.remove('breaks_of_serve')
            if 'games_lost' not in metrics:
                metrics.append('games_lost')
            # Remove points_won/win_percentage if they were incorrectly added
            if 'points_won' in metrics:
                metrics.remove('points_won')
            if 'win_percentage' in metrics and 'games_lost' in metrics:
                # Keep win_percentage only if it's asking for percentage
                if 'percentage' not in question_lower:
                    metrics.remove('win_percentage')
            classification['metrics'] = metrics
            print(f"[LLM-PARSE] Fixed break serve query - using games_lost metric with role=returner")
        
        # === POST-PROCESSING: Clear shot_type='serve' if serve_number filter exists ===
        # CRITICAL: serve_number is POINT-LEVEL metadata (what serve # the point was played on)
        # shot_type='serve' is a SHOT-LEVEL filter (filters to only serve shots)
        # These are incompatible! When asking "points on 2nd serve", we want:
        # - ALL points where serve_number=2 (used the 2nd serve)
        # - NOT just the serve shot itself
        # So if serve_number is present, remove shot_type='serve' from tree filters
        filters = classification.get('filters', {})
        if filters.get('serve_number') is not None and filters.get('shot_type') == 'serve':
            serve_ordinal = "1st" if filters['serve_number'] == 1 else "2nd"
            print(f"[LLM-PARSE] CRITICAL: Removing shot_type='serve' because serve_number={filters['serve_number']} is present")
            print(f"[LLM-PARSE]   serve_number is point metadata, shot_type='serve' would filter to only serve shots")
            print(f"[LLM-PARSE]   We want ALL points on {serve_ordinal} serve, not just the serve shot!")
            del filters['shot_type']
            classification['filters'] = filters
        
        # === FINAL STEP: Normalize and validate ALL field placement ===
        # This gatekeeper function enforces the canonical schema:
        # - Tree dimensions → filters
        # - Shot-level fields → top-level (NOT filters)
        # - Grouping/comparison → top-level only
        classification = self._normalize_and_validate_classification(classification)
        
        return classification
    
    def ask_question(self, question: str, top_k: int = None) -> str:
        """
        Main method to ask a question and get an answer.
        
        INTELLIGENT ROUTING:
        1. LLM parses query -> structured understanding
        2. Classification uses LLM output + keyword detection
        3. Route by category:
           - 'analytical' -> Taxonomy/PBP parsing
           - 'comparative' -> Taxonomy + LLM synthesis
           - 'narrative' -> NL retrieval + LLM
        """
        print(f"Processing question: {question}")
        
        # STEP 1: LLM PARSES THE QUERY FIRST
        print("[LLM-PARSE] Using LLM to understand query structure...")
        llm_parse = self._llm_parse_query(question)
        
        # STEP 2: TAXONOMY CLASSIFICATION (enhanced by LLM parse)
        classification = self._classify_query(question)
        
        # STEP 3: APPLY LLM PARSE TO CLASSIFICATION
        if llm_parse:
            classification = self._apply_llm_parse_to_classification(classification, llm_parse, original_question=question)
        
        # STEP 3.1: POST-PROCESS PLAYER + ROLE DETECTION
        # Fix cases like "Sinner's return games" where LLM sets player='both' but should be 'Jannik Sinner'
        classification = self._fix_player_role_detection(question, classification)
        
        # STEP 3.25: RESOLVE VAGUE TERMS TO METRICS
        # Convert terms like "effective", "aggressive", "momentum" to concrete metric bundles
        classification = self._resolve_vague_terms(question, classification)
        
        # STEP 3.4: GAME-LEVEL QUERIES NOW USE UNIFIED TREE
        # Games should aggregate naturally from point data through score parsing
        # TODO CRITICAL: Add game/set info to point metadata for proper hierarchical aggregation:
        #   - Parse score from each point header (set-game-point)
        #   - Add 'game_number' and 'set_number' to point metadata
        #   - Track unique (set, game) tuples won by each player during tree traversal
        #   - Aggregate games -> sets -> match naturally through the tree
        # For now, games_won metric temporarily falls back to game_winners dict
        
        # STEP 3.5: CLASSIFY QUERY COMPLEXITY FOR MODEL SELECTION
        complexity = self._classify_query_complexity(question, classification)
        model_config = self._get_model_config(complexity)
        classification['_complexity'] = complexity  # Store for later use
        classification['_model_config'] = model_config  # Store model config
        
        complexity_labels = {1: "SIMPLE (2.5 Flash)", 2: "MODERATE (3 Flash)", 3: "COMPLEX (3 Flash)"}
        print(f"[MODEL-TIER] Complexity: {complexity_labels.get(complexity, 'UNKNOWN')} | Model: {model_config['model_name']} | Temp: {model_config.get('temperature', 0.7)}")
        
        # =====================================================================
        # QUERY PLAN MODE (primary intelligent routing)
        # =====================================================================
        # Query Plan LLM determines the optimal operation structure:
        # - When to use tree filtering before narrative
        # - Multiple conditions combined
        # - Stats + patterns together
        # - Complex multi-filter analysis
        use_query_plan = self._should_use_query_plan(question, classification, llm_parse)
        
        if use_query_plan:
            print("[QUERY-PLAN] Using Query Plan architecture for multi-operation query")
            query_plan = self._generate_query_plan(question, classification)
            
            if query_plan and query_plan.get('query_plan'):
                for i, op in enumerate(query_plan['query_plan']):
                    print(f"[QUERY-PLAN]   Op {op.get('id', i)}: {op.get('route')} | filters={op.get('filters', {})} | metrics={op.get('metrics', [])}")
                
                answer = self._execute_query_plan(question, query_plan, classification, top_k)
                self.last_answer = answer
                self.last_analysis = None
                return answer
        
        group_by = classification.get('group_by')
        secondary_group_by = classification.get('secondary_group_by')
        tertiary_group_by = classification.get('tertiary_group_by')
        analysis_type = classification.get('analysis_type', 'count')
        query_category = classification.get('query_category', 'analytical')
        is_n_dimensional = classification.get('n_dimensional', False)
        
        # Count total dimensions (filters with values + groups)
        filters = classification.get('filters', {})
        # Exclude non-restrictive filters: player='both', handedness (default), None values
        active_filters = sum(1 for k, v in filters.items() 
                           if v is not None 
                           and not (k == 'player' and v and v.lower() == 'both')
                           and not (k == 'handedness'))
        group_count = sum(1 for g in [group_by, secondary_group_by, tertiary_group_by] if g)
        total_dimensions = active_filters + group_count
        
        print(f"[ROUTING] Category: {query_category}, Domain: {classification['domain']}, Group: {group_by}")
        print(f"[ROUTING] Analysis Type: {analysis_type}, Secondary Group: {secondary_group_by}")
        print(f"[ROUTING] Filters: {filters}")
        print(f"[ROUTING] Metrics: {classification.get('metrics', [])}")
        print(f"[ROUTING] Total Dimensions: {total_dimensions} (filters: {active_filters}, groups: {group_count})")
        
        # =====================================================================
        # INTELLIGENT ROUTING (Three-Level System)
        # =====================================================================
        # LEVEL 0: HYBRID DETECTION
        #   - Tree-filterable condition + shot question â†' Tree filter then Narrative
        #   - Needed when shot stats aren't pre-computed for specific filters
        #
        # LEVEL 1: Query Type Detection
        #   - SHOT-LEVEL: direction, shot_type filters â†' Embeddings (pre-computed)
        #   - POINT-LEVEL: situation, serve, role filters â†' Tree (point aggregation)
        #
        # LEVEL 2: Within Point-Level
        #   1. NARRATIVE â†' LLM identified descriptive/strategic
        #   2. CHAIN LOGIC â†' Shot A â†' Shot B patterns
        #   3. ANALYTICAL â†' Taxonomy/tree analysis
        # =====================================================================
        
        question_lower = question.lower()
        
        # Normalize arrows (Unicode → to ASCII ->)
        question_normalized = question.replace('→', '->').replace('→', '->')
        question_lower_normalized = question_normalized.lower()
        
        # === LEVEL -3: MULTI-STEP PATTERN DETECTION (BEFORE CONSECUTIVE) ===
        # Multi-step patterns: "forehand -> approach -> volley -> winner"
        # Can come from:
        # 1. Explicit arrows: "crosscourt -> crosscourt -> down-the-line"
        # 2. LLM parsing natural language into nested chain_logic with 'next_shot'
        
        # Check if LLM detected a multi-step pattern (nested next_shot in chain_logic)
        chain_logic = classification.get('chain_logic') or filters.get('chain_logic')
        has_nested_pattern = False
        if chain_logic and isinstance(chain_logic, dict):
            shot_b = chain_logic.get('shot_b')
            if shot_b and isinstance(shot_b, dict) and 'next_shot' in shot_b:
                has_nested_pattern = True
                print("[MULTI-STEP] Detected nested pattern in chain_logic (LLM parsed multi-step from natural language)")
        
        has_multistep_keywords = (
            '->' in question_lower_normalized or
            ' then ' in question_lower_normalized or
            'sequence' in question_lower_normalized or
            re.search(r'(forehand|backhand|volley|slice|approach|crosscourt|down.the.line)\s*(,|then|->|followed by)\s*(forehand|backhand|volley|slice|approach|crosscourt|down.the.line|winner|error)', question_lower_normalized)
        )
        
        if has_nested_pattern or (has_multistep_keywords and '->' in question_normalized):
            pattern = []
            
            # OPTION 1: LLM already parsed nested pattern from natural language
            if has_nested_pattern:
                # Extract pattern from nested chain_logic structure
                # e.g., {shot_a: {direction: 'crosscourt'}, shot_b: {direction: 'crosscourt', next_shot: {direction: 'down_the_line'}}}
                def extract_pattern_from_chain(chain_dict, current_pattern=[]):
                    if not chain_dict:
                        return current_pattern
                    
                    # Extract shot_a
                    shot_a = chain_dict.get('shot_a', {})
                    if shot_a:
                        # Build description from shot_a attributes
                        parts = []
                        if shot_a.get('shot_type'): parts.append(shot_a['shot_type'])
                        if shot_a.get('direction'): parts.append(shot_a['direction'])
                        if shot_a.get('intent'): parts.append(shot_a['intent'])
                        if shot_a.get('outcome'): parts.append(shot_a['outcome'])
                        if parts:
                            current_pattern.append(' '.join(parts))
                    
                    # Extract shot_b
                    shot_b = chain_dict.get('shot_b', {})
                    if shot_b:
                        parts = []
                        if shot_b.get('shot_type'): parts.append(shot_b['shot_type'])
                        if shot_b.get('contact_type'): parts.append(shot_b['contact_type'])
                        if shot_b.get('direction'): parts.append(shot_b['direction'])
                        if shot_b.get('intent'): parts.append(shot_b['intent'])
                        if shot_b.get('outcome'): parts.append(shot_b['outcome'])
                        if parts:
                            current_pattern.append(' '.join(parts))
                        
                        # Recursively extract next_shot
                        if 'next_shot' in shot_b:
                            return extract_pattern_from_chain({'shot_a': shot_b['next_shot']}, current_pattern)
                    
                    return current_pattern
                
                pattern = extract_pattern_from_chain(chain_logic)
                print(f"[MULTI-STEP] Extracted pattern from LLM chain_logic: {pattern}")
                
                # Check if LLM parsed "winner" or "error" as a METRIC instead of as an outcome
                # If so, append it to the pattern as the final shot outcome
                metrics_parsed = classification.get('metrics_parsed', [])
                for metric_info in metrics_parsed:
                    metric = metric_info.get('metric', '')
                    if metric in ['winners', 'winner']:
                        # Add "winner" as final element if not already there
                        if pattern and 'winner' not in pattern[-1].lower():
                            pattern[-1] = pattern[-1] + ' winner'
                            print(f"[MULTI-STEP] Added 'winner' outcome from metrics to last shot: {pattern[-1]}")
                    elif metric in ['unforced_errors', 'unforced error', 'forced_errors', 'forced error', 'errors']:
                        if pattern and 'error' not in pattern[-1].lower():
                            error_type = 'unforced error' if 'unforced' in metric else 'error'
                            pattern[-1] = pattern[-1] + ' ' + error_type
                            print(f"[MULTI-STEP] Added '{error_type}' outcome from metrics to last shot: {pattern[-1]}")
            
            # OPTION 2: Parse explicit arrow pattern from question
            elif '->' in question_normalized:
                pattern_match = re.findall(r'([a-zA-Z\s\-_]+)\s*->', question_lower_normalized)
                if pattern_match:
                    # Add the last element (after final arrow)
                    last_match = re.search(r'->\s*([a-zA-Z\s\-_]+?)(?:\?|$|\s*,|\s*and)', question_lower_normalized)
                    if last_match:
                        pattern_match.append(last_match.group(1).strip())
                    
                    pattern = [p.strip() for p in pattern_match if p.strip()]
                    print(f"[MULTI-STEP] Detected pattern from arrows: {pattern}")
            
            # CRITICAL: Multi-attribute shot support - CONFIG-DRIVEN
            # Patterns can have multiple attributes per shot:
            # - "forehand crosscourt winner" (shot_type + direction + outcome)
            # - "backhand slice down-the-line" (shot_type + spin + direction)
            # - "volley winner" (contact_type + outcome)
            # 
            # Approach: Keep pattern elements as-is (they may already contain multiple words)
            # The matching logic will handle multi-word patterns by checking ALL attributes
            # 
            # We DON'T need to pre-combine because:
            # 1. Arrow patterns already have combined elements: "forehand crosscourt → backhand"
            # 2. LLM extraction already builds combined descriptions
            # 3. The matcher checks if pattern step matches shot (not exact equality)
            
            # COMBINE adjacent pattern elements that are different attributes of the same shot
            # E.g., ['forehand', 'approach', 'volley', 'winner'] -> ['forehand approach', 'volley winner']
            if pattern:  # Only process if pattern was extracted
                pattern = [p.strip() for p in pattern if p.strip()]
                print(f"[MULTI-STEP] Raw pattern from extraction: {pattern}")
                
                # Combine logic: merge adjacent elements if they are different attribute types
                # Shot attributes from config:
                shot_types = self.GROUP_CONFIG.get('shot_type', {}).get('default_branches', [])
                outcomes = self.GROUP_CONFIG.get('outcome', {}).get('default_branches', [])
                intents = self.match_filter_inventory.get('intents', [])
                contact_types = self.match_filter_inventory.get('contact_types', [])
                directions = self.GROUP_CONFIG.get('shot_direction', {}).get('default_branches', [])
                
                combined_pattern = []
                i = 0
                
                # Get ALL config-driven categories for combining
                shot_modifiers = self.GROUP_CONFIG.get('shot_modifier', {}).get('default_branches', [])
                spins = self.GROUP_CONFIG.get('spin', {}).get('default_branches', [])
                
                while i < len(pattern):
                    current = pattern[i].lower().strip()
                    
                    # Check if next element should be combined with current
                    if i + 1 < len(pattern):
                        next_elem = pattern[i + 1].lower().strip()
                        
                        # Detect what category each element belongs to
                        # Use exact matching for reliability
                        def matches_category(elem, category_list):
                            elem_normalized = elem.replace('-', '_').replace(' ', '_')
                            for item in category_list:
                                item_normalized = item.lower().replace('-', '_').replace(' ', '_')
                                if elem_normalized == item_normalized or elem in item.lower() or item.lower() in elem:
                                    return True
                            return False
                        
                        current_is_shot_type = matches_category(current, shot_types)  # forehand, backhand
                        current_is_modifier = matches_category(current, shot_modifiers)  # approach, volley, slice, drop_shot
                        current_is_spin = matches_category(current, spins)  # slice, topspin, flat
                        current_is_direction = matches_category(current, directions)  # crosscourt, down_the_line
                        current_is_contact = matches_category(current, contact_types)  # volley, overhead
                        
                        next_is_outcome = matches_category(next_elem, outcomes)  # winner, error
                        next_is_modifier = matches_category(next_elem, shot_modifiers)  # approach, volley, slice
                        next_is_direction = matches_category(next_elem, directions)
                        next_is_shot_type = matches_category(next_elem, shot_types)
                        next_is_contact = matches_category(next_elem, contact_types)
                        next_is_spin = matches_category(next_elem, spins)
                        
                        # Combining rules:
                        # 1. shot_type + modifier (forehand + approach) → COMBINE
                        # 2. modifier/contact + outcome (volley + winner) → COMBINE
                        # 3. spin + modifier (slice + approach) → COMBINE
                        # 4. shot_type + spin (forehand + slice) → COMBINE
                        # 5. direction + direction → DON'T COMBINE (separate shots)
                        
                        should_combine = (
                            # Rule 1: shot_type + modifier/spin (forehand approach, backhand slice)
                            (current_is_shot_type and (next_is_modifier or next_is_spin)) or
                            # Rule 2: modifier/contact + outcome (volley winner, approach winner)
                            ((current_is_modifier or current_is_contact) and next_is_outcome) or
                            # Rule 3: spin + modifier (slice approach)
                            (current_is_spin and next_is_modifier) or
                            # Rule 4: shot_type + spin (forehand slice - rare but valid)
                            (current_is_shot_type and next_is_spin)
                        )
                        
                        # NEVER combine two directions (crosscourt + crosscourt = 2 separate shots)
                        if current_is_direction and next_is_direction:
                            should_combine = False
                        
                        print(f"[MULTI-STEP-COMBINE] '{current}' (shot_type={current_is_shot_type}, mod={current_is_modifier}, spin={current_is_spin}, dir={current_is_direction}, contact={current_is_contact})")
                        print(f"[MULTI-STEP-COMBINE] '{next_elem}' (outcome={next_is_outcome}, mod={next_is_modifier}, dir={next_is_direction}, shot_type={next_is_shot_type}, contact={next_is_contact}, spin={next_is_spin})")
                        print(f"[MULTI-STEP-COMBINE] Should combine? {should_combine}")
                        
                        if should_combine:
                            combined_pattern.append(f"{pattern[i]} {pattern[i+1]}")
                            print(f"[MULTI-STEP] Combined '{pattern[i]}' + '{pattern[i+1]}' into '{pattern[i]} {pattern[i+1]}'")
                            i += 2
                            continue
                    
                    combined_pattern.append(pattern[i])
                    i += 1
                
                pattern = combined_pattern
                print(f"[MULTI-STEP] Pattern after combining: {pattern}")
                
                # Process ALL combined patterns (2+ shots) - multi-step handler works for any length
                if len(pattern) >= 2:
                    print(f"[MULTI-STEP] Detected pattern: {pattern}")
                    classification['multi_step_pattern'] = pattern
                    
                    try:
                        analysis = self._analyze_multi_step_pattern(classification)
                        if 'error' not in analysis and analysis.get('total_matches', 0) > 0:
                            self.last_analysis = analysis
                            data_response = self._format_multi_step_pattern_analysis(analysis)
                            answer = self._synthesize_with_narrative(question, data_response, classification)
                            
                            # Append debug info (matching points) AFTER narrative synthesis
                            debug_info = analysis.get('debug_info', [])
                            if debug_info:
                                answer += "\n\n" + "\n".join(debug_info)
                            
                            self.last_answer = answer
                            print(f"[MULTI-STEP] Successfully analyzed: {analysis.get('total_matches')} pattern matches")
                            return answer
                        elif 'error' in analysis:
                            print(f"[MULTI-STEP] Error: {analysis.get('error')}, falling back")
                        else:
                            print(f"[MULTI-STEP] No pattern matches found, falling back")
                    except Exception as e:
                        print(f"[MULTI-STEP] Exception: {e}, falling back")
        
        # === LEVEL -2: CONSECUTIVE SHOTS DETECTION (BEFORE CHAIN) ===
        # Consecutive shot patterns: "3+ forehands in a row", "consecutive crosscourts"
        has_consecutive_keywords = (
            'consecutive' in question_lower or
            'in a row' in question_lower or
            'in-a-row' in question_lower or
            re.search(r'\d+\+?\s*(straight|consecutive)', question_lower) or
            re.search(r'(hit|hitting|had)\s+\d+\+?\s*(fore|back|cross|down)', question_lower)
        )
        has_consecutive_filters = (
            classification.get('consecutive_shots_min') or
            filters.get('consecutive_shots_min') or
            filters.get('sequence_shot_type')
        )
        is_consecutive_query = has_consecutive_keywords or has_consecutive_filters
        
        if is_consecutive_query:
            print("[CONSECUTIVE] Consecutive shots query detected -> Attempting sequence analysis")
            
            # Extract minimum consecutive count from question if not in classification
            if not classification.get('consecutive_shots_min'):
                # Try to extract number from question like "3+ consecutive" or "hit 4 forehands"
                num_match = re.search(r'(\d+)\+?\s*(consecutive|straight|in a row|fore|back)', question_lower)
                if num_match:
                    classification['consecutive_shots_min'] = int(num_match.group(1))
                else:
                    classification['consecutive_shots_min'] = 3  # Default
            
            # Extract shot type if not set
            if not classification.get('sequence_shot_type') and not filters.get('shot_type'):
                if 'forehand' in question_lower:
                    classification['sequence_shot_type'] = 'forehand'
                elif 'backhand' in question_lower:
                    classification['sequence_shot_type'] = 'backhand'
            
            # Extract direction if present
            if 'crosscourt' in question_lower or 'cross court' in question_lower:
                classification['sequence_direction'] = 'crosscourt'
            elif 'down the line' in question_lower or 'down-the-line' in question_lower:
                classification['sequence_direction'] = 'down_the_line'
            
            try:
                analysis = self._analyze_consecutive_shots(classification)
                if 'error' not in analysis and analysis.get('total_sequences', 0) > 0:
                    self.last_analysis = analysis
                    data_response = self._format_consecutive_shots_analysis(analysis)
                    answer = self._synthesize_with_narrative(question, data_response, classification)
                    
                    # Append debug info (matching points) AFTER narrative synthesis
                    debug_info = analysis.get('debug_info', [])
                    if debug_info:
                        answer += "\n\n" + "\n".join(debug_info)
                    
                    self.last_answer = answer
                    print(f"[CONSECUTIVE] Successfully analyzed: {analysis.get('total_sequences')} qualifying sequences, max {analysis.get('max_consecutive')} consecutive")
                    return answer
                elif 'error' in analysis:
                    print(f"[CONSECUTIVE] Error: {analysis.get('error')}, falling back to narrative")
                else:
                    print(f"[CONSECUTIVE] No matching sequences found, falling back to narrative")
            except Exception as e:
                print(f"[CONSECUTIVE] Exception: {e}, falling back to narrative")
            
            # Fallback to narrative
            print("[CONSECUTIVE] Using narrative fallback")
            answer = self._handle_narrative_query(question, classification, top_k)
            self.last_answer = answer
            self.last_analysis = None
            return answer
        
        # === LEVEL -1: CHAIN LOGIC DETECTION (MUST BE FIRST) ===
        # Chain queries have their own dedicated handler and should bypass all other routing
        # Detect chain patterns: "X led to Y", "X followed by Y", "when X...respond", "after/before X...did Y"
        has_chain_keywords = (
            'led to' in question_lower or 
            'lead to' in question_lower or 
            'followed by' in question_lower or
            ('when' in question_lower and 'respond' in question_lower) or
            ('after' in question_lower and 'respond' in question_lower) or
            ('before' in question_lower and 'respond' in question_lower) or
            ('after' in question_lower and 'did' in question_lower) or
            ('before' in question_lower and 'did' in question_lower)
        )
        is_chain_query = analysis_type == 'chain' or filters.get('chain_logic') or has_chain_keywords
        
        if is_chain_query:
            # ALL chain queries → Try dedicated chain handler first
            # The chain handler can parse rally sequences for shot-level attributes (forehand, crosscourt, etc.)
            print("[CHAIN] Chain query detected -> Attempting sequence analysis")
            try:
                analysis = self._analyze_chain_logic(classification)
                if 'error' not in analysis and analysis.get('total_shot_a', 0) > 0:
                    # Success! Store analysis and format response
                    self.last_analysis = analysis
                    data_response = self._format_chain_logic_analysis(analysis)
                    answer = self._synthesize_with_narrative(question, data_response, classification)
                    
                    # Append debug info (matching points) AFTER narrative synthesis
                    debug_info = analysis.get('debug_info', [])
                    if debug_info:
                        answer += "\n\n" + "\n".join(debug_info)
                    
                    self.last_answer = answer
                    print(f"[CHAIN] Successfully analyzed: {analysis.get('total_shot_a')} Shot A occurrences, {analysis.get('total_chain_sequences')} complete sequences")
                    return answer
                elif 'error' in analysis:
                    print(f"[CHAIN] Error: {analysis.get('error')}, falling back to narrative")
                else:
                    print(f"[CHAIN] No pattern matches found, falling back to narrative")
            except Exception as e:
                print(f"[CHAIN] Exception: {e}, falling back to narrative")
            
            # Fallback: If chain handler couldn't find patterns, use narrative
            print("[CHAIN] Using narrative fallback for complex chain analysis")
            answer = self._handle_narrative_query(question, classification, top_k)
            self.last_answer = answer
            self.last_analysis = None
            return answer
        
        # === LEVEL -0.5: SHOT PRE-FILTERING DETECTION (BEFORE HYBRID) ===
        # Shot prefilter queries have shot-level attributes (e.g., "When Nadal hit forehand down-the-line...")
        # These need _prefilter_points_by_shot_attributes to filter by shot attributes
        filters_dict = classification.get('filters', {})
        has_shot_attributes = any([
            filters_dict.get('shot_type'),
            classification.get('shot_type'),
            filters_dict.get('direction'),
            classification.get('direction'),
            filters_dict.get('spin'),
            classification.get('spin'),
            filters_dict.get('outcome')
        ])
        
        # Don't use shot prefilter for chain/consecutive (they have their own handlers)
        # Multi-step patterns are handled earlier, so no need to check
        is_shot_prefilter_query = has_shot_attributes and not (is_chain_query or is_consecutive_query)
        
        if is_shot_prefilter_query:
            print("[SHOT-PREFILTER] Shot attribute query detected -> Using shot pre-filtering")
            answer = self._handle_narrative_query(question, classification, top_k)
            self.last_answer = answer
            self.last_analysis = None
            return answer
        
        # === LEVEL 0: HYBRID ROUTING (Tree Filter â†' Narrative Analysis) ===
        # Hybrid is needed when:
        # 1. Query has tree-filterable condition (set, point_score, situation+shots, etc.)
        # 2. AND requires shot-level analysis (directions, shot counting, patterns)
        # 3. AND the combination is NOT pre-computed in NL file
        hybrid_result = self._check_hybrid_routing(question, classification, filters)
        if hybrid_result['needs_hybrid']:
            print(f"[HYBRID] Detected: {hybrid_result['reason']}")
            print(f"[HYBRID] Tree filters: {hybrid_result['tree_filters']}, Shot analysis: {hybrid_result['shot_trigger']}")
            answer = self._handle_hybrid_query(question, classification, hybrid_result, top_k)
            self.last_answer = answer
            self.last_analysis = None
            return answer
        
        # === LEVEL 1: SHOT-LEVEL vs POINT-LEVEL ROUTING ===
        is_shot_level_query = self._is_shot_level_query(question, classification)
        if is_shot_level_query:
            print("[SHOT-LEVEL] Query requires shot-level stats -> Routing to embeddings ONLY (bypassing tree)")
            answer = self._handle_narrative_query(question, classification, top_k)
            self.last_answer = answer
            self.last_analysis = None
            return answer
        
        # === LEVEL 2: POINT-LEVEL ROUTING ===
        # === 0. NARRATIVE ROUTE -> LLM identified as narrative ===
        # Questions about strategy, momentum, patterns, "did X change?", etc.
        # Narrative has access to BOTH NL file AND point-by-point data
        if query_category == 'narrative':
            print("[NARRATIVE] LLM classified as narrative question -> Using NL file + PBP data context")
            answer = self._handle_narrative_query(question, classification, top_k)
            self.last_answer = answer
            self.last_analysis = None  # Narrative queries don't have structured analysis
            return answer
        
        # === 0.5. GAME QUERY ROUTE -> "How many games won?" ===
        # Games are aggregated from score transitions, not point counts
        # Route game queries to narrative instead of dedicated game handler
        if self._is_game_query(question):
            print("[GAME-QUERY] Detected game-level query -> Routing to narrative")
            answer = self._handle_narrative_query(question, classification, top_k)
            self.last_answer = answer
            self.last_analysis = None  # Narrative queries don't have structured analysis
            return answer
        
        # === 1. CHAIN LOGIC ANALYSIS -> Shot A -> Shot B patterns ===
        # CRITICAL: Chain logic is conceptually shot-level (requires full shot sequences)
        # But we distinguish between:
        #   - Shot-to-shot chains (Shot A with shot filters) -> Embeddings (default)
        #   - Point-level event chains (serve -> return -> outcome) -> Tree
        is_chain_query = analysis_type == 'chain' or filters.get('chain_logic') or 'led to' in question_lower or 'lead to' in question_lower or 'followed by' in question_lower
        
        if is_chain_query:
            # Check if chain involves shot attributes (shot_type, direction, shot_modifier)
            # Shot-to-shot chains require shot attributes; point-level chains don't
            chain_logic = filters.get('chain_logic', {})
            shot_a = chain_logic.get('shot_a', {})
            
            # Check if Shot A has shot-level attributes (in dict or as keywords in question)
            has_shot_attributes_in_chain = False
            if isinstance(shot_a, dict):
                has_shot_attributes_in_chain = any(shot_a.get(key) for key in ['shot_type', 'direction', 'shot_modifier'])
            elif isinstance(shot_a, str):
                # Check question for shot type/direction keywords
                shot_type_terms = []
                shot_type_config = self.GROUP_CONFIG.get('shot_type', {}).get('default_branches', [])
                if shot_type_config:
                    for st in shot_type_config:
                        shot_type_terms.append(st.lower())
                        shot_type_terms.append(st.lower().replace('_', ' '))
                        shot_type_terms.append(st.lower().replace('_', '-'))
                
                direction_terms = []
                direction_config = self.GROUP_CONFIG.get('direction', {}).get('default_branches', [])
                for d in direction_config:
                    direction_terms.append(d.lower())
                    direction_terms.append(d.lower().replace('_', ' '))
                    direction_terms.append(d.lower().replace('_', '-'))
                
                shot_a_lower = shot_a.lower()
                has_shot_type = any(term in shot_a_lower for term in shot_type_terms)
                has_direction = any(term in shot_a_lower for term in direction_terms)
                has_shot_attributes_in_chain = has_shot_type or has_direction
            
            # Also check question for shot keywords if Shot A isn't explicitly provided
            if not has_shot_attributes_in_chain:
                shot_keywords_in_question = any(kw in question_lower for kw in ['forehand', 'backhand', 'volley', 'crosscourt', 'down-the-line', 'down the line', 'inside-out', 'inside-in'])
                # But exclude serve/return (point-level events)
                is_serve_return_only = ('serve' in question_lower or 'return' in question_lower) and not shot_keywords_in_question
                has_shot_attributes_in_chain = shot_keywords_in_question and not is_serve_return_only
            
            if has_shot_attributes_in_chain:
                # Shot-to-shot chain -> Embeddings (requires full rally shot sequences)
                print("[CHAIN] Shot-to-shot chain detected (requires shot sequences) -> Routing to embeddings")
                answer = self._handle_narrative_query(question, classification, top_k)
                self.last_answer = answer
                self.last_analysis = None
                return answer
            else:
                # Point-level event chain (serve -> return -> outcome) -> Tree
                print("[CHAIN] Point-level event chain detected (serve/return events) -> Routing to tree analysis")
                try:
                    analysis = self._analyze_chain_logic(classification)
                    if 'error' not in analysis and analysis.get('total_shot_a', 0) > 0:
                        # Store analysis for external access
                        self.last_analysis = analysis
                        data_response = self._format_chain_logic_analysis(analysis)
                        answer = self._synthesize_with_narrative(question, data_response, classification)
                        
                        # Append debug info (matching points) AFTER narrative synthesis
                        debug_info = analysis.get('debug_info', [])
                        if debug_info:
                            answer += "\n\n" + "\n".join(debug_info)
                        
                        self.last_answer = answer
                        return answer
                    elif 'error' in analysis:
                        print(f"[CHAIN] Error: {analysis.get('error')}, falling through to taxonomy")
                    else:
                        print(f"[CHAIN] No matches found, falling through to taxonomy")
                except Exception as e:
                    print(f"[CHAIN] Exception: {e}, falling through to taxonomy")
        
        # === 2. UNIFIED TREE ANALYZER -> ALL analytical queries ===
        # ONE PATH for all queries - complexity just affects tree depth
        # Simple query = shallow tree (0-1 filters), Complex = deep tree (3+ filters)
        # NOTE: "TAXONOMY" and "N-DIM" are the SAME system - just different log labels
        print(f"[ANALYSIS] Unified tree analyzer (depth={total_dimensions})")
        try:
            analysis = self._analyze_n_dimensional(classification)
            if 'error' not in analysis:
                # Store analysis for external access
                self.last_analysis = analysis
                data_response = self._format_n_dimensional_results(analysis)
                answer = self._synthesize_with_narrative(question, data_response, classification)
                self.last_answer = answer
                return answer
            else:
                print(f"[TAXONOMY] Analysis error: {analysis.get('error')}, falling through to narrative")
        except Exception as e:
            import traceback
            print(f"[TAXONOMY] Exception: {e}")
            traceback.print_exc()
        
        # === 3. NARRATIVE FALLBACK -> Pure summary/story questions ===
        # Also handles any queries that taxonomy couldn't process
        print("[NARRATIVE] Routing to NL retrieval + LLM for narrative synthesis")
        answer = self._handle_narrative_query(question, classification, top_k)
        self.last_answer = answer
        self.last_analysis = None  # Narrative queries don't have structured analysis
        return answer
    
    def get_chunk_info(self) -> Dict:
        """
        Get information about the loaded chunks.
        """
        if not self.chunks:
            return {"error": "No chunks loaded"}
        
        # Count chunks by type and section
        type_counts = {}
        section_counts = {}
        
        for chunk in self.chunks:
            chunk_type = chunk["metadata"]["type"]
            section = chunk["metadata"]["section"]
            
            type_counts[chunk_type] = type_counts.get(chunk_type, 0) + 1
            section_counts[section] = section_counts.get(section, 0) + 1
        
        return {
            "total_chunks": len(self.chunks),
            "chunks_by_type": type_counts,
            "chunks_by_section": section_counts,
            "match_id": self.match_id,
            "llm_provider": self.llm_provider
        }

    def convert_json_to_natural_language(self, match_data: Dict[str, Any]) -> str:
        """
        Convert all JSON data to natural language text that the LLM can easily read and analyze.
        This includes all tables, player names, data descriptions, and context.
        """
        if not match_data:
            return "No match data available."
            
        natural_language = []
        natural_language.append("TENNIS MATCH DATA - NATURAL LANGUAGE FORMAT")
        natural_language.append("=" * 60)
        natural_language.append("")
        natural_language.append("IMPORTANT INSTRUCTIONS FOR DATA ANALYSIS:")
        natural_language.append("")
        natural_language.append("CRITICAL RULE FOR PER-SET / PER-GAME QUESTIONS:")
        natural_language.append("- If asked for PER-SET or PER-GAME breakdowns (e.g., 'unforced errors in each set', 'aces per set', 'serve % across sets'):")
        natural_language.append("  1. Check if the summary tables contain this per-set breakdown")
        natural_language.append("  2. If NOT in tables, you MUST count from the point-by-point narrative")
        natural_language.append("  3. Do NOT say 'data not available' - the point-by-point data contains everything")
        natural_language.append("")
        natural_language.append("GENERAL RULES FOR AGGREGATE TOTALS:")
        natural_language.append("- When answering about MATCH TOTALS (aces, double faults, points won), use only the AUTHORITATIVE TOTALS as the single source of truth")
        natural_language.append("- Use detailed breakdowns only for distributions and patterns, never for recalculating totals")
        natural_language.append("- Breakdowns sum to the authoritative totals - do not add them again")
        natural_language.append("- Summary statistics take precedence over detailed breakdowns for aggregate numbers")
        natural_language.append("")
        
        # Handle the actual JSON structure with matches array
        if 'matches' in match_data and match_data['matches']:
            match = match_data['matches'][0]  # Get the first match
        else:
            # Direct match object passed
            match = match_data
            
        # Get player names from match data first
        self.player1 = match.get('basic', {}).get('player1', 'Player 1')
        self.player2 = match.get('basic', {}).get('player2', 'Player 2')
        player1 = self.player1
        player2 = self.player2
        
        # Add match overview information
        natural_language.extend(self._get_match_overview_text(match))
        natural_language.append("")
        
        # Add all detailed statistics in natural language
        if 'details_tables' in match:
            natural_language.extend(self._convert_details_tables_to_text(match['details_tables'], player1, player2))
        
        # Add details_flat data for shots, shotdir, and netpts (these are not in details_tables)
        if 'details_flat' in match:
            natural_language.extend(self._convert_details_flat_to_text(match['details_flat'], player1, player2))
        
        # Add point-by-point data if available
        if 'point_log' in match:
            natural_language.extend(self._convert_point_log_to_text(match['point_log'], player1, player2))
        elif 'pointlog_rows' in match:
            natural_language.extend(self._convert_point_log_to_text(match['pointlog_rows'], player1, player2))
            
        # Post-process to move rally outcomes to the end for optimal embedding order
        final_text = "\n".join(natural_language)
        final_text = self._move_rally_outcomes_to_end(final_text)
        
        return final_text

    def _move_rally_outcomes_to_end(self, content: str) -> str:
        """Move RALLY OUTCOMES STATISTICS section to the very end for optimal embedding order"""
        
        lines = content.split('\n')
        
        # Find the rally outcomes section
        rally_start = None
        rally_end = None
        
        for i, line in enumerate(lines):
            if "RALLY OUTCOMES STATISTICS:" in line:
                rally_start = i
            elif rally_start is not None and line.strip() and any(keyword in line for keyword in ["STATISTICS:", "NARRATIVE:"]) and "RALLY OUTCOMES" not in line:
                rally_end = i
                break
        
        if rally_start is None:
            # No rally outcomes section found, return as-is
            return content
        
        if rally_end is None:
            rally_end = len(lines)  # If it's the last section
        
        # Extract the rally outcomes section
        rally_section = lines[rally_start:rally_end]
        
        # Remove rally outcomes from its current position
        lines_without_rally = lines[:rally_start] + lines[rally_end:]
        
        # Add rally outcomes at the very end
        lines_without_rally.extend([''] + rally_section)
        
        return '\n'.join(lines_without_rally)

    def _get_match_overview_text(self, match: Dict[str, Any]) -> List[str]:
        """Convert match overview data to natural language"""
        text = []
        text.append("MATCH OVERVIEW:")
        text.append("-" * 20)
        
        # Extract basic match information
        if 'basic' in match:
            basic = match['basic']
            text.append(f"The match was played on {basic.get('date', 'Unknown')} at the {basic.get('tournament', 'Unknown')} tournament.")
            text.append(f"The players were {basic.get('player1', 'Unknown')} and {basic.get('player2', 'Unknown')}.")
            text.append(f"This was a {basic.get('tour', 'Unknown')} match.")
            
            # Try to get match result from multiple possible locations
            match_result = None
            
            # First try: basic["match_result"]
            if 'match_result' in basic and basic['match_result']:
                match_result = basic['match_result']
            # Second try: details_flat["Match Result"]
            elif 'details_flat' in match and 'Match Result' in match['details_flat']:
                match_result = match['details_flat']['Match Result']
                # Clean up the result (remove extra player name prefix like "PegulaJessica Pegula")
                if match_result:
                    # Remove last name prefix (e.g., "PegulaJessica Pegula d. ..." -> "Jessica Pegula d. ...")
                    for player in [basic.get('player1', ''), basic.get('player2', '')]:
                        if player:
                            # Get last name
                            last_name = player.split()[-1] if ' ' in player else player
                            # Check if result starts with last name + full name
                            if match_result.startswith(last_name):
                                # Remove the last name prefix
                                match_result = match_result[len(last_name):]
                                break
            
            if match_result and match_result != "Unknown":
                text.append(f"Final Score: {match_result}")
            else:
                final_score = self._extract_final_score(match)
                if final_score:
                    text.append(f"Final Score: {final_score['winner']} defeated {final_score['loser']} {final_score['score']}")
                else:
                    text.append("Final Score: Unknown")
        
        return text

    def _extract_final_score(self, match: Dict[str, Any]) -> Optional[Dict[str, str]]:
        """Extract final score from point-by-point data"""
        try:
            if 'pointlog_rows' not in match:
                return None
            
            pointlog = match['pointlog_rows']
            if not pointlog:
                return None
            
            # Get the last point to find final score
            last_point = pointlog[-1]
            
            # Extract final sets and games from the last point
            final_sets = last_point.get('sets', '0-0')
            final_games = last_point.get('games', '0-0')
            
            # Parse sets score to determine winner
            sets_parts = final_sets.split('-')
            if len(sets_parts) == 2:
                player1_sets = int(sets_parts[0])  # Player 1's sets
                player2_sets = int(sets_parts[1])  # Player 2's sets
                
                # Get player names
                player1 = match.get('basic', {}).get('player1', 'Player 1')
                player2 = match.get('basic', {}).get('player2', 'Player 2')
                
                if player2_sets > player1_sets:
                    winner = player2
                    loser = player1
                    score = f"{player2_sets}-{player1_sets} in sets ({final_games} in final set)"
                else:
                    winner = player1
                    loser = player2  
                    score = f"{player1_sets}-{player2_sets} in sets ({final_games} in final set)"
                
                return {
                    'winner': winner,
                    'loser': loser,
                    'score': score
                }
            
        except Exception as e:
            print(f"Error extracting final score: {e}")
        
        return None

    def _determine_match_winner(self, match: Dict[str, Any]) -> Optional[str]:
        """Determine match winner from available data sources"""
        try:
            # Method 1: Check for explicit match result in details_tables
            if 'details_tables' in match:
                for table in match['details_tables']:
                    if table.get('name', '').lower() in ['other data', 'match result', 'result']:
                        for row in table.get('rows', []):
                            label = row.get('label', '').lower()
                            if 'match result' in label or 'result' in label:
                                values = row.get('values', [])
                                if values and values[0]:
                                    result_text = values[0]
                                    # Parse format like "Player 2 d. Player 1 6-4 7-5"
                                    if ' d. ' in result_text:
                                        winner = result_text.split(' d. ')[0].strip()
                                        return winner
            
            # Method 2: Check details_flat for match result
            if 'details_flat' in match:
                flat_data = match['details_flat']
                for key, value in flat_data.items():
                    if 'result' in key.lower() and isinstance(value, str) and ' d. ' in value:
                        winner = value.split(' d. ')[0].strip()
                        return winner
            
            return None
        except Exception:
            return None

    def _extract_match_result_with_score(self, match: Dict[str, Any]) -> Optional[str]:
        """Extract match result with score from available data"""
        try:
            # Check details_flat for match result
            if 'details_flat' in match:
                flat_data = match['details_flat']
                for key, value in flat_data.items():
                    if 'result' in key.lower() and isinstance(value, str):
                        # Clean up malformed player names
                        result = value
                        # Fix duplicate name patterns dynamically
                        if self.player1 and f"{self.player1.split()[-1]}{self.player1}" in result:
                            result = result.replace(f"{self.player1.split()[-1]}{self.player1}", self.player1)
                        if self.player2 and f"{self.player2.split()[-1]}{self.player2}" in result:
                            result = result.replace(f"{self.player2.split()[-1]}{self.player2}", self.player2)
                        return result
            
            return None
        except Exception:
            return None

    def _convert_details_tables_to_text(self, details_tables: List[Dict[str, Any]], player1: str, player2: str) -> List[str]:
        """Convert all details tables to natural language text"""
        text = []
        
        for table in details_tables:
            table_name = table.get('name', 'Unknown Table')
            rows = table.get('rows', [])
            
            # Skip shots, shotdir, netpts, serve, return, and keypoints tables since they will be handled by _convert_details_flat_to_text
            if any(keyword in table_name.lower() for keyword in ['shots', 'shotdir', 'netpts', 'serve', 'return', 'keypoints']):
                continue
            
            # Handle special cases
            # Skip 'other data' table since match result is already in overview
            if table_name.lower() == 'other data':
                continue
            elif 'serve' in table_name.lower():
                text.extend(self._convert_serve_table(table_name, rows))
            elif 'return' in table_name.lower():
                text.extend(self._convert_return_table(table_name, rows))
            elif 'keypoints' in table_name.lower():
                text.extend(self._convert_keypoints_table(rows))
            elif 'serveneut' in table_name.lower():
                text.extend(self._convert_serveneut_table(rows))
            elif 'rallyoutcomes' in table_name.lower():
                text.extend(self._convert_rallyoutcomes_table(rows, player1, player2))
            elif 'overview' in table_name.lower():
                text.extend(self._convert_overview_table(rows, player1, player2))
            else:
                # Generic table conversion
                text.extend(self._convert_generic_table(table_name, rows))
            
            text.append("")  # Add spacing between tables
            
        return text

    def _convert_table_row_to_text(self, row: Dict[str, Any], table_name: str, column_headers: List[str]) -> List[str]:
        """Convert a single table row to natural language sentences"""
        text = []
        
        row_label = row.get('label', 'Unknown')
        values = row.get('values', [])
        
        # Determine player from table name or row label
        player = self._get_player_from_table_or_row(table_name, row_label)
        
        # Determine table type (table1 vs table2) based on column headers
        table_type = self._determine_table_type(column_headers)
        
        # Handle different table types
        if 'serveneut' in table_name.lower():
            text.extend(self._convert_serveneut_row_to_sentences(row_label, values, column_headers, player))
        elif 'serve' in table_name.lower():
            text.extend(self._convert_serve_row_to_sentences(row_label, values, column_headers, player, table_type))
        elif 'return' in table_name.lower():
            text.extend(self._convert_return_row_to_sentences(row_label, values, column_headers, player, table_type))
        elif 'keypoints' in table_name.lower():
            text.extend(self._convert_keypoints_row_to_sentences(row_label, values, column_headers, player))
        elif 'shots' in table_name.lower():
            text.extend(self._convert_shots_row_to_sentences(row_label, values, column_headers, player))
        elif 'shotdir' in table_name.lower():
            text.extend(self._convert_shotdir_row_to_sentences(row_label, values, column_headers, player, table_type))
        elif 'netpts' in table_name.lower():
            text.extend(self._convert_netpts_row_to_sentences(row_label, values, column_headers, player))
        elif 'rallyoutcomes' in table_name.lower():
            text.extend(self._convert_rallyoutcomes_row_to_sentences(row_label, values, column_headers))
        elif 'overview' in table_name.lower():
            text.extend(self._convert_overview_row_to_sentences(row_label, values, column_headers))
        else:
            # Generic conversion for unknown table types
            text.extend(self._convert_generic_row_to_sentences(row_label, values, column_headers, table_name))
            
        return text

    def _get_player_from_table_or_row(self, table_name: str, row_label: str) -> str:
        """Determine player name from table name or row label"""
        if 'serve1' in table_name or 'return1' in table_name or 'shots1' in table_name or 'shotdir1' in table_name or 'netpts1' in table_name:
            return self.player1 if self.player1 else "Player 1"
        elif 'serve2' in table_name or 'return2' in table_name or 'shots2' in table_name or 'shotdir2' in table_name or 'netpts2' in table_name:
            return self.player2 if self.player2 else "Player 2"
        else:
            # Try to extract player initials from row_label dynamically
            if self.player1 and self.player2:
                player1_initials = ''.join([word[0] for word in self.player1.split()]).upper()
                player2_initials = ''.join([word[0] for word in self.player2.split()]).upper()
                if player1_initials in row_label:
                    return self.player1
                elif player2_initials in row_label:
                    return self.player2
            return "Unknown Player"

    def _determine_table_type(self, column_headers: List[str]) -> str:
        """Determine if this is table1 or table2 based on column headers"""
        # For serves: table1 has "Total: Pts", table2 has "1st: Pts" and "2nd: Pts"
        if "Total: Pts" in column_headers:
            return "table1"
        elif "1st: Pts" in column_headers and "2nd: Pts" in column_headers:
            return "table2"
        
        # For returns: table1 has outcome columns, table2 has depth columns
        return_table1_specific = ["Pts", "Total: Pts", "PtsW----%", "RtbleW--%", "inPlay--%", "inPlayW-%", "Wnr-----%", "AvgRally"]
        return_table2_specific = ["Shlw----%", "Deep----%", "V Deep--%", "UFE-----%", "net-----%", "deep----%", "wide----%", "wide&deep"]
        
        # Check for return table2 first (more specific columns)
        if any(col in column_headers for col in return_table2_specific):
            return "table2"
        elif any(col in column_headers for col in return_table1_specific):
            return "table1"
        
        # Default to table1
        return "table1"

    def _convert_shot_abbreviations(self, shot_type: str) -> str:
        """Convert shot type abbreviations to proper descriptions"""
        shot_type = shot_type.lower()
        
        # Replace common abbreviations
        if shot_type.startswith("fh "):
            shot_type = shot_type.replace("fh ", "forehand ")
        elif shot_type.startswith("bh "):
            shot_type = shot_type.replace("bh ", "backhand ")
        
        # Handle specific shot types
        if "gs (top/flt/slc)" in shot_type:
            shot_type = shot_type.replace("gs (top/flt/slc)", "groundstrokes with topspin, flat, or slice")
        elif "(top/flt)" in shot_type:
            shot_type = shot_type.replace("(top/flt)", "with topspin or flat")
        elif "gs" in shot_type:
            shot_type = shot_type.replace("gs", "groundstrokes")
        elif "lob" in shot_type:
            shot_type = shot_type.replace("lob", "lobs")
        elif "drop shot" in shot_type:
            shot_type = shot_type.replace("drop shot", "drop shots")
        elif "slice/chip" in shot_type:
            shot_type = shot_type.replace("slice/chip", "slice or chip shots")
        elif "swinging volley" in shot_type:
            shot_type = shot_type.replace("swinging volley", "swinging volleys")
        elif "volley" in shot_type:
            shot_type = shot_type.replace("volley", "volleys")
        
        return shot_type

    def _convert_shots_row_to_sentences(self, row_label: str, values: List[str], column_headers: List[str], player: str) -> List[str]:
        """Convert shot statistics row to natural language sentences"""
        sentences = []
        
        # Handle different shot row types
        if "Total" in row_label:
            context = f"{player} hit shots"
        elif "Forehand side" in row_label:
            context = f"{player} hit forehand shots"
        elif "Backhand side" in row_label:
            context = f"{player} hit backhand shots"
        elif "FH GS (top/flt/slc)" in row_label:
            context = f"{player} hit forehand groundstrokes with topspin or flat shots or slice shots"
        elif "BH GS (top/flt/slc)" in row_label:
            context = f"{player} hit backhand groundstrokes with topspin or flat shots or slice shots"
        elif "Groundstrokes (top/flt)" in row_label:
            context = f"{player} hit groundstrokes with topspin or flat shots"
        elif "Baseline shots" in row_label:
            context = f"{player} hit baseline shots"
        elif "Net shots" in row_label:
            context = f"{player} hit shots at the net"
        elif "Dropshots" in row_label:
            context = f"{player} hit dropshots"
        elif "Lobs" in row_label:
            context = f"{player} hit lobs"
        elif "Volleys" in row_label:
            context = f"{player} hit volleys"
        elif "Swinging volleys" in row_label:
            context = f"{player} hit swinging volleys"
        elif "Forehands (top/flt)" in row_label:
            context = f"{player} hit forehand topspin or flat shots"
        elif "Backhands (top/flt)" in row_label:
            context = f"{player} hit backhand topspin or flat shots"
        elif "FH slice/chip" in row_label:
            context = f"{player} hit forehand slice or chip shots"
        elif "BH slice/chip" in row_label:
            context = f"{player} hit backhand slice or chip shots"
        elif "BH drop shot" in row_label:
            context = f"{player} hit backhand drop shots"
        elif "BH lob" in row_label:
            context = f"{player} hit backhand lobs"
        elif "FH volley" in row_label:
            context = f"{player} hit forehand volleys"
        elif "FH swinging volley" in row_label:
            context = f"{player} hit forehand swinging volleys"
        else:
            context = f"{player} hit shots"
        
        # Convert each value to a sentence with better formatting
        for i, value in enumerate(values):
            if i < len(column_headers) and value and value != "0":
                header = column_headers[i]
                
                if header == "Total":
                    sentences.append(f"{context} {value} times.")
                elif header == "Winner--%":
                     # Extract the number and percentage
                     if "(" in value and ")" in value:
                         number = value.split("(")[0].strip()
                         percentage = value.split("(")[1].split(")")[0].replace("%", "")
                         if "Total" in row_label:
                             sentences.append(f"{player} hit {number} winners, which represents {percentage}% of all shots hit by {player}.")
                         elif "Forehand side" in row_label:
                             sentences.append(f"{player} hit {number} forehand winners, which represents {percentage}% of all forehand shots hit by {player}.")
                         elif "Backhand side" in row_label:
                             sentences.append(f"{player} hit {number} backhand winners, which represents {percentage}% of all backhand shots hit by {player}.")
                         else:
                             # Use the actual row label instead of generic "this shot type"
                             shot_type = self._convert_shot_abbreviations(row_label)
                             sentences.append(f"{player} hit {number} winners with {shot_type}, which represents {percentage}% of all {shot_type} hit by {player}.")
                     else:
                         sentences.append(f"{player} hit {value} winners.")
                elif header == "UnfErr--%":
                     # Extract the number and percentage
                     if "(" in value and ")" in value:
                         number = value.split("(")[0].strip()
                         percentage = value.split("(")[1].split(")")[0].replace("%", "")
                         if "Total" in row_label:
                             sentences.append(f"{player} made {number} unforced errors, which represents {percentage}% of all shots hit by {player}.")
                         elif "Forehand side" in row_label:
                             sentences.append(f"{player} made {number} forehand unforced errors, which represents {percentage}% of all forehand shots hit by {player}.")
                         elif "Backhand side" in row_label:
                             sentences.append(f"{player} made {number} backhand unforced errors, which represents {percentage}% of all backhand shots hit by {player}.")
                         else:
                             # Use the actual row label instead of generic "this shot type"
                             shot_type = self._convert_shot_abbreviations(row_label)
                             sentences.append(f"{player} made {number} unforced errors with {shot_type}, which represents {percentage}% of all {shot_type} hit by {player}.")
                     else:
                         sentences.append(f"{player} made {value} unforced errors.")
                elif header == "IndFcd--%":
                     # Extract the number and percentage
                     if "(" in value and ")" in value:
                         number = value.split("(")[0].strip()
                         percentage = value.split("(")[1].split(")")[0].replace("%", "")
                         if "Total" in row_label:
                             sentences.append(f"{player} made {number} induced forced errors, which represents {percentage}% of all shots hit by {player}.")
                         elif "Forehand side" in row_label:
                             sentences.append(f"{player} made {number} induced forced errors with forehand shots, which represents {percentage}% of all forehand shots hit by {player}.")
                         elif "Backhand side" in row_label:
                             sentences.append(f"{player} made {number} induced forced errors with backhand shots, which represents {percentage}% of all backhand shots hit by {player}.")
                         else:
                             # Use the actual row label instead of generic "this shot type"
                             shot_type = self._convert_shot_abbreviations(row_label)
                             sentences.append(f"{player} made {number} induced forced errors with {shot_type}, which represents {percentage}% of all {shot_type} hit by {player}.")
                     else:
                         sentences.append(f"{player} made {value} induced forced errors.")
                elif header == "PtEnd---%":
                     # Extract the number and percentage
                     if "(" in value and ")" in value:
                         number = value.split("(")[0].strip()
                         percentage = value.split("(")[1].split(")")[0].replace("%", "")
                         if "Total" in row_label:
                             sentences.append(f"{player} ended {number} points with shots, which represents {percentage}% of all shots hit by {player}.")
                         elif "Forehand side" in row_label:
                             sentences.append(f"{player} ended {number} points with forehand shots, which represents {percentage}% of all forehand shots hit by {player}.")
                         elif "Backhand side" in row_label:
                             sentences.append(f"{player} ended {number} points with backhand shots, which represents {percentage}% of all backhand shots hit by {player}.")
                         else:
                             # Use the actual row label instead of generic "this shot type"
                             shot_type = self._convert_shot_abbreviations(row_label)
                             sentences.append(f"{player} ended {number} points with {shot_type}, which represents {percentage}% of all {shot_type} hit by {player}.")
                     else:
                         sentences.append(f"{player} ended {value} points with shots.")
                elif header == "SvReturn":
                     # Extract the number and percentage
                     if "(" in value and ")" in value:
                         number = value.split("(")[0].strip()
                         percentage = value.split("(")[1].split(")")[0].replace("%", "")
                         if "Total" in row_label:
                             sentences.append(f"{player} hit {number} serve returns, which represents {percentage}% of all shots hit by {player}.")
                         elif "Forehand side" in row_label:
                             sentences.append(f"{player} hit {number} forehand serve returns, which represents {percentage}% of all forehand shots hit by {player}.")
                         elif "Backhand side" in row_label:
                             sentences.append(f"{player} hit {number} backhand serve returns, which represents {percentage}% of all backhand shots hit by {player}.")
                         else:
                             # Use the actual row label instead of generic "this shot type"
                             shot_type = self._convert_shot_abbreviations(row_label)
                             sentences.append(f"{player} hit {number} serve returns with {shot_type}, which represents {percentage}% of all {shot_type} hit by {player}.")
                     else:
                         sentences.append(f"{player} hit {value} serve returns.")
                elif header == "inPtsW--%":
                     # Extract the number and percentage
                     if "(" in value and ")" in value:
                         number = value.split("(")[0].strip()
                         percentage = value.split("(")[1].split(")")[0].replace("%", "")
                         if "Total" in row_label:
                             sentences.append(f"{player} won {number} points with shots, which represents {percentage}% of all shots hit by {player}.")
                         elif "Forehand side" in row_label:
                             sentences.append(f"{player} won {number} points with forehand shots, which represents {percentage}% of all forehand shots hit by {player}.")
                         elif "Backhand side" in row_label:
                             sentences.append(f"{player} won {number} points with backhand shots, which represents {percentage}% of all backhand shots hit by {player}.")
                         else:
                             # Use the actual row label instead of generic "this shot type"
                             shot_type = self._convert_shot_abbreviations(row_label)
                             sentences.append(f"{player} won {number} points with {shot_type}, which represents {percentage}% of all {shot_type} hit by {player}.")
                     else:
                         sentences.append(f"{player} won {value} points with shots.")
                elif header == "inPtsL--%":
                     # Extract the number and percentage
                     if "(" in value and ")" in value:
                         number = value.split("(")[0].strip()
                         percentage = value.split("(")[1].split(")")[0].replace("%", "")
                         if "Total" in row_label:
                             sentences.append(f"{player} lost {number} points with shots, which represents {percentage}% of all shots hit by {player}.")
                         elif "Forehand side" in row_label:
                             sentences.append(f"{player} lost {number} points with forehand shots, which represents {percentage}% of all forehand shots hit by {player}.")
                         elif "Backhand side" in row_label:
                             sentences.append(f"{player} lost {number} points with backhand shots, which represents {percentage}% of all backhand shots hit by {player}.")
                         else:
                             # Use the actual row label instead of generic "this shot type"
                             shot_type = self._convert_shot_abbreviations(row_label)
                             sentences.append(f"{player} lost {number} points with {shot_type}, which represents {percentage}% of all {shot_type} hit by {player}.")
                     else:
                         sentences.append(f"{player} lost {value} points with shots.")
                else:
                    # Generic fallback for any other headers
                    sentences.append(f"{context} and {header}: {value}.")
        
        return sentences

    def _convert_shotdir_row_to_sentences(self, row_label: str, values: List[str], column_headers: List[str], player: str, table_type: str = "table1") -> List[str]:
        """Convert shot direction statistics row to natural language sentences"""
        sentences = []
        
        # Handle different shot direction row types
        if "Total" in row_label:
            context = f"{player} hit shots in different directions"
        elif "Forehand" in row_label:
            context = f"{player} hit forehand shots"
        elif "Backhand" in row_label:
            context = f"{player} hit backhand shots"
        elif "BH slice" in row_label:
            context = f"{player} hit backhand slice shots"
        else:
            context = f"{player} hit shots in different directions"
        
        # Convert each value to a sentence with better formatting
        for i, value in enumerate(values):
            if i < len(column_headers) and value and value != "0":
                header = column_headers[i]
                
                # Handle table1 structure (direction breakdowns)
                if table_type == "table1":
                    if "Total" in row_label:
                        # Handle Total row - process each column as direction breakdown
                        if header == "Crosscourt":
                            # Extract just the number from percentage format
                            if "(" in value and ")" in value:
                                number = value.split("(")[0].strip()
                                sentences.append(f"{player} hit {number} crosscourt shots.")
                            else:
                                sentences.append(f"{player} hit {value} crosscourt shots.")
                        elif header == "Down middle":
                            # Extract just the number from percentage format
                            if "(" in value and ")" in value:
                                number = value.split("(")[0].strip()
                                sentences.append(f"{player} hit {number} down-the-middle shots.")
                            else:
                                sentences.append(f"{player} hit {value} down-the-middle shots.")
                        elif header == "Down the line":
                            # Extract just the number from percentage format
                            if "(" in value and ")" in value:
                                number = value.split("(")[0].strip()
                                sentences.append(f"{player} hit {number} down-the-line shots.")
                            else:
                                sentences.append(f"{player} hit {value} down-the-line shots.")
                        elif header == "Inside-out":
                            # Extract just the number from percentage format
                            if "(" in value and ")" in value:
                                number = value.split("(")[0].strip()
                                sentences.append(f"{player} hit {number} inside-out shots.")
                            else:
                                sentences.append(f"{player} hit {value} inside-out shots.")
                        elif header == "Inside-in":
                            # Extract just the number from percentage format
                            if "(" in value and ")" in value:
                                number = value.split("(")[0].strip()
                                sentences.append(f"{player} hit {number} inside-in shots.")
                            else:
                                sentences.append(f"{player} hit {value} inside-in shots.")
                        else:
                            # Generic fallback for table1 Total row
                            sentences.append(f"{context} and {header}: {value}.")
                    else:
                        # Handle other table1 rows (Forehand, Backhand, BH slice) - sum up the values
                        if "(" in value and ")" in value:
                            number = value.split("(")[0].strip()
                            if "Forehand" in row_label:
                                sentences.append(f"{player} hit {number} forehand shots.")
                            elif "Backhand" in row_label:
                                sentences.append(f"{player} hit {number} backhand shots.")
                            elif "BH slice" in row_label:
                                sentences.append(f"{player} hit {number} backhand slice shots.")
                            else:
                                sentences.append(f"{context} and {header}: {number}.")
                        else:
                            if "Forehand" in row_label:
                                sentences.append(f"{player} hit {value} forehand shots.")
                            elif "Backhand" in row_label:
                                sentences.append(f"{player} hit {value} backhand shots.")
                            elif "BH slice" in row_label:
                                sentences.append(f"{player} hit {value} backhand slice shots.")
                            else:
                                sentences.append(f"{context} and {header}: {value}.")
                    continue  # Skip the table2 processing for table1
                
                # Handle table2 structure (outcome breakdowns)
                if table_type == "table2":
                    if header == "Total":
                        if "FH crosscourt" in row_label:
                            sentences.append(f"{player} hit {value} forehand crosscourt shots.")
                        elif "FH down middle" in row_label:
                            sentences.append(f"{player} hit {value} forehand down-the-middle shots.")
                        elif "FH down the line" in row_label:
                            sentences.append(f"{player} hit {value} forehand down-the-line shots.")
                        elif "FH inside-out" in row_label:
                            sentences.append(f"{player} hit {value} forehand inside-out shots.")
                        elif "BH crosscourt" in row_label:
                            sentences.append(f"{player} hit {value} backhand crosscourt shots.")
                        elif "BH down middle" in row_label:
                            sentences.append(f"{player} hit {value} backhand down-the-middle shots.")
                        elif "BH down the line" in row_label:
                            sentences.append(f"{player} hit {value} backhand down-the-line shots.")
                        elif "BH inside-out" in row_label:
                            sentences.append(f"{player} hit {value} backhand inside-out shots.")
                        else:
                            sentences.append(f"{player} hit {value} {row_label.lower().replace('down the line', 'down-the-line')} shots.")
                    elif header == "PtEnding":
                        if "(" in value and ")" in value:
                            number = value.split("(")[0].strip()
                            percentage = value.split("(")[1].split(")")[0]
                            sentences.append(f"{player} ended {number} points with {row_label.lower().replace('down the line', 'down-the-line')} shots, or {percentage} of {row_label.lower().replace('down the line', 'down-the-line')} shots ended points.")
                        else:
                            sentences.append(f"{player} ended {value} points with {row_label.lower()} shots.")
                    elif header == "Winner":
                        if "(" in value and ")" in value:
                            number = value.split("(")[0].strip()
                            percentage = value.split("(")[1].split(")")[0]
                            sentences.append(f"{player} hit {number} {row_label.lower().replace('down the line', 'down-the-line')} winners, or {percentage} of {row_label.lower().replace('down the line', 'down-the-line')} shots were winners.")
                        else:
                            sentences.append(f"{player} hit {value} {row_label.lower()} winners.")
                    elif header == "InduceFcd":
                        if "(" in value and ")" in value:
                            number = value.split("(")[0].strip()
                            percentage = value.split("(")[1].split(")")[0]
                            sentences.append(f"{player} induced {number} forced errors with {row_label.lower().replace('down the line', 'down-the-line')} shots, or {percentage} of {row_label.lower().replace('down the line', 'down-the-line')} shots induced forced errors.")
                        else:
                            sentences.append(f"{player} induced {value} forced errors with {row_label.lower()} shots.")
                    elif header == "UnfErr":
                        if "(" in value and ")" in value:
                            number = value.split("(")[0].strip()
                            percentage = value.split("(")[1].split(")")[0]
                            sentences.append(f"{player} had {number} unforced errors with {row_label.lower().replace('down the line', 'down-the-line')} shots, or {percentage} of {row_label.lower().replace('down the line', 'down-the-line')} shots were unforced errors.")
                        else:
                            sentences.append(f"{player} had {value} unforced errors with {row_label.lower()} shots.")
                    elif header == "inPtsWon":
                        if "(" in value and ")" in value:
                            number = value.split("(")[0].strip()
                            percentage = value.split("(")[1].split(")")[0]
                            sentences.append(f"{player} won {number} points when hitting {row_label.lower().replace('down the line', 'down-the-line')} shots, or {percentage} success rate with {row_label.lower().replace('down the line', 'down-the-line')} shots.")
                        else:
                            sentences.append(f"{player} won {value} points when hitting {row_label.lower()} shots.")
                    elif header == "inPtsLost":
                        if "(" in value and ")" in value:
                            number = value.split("(")[0].strip()
                            percentage = value.split("(")[1].split(")")[0]
                            sentences.append(f"{player} lost {number} points when hitting {row_label.lower().replace('down the line', 'down-the-line')} shots, or {percentage} failure rate with {row_label.lower().replace('down the line', 'down-the-line')} shots.")
                        else:
                            sentences.append(f"{player} lost {value} points when hitting {row_label.lower()} shots.")
                    else:
                        # Generic fallback for table2
                        sentences.append(f"{context} and {header}: {value}.")
                    continue  # Skip the existing table2 processing
                
                # Generic fallback for any other cases
                sentences.append(f"{context} and {header}: {value}.")
        
        return sentences

    def _convert_serve_row_to_sentences(self, row_label: str, values: List[str], column_headers: List[str], player: str, table_type: str) -> List[str]:
        """Convert serve statistics row to natural language sentences"""
        sentences = []
        
        # Handle different serve row types
        if "Total" in row_label:
            context = f"{player} served"
        elif "1st Serve" in row_label:
            context = f"{player} hit first serves"
        elif "2nd Serve" in row_label:
            context = f"{player} hit second serves"
        else:
            context = f"{player} served"
        
        # Convert each value to a sentence
        for i, value in enumerate(values):
            if i < len(column_headers) and value and value != "0":
                header = column_headers[i]
                
                if header == "Total":
                    sentences.append(f"{context} {value} times.")
                elif header == "Pts":
                    sentences.append(f"{context} and won {value} points.")
                elif header == "PtsW----%":
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0]
                        sentences.append(f"{context} and won {number} points, or {percentage} of serves were won.")
                    else:
                        sentences.append(f"{context} and won {value} points.")
                elif header == "ACE":
                    sentences.append(f"{context} and hit {value} aces.")
                elif header == "DF":
                    sentences.append(f"{context} and made {value} double faults.")
                else:
                    sentences.append(f"{context} and {header}: {value}.")
        
        return sentences

    def _convert_return_row_to_sentences(self, row_label: str, values: List[str], column_headers: List[str], player: str, table_type: str) -> List[str]:
        """Convert return statistics row to natural language sentences"""
        sentences = []
        
        # Handle different return row types
        if "Total" in row_label:
            context = f"{player} returned"
        elif "1st Serve Return" in row_label:
            context = f"{player} returned first serves"
        elif "2nd Serve Return" in row_label:
            context = f"{player} returned second serves"
        else:
            context = f"{player} returned"
        
        # Convert each value to a sentence
        for i, value in enumerate(values):
            if i < len(column_headers) and value and value != "0":
                header = column_headers[i]
                
                if header == "Total":
                    sentences.append(f"{context} {value} times.")
                elif header == "Pts":
                    sentences.append(f"{context} and won {value} points.")
                elif header == "PtsW----%":
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0]
                        sentences.append(f"{context} and won {number} points, or {percentage} of returns were won.")
                    else:
                        sentences.append(f"{context} and won {value} points.")
                else:
                    sentences.append(f"{context} and {header}: {value}.")
        
        return sentences

    def _convert_keypoints_row_to_sentences(self, row_label: str, values: List[str], column_headers: List[str], player: str) -> List[str]:
        """Convert key points statistics row to natural language sentences"""
        sentences = []
        
        # Handle different key points row types
        if "Break Points" in row_label:
            context = f"{player} faced break points"
        elif "Set Points" in row_label:
            context = f"{player} faced set points"
        elif "Match Points" in row_label:
            context = f"{player} faced match points"
        else:
            context = f"{player} played key points"
        
        # Convert each value to a sentence
        for i, value in enumerate(values):
            if i < len(column_headers) and value and value != "0":
                header = column_headers[i]
                
                if header == "OPP":
                    sentences.append(f"{context} {value} times.")
                elif header == "CONV":
                    sentences.append(f"{context} and converted {value}.")
                elif header == "CONV--%":
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{context} and converted {number}, or {percentage} conversion rate.")
                    else:
                        sentences.append(f"{context} and converted {value}.")
                else:
                    sentences.append(f"{context} and {header}: {value}.")
        
        return sentences

    def _convert_serveneut_row_to_sentences(self, row_label: str, values: List[str], column_headers: List[str], player: str) -> List[str]:
        """Convert serve neutral rally distribution row to natural language sentences"""
        sentences = []
        
        # Use the player parameter that's already passed in
        # If we need to determine player from row_label, do it here
        if self.player1 and self.player2:
            player1_initials = ''.join([word[0] for word in self.player1.split()]).upper()
            player2_initials = ''.join([word[0] for word in self.player2.split()]).upper()
            if player1_initials in row_label:
                player = self.player1
            elif player2_initials in row_label:
                player = self.player2
        
        # Determine serve type context
        if "1st Serve" in row_label:
            serve_type = "first serve"
        elif "2nd Serve" in row_label:
            serve_type = "second serve"
        else:
            serve_type = "serve"
        
        for i, value in enumerate(values):
            if i < len(column_headers) and value and value != "0" and value != "-":
                header = column_headers[i]
                
                if header == "Pts":
                    sentences.append(f"{player} served {value} {serve_type}s.")
                elif header == "1+ shots":
                    if "%" in value:
                        percentage = value.replace("%", "")
                        sentences.append(f"{player} won {percentage}% of {serve_type} points overall.")
                    else:
                        sentences.append(f"{player} won {value} {serve_type} points overall.")
                elif header == "2+":
                    if "%" in value:
                        percentage = value.replace("%", "")
                        sentences.append(f"{player} won {percentage}% of {serve_type} points when rallies reached 2 or more shots.")
                    else:
                        sentences.append(f"{player} won {value} {serve_type} points when rallies reached 2 or more shots.")
                elif header == "3+":
                    if "%" in value:
                        percentage = value.replace("%", "")
                        sentences.append(f"{player} won {percentage}% of {serve_type} points when rallies reached 3 or more shots.")
                    else:
                        sentences.append(f"{player} won {value} {serve_type} points when rallies reached 3 or more shots.")
                elif header == "4+":
                    if "%" in value:
                        percentage = value.replace("%", "")
                        sentences.append(f"{player} won {percentage}% of {serve_type} points when rallies reached 4 or more shots.")
                    else:
                        sentences.append(f"{player} won {value} {serve_type} points when rallies reached 4 or more shots.")
                elif header == "5+":
                    if "%" in value:
                        percentage = value.replace("%", "")
                        sentences.append(f"{player} won {percentage}% of {serve_type} points when rallies reached 5 or more shots.")
                    else:
                        sentences.append(f"{player} won {value} {serve_type} points when rallies reached 5 or more shots.")
                elif header == "6+":
                    if "%" in value:
                        percentage = value.replace("%", "")
                        sentences.append(f"{player} won {percentage}% of {serve_type} points when rallies reached 6 or more shots.")
                    else:
                        sentences.append(f"{player} won {value} {serve_type} points when rallies reached 6 or more shots.")
                elif header == "7+":
                    if "%" in value:
                        percentage = value.replace("%", "")
                        sentences.append(f"{player} won {percentage}% of {serve_type} points when rallies reached 7 or more shots.")
                    else:
                        sentences.append(f"{player} won {value} {serve_type} points when rallies reached 7 or more shots.")
                elif header == "8+":
                    if "%" in value:
                        percentage = value.replace("%", "")
                        sentences.append(f"{player} won {percentage}% of {serve_type} points when rallies reached 8 or more shots.")
                    else:
                        sentences.append(f"{player} won {value} {serve_type} points when rallies reached 8 or more shots.")
                elif header == "9+":
                    if "%" in value:
                        percentage = value.replace("%", "")
                        sentences.append(f"{player} won {percentage}% of {serve_type} points when rallies reached 9 or more shots.")
                    else:
                        sentences.append(f"{player} won {value} {serve_type} points when rallies reached 9 or more shots.")
                elif header == "10+":
                    if "%" in value:
                        percentage = value.replace("%", "")
                        sentences.append(f"{player} won {percentage}% of {serve_type} points when rallies reached 10 or more shots.")
                    else:
                        sentences.append(f"{player} won {value} {serve_type} points when rallies reached 10 or more shots.")
        
        return sentences

    def _convert_rallyoutcomes_row_to_sentences(self, row_label: str, values: List[str], column_headers: List[str]) -> List[str]:
        """Convert rally outcomes statistics row to natural language sentences"""
        sentences = []
        
        # Handle different rally outcome row types
        if "Total" in row_label:
            context = "Rally outcomes"
        elif "Short" in row_label:
            context = "Short rallies (1-3 shots)"
        elif "Medium" in row_label:
            context = "Medium rallies (4-6 shots)"
        elif "Long" in row_label:
            context = "Long rallies (7+ shots)"
        else:
            context = "Rally outcomes"
        
        # Convert each value to a sentence
        for i, value in enumerate(values):
            if i < len(column_headers) and value and value != "0":
                header = column_headers[i]
                
                if header == "Total":
                    sentences.append(f"{context} occurred {value} times.")
                elif header == "Pts":
                    sentences.append(f"{context} and {value} points were played.")
                else:
                    sentences.append(f"{context} and {header}: {value}.")
        
        return sentences

    def _convert_overview_row_to_sentences(self, row_label: str, values: List[str], column_headers: List[str]) -> List[str]:
        """Convert overview statistics row to natural language sentences"""
        sentences = []
        
        # Handle different overview row types
        if "A%" in row_label:
            context = "Ace percentage"
        elif "DF%" in row_label:
            context = "Double fault percentage"
        elif "1stIn" in row_label:
            context = "First serve in percentage"
        elif "1st%" in row_label:
            context = "First serve won percentage"
        elif "2nd%" in row_label:
            context = "Second serve won percentage"
        elif "BPSaved" in row_label:
            context = "Break points saved"
        elif "RPW%" in row_label:
            context = "Return points won percentage"
        elif "Winners" in row_label:
            context = "Winners"
        elif "UFE" in row_label:
            context = "Unforced errors"
        else:
            context = "Overview statistic"
        
        # Convert each value to a sentence
        for i, value in enumerate(values):
            if i < len(column_headers) and value and value != "0":
                header = column_headers[i]
                
                if header == "A%":
                    sentences.append(f"{context} was {value}.")
                elif header == "DF%":
                    sentences.append(f"{context} was {value}.")
                elif header == "1stIn":
                    sentences.append(f"{context} was {value}.")
                elif header == "1st%":
                    sentences.append(f"{context} was {value}.")
                elif header == "2nd%":
                    sentences.append(f"{context} was {value}.")
                elif header == "BPSaved":
                    sentences.append(f"{context} were {value}.")
                elif header == "RPW%":
                    sentences.append(f"{context} was {value}.")
                elif header == "Winners":
                    sentences.append(f"{context} were {value}.")
                elif header == "UFE":
                    sentences.append(f"{context} were {value}.")
                else:
                    sentences.append(f"{context} and {header}: {value}.")
        
        return sentences

    def _convert_generic_row_to_sentences(self, row_label: str, values: List[str], column_headers: List[str], table_name: str) -> List[str]:
        """Convert generic row to natural language sentences"""
        sentences = []
        
        context = f"In the {table_name} category"
        
        # Convert each value to a sentence
        for i, value in enumerate(values):
            if i < len(column_headers) and value and value != "0":
                header = column_headers[i]
                sentences.append(f"{context}, {row_label}: {header} = {value}.")
        
        return sentences

    def _convert_netpts_row_to_sentences(self, row_label: str, values: List[str], column_headers: List[str], player: str) -> List[str]:
        """Convert net points statistics row to natural language sentences"""
        sentences = []
        
        # Handle different net row types
        if "All Net Points" in row_label:
            context = f"{player} played"
        elif "All Net Approaches" in row_label:
            context = f"{player} made"
        elif "Net Points (excl S-and-V)" in row_label:
            context = f"{player} played"
        elif "Net Approaches (excl S-and-V)" in row_label:
            context = f"{player} made"
        else:
            context = f"{player} played"
        
        # Convert each value to a sentence with better formatting
        for i, value in enumerate(values):
            if i < len(column_headers) and value and value != "0":
                header = column_headers[i]
                
                if header == "Pts":
                    if "All Net Points" in row_label:
                        sentences.append(f"{player} played {value} net points.")
                    elif "Net Points (excl S-and-V)" in row_label:
                        sentences.append(f"{player} played {value} net points excluding serve and volleys.")
                    elif "All Net Approaches" in row_label:
                        sentences.append(f"{player} made {value} net approaches.")
                    elif "Net Approaches (excl S-and-V)" in row_label:
                        sentences.append(f"{player} made {value} net approaches excluding serve and volleys.")
                    else:
                        sentences.append(f"{context} {value} times.")
                elif header == "Won-----%":
                    # Extract the number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        if "All Net Points" in row_label:
                            sentences.append(f"{player} won {number} net points, or {percentage}% of total net points for {player}.")
                        elif "All Net Approaches" in row_label:
                            sentences.append(f"{player} won {number} net approaches, or {percentage}% of total net approaches for {player}.")
                        elif "Net Points (excl S-and-V)" in row_label:
                            sentences.append(f"{player} won {number} net points excluding serve and volleys, or {percentage}% of total net points excluding serve and volleys for {player}.")
                        elif "Net Approaches (excl S-and-V)" in row_label:
                            sentences.append(f"{player} won {number} net approaches excluding serve and volleys, or {percentage}% of total net approaches excluding serve and volleys for {player}.")
                        else:
                            sentences.append(f"{context} and won {number} points, or {percentage}% of total net points for {player}.")
                    else:
                        sentences.append(f"{context} and won {value} points.")
                elif header == "Wnr at Net":
                    # Extract number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        if "All Net Points" in row_label:
                            sentences.append(f"{player} hit {number} winners at the net, which represents {percentage}% of net points for {player}.")
                        elif "All Net Approaches" in row_label:
                            sentences.append(f"{player} hit {number} winners on net approaches, which represents {percentage}% of net approaches for {player}.")
                        elif "Net Points (excl S-and-V)" in row_label:
                            sentences.append(f"{player} hit {number} winners at the net excluding serve and volleys, which represents {percentage}% of net points for {player}.")
                        elif "Net Approaches (excl S-and-V)" in row_label:
                            sentences.append(f"{player} hit {number} winners on net approaches excluding serve and volleys, which represents {percentage}% of net approaches for {player}.")
                        else:
                            sentences.append(f"{player} hit {number} winners at the net, which represents {percentage}% of net points for {player}.")
                    else:
                        if "All Net Points" in row_label:
                            sentences.append(f"{player} hit {value} winners at the net.")
                        elif "All Net Approaches" in row_label:
                            sentences.append(f"{player} hit {value} winners on net approaches.")
                        else:
                            sentences.append(f"{player} hit {value} winners at the net.")
                elif header == "indFcd at Net":
                    # Extract number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        if "All Net Points" in row_label:
                            sentences.append(f"{player} made {number} induced forced errors at the net, which represents {percentage}% of net points for {player}.")
                        elif "All Net Approaches" in row_label:
                            sentences.append(f"{player} made {number} induced forced errors on net approaches, which represents {percentage}% of net approaches for {player}.")
                        elif "Net Points (excl S-and-V)" in row_label:
                            sentences.append(f"{player} made {number} induced forced errors at the net excluding serve and volleys, which represents {percentage}% of net points for {player}.")
                        elif "Net Approaches (excl S-and-V)" in row_label:
                            sentences.append(f"{player} made {number} induced forced errors on net approaches excluding serve and volleys, which represents {percentage}% of net approaches for {player}.")
                        else:
                            sentences.append(f"{player} made {number} induced forced errors at the net, which represents {percentage}% of net points for {player}.")
                    else:
                        if "All Net Points" in row_label:
                            sentences.append(f"{player} made {value} induced forced errors at the net.")
                        elif "All Net Approaches" in row_label:
                            sentences.append(f"{player} made {value} induced forced errors on net approaches.")
                        else:
                            sentences.append(f"{player} made {value} induced forced errors at the net.")
                elif header == "UFE at Net":
                    # Extract number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        if "All Net Points" in row_label:
                            sentences.append(f"{player} made {number} unforced errors at the net, which represents {percentage}% of net points for {player}.")
                        elif "All Net Approaches" in row_label:
                            sentences.append(f"{player} made {number} unforced errors on net approaches, which represents {percentage}% of net approaches for {player}.")
                        elif "Net Points (excl S-and-V)" in row_label:
                            sentences.append(f"{player} made {number} unforced errors at the net excluding serve and volleys, which represents {percentage}% of net points for {player}.")
                        elif "Net Approaches (excl S-and-V)" in row_label:
                            sentences.append(f"{player} made {number} unforced errors on net approaches excluding serve and volleys, which represents {percentage}% of net approaches for {player}.")
                        else:
                            sentences.append(f"{player} made {number} unforced errors at the net, which represents {percentage}% of net points for {player}.")
                    else:
                        if "All Net Points" in row_label:
                            sentences.append(f"{player} made {value} unforced errors at the net.")
                        elif "All Net Approaches" in row_label:
                            sentences.append(f"{player} made {value} unforced errors on net approaches.")
                        else:
                            sentences.append(f"{player} made {value} unforced errors at the net.")
                elif header == "Passed at Net":
                    # Extract number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        if "All Net Points" in row_label:
                            sentences.append(f"{player} was passed {number} times at the net, which represents {percentage}% of net points for {player}.")
                        elif "All Net Approaches" in row_label:
                            sentences.append(f"{player} was passed {number} times on net approaches, which represents {percentage}% of net approaches for {player}.")
                        elif "Net Points (excl S-and-V)" in row_label:
                            sentences.append(f"{player} was passed {number} times at the net excluding serve and volleys, which represents {percentage}% of net points for {player}.")
                        elif "Net Approaches (excl S-and-V)" in row_label:
                            sentences.append(f"{player} was passed {number} times on net approaches excluding serve and volleys, which represents {percentage}% of net approaches for {player}.")
                        else:
                            sentences.append(f"{player} was passed {number} times at the net, which represents {percentage}% of net points for {player}.")
                    else:
                        if "All Net Points" in row_label:
                            sentences.append(f"{player} was passed {value} times at the net.")
                        elif "All Net Approaches" in row_label:
                            sentences.append(f"{player} was passed {value} times on net approaches.")
                        else:
                            sentences.append(f"{player} was passed {value} times at the net.")
                elif header == "PsgSht indFcd":
                    # Extract number and percentage (passing shots that forced errors)
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        if "All Net Points" in row_label:
                            sentences.append(f"{player} made {number} induced forced errors during passing shots at the net, which represents {percentage}% of net points.")
                        elif "All Net Approaches" in row_label:
                            sentences.append(f"{player} made {number} induced forced errors during passing shots on net approaches, which represents {percentage}% of net approaches.")
                        elif "Net Points (excl S-and-V)" in row_label:
                            sentences.append(f"{player} made {number} induced forced errors during passing shots at the net excluding serve and volleys, which represents {percentage}% of net points.")
                        elif "Net Approaches (excl S-and-V)" in row_label:
                            sentences.append(f"{player} made {number} induced forced errors during passing shots on net approaches excluding serve and volleys, which represents {percentage}% of net approaches.")
                        else:
                            sentences.append(f"{player} made {number} induced forced errors during passing shots at the net, which represents {percentage}% of net points.")
                    else:
                        if "All Net Points" in row_label:
                            sentences.append(f"{player} made {value} induced forced errors during passing shots at the net.")
                        elif "All Net Approaches" in row_label:
                            sentences.append(f"{player} made {value} induced forced errors during passing shots on net approaches.")
                        else:
                            sentences.append(f"{player} made {value} induced forced errors during passing shots at the net.")
                elif header == "rallyLen":
                    if "All Net Points" in row_label:
                        sentences.append(f"{player} played at the net and the average rally length was {value} strokes.")
                    elif "All Net Approaches" in row_label:
                        sentences.append(f"{player} approached the net and the average rally length was {value} strokes.")
                    elif "Net Points (excl S-and-V)" in row_label:
                        sentences.append(f"{player} played at the net excluding serve and volleys and the average rally length was {value} strokes.")
                    elif "Net Approaches (excl S-and-V)" in row_label:
                        sentences.append(f"{player} approached the net excluding serve and volleys and the average rally length was {value} strokes.")
                    else:
                        sentences.append(f"{context} and the average rally length was {value} strokes.")
                else:
                    # Generic fallback
                    sentences.append(f"{context} and {header}: {value}.")
        
        return sentences

    def _convert_netpts_table2_row_to_sentences(self, row_label: str, values: List[str], column_headers: List[str], player: str, opponent: str) -> List[str]:
        """Convert net points table2 (serve-and-volley) statistics row to natural language sentences"""
        sentences = []
        
        # Handle different serve-and-volley row types
        # Check more specific strings FIRST to avoid substring matching issues
        if "non-S-and-V 2nds" in row_label:
            context = f"{player} played non-serve-and-volley points on second serves"
            serve_type = "non-serve-and-volley on second serves"
        elif "non-S-and-V 1sts" in row_label:
            context = f"{player} played non-serve-and-volley points on first serves"
            serve_type = "non-serve-and-volley on first serves"
        elif "non-S-and-V" in row_label:
            context = f"{player} played non-serve-and-volley points"
            serve_type = "non-serve-and-volley"
        elif "S-and-V 2nds" in row_label:
            context = f"{player} played serve-and-volley points on second serves"
            serve_type = "serve-and-volley on second serves"
        elif "S-and-V 1sts" in row_label:
            context = f"{player} played serve-and-volley points on first serves"
            serve_type = "serve-and-volley on first serves"
        elif "Serve-and-Volley" in row_label:
            context = f"{player} played serve-and-volley points"
            serve_type = "serve-and-volley"
        else:
            context = f"{player} played points"
            serve_type = ""
        
        # Convert each value to a sentence with better formatting
        for i, value in enumerate(values):
            if i < len(column_headers) and value and value != "0":
                header = column_headers[i]
                
                if header == "Pts":
                    if "non-S-and-V" in row_label:
                        sentences.append(f"{player} played {value} {serve_type} points.")
                    elif "Serve-and-Volley" in row_label or "S-and-V" in row_label:
                        sentences.append(f"{player} played {value} {serve_type} points.")
                    else:
                        sentences.append(f"{player} played {value} points.")
                elif header == "Won-----%":
                    # Extract the number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        if "non-S-and-V" in row_label:
                            sentences.append(f"{player} won {number} {serve_type} points, or {percentage}% of total {serve_type} points for {player}.")
                        elif "Serve-and-Volley" in row_label or "S-and-V" in row_label:
                            sentences.append(f"{player} won {number} {serve_type} points, or {percentage}% of total {serve_type} points for {player}.")
                        else:
                            sentences.append(f"{player} won {number} points, or {percentage}% of total points for {player}.")
                    else:
                        sentences.append(f"{context} and won {value} points.")
                elif header == "Aces----%":
                    # Extract number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        if number != "0":
                            sentences.append(f"{player} hit {number} aces on {serve_type} points, which represents {percentage}% of {serve_type} points for {player}.")
                    else:
                        if value != "0":
                            sentences.append(f"{player} hit {value} aces on {serve_type} points.")
                elif header == "Unret---%":
                    # Extract number and percentage (unreturned serves)
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        if number != "0":
                            sentences.append(f"{player} hit {number} unreturned serves during {serve_type}, which represents {percentage}% of {serve_type} points.")
                    else:
                        if value != "0":
                            sentences.append(f"{player} hit {value} unreturned serves during {serve_type}.")
                elif header == "retFcd--%":
                    # Extract number and percentage (return forced errors)
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        if number != "0":
                            error_text = "error" if number == "1" else "errors"
                            sentences.append(f"{player} made {number} forced {error_text} during {opponent}'s returns during {serve_type}, which represents {percentage}% of {serve_type} points.")
                    else:
                        if value != "0":
                            error_text = "error" if value == "1" else "errors"
                            sentences.append(f"{player} made {value} forced {error_text} during {opponent}'s returns during {serve_type}.")
                elif header == "Wnr at Net":
                    # Extract number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        if number != "0":
                            sentences.append(f"{player} hit {number} winner{'s' if number != '1' else ''} at the net during {serve_type}, which represents {percentage}% of {serve_type} points.")
                    else:
                        if value != "0":
                            sentences.append(f"{player} hit {value} winner{'s' if value != '1' else ''} at the net during {serve_type}.")
                elif header == "indFcd at Net":
                    # Extract number and percentage (induced forced errors while at the net)
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        if number != "0":
                            error_text = "error" if number == "1" else "errors"
                            sentences.append(f"{player} made {number} induced forced {error_text} while at the net during {serve_type}, which represents {percentage}% of {serve_type} points.")
                    else:
                        if value != "0":
                            error_text = "error" if value == "1" else "errors"
                            sentences.append(f"{player} made {value} induced forced {error_text} while at the net during {serve_type}.")
                elif header == "UFE at Net":
                    # Extract number and percentage (unforced errors made by the player at the net)
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        if number != "0":
                            error_text = "error" if number == "1" else "errors"
                            sentences.append(f"{player} had {number} unforced {error_text} while at the net during {serve_type}, which represents {percentage}% of {serve_type} points.")
                    else:
                        if value != "0":
                            error_text = "error" if value == "1" else "errors"
                            sentences.append(f"{player} had {value} unforced {error_text} while at the net during {serve_type}.")
                elif header == "Passed at Net":
                    # Extract number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        if number != "0":
                            sentences.append(f"{player} was passed at the net {number} time{'s' if number != '1' else ''} during {serve_type}, which represents {percentage}% of {serve_type} points.")
                    else:
                        if value != "0":
                            sentences.append(f"{player} was passed at the net {value} time{'s' if value != '1' else ''} during {serve_type}.")
                elif header == "PsgSht indFcd":
                    # Extract number and percentage (passing shots that induced forced errors from opponent)
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        if number != "0":
                            error_text = "error" if number == "1" else "errors"
                            sentences.append(f"{player} made {number} induced forced {error_text} during passing shots from {opponent} during {serve_type}, which represents {percentage}% of {serve_type} points.")
                    else:
                        if value != "0":
                            error_text = "error" if value == "1" else "errors"
                            sentences.append(f"{player} made {value} induced forced {error_text} during passing shots from {opponent} during {serve_type}.")
                elif header == "rallyLen":
                    sentences.append(f"{player} played {serve_type} points and the average rally length was {value} strokes.")
                else:
                    # Generic fallback
                    sentences.append(f"{context} and {header}: {value}.")
        
        return sentences

    def _convert_details_flat_to_text(self, details_flat: Dict[str, Any], player1: str, player2: str) -> List[str]:
        """Convert details_flat data to natural language text"""
        text = []
        
        # Group the flat data by table type
        shots_data = {}
        shotdir_data = {}
        netpts_data = {}
        serve_data = {}
        return_data = {}
        keypoints_data = {}
        overview_data = {}
        
        for key, value in details_flat.items():
            if key.startswith('shots1') or key.startswith('shots2'):
                shots_data[key] = value
            elif key.startswith('shotdir1') or key.startswith('shotdir2'):
                shotdir_data[key] = value
            elif key.startswith('netpts1') or key.startswith('netpts2'):
                netpts_data[key] = value
            elif key.startswith('serve1') or key.startswith('serve2'):
                serve_data[key] = value
            elif key.startswith('return1') or key.startswith('return2'):
                return_data[key] = value
            elif key.startswith('keypoints'):
                keypoints_data[key] = value
            elif key.startswith('overview'):
                overview_data[key] = value
        
        # Convert serve data (most important - comes first)
        if serve_data:
            text.extend(self._convert_flat_serve_to_text(serve_data, player1, player2))
        
        # Convert return data (second most important)
        if return_data:
            text.extend(self._convert_flat_return_to_text(return_data, player1, player2))
        
        # Convert overview data (summary statistics)
        if overview_data:
            text.extend(self._convert_flat_overview_to_text(overview_data, player1, player2))
        
        # Convert key points data
        if keypoints_data:
            text.extend(self._convert_flat_keypoints_to_text(keypoints_data, player1, player2))
        
        # Convert shots data
        if shots_data:
            text.extend(self._convert_flat_shots_to_text(shots_data, player1, player2))
        
        # Convert shotdir data
        if shotdir_data:
            text.extend(self._convert_flat_shotdir_to_text(shotdir_data, player1, player2))
        
        # Convert netpts data
        if netpts_data:
            text.extend(self._convert_flat_netpts_to_text(netpts_data, player1, player2))
        
        return text

    def _convert_flat_shots_to_text(self, shots_data: Dict[str, Any], player1: str, player2: str) -> List[str]:
        """Convert flat shots data to natural language text"""
        text = []
        
        # Group by player
        shots1_data = {k: v for k, v in shots_data.items() if k.startswith('shots1')}
        shots2_data = {k: v for k, v in shots_data.items() if k.startswith('shots2')}
        
        if shots1_data:
            text.append("SHOTS1 STATISTICS:")
            text.append("-" * 20)
            text.extend(self._convert_flat_shots_player_to_text(shots1_data, player1))
            text.append("")
        
        if shots2_data:
            text.append("SHOTS2 STATISTICS:")
            text.append("-" * 20)
            text.extend(self._convert_flat_shots_player_to_text(shots2_data, player2))
            text.append("")
        
        return text

    def _convert_flat_shots_player_to_text(self, shots_data: Dict[str, Any], player: str) -> List[str]:
        """Convert flat shots data for one player to natural language text"""
        text = []
        
        # TIER 1 (AUTHORITATIVE): Extract all columns from TOTAL, FOREHAND, and BACKHAND rows
        total_row_values = None
        forehand_row_values = None
        backhand_row_values = None
        row_headers = None
        
        # Find the header row
        header_key = None
        for key in shots_data.keys():
            if 'SHOT TYPES' in key:
                header_key = key
                break
        
        if header_key:
            headers = [h.strip() for h in shots_data[header_key].split(' | ')]
            
            # Extract all columns from TOTAL, FOREHAND, and BACKHAND rows (all are authoritative)
            for key, value in shots_data.items():
                if key != header_key and 'SHOT TYPES' not in key:
                    # Extract the row label (remove the prefix like "shots1 - ")
                    row_label = key.split(' - ', 1)[1] if ' - ' in key else key
                    
                    # Skip if this looks like a header row
                    if any(header_word in row_label for header_word in ['SHOT TYPES', 'PtEnd', 'Winner', 'IndFcd', 'UnfErr', 'SvReturn', 'inPtsW', 'inPtsL']):
                        continue
                    
                    # Split the value by | to get individual values
                    values = [v.strip() for v in value.split(' | ')]
                    
                    # Extract all columns from the authoritative rows
                    if len(values) == len(headers) and any(v != '' and v != '0' for v in values):
                        if 'Total' in row_label:
                            total_row_values = values
                            row_headers = headers
                        elif 'Forehand side' in row_label:
                            forehand_row_values = values
                            row_headers = headers
                        elif 'Backhand side' in row_label:
                            backhand_row_values = values
                            row_headers = headers
        
        # Add all authoritative totals from TOTAL, FOREHAND, and BACKHAND rows
        if row_headers:
            text.append(f"AUTHORITATIVE TOTALS FOR {player.upper()} SHOT STATISTICS:")
            
            # Add TOTAL row data
            if total_row_values:
                text.append("TOTAL SHOTS AUTHORITATIVE DATA:")
                for i, (header, value) in enumerate(zip(row_headers, total_row_values)):
                    if value and value != "0":
                        if header == "Total":
                            text.append(f"{player} hit {value} total shots.")
                        elif header == "PtEnd---%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} ended {number} total points with shots.")
                        elif header == "Winner--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} hit {number} total winners.")
                        elif header == "IndFcd--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} was induced into making {number} total forced errors.")
                        elif header == "UnfErr--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} made {number} total unforced errors.")
                        elif header == "SvReturn":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} hit {number} total serve returns.")
                        elif header == "inPtsW--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} won {number} total points with shots.")
                        elif header == "inPtsL--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} lost {number} total points with shots.")
            
            # Add FOREHAND row data
            if forehand_row_values:
                text.append("FOREHAND SHOTS AUTHORITATIVE DATA:")
                for i, (header, value) in enumerate(zip(row_headers, forehand_row_values)):
                    if value and value != "0":
                        if header == "Total":
                            text.append(f"{player} hit {value} forehand shots.")
                        elif header == "PtEnd---%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} ended {number} points with forehand shots.")
                        elif header == "Winner--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} hit {number} forehand winners.")
                        elif header == "IndFcd--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} was induced into making {number} forced errors with forehand shots.")
                        elif header == "UnfErr--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} made {number} forehand unforced errors.")
                        elif header == "SvReturn":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} hit {number} forehand serve returns.")
                        elif header == "inPtsW--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} won {number} points with forehand shots.")
                        elif header == "inPtsL--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} lost {number} points with forehand shots.")
            
            # Add BACKHAND row data
            if backhand_row_values:
                text.append("BACKHAND SHOTS AUTHORITATIVE DATA:")
                for i, (header, value) in enumerate(zip(row_headers, backhand_row_values)):
                    if value and value != "0":
                        if header == "Total":
                            text.append(f"{player} hit {value} backhand shots.")
                        elif header == "PtEnd---%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} ended {number} points with backhand shots.")
                        elif header == "Winner--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} hit {number} backhand winners.")
                        elif header == "IndFcd--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} was induced into making {number} forced errors with backhand shots.")
                        elif header == "UnfErr--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} made {number} backhand unforced errors.")
                        elif header == "SvReturn":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} hit {number} backhand serve returns.")
                        elif header == "inPtsW--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} won {number} points with backhand shots.")
                        elif header == "inPtsL--%":
                            number = value.split('(')[0].strip()
                            text.append(f"{player} lost {number} points with backhand shots.")
            
            text.append("")
            text.append("DETAILED BREAKDOWN (these are contextual details, not for recalculating totals):")
            text.append("")
        
        # Second pass: process all rows for detailed breakdown
        if header_key:
            headers = [h.strip() for h in shots_data[header_key].split(' | ')]
            
            # Process each data row (skip the header row)
            for key, value in shots_data.items():
                if key != header_key and 'SHOT TYPES' not in key:
                    # Extract the row label (remove the prefix like "shots1 - ")
                    row_label = key.split(' - ', 1)[1] if ' - ' in key else key
                    
                    # Skip if this looks like a header row
                    if any(header_word in row_label for header_word in ['SHOT TYPES', 'Total', 'PtEnd', 'Winner', 'IndFcd', 'UnfErr', 'SvReturn', 'inPtsW', 'inPtsL']):
                        continue
                    
                    # Split the value by | to get individual values
                    values = [v.strip() for v in value.split(' | ')]
                    
                    # Only process if we have valid data (not just headers)
                    if len(values) == len(headers) and any(v != '' and v != '0' for v in values):
                        # Convert to sentences using the existing method
                        sentences = self._convert_shots_row_to_sentences(row_label, values, headers, player)
                        text.extend(sentences)
        
        return text

    def _convert_flat_shotdir_to_text(self, shotdir_data: Dict[str, Any], player1: str, player2: str) -> List[str]:
        """Convert flat shotdir data to natural language text"""
        text = []
        
        # Group by player
        shotdir1_data = {k: v for k, v in shotdir_data.items() if k.startswith('shotdir1')}
        shotdir2_data = {k: v for k, v in shotdir_data.items() if k.startswith('shotdir2')}
        
        if shotdir1_data:
            text.append("SHOTDIR1 STATISTICS:")
            text.append("-" * 22)
            text.extend(self._convert_flat_shotdir_player_to_text(shotdir1_data, player1))
            text.append("")
        
        if shotdir2_data:
            text.append("SHOTDIR2 STATISTICS:")
            text.append("-" * 22)
            text.extend(self._convert_flat_shotdir_player_to_text(shotdir2_data, player2))
            text.append("")
        
        # Add explicit totals for complex shot direction + outcome combinations
        # These help the LLM anchor on correct totals for complex questions
        text.append("")
        text.append("EXPLICIT TOTALS FOR SHOT DIRECTION + OUTCOME COMBINATIONS:")
        text.append("-" * 50)
        
        # Calculate explicit totals from the natural language sentences we just generated
        directions = ['crosscourt', 'down middle', 'down the line', 'inside-out', 'inside-in']
        outcomes = ['winners', 'induced forced errors', 'unforced errors', 'points won', 'points lost']
        
        # Create a nested dictionary to store all combinations for both players
        player_totals = {player1: {}, player2: {}}
        for player in player_totals:
            player_totals[player] = {}
            for direction in directions:
                player_totals[player][direction] = {}
                for outcome in outcomes:
                    player_totals[player][direction][outcome] = {'forehand': 0, 'backhand': 0, 'slice': 0}
        
        # Parse the natural language sentences to extract numbers
        for line in text:
            # Extract the number from the beginning of the line
            import re
            number_match = re.search(r'(\d+)', line)
            if not number_match:
                continue
            number = int(number_match.group(1))
            
            # Determine which player this line is for
            current_player = None
            if player1 in line:
                current_player = player1
            elif player2 in line:
                current_player = player2
            else:
                continue
            
            # Look for lines like "hit X winners with [shot type] [direction] shots"
            if 'hit' in line and 'winners' in line and 'shots' in line:
                for direction in directions:
                    if direction in line:
                        if 'forehand' in line:
                            player_totals[current_player][direction]['winners']['forehand'] = number
                        elif 'backhand' in line and 'slice' not in line:
                            player_totals[current_player][direction]['winners']['backhand'] = number
                        elif 'slice' in line:
                            player_totals[current_player][direction]['winners']['slice'] = number
                        break
            
            elif 'made' in line and 'induced forced errors' in line and 'shots' in line:
                for direction in directions:
                    if direction in line:
                        if 'forehand' in line:
                            player_totals[current_player][direction]['induced forced errors']['forehand'] = number
                        elif 'backhand' in line and 'slice' not in line:
                            player_totals[current_player][direction]['induced forced errors']['backhand'] = number
                        elif 'slice' in line:
                            player_totals[current_player][direction]['induced forced errors']['slice'] = number
                        break
            
            elif 'made' in line and 'unforced errors' in line and 'shots' in line:
                for direction in directions:
                    if direction in line:
                        if 'forehand' in line:
                            player_totals[current_player][direction]['unforced errors']['forehand'] = number
                        elif 'backhand' in line and 'slice' not in line:
                            player_totals[current_player][direction]['unforced errors']['backhand'] = number
                        elif 'slice' in line:
                            player_totals[current_player][direction]['unforced errors']['slice'] = number
                        break
            
            elif 'won' in line and 'points' in line and 'shots' in line:
                for direction in directions:
                    if direction in line:
                        if 'forehand' in line:
                            player_totals[current_player][direction]['points won']['forehand'] = number
                        elif 'backhand' in line and 'slice' not in line:
                            player_totals[current_player][direction]['points won']['backhand'] = number
                        elif 'slice' in line:
                            player_totals[current_player][direction]['points won']['slice'] = number
                        break
            
            elif 'lost' in line and 'points' in line and 'shots' in line:
                for direction in directions:
                    if direction in line:
                        if 'forehand' in line:
                            player_totals[current_player][direction]['points lost']['forehand'] = number
                        elif 'backhand' in line and 'slice' not in line:
                            player_totals[current_player][direction]['points lost']['backhand'] = number
                        elif 'slice' in line:
                            player_totals[current_player][direction]['points lost']['slice'] = number
                        break
        
        # Generate explicit totals for ALL combinations (including zeros) for both players
        for player in [self.player1, self.player2] if self.player1 and self.player2 else ['Player 1', 'Player 2']:
            for direction in directions:
                for outcome in outcomes:
                    total = sum(player_totals[player][direction][outcome].values())
                    fh, bh, sl = player_totals[player][direction][outcome].values()
                    if outcome == 'winners':
                        text.append(f"{player} hit {total} {direction} {outcome} total, including {fh} forehand {direction} {outcome}, {bh} backhand {direction} {outcome}, and {sl} slice {direction} {outcome}")
                    elif outcome == 'induced forced errors':
                        text.append(f"{player} made {total} {direction} {outcome} total, including {fh} forehand {direction} {outcome}, {bh} backhand {direction} {outcome}, and {sl} slice {direction} {outcome}")
                    elif outcome == 'unforced errors':
                        text.append(f"{player} made {total} {direction} {outcome} total, including {fh} forehand {direction} {outcome}, {bh} backhand {direction} {outcome}, and {sl} slice {direction} {outcome}")
                    elif outcome == 'points won':
                        text.append(f"{player} won {total} {direction} {outcome} total, including {fh} forehand {direction} {outcome}, {bh} backhand {direction} {outcome}, and {sl} slice {direction} {outcome}")
                    elif outcome == 'points lost':
                        text.append(f"{player} lost {total} {direction} {outcome} total, including {fh} forehand {direction} {outcome}, {bh} backhand {direction} {outcome}, and {sl} slice {direction} {outcome}")
        
        text.append("")
        
        return text

    def _convert_flat_shotdir_player_to_text(self, shotdir_data: Dict[str, Any], player: str) -> List[str]:
        """Convert flat shotdir data for one player to natural language text"""
        text = []
        
        # Group by table type
        table1_data = {k: v for k, v in shotdir_data.items() if '_table1' in k}
        table2_data = {k: v for k, v in shotdir_data.items() if '_table2' in k}
        
        # TIER 1 (AUTHORITATIVE): Extract totals from "Total" row as single source of truth
        total_shots_all_directions = 0
        total_forehand_shots = 0
        total_backhand_shots = 0
        total_backhand_slice_shots = 0
        
        # Directional totals
        total_crosscourt_shots = 0
        total_down_the_line_shots = 0
        total_down_the_middle_shots = 0
        total_inside_out_shots = 0
        total_inside_in_shots = 0
        
        # Extract authoritative totals from table1 rows
        if table1_data:
            header_key = None
            for key in table1_data.keys():
                if 'SHOT DIRECTION' in key:
                    header_key = key
                    break
            
            if header_key:
                headers = [h.strip() for h in table1_data[header_key].split(' | ')]
                
                for key, value in table1_data.items():
                    if key != header_key and 'SHOT DIRECTION' not in key:
                        row_label = key.split(' - ', 1)[1] if ' - ' in key else key
                        
                        # Skip header rows except Total
                        if any(header_word in row_label for header_word in ['SHOT DIRECTION', 'PtEnding', 'Winner', 'InduceFcd', 'UnfErr', 'inPtsWon', 'inPtsLost']):
                            continue
                        
                        values = [v.strip() for v in value.split(' | ')]
                        
                        # Extract totals from each row
                        if len(values) == len(headers) and any(v != '' and v != '0' for v in values):
                            try:
                                # Sum up all direction values for this shot type
                                shot_total = sum(int(v.split('(')[0].strip()) for v in values if v and '(' in v and v.split('(')[0].strip().isdigit())
                                
                                if 'Total' in row_label:
                                    total_shots_all_directions = shot_total  # AUTHORITATIVE
                                    
                                    # Extract directional totals from the Total row
                                    for i, header in enumerate(headers):
                                        if i < len(values) and values[i] and '(' in values[i]:
                                            direction_value = int(values[i].split('(')[0].strip())
                                            if 'Crosscourt' in header:
                                                total_crosscourt_shots = direction_value
                                            elif 'Down the line' in header:
                                                total_down_the_line_shots = direction_value
                                            elif 'Down middle' in header:
                                                total_down_the_middle_shots = direction_value
                                            elif 'Inside-out' in header:
                                                total_inside_out_shots = direction_value
                                            elif 'Inside-in' in header:
                                                total_inside_in_shots = direction_value
                                
                                elif 'Forehand' in row_label:
                                    total_forehand_shots = shot_total
                                elif 'BH slice' in row_label:
                                    total_backhand_slice_shots = shot_total
                                elif 'Backhand' in row_label:
                                    total_backhand_shots = shot_total
                            except (ValueError, IndexError):
                                continue
        
        # Add authoritative summary (TIER 1)
        if total_shots_all_directions > 0:
            text.append(f"AUTHORITATIVE TOTALS FOR {player.upper()} SHOT DIRECTIONS:")
            text.append(f"{player} hit {total_shots_all_directions} total shots in all directions including crosscourt, down the middle, down the line, inside-out, and inside-in.")
            text.append("")
            text.append("SHOT TYPE BREAKDOWN (these sum to total above, do not add again):")
            if total_forehand_shots > 0:
                text.append(f"{player} hit {total_forehand_shots} forehand shots in all directions including crosscourt, down the middle, down the line, inside-out, and inside-in.")
            if total_backhand_shots > 0:
                text.append(f"{player} hit {total_backhand_shots} backhand shots in all directions including crosscourt, down the middle, down the line, inside-out, and inside-in.")
            if total_backhand_slice_shots > 0:
                text.append(f"{player} hit {total_backhand_slice_shots} backhand slice shots in all directions including crosscourt, down the middle, down the line, inside-out, and inside-in.")
            text.append("")
            text.append("AUTHORITATIVE TOTALS BY DIRECTION (these sum to total above, do not add again):")
            text.append(f"{player} hit {total_crosscourt_shots} total crosscourt shots.")
            text.append(f"{player} hit {total_inside_out_shots} total inside-out shots.")
            text.append(f"{player} hit {total_down_the_line_shots} total down the line shots.")
            text.append(f"{player} hit {total_down_the_middle_shots} total down the middle shots.")
            text.append(f"{player} hit {total_inside_in_shots} total inside-in shots.")
            text.append("")
        
        # Process table1 (direction breakdowns)
        if table1_data:
            text.append("SHOT DIRECTION BREAKDOWN:")
            text.append("-" * 25)
            
            # Find the header row for table1
            header_key = None
            for key in table1_data.keys():
                if 'SHOT DIRECTION' in key:
                    header_key = key
                    break
            
            if header_key:
                headers = [h.strip() for h in table1_data[header_key].split(' | ')]
                
                # Process each data row in table1
                for key, value in table1_data.items():
                    if key != header_key and 'SHOT DIRECTION' not in key:
                        # Extract the row label
                        row_label = key.split(' - ', 1)[1] if ' - ' in key else key
                        
                        # Skip if this looks like a header row
                        if any(header_word in row_label for header_word in ['SHOT DIRECTION', 'Total', 'PtEnding', 'Winner', 'InduceFcd', 'UnfErr', 'inPtsWon', 'inPtsLost']):
                            continue
                        
                        # Split the value by | to get individual values
                        values = [v.strip() for v in value.split(' | ')]
                        
                        # Only process if we have valid data
                        if len(values) == len(headers) and any(v != '' and v != '0' for v in values):
                            # Convert to sentences for table1
                            sentences = self._convert_shotdir_table1_row_to_sentences(row_label, values, headers, player)
                            text.extend(sentences)
            
            text.append("")
        
        # Process table2 (detailed breakdowns by shot type and direction)
        if table2_data:
            text.append("SHOT DIRECTION DETAILED BREAKDOWN:")
            text.append("-" * 35)
            
            # Find the header row for table2
            header_key = None
            for key in table2_data.keys():
                if 'SHOT DIRECTION' in key:
                    header_key = key
                    break
            
            if header_key:
                headers = [h.strip() for h in table2_data[header_key].split(' | ')]
                
                # Process each data row in table2
                for key, value in table2_data.items():
                    if key != header_key and 'SHOT DIRECTION' not in key:
                        # Extract the row label
                        row_label = key.split(' - ', 1)[1] if ' - ' in key else key
                        
                        # Skip if this looks like a header row
                        if any(header_word in row_label for header_word in ['SHOT DIRECTION', 'Total', 'PtEnding', 'Winner', 'InduceFcd', 'UnfErr', 'inPtsWon', 'inPtsLost']):
                            continue
                        
                        # Split the value by | to get individual values
                        values = [v.strip() for v in value.split(' | ')]
                        
                        # Only process if we have valid data
                        if len(values) == len(headers) and any(v != '' and v != '0' for v in values):
                            # Convert to sentences for table2
                            sentences = self._convert_shotdir_table2_row_to_sentences(row_label, values, headers, player)
                            text.extend(sentences)
        

        
        return text

    def _convert_shotdir_table1_row_to_sentences(self, row_label: str, values: List[str], headers: List[str], player: str) -> List[str]:
        """Convert shot direction table1 row to natural language sentences"""
        sentences = []
        
        # Handle different row types
        if "Total" in row_label:
            # Total row shows breakdown by direction
            for i, value in enumerate(values):
                if i < len(headers) and value and value != "0":
                    header = headers[i]
                    
                    # Extract number and percentage from format like "57  (48%)"
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        
                        if header == "Crosscourt":
                            sentences.append(f"{player} hit {number} crosscourt shots, which represents {percentage}% of all shots hit by {player}.")
                        elif header == "Down middle":
                            sentences.append(f"{player} hit {number} down-the-middle shots, which represents {percentage}% of all shots hit by {player}.")
                        elif header == "Down the line":
                            sentences.append(f"{player} hit {number} down-the-line shots, which represents {percentage}% of all shots hit by {player}.")
                        elif header == "Inside-out":
                            sentences.append(f"{player} hit {number} inside-out shots, which represents {percentage}% of all shots hit by {player}.")
                        elif header == "Inside-in":
                            sentences.append(f"{player} hit {number} inside-in shots, which represents {percentage}% of all shots hit by {player}.")
                        else:
                            sentences.append(f"{player} hit {number} {header.lower()} shots, which represents {percentage}% of all shots hit by {player}.")
                    else:
                        sentences.append(f"{player} hit {value} {header.lower()} shots.")
        else:
            # Other rows (Forehand, Backhand, BH slice) show breakdown by direction for that shot type
            for i, value in enumerate(values):
                if i < len(headers) and value and value != "0":
                    header = headers[i]
                    
                    # Extract number and percentage from format like "57  (48%)"
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        
                        if "Forehand" in row_label:
                            if header == "Crosscourt":
                                sentences.append(f"{player} hit {number} forehand crosscourt shots, which represents {percentage}% of all forehand shots hit by {player}.")
                            elif header == "Down middle":
                                sentences.append(f"{player} hit {number} forehand down-the-middle shots, which represents {percentage}% of all forehand shots hit by {player}.")
                            elif header == "Down the line":
                                sentences.append(f"{player} hit {number} forehand down-the-line shots, which represents {percentage}% of all forehand shots hit by {player}.")
                            elif header == "Inside-out":
                                sentences.append(f"{player} hit {number} forehand inside-out shots, which represents {percentage}% of all forehand shots hit by {player}.")
                            elif header == "Inside-in":
                                sentences.append(f"{player} hit {number} forehand inside-in shots, which represents {percentage}% of all forehand shots hit by {player}.")
                        elif "Backhand" in row_label:
                            if header == "Crosscourt":
                                sentences.append(f"{player} hit {number} backhand crosscourt shots, which represents {percentage}% of all backhand shots hit by {player}.")
                            elif header == "Down middle":
                                sentences.append(f"{player} hit {number} backhand down-the-middle shots, which represents {percentage}% of all backhand shots hit by {player}.")
                            elif header == "Down the line":
                                sentences.append(f"{player} hit {number} backhand down-the-line shots, which represents {percentage}% of all backhand shots hit by {player}.")
                            elif header == "Inside-out":
                                sentences.append(f"{player} hit {number} backhand inside-out shots, which represents {percentage}% of all backhand shots hit by {player}.")
                            elif header == "Inside-in":
                                sentences.append(f"{player} hit {number} backhand inside-in shots, which represents {percentage}% of all backhand shots hit by {player}.")
                        elif "BH slice" in row_label:
                            if header == "Crosscourt":
                                sentences.append(f"{player} hit {number} backhand slice crosscourt shots, which represents {percentage}% of all backhand slice shots hit by {player}.")
                            elif header == "Down middle":
                                sentences.append(f"{player} hit {number} backhand slice down-the-middle shots, which represents {percentage}% of all backhand slice shots hit by {player}.")
                            elif header == "Down the line":
                                sentences.append(f"{player} hit {number} backhand slice down-the-line shots, which represents {percentage}% of all backhand slice shots hit by {player}.")
                            elif header == "Inside-out":
                                sentences.append(f"{player} hit {number} backhand slice inside-out shots, which represents {percentage}% of all backhand slice shots hit by {player}.")
                            elif header == "Inside-in":
                                sentences.append(f"{player} hit {number} backhand slice inside-in shots, which represents {percentage}% of all backhand slice shots hit by {player}.")
                    else:
                        if "Forehand" in row_label:
                            sentences.append(f"{player} hit {value} forehand {header.lower()} shots.")
                        elif "Backhand" in row_label:
                            sentences.append(f"{player} hit {value} backhand {header.lower()} shots.")
                        elif "BH slice" in row_label:
                            sentences.append(f"{player} hit {value} backhand slice {header.lower()} shots.")
        
        return sentences

    def _convert_shotdir_table2_row_to_sentences(self, row_label: str, values: List[str], headers: List[str], player: str) -> List[str]:
        """Convert shot direction table2 row to natural language sentences"""
        sentences = []
        
        # Extract shot type and direction from row label (e.g., "FH crosscourt_table2" -> "forehand crosscourt")
        shot_type = row_label.lower()
        
        # Remove table suffix if present
        if "_table" in shot_type:
            shot_type = shot_type.split("_table")[0]
        
        # Convert abbreviations
        if "FH" in shot_type:
            shot_type = shot_type.replace("FH", "forehand")
        if "BH" in shot_type:
            shot_type = shot_type.replace("BH", "backhand")
        if "fh" in shot_type:
            shot_type = shot_type.replace("fh", "forehand")
        if "bh" in shot_type:
            shot_type = shot_type.replace("bh", "backhand")
        
        # Convert each value to a sentence
        for i, value in enumerate(values):
            if i < len(headers) and value and value != "0":
                header = headers[i]
                
                if header == "Total":
                    sentences.append(f"{player} hit {value} {shot_type} shots.")
                elif header == "PtEnding":
                    # Extract number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} ended {number} points with {shot_type} shots, which represents {percentage}% of all {shot_type} shots hit by {player}.")
                    else:
                        sentences.append(f"{player} ended {value} points with {shot_type} shots.")
                elif header == "Winner":
                    # Extract number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} hit {number} winners with {shot_type} shots, which represents {percentage}% of all {shot_type} shots hit by {player}.")
                    else:
                        sentences.append(f"{player} hit {value} winners with {shot_type} shots.")
                elif header == "InduceFcd":
                    # Extract number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} made {number} induced forced errors with {shot_type} shots, which represents {percentage}% of all {shot_type} shots hit by {player}.")
                    else:
                        sentences.append(f"{player} made {value} induced forced errors with {shot_type} shots.")
                elif header == "UnfErr":
                    # Extract number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} made {number} unforced errors with {shot_type} shots, which represents {percentage}% of all {shot_type} shots hit by {player}.")
                    else:
                        sentences.append(f"{player} made {value} unforced errors with {shot_type} shots.")
                elif header == "inPtsWon":
                    # Extract number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} won {number} points with {shot_type} shots, which represents {percentage}% of all {shot_type} shots hit by {player}.")
                    else:
                        sentences.append(f"{player} won {value} points with {shot_type} shots.")
                elif header == "inPtsLost":
                    # Extract number and percentage
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} lost {number} points with {shot_type} shots, which represents {percentage}% of all {shot_type} shots hit by {player}.")
                    else:
                        sentences.append(f"{player} lost {value} points with {shot_type} shots.")
                else:
                    sentences.append(f"{player} had {header}: {value} with {shot_type} shots.")
        
        return sentences

    def _convert_flat_netpts_to_text(self, netpts_data: Dict[str, Any], player1: str, player2: str) -> List[str]:
        """Convert flat netpts data to natural language text"""
        text = []
        
        # Group by player
        netpts1_data = {k: v for k, v in netpts_data.items() if k.startswith('netpts1')}
        netpts2_data = {k: v for k, v in netpts_data.items() if k.startswith('netpts2')}
        
        if netpts1_data:
            text.append("NETPTS1 STATISTICS:")
            text.append("-" * 21)
            text.extend(self._convert_flat_netpts_player_to_text(netpts1_data, player1, player2))
            text.append("")
        
        if netpts2_data:
            text.append("NETPTS2 STATISTICS:")
            text.append("-" * 21)
            text.extend(self._convert_flat_netpts_player_to_text(netpts2_data, player2, player1))
            text.append("")
        
        return text

    def _convert_flat_netpts_player_to_text(self, netpts_data: Dict[str, Any], player: str, opponent: str) -> List[str]:
        """Convert flat netpts data for one player to natural language text"""
        text = []
        
        # Find table1 header row (NET POINTS)
        table1_header_key = None
        for key in netpts_data.keys():
            if 'NET POINTS' in key and '_table1' in key:
                table1_header_key = key
                break
        
        # Find table2 header row (SERVE-AND-VOLLEY)
        table2_header_key = None
        for key in netpts_data.keys():
            if 'SERVE-AND-VOLLEY' in key and '_table2' in key:
                table2_header_key = key
                break
        
        # Process table1 (NET POINTS format - general net points statistics)
        if table1_header_key:
            headers = [h.strip() for h in netpts_data[table1_header_key].split(' | ')]
            
            # Add section header for table1 (net points/net approaches)
            text.append("Net Points and Net Approaches Statistics:")
            text.append("-" * 40)
            
            # Process each table1 data row
            for key, value in netpts_data.items():
                if key != table1_header_key and '_table1' in key and 'NET POINTS' not in key and 'SERVE-AND-VOLLEY' not in key:
                    # Extract the row label
                    row_label = key.split(' - ', 1)[1] if ' - ' in key else key
                    row_label = row_label.replace('_table1', '').strip()
                    
                    # Split the value by | to get individual values
                    values = [v.strip() for v in value.split(' | ')]
                    
                    # Convert to sentences using the existing method
                    sentences = self._convert_netpts_row_to_sentences(row_label, values, headers, player)
                    text.extend(sentences)
            
            text.append("")
        
        # Process table2 (SERVE-AND-VOLLEY format - serve-and-volley vs non-serve-and-volley breakdown)
        if table2_header_key:
            headers = [h.strip() for h in netpts_data[table2_header_key].split(' | ')]
            
            # Add section header for table2 (serve-and-volley breakdown)
            text.append("Serve-and-Volley vs Non-Serve-and-Volley Breakdown:")
            text.append("-" * 47)
            
            # Process each table2 data row
            for key, value in netpts_data.items():
                if key != table2_header_key and '_table2' in key and 'SERVE-AND-VOLLEY' not in key:
                    # Extract the row label
                    row_label = key.split(' - ', 1)[1] if ' - ' in key else key
                    row_label = row_label.replace('_table2', '').strip()
                    
                    # Split the value by | to get individual values
                    values = [v.strip() for v in value.split(' | ')]
                    
                    # Convert to sentences using the table2-specific method
                    sentences = self._convert_netpts_table2_row_to_sentences(row_label, values, headers, player, opponent)
                    text.extend(sentences)
        
        return text

    def _convert_flat_serve_to_text(self, serve_data: Dict[str, Any], player1: str, player2: str) -> List[str]:
        """Convert flat serve data to natural language text"""
        text = []
        
        # Group by player
        serve1_data = {k: v for k, v in serve_data.items() if k.startswith('serve1')}
        serve2_data = {k: v for k, v in serve_data.items() if k.startswith('serve2')}
        
        # Serve1 Table 1 (Summary)
        if serve1_data:
            text.append("SERVE1 STATISTICS (SUMMARY):")
            text.append("-" * 28)
            text.extend(self._convert_flat_serve_player_table1_to_text(serve1_data, player1))
            text.append("")
        
        # Serve1 Table 2 (Detailed)
        if serve1_data:
            text.append("SERVE1 STATISTICS (DETAILED):")
            text.append("-" * 30)
            text.extend(self._convert_flat_serve_player_table2_to_text(serve1_data, player1))
            text.append("")
        
        # Serve2 Table 1 (Summary)
        if serve2_data:
            text.append("SERVE2 STATISTICS (SUMMARY):")
            text.append("-" * 28)
            text.extend(self._convert_flat_serve_player_table1_to_text(serve2_data, player2))
            text.append("")
        
        # Serve2 Table 2 (Detailed)
        if serve2_data:
            text.append("SERVE2 STATISTICS (DETAILED):")
            text.append("-" * 30)
            text.extend(self._convert_flat_serve_player_table2_to_text(serve2_data, player2))
            text.append("")
        
        return text

    def _convert_flat_serve_player_table1_to_text(self, serve_data: Dict[str, Any], player: str) -> List[str]:
        """Convert flat serve data table1 (summary) for one player to natural language text"""
        text = []
        
        # TIER 1 (AUTHORITATIVE): Calculate summary totals first
        total_aces = 0
        total_double_faults = 0
        total_points_served = 0
        total_points_won = 0
        
        # Extract authoritative totals ONLY from Deuce Court and Ad Court (non-overlapping categories)
        for key, value in serve_data.items():
            if '_table1' in key and ' - ' in key:
                location_part = key.split(' - ')[1].split('_table1')[0]
                # Only use Deuce Court and Ad Court as authoritative sources (they don't overlap)
                if location_part in ['Deuce Court', 'Ad Court']:
                    values = [v.strip() for v in value.split(' | ')]
                    if len(values) >= 8:
                        try:
                            total_points_served += int(values[0]) if values[0] and values[0] != "0" else 0
                            if "(" in values[1]:
                                total_points_won += int(values[1].split('(')[0].strip()) if values[1].split('(')[0].strip() else 0
                            total_aces += int(values[2].split('(')[0].strip()) if values[2] and "(" in values[2] else (int(values[2]) if values[2] and values[2] != "0" else 0)
                            total_double_faults += int(values[7].split('(')[0].strip()) if values[7] and "(" in values[7] else (int(values[7]) if values[7] and values[7] != "0" else 0)
                        except (ValueError, IndexError):
                            continue
        
        # Add authoritative summary (TIER 1)
        text.append(f"AUTHORITATIVE TOTALS FOR {player.upper()}:")
        text.append(f"{player} served {total_points_served} total points.")
        text.append(f"{player} won {total_points_won} total serve points.")
        text.append(f"{player} hit {total_aces} total aces.")
        text.append(f"{player} made {total_double_faults} total double faults.")
        text.append("")
        text.append("BREAKDOWN BY COURT LOCATION (these sum to totals above, do not add again):")
        text.append("")
        
        # Process each serve breakdown for table1 (summary)
        for key, value in serve_data.items():
            # Only process table1 data
            if '_table1' not in key:
                continue
                
            # Extract the location from the key
            # Format: "serve1 - Deuce Court_table1"
            if ' - ' in key and '_table1' in key:
                location_part = key.split(' - ')[1].split('_table1')[0]
                
                # Skip header rows
                if 'BREAKDOWN' in location_part:
                    continue
                
                # Split the value by | to get individual values
                values = [v.strip() for v in value.split(' | ')]
                
                # Convert location to proper description
                if 'Deuce Court' in location_part:
                    location_desc = "to the Deuce court"
                elif 'Ad Court' in location_part:
                    location_desc = "to the Ad court"
                else:
                    location_desc = location_part.lower()
                
                # Extract stats for table1 (summary)
                if len(values) >= 8:
                    total_pts = values[0]
                    won_pts = values[1]
                    aces = values[2]
                    unreturned = values[3]
                    forced_errors = values[4]
                    won_3_or_less = values[5]
                    first_serves_in = values[6]
                    double_faults = values[7]
                    
                    # Create detailed descriptions
                    if total_pts and total_pts != "0":
                        text.append(f"{player} served {location_desc} {total_pts} times.")
                        
                        # Points won
                        if won_pts and won_pts != "0":
                            if "(" in won_pts and ")" in won_pts:
                                percentage = won_pts.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} served {location_desc} and won {won_pts.split('(')[0].strip()} points, or {percentage}% of total points served {location_desc} by {player}.")
                            else:
                                text.append(f"{player} served {location_desc} and won {won_pts} points, or {won_pts}% of total points served {location_desc} by {player}.")
                        
                        # Aces
                        if aces and aces != "0":
                            if "(" in aces and ")" in aces:
                                percentage = aces.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} hit {aces.split('(')[0].strip()} aces served {location_desc}, or {percentage}% of total points served {location_desc} by {player}.")
                            else:
                                text.append(f"{player} hit {aces} aces served {location_desc}, or {aces}% of total points served {location_desc} by {player}.")
                        
                        # Unreturned serves
                        if unreturned and unreturned != "0":
                            if "(" in unreturned and ")" in unreturned:
                                percentage = unreturned.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} had {unreturned.split('(')[0].strip()} unreturned serves served {location_desc}, or {percentage}% of total points served {location_desc} by {player}.")
                            else:
                                text.append(f"{player} had {unreturned} unreturned serves served {location_desc}, or {unreturned}% of total points served {location_desc} by {player}.")
                        
                        # Forced errors
                        if forced_errors and forced_errors != "0":
                            if "(" in forced_errors and ")" in forced_errors:
                                percentage = forced_errors.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} forced {forced_errors.split('(')[0].strip()} errors from her opponent on serves {location_desc}, or {percentage}% of total points served {location_desc} by {player}.")
                            else:
                                text.append(f"{player} forced {forced_errors} errors from her opponent on serves {location_desc}, or {forced_errors}% of total points served {location_desc} by {player}.")
                        
                        # Won in 3 shots or less
                        if won_3_or_less and won_3_or_less != "0":
                            if "(" in won_3_or_less and ")" in won_3_or_less:
                                percentage = won_3_or_less.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} won {won_3_or_less.split('(')[0].strip()} points in 3 shots or less on serves {location_desc}, or {percentage}% of total points served {location_desc} by {player}.")
                            else:
                                text.append(f"{player} won {won_3_or_less} points in 3 shots or less on serves {location_desc}, or {won_3_or_less}% of total points served {location_desc} by {player}.")
                        
                        # First serves in
                        if first_serves_in and first_serves_in != "0":
                            if "(" in first_serves_in and ")" in first_serves_in:
                                percentage = first_serves_in.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} hit in {first_serves_in.split('(')[0].strip()} first serves served {location_desc}, or {percentage}% of first serves served {location_desc} by {player}.")
                            else:
                                text.append(f"{player} hit in {first_serves_in} first serves served {location_desc}, or {first_serves_in}% of first serves served {location_desc} by {player}.")
                        
                        # Double faults
                        if double_faults and double_faults != "0":
                            if "(" in double_faults and ")" in double_faults:
                                percentage = double_faults.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} served {location_desc} and had {double_faults.split('(')[0].strip()} double faults, or {percentage}% of serves {location_desc} by {player}.")
                            else:
                                text.append(f"{player} served {location_desc} and had {double_faults} double faults, or {double_faults}% of serves {location_desc} by {player}.")
        
        return text

    def _convert_flat_serve_player_table2_to_text(self, serve_data: Dict[str, Any], player: str) -> List[str]:
        """Convert flat serve data table2 (detailed) for one player to natural language text"""
        text = []
        
        # Process each serve breakdown for table2 (detailed)
        for key, value in serve_data.items():
            # Only process table2 data
            if '_table2' not in key:
                continue
                
            # Extract the location from the key
            # Format: "serve1 - Deuce Court_table2"
            if ' - ' in key and '_table2' in key:
                location_part = key.split(' - ')[1].split('_table2')[0]
                
                # Skip header rows
                if 'BREAKDOWN' in location_part:
                    continue
                
                # Split the value by | to get individual values
                values = [v.strip() for v in value.split(' | ')]
                
                # Convert location to proper description
                if 'Deuce Court' in location_part:
                    location_desc = "to the Deuce court"
                elif 'Ad Court' in location_part:
                    location_desc = "to the Ad court"
                else:
                    location_desc = location_part.lower()
                
                # Extract stats for table2 (detailed - separates first and second serves)
                if len(values) >= 12:
                    # First serve stats
                    first_pts = values[0]
                    first_won = values[1]
                    first_aces = values[2]
                    first_unreturned = values[3]
                    first_forced_errors = values[4]
                    first_won_3_or_less = values[5]
                    
                    # Second serve stats
                    second_pts = values[6]
                    second_won = values[7]
                    second_aces = values[8]
                    second_unreturned = values[9]
                    second_forced_errors = values[10]
                    second_won_3_or_less = values[11]
                    
                    # First serve details
                    if first_pts and first_pts != "0":
                        text.append(f"{player} served {location_desc} {first_pts} first serves.")
                        
                        if first_won and first_won != "0":
                            if "(" in first_won and ")" in first_won:
                                percentage = first_won.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} won {first_won.split('(')[0].strip()} first serve points {location_desc}, or {percentage}% of first serves {location_desc} by {player}.")
                            else:
                                text.append(f"{player} won {first_won} first serve points {location_desc}, or {first_won}% of first serves {location_desc} by {player}.")
                        
                        if first_aces and first_aces != "0":
                            if "(" in first_aces and ")" in first_aces:
                                percentage = first_aces.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} hit {first_aces.split('(')[0].strip()} aces on first serves {location_desc}, or {percentage}% of first serves {location_desc} by {player}.")
                            else:
                                text.append(f"{player} hit {first_aces} aces on first serves {location_desc}, or {first_aces}% of first serves {location_desc} by {player}.")
                        
                        if first_won_3_or_less and first_won_3_or_less != "0":
                            if "(" in first_won_3_or_less and ")" in first_won_3_or_less:
                                percentage = first_won_3_or_less.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} won {first_won_3_or_less.split('(')[0].strip()} first serve points in 3 shots or less {location_desc}, or {percentage}% of first serves {location_desc} by {player}.")
                            else:
                                text.append(f"{player} won {first_won_3_or_less} first serve points in 3 shots or less {location_desc}, or {first_won_3_or_less}% of first serves {location_desc} by {player}.")
                    
                    # Second serve details
                    if second_pts and second_pts != "0":
                        text.append(f"{player} served {location_desc} {second_pts} second serves.")
                        
                        if second_won and second_won != "0":
                            if "(" in second_won and ")" in second_won:
                                percentage = second_won.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} won {second_won.split('(')[0].strip()} second serve points {location_desc}, or {percentage}% of second serves {location_desc} by {player}.")
                            else:
                                text.append(f"{player} won {second_won} second serve points {location_desc}, or {second_won}% of second serves {location_desc} by {player}.")
                        
                        if second_aces and second_aces != "0":
                            if "(" in second_aces and ")" in second_aces:
                                percentage = second_aces.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} hit {second_aces.split('(')[0].strip()} aces on second serves {location_desc}, or {percentage}% of second serves {location_desc} by {player}.")
                            else:
                                text.append(f"{player} hit {second_aces} aces on second serves {location_desc}, or {second_aces}% of second serves {location_desc} by {player}.")
                        
                        if second_won_3_or_less and second_won_3_or_less != "0":
                            if "(" in second_won_3_or_less and ")" in second_won_3_or_less:
                                percentage = second_won_3_or_less.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} won {second_won_3_or_less.split('(')[0].strip()} second serve points in 3 shots or less {location_desc}, or {percentage}% of second serves {location_desc} by {player}.")
                            else:
                                text.append(f"{player} won {second_won_3_or_less} second serve points in 3 shots or less {location_desc}, or {second_won_3_or_less}% of second serves {location_desc} by {player}.")
        
        return text

    def _convert_flat_serve_player_to_text(self, serve_data: Dict[str, Any], player: str) -> List[str]:
        """Convert flat serve data for one player to natural language text"""
        text = []
        
        # Process each serve breakdown
        for key, value in serve_data.items():
            # Extract the location and table type from the key
            # Format: "serve1 - Deuce Court_table1" or "serve1 - Ad Court_table2"
            if ' - ' in key and '_table' in key:
                location_part = key.split(' - ')[1].split('_table')[0]
                table_type = key.split('_table')[1]
                
                # Skip header rows
                if 'BREAKDOWN' in location_part:
                    continue
                
                # Split the value by | to get individual values
                values = [v.strip() for v in value.split(' | ')]
                
                # Determine serve type based on table type
                if table_type == '1':
                    serve_type = "first serves"
                elif table_type == '2':
                    serve_type = "second serves"
                else:
                    serve_type = "serves"
                
                # Convert location to proper description
                if 'Deuce Court' in location_part:
                    location_desc = "to the Deuce court"
                elif 'Ad Court' in location_part:
                    location_desc = "to the Ad court"
                else:
                    location_desc = location_part.lower()
                
                # Extract stats (similar to the serve table conversion)
                if len(values) >= 8:
                    total_pts = values[0]
                    won_pts = values[1]
                    aces = values[2]
                    unreturned = values[3]
                    forced_errors = values[4]
                    won_3_or_less = values[5]
                    first_serves_in = values[6]
                    double_faults = values[7]
                    
                    # Create detailed descriptions
                    if total_pts and total_pts != "0":
                        text.append(f"{player} served {location_desc} {total_pts} times ({serve_type}).")
                        
                        # Points won
                        if won_pts and won_pts != "0":
                            if "(" in won_pts and ")" in won_pts:
                                percentage = won_pts.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} served {location_desc} and won {won_pts.split('(')[0].strip()} points, or {percentage}% of total points served {location_desc} by {player}.")
                            else:
                                text.append(f"{player} served {location_desc} and won {won_pts} points, or {won_pts}% of total points served {location_desc} by {player}.")
                        
                        # Aces
                        if aces and aces != "0":
                            if "(" in aces and ")" in aces:
                                percentage = aces.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} hit {aces.split('(')[0].strip()} aces served {location_desc}, or {percentage}% of total points served {location_desc} by {player}.")
                            else:
                                text.append(f"{player} hit {aces} aces served {location_desc}, or {aces}% of total points served {location_desc} by {player}.")
                        
                        # Unreturned serves
                        if unreturned and unreturned != "0":
                            if "(" in unreturned and ")" in unreturned:
                                percentage = unreturned.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} had {unreturned.split('(')[0].strip()} unreturned serves served {location_desc}, or {percentage}% of total points served {location_desc} by {player}.")
                            else:
                                text.append(f"{player} had {unreturned} unreturned serves served {location_desc}, or {unreturned}% of total points served {location_desc} by {player}.")
                        
                        # Forced errors
                        if forced_errors and forced_errors != "0":
                            if "(" in forced_errors and ")" in forced_errors:
                                percentage = forced_errors.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} forced {forced_errors.split('(')[0].strip()} errors from her opponent on serves {location_desc}, or {percentage}% of total points served {location_desc} by {player}.")
                            else:
                                text.append(f"{player} forced {forced_errors} errors from her opponent on serves {location_desc}, or {forced_errors}% of total points served {location_desc} by {player}.")
                        
                        # Points won in 3 shots or less
                        if won_3_or_less and won_3_or_less != "0":
                            if "(" in won_3_or_less and ")" in won_3_or_less:
                                percentage = won_3_or_less.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} won {won_3_or_less.split('(')[0].strip()} points in 3 shots or less on serves {location_desc}, or {percentage}% of total points served {location_desc} by {player}.")
                            else:
                                text.append(f"{player} won {won_3_or_less} points in 3 shots or less on serves {location_desc}, or {won_3_or_less}% of total points served {location_desc} by {player}.")
                        
                        # First serves in
                        if first_serves_in and first_serves_in != "0":
                            if "(" in first_serves_in and ")" in first_serves_in:
                                percentage = first_serves_in.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} hit in {first_serves_in.split('(')[0].strip()} first serves served {location_desc}, or {percentage}% of first serves served {location_desc} by {player}.")
                            else:
                                text.append(f"{player} hit in {first_serves_in} first serves served {location_desc}, or {first_serves_in}% of first serves served {location_desc} by {player}.")
                        
                        # Double faults
                        if double_faults and double_faults != "0":
                            if "(" in double_faults and ")" in double_faults:
                                percentage = double_faults.split("(")[1].split(")")[0].replace("%", "")
                                text.append(f"{player} served {location_desc} and had {double_faults.split('(')[0].strip()} double faults, or {percentage}% of serves {location_desc} by {player}.")
                            else:
                                text.append(f"{player} served {location_desc} and had {double_faults} double faults, or {double_faults}% of serves {location_desc} by {player}.")
        
        return text

    def _convert_flat_return_to_text(self, return_data: Dict[str, Any], player1: str, player2: str) -> List[str]:
        """Convert flat return data to natural language text"""
        text = []
        
        # Group by player
        return1_data = {k: v for k, v in return_data.items() if k.startswith('return1')}
        return2_data = {k: v for k, v in return_data.items() if k.startswith('return2')}
        
        if return1_data:
            text.append("RETURN1 STATISTICS (DETAILED):")
            text.append("-" * 32)
            text.extend(self._convert_flat_return_player_to_text(return1_data, player1))
            text.append("")
        
        if return2_data:
            text.append("RETURN2 STATISTICS (DETAILED):")
            text.append("-" * 32)
            text.extend(self._convert_flat_return_player_to_text(return2_data, player2))
            text.append("")
        
        return text

    def _convert_flat_return_player_to_text(self, return_data: Dict[str, Any], player: str) -> List[str]:
        """Convert flat return data for one player to natural language text"""
        text = []
        
        # TIER 1 (AUTHORITATIVE): Extract totals from "Total" row first
        total_returns = 0
        total_points_won = 0
        total_returnable = 0
        total_returnable_won = 0
        total_in_play = 0
        total_in_play_won = 0
        total_winners = 0
        
        # Find and process the "Total" row as authoritative source
        for key, value in return_data.items():
            if ' - ' in key and '_table' in key:
                return_type_part = key.split(' - ')[1].split('_table')[0]
                table_type = key.split('_table')[1]
                
                # Only process table1 (outcomes) and only the "Total" row
                if table_type == '1' and return_type_part.lower() == 'total':
                    values = [v.strip() for v in value.split(' | ')]
                    if len(values) >= 8:
                        try:
                            total_returns = int(values[0]) if values[0] and values[0] != "0" else 0
                            if "(" in values[1]:
                                total_points_won = int(values[1].split('(')[0].strip()) if values[1].split('(')[0].strip() else 0
                            if "(" in values[2]:
                                total_returnable = int(values[2].split('(')[0].strip()) if values[2].split('(')[0].strip() else 0
                            if "(" in values[3]:
                                total_returnable_won = int(values[3].split('(')[0].strip()) if values[3].split('(')[0].strip() else 0
                            if "(" in values[4]:
                                total_in_play = int(values[4].split('(')[0].strip()) if values[4].split('(')[0].strip() else 0
                            if "(" in values[5]:
                                total_in_play_won = int(values[5].split('(')[0].strip()) if values[5].split('(')[0].strip() else 0
                            if "(" in values[6]:
                                total_winners = int(values[6].split('(')[0].strip()) if values[6].split('(')[0].strip() else 0
                        except (ValueError, IndexError):
                            continue
                    break
        
        # Add authoritative summary (TIER 1)
        if total_returns > 0:
            text.append(f"AUTHORITATIVE TOTALS FOR {player.upper()} RETURNS:")
            text.append(f"{player} returned {total_returns} total serves.")
            text.append(f"{player} won {total_points_won} total return points.")
            text.append(f"{player} faced {total_returnable} total returnable serves (non-aces).")
            text.append(f"{player} won {total_returnable_won} total points on returnable serves.")
            text.append(f"{player} got {total_in_play} total returns in play.")
            text.append(f"{player} won {total_in_play_won} total points when returns were in play.")
            text.append(f"{player} hit {total_winners} total return winners.")
            text.append("")
            text.append("BREAKDOWN BY SERVE TYPE (these sum to totals above, do not add again):")
            text.append("")
        
        # Process each return breakdown
        for key, value in return_data.items():
            # Extract the return type and table type from the key
            # Format: "return1 - vs 1st Svs_table1" or "return1 - Deuce Court_table2"
            if ' - ' in key and '_table' in key:
                return_type_part = key.split(' - ')[1].split('_table')[0]
                table_type = key.split('_table')[1]
                
                # Skip header rows
                if 'OUTCOMES' in return_type_part or 'DEPTH' in return_type_part:
                    continue
                
                # Split the value by | to get individual values
                values = [v.strip() for v in value.split(' | ')]
                
                # Determine return type based on the return_type_part
                if 'vs 1st Svs' in return_type_part:
                    return_desc = "first serves"
                elif 'vs 2nd Svs' in return_type_part:
                    return_desc = "second serves"
                elif 'Deuce Court' in return_type_part:
                    return_desc = "serves from the Deuce court"
                elif 'Ad Court' in return_type_part:
                    return_desc = "serves from the Ad court"
                elif 'Wide serves' in return_type_part:
                    return_desc = "wide serves"
                elif 'Body serves' in return_type_part:
                    return_desc = "body serves"
                elif 'T serves' in return_type_part:
                    return_desc = "T serves"
                elif 'Deuce-Wide' in return_type_part:
                    return_desc = "wide serves from the Deuce court"
                elif 'Ad-Wide' in return_type_part:
                    return_desc = "wide serves from the Ad court"
                elif 'Deuce-Body' in return_type_part:
                    return_desc = "body serves from the Deuce court"
                elif 'Ad-Body' in return_type_part:
                    return_desc = "body serves from the Ad court"
                elif 'Deuce-T' in return_type_part:
                    return_desc = "T serves from the Deuce court"
                elif 'Ad-T' in return_type_part:
                    return_desc = "T serves from the Ad court"
                elif 'Forehand side' in return_type_part:
                    return_desc = "serves to the forehand side"
                elif 'Backhand side' in return_type_part:
                    return_desc = "serves to the backhand side"
                elif 'Flat/Topspin' in return_type_part:
                    return_desc = "flat or topspin serves"
                elif 'Slice/Chip' in return_type_part:
                    return_desc = "slice or chip serves"
                elif 'Svc Box' in return_type_part:
                    return_desc = "serves into the service box"
                elif 'Beh Svc Ln' in return_type_part:
                    return_desc = "serves behind the service line"
                elif 'Back qtr' in return_type_part:
                    return_desc = "serves to the back quarter"
                else:
                    return_desc = return_type_part.lower()
                
                # Handle table1 (outcomes) and table2 (depth) differently
                if table_type == '1':
                    # Table1: Outcomes data
                    if len(values) >= 8:
                        total_pts = values[0]
                        won_pts = values[1]
                        returnable = values[2]
                        returnable_won = values[3]
                        in_play = values[4]
                        in_play_won = values[5]
                        winners = values[6]
                        avg_rally = values[7]
                        
                        # Create detailed descriptions for outcomes
                        if total_pts and total_pts != "0":
                            # Remove "total" from the description when return_desc is "total"
                            if return_desc.lower() == "total":
                                text.append(f"{player} returned {total_pts} times.")
                            else:
                                text.append(f"{player} returned {return_desc} {total_pts} times.")
                            
                            # Points won
                            if won_pts and won_pts != "0":
                                if "(" in won_pts and ")" in won_pts:
                                    percentage = won_pts.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} returned {return_desc} and won {won_pts.split('(')[0].strip()} points, or {percentage}% of returns when {player} was returning.")
                                else:
                                    text.append(f"{player} returned {return_desc} and won {won_pts} points, or {won_pts}% of returns when {player} was returning.")
                            
                            # Returnable serves
                            if returnable and returnable != "0":
                                if "(" in returnable and ")" in returnable:
                                    percentage = returnable.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} got {returnable.split('(')[0].strip()} returnable serves when returning {return_desc}, or {percentage}% of serves when {player} was returning.")
                                else:
                                    text.append(f"{player} got {returnable} returnable serves when returning {return_desc}, or {returnable}% of serves when {player} was returning.")
                            
                            # Points won on returnable serves
                            if returnable_won and returnable_won != "0":
                                if "(" in returnable_won and ")" in returnable_won:
                                    percentage = returnable_won.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} won {returnable_won.split('(')[0].strip()} points on returnable serves when returning {return_desc}, or {percentage}% of returnable serves when {player} was returning.")
                                else:
                                    text.append(f"{player} won {returnable_won} points on returnable serves when returning {return_desc}, or {returnable_won}% of returnable serves when {player} was returning.")
                            
                            # Returns in play
                            if in_play and in_play != "0":
                                if "(" in in_play and ")" in in_play:
                                    percentage = in_play.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} got {in_play.split('(')[0].strip()} returns in play when returning {return_desc}, or {percentage}% of returns when {player} was returning.")
                                else:
                                    text.append(f"{player} got {in_play} returns in play when returning {return_desc}, or {in_play}% of returns when {player} was returning.")
                            
                            # Points won on returns in play
                            if in_play_won and in_play_won != "0":
                                if "(" in in_play_won and ")" in in_play_won:
                                    percentage = in_play_won.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} won {in_play_won.split('(')[0].strip()} points on returns in play when returning {return_desc}, or {percentage}% of returns in play when {player} was returning.")
                                else:
                                    text.append(f"{player} won {in_play_won} points on returns in play when returning {return_desc}, or {in_play_won}% of returns in play when {player} was returning.")
                            
                            # Winners
                            if winners and winners != "0":
                                if "(" in winners and ")" in winners:
                                    percentage = winners.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} hit {winners.split('(')[0].strip()} winners when returning {return_desc}, or {percentage}% of returns when {player} was returning.")
                                else:
                                    text.append(f"{player} hit {winners} winners when returning {return_desc}, or {winners}% of returns when {player} was returning.")
                            
                            # Average rally length
                            if avg_rally and avg_rally != "0":
                                text.append(f"{player} had an average rally length of {avg_rally} shots when returning {return_desc}.")
                
                elif table_type == '2':
                    # Table2: Depth data
                    if len(values) >= 9:
                        returnable = values[0]
                        shallow = values[1]
                        deep = values[2]
                        very_deep = values[3]
                        unforced_errors = values[4]
                        net_approaches = values[5]
                        deep_returns = values[6]
                        wide_returns = values[7]
                        wide_and_deep = values[8]
                        
                        # Create detailed descriptions for depth
                        if returnable and returnable != "0":
                            # Remove "returning {return_desc}" when return_desc is "total"
                            if return_desc.lower() == "total":
                                text.append(f"{player} had {returnable} returnable serves.")
                            else:
                                text.append(f"{player} had {returnable} returnable serves when returning {return_desc}.")
                            
                            # Shallow returns
                            if shallow and shallow != "0":
                                if "(" in shallow and ")" in shallow:
                                    percentage = shallow.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} hit {shallow.split('(')[0].strip()} shallow returns when returning {return_desc}, or {percentage}% of returnable serves when {player} was returning.")
                                else:
                                    text.append(f"{player} hit {shallow} shallow returns when returning {return_desc}.")
                            
                            # Deep returns
                            if deep and deep != "0":
                                if "(" in deep and ")" in deep:
                                    percentage = deep.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} hit {deep.split('(')[0].strip()} deep returns when returning {return_desc}, or {percentage}% of returnable serves when {player} was returning.")
                                else:
                                    text.append(f"{player} hit {deep} deep returns when returning {return_desc}.")
                            
                            # Very deep returns
                            if very_deep and very_deep != "0":
                                if "(" in very_deep and ")" in very_deep:
                                    percentage = very_deep.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} hit {very_deep.split('(')[0].strip()} very deep returns when returning {return_desc}, or {percentage}% of returnable serves when {player} was returning.")
                                else:
                                    text.append(f"{player} hit {very_deep} very deep returns when returning {return_desc}.")
                            
                            # Unforced errors
                            if unforced_errors and unforced_errors != "0":
                                if "(" in unforced_errors and ")" in unforced_errors:
                                    percentage = unforced_errors.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} made {unforced_errors.split('(')[0].strip()} unforced errors when returning {return_desc}, or {percentage}% of returnable serves when {player} was returning.")
                                else:
                                    text.append(f"{player} made {unforced_errors} unforced errors when returning {return_desc}.")
                            
                            # Net approaches
                            if net_approaches and net_approaches != "0":
                                if "(" in net_approaches and ")" in net_approaches:
                                    percentage = net_approaches.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} made {net_approaches.split('(')[0].strip()} net approaches when returning {return_desc}, or {percentage}% of returnable serves when {player} was returning.")
                                else:
                                    text.append(f"{player} made {net_approaches} net approaches when returning {return_desc}.")
                            
                            # Deep returns (from depth column)
                            if deep_returns and deep_returns != "0":
                                if "(" in deep_returns and ")" in deep_returns:
                                    percentage = deep_returns.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} hit {deep_returns.split('(')[0].strip()} deep returns when returning {return_desc}, or {percentage}% of returnable serves when {player} was returning.")
                                else:
                                    text.append(f"{player} hit {deep_returns} deep returns when returning {return_desc}.")
                            
                            # Wide returns
                            if wide_returns and wide_returns != "0":
                                if "(" in wide_returns and ")" in wide_returns:
                                    percentage = wide_returns.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} hit {wide_returns.split('(')[0].strip()} wide returns when returning {return_desc}, or {percentage}% of returnable serves when {player} was returning.")
                                else:
                                    text.append(f"{player} hit {wide_returns} wide returns when returning {return_desc}.")
                            
                            # Wide and deep returns
                            if wide_and_deep and wide_and_deep != "0":
                                if "(" in wide_and_deep and ")" in wide_and_deep:
                                    percentage = wide_and_deep.split("(")[1].split(")")[0].replace("%", "")
                                    text.append(f"{player} hit {wide_and_deep.split('(')[0].strip()} wide and deep returns when returning {return_desc}, or {percentage}% of returnable serves when {player} was returning.")
                                else:
                                    text.append(f"{player} hit {wide_and_deep} wide and deep returns when returning {return_desc}.")
        
        return text

    def _convert_flat_keypoints_to_text(self, keypoints_data: Dict[str, Any], player1: str, player2: str) -> List[str]:
        """Convert flat key points data to natural language text with hierarchy"""
        text = []
        
        # TIER 1 (AUTHORITATIVE): Extract key point totals as single source of truth
        player1_keypoints = {}
        player2_keypoints = {}
        
        # Group by table type
        table1_data = {k: v for k, v in keypoints_data.items() if '_table1' in k}
        table2_data = {k: v for k, v in keypoints_data.items() if '_table2' in k}
        
        # Extract authoritative totals from both tables
        if table1_data:
            player1_keypoints.update(self._extract_keypoints_totals(table1_data, player1))
        if table2_data:
            player1_keypoints.update(self._extract_keypoints_totals(table2_data, player1))
            
        if table1_data:
            player2_keypoints.update(self._extract_keypoints_totals(table1_data, player2))
        if table2_data:
            player2_keypoints.update(self._extract_keypoints_totals(table2_data, player2))
        
        # Add comprehensive authoritative summary (TIER 1)
        text.append("AUTHORITATIVE TOTALS FOR KEY POINTS:")
        text.append("-" * 35)
        
        # Extract comprehensive totals for both players
        player1_comprehensive = self._extract_comprehensive_keypoints_totals(table1_data, table2_data, player1)
        player2_comprehensive = self._extract_comprehensive_keypoints_totals(table1_data, table2_data, player2)
        
        if player1_comprehensive:
            text.append(f"{player1.upper()} KEY POINTS AUTHORITATIVE TOTALS:")
            text.append(f"{player1} faced {player1_comprehensive['total_break_points_faced']} break points total.")
            text.append(f"{player1} faced {player1_comprehensive['total_game_points_faced']} game points total.")
            text.append(f"{player1} faced {player1_comprehensive['break_points_faced_serving']} break points while serving and won {player1_comprehensive['break_points_won_serving']} of them.")
            text.append(f"{player1} faced {player1_comprehensive['break_points_faced_returning']} break points while returning and won {player1_comprehensive['break_points_won_returning']} of them.")
            text.append(f"{player1} faced {player1_comprehensive['game_points_faced_serving']} game points while serving and won {player1_comprehensive['game_points_won_serving']} of them.")
            text.append(f"{player1} faced {player1_comprehensive['game_points_faced_returning']} game points while returning and won {player1_comprehensive['game_points_won_returning']} of them.")
            text.append(f"{player1} played {player1_comprehensive['deuce_points_serving']} deuce points while serving and won {player1_comprehensive['deuce_points_won_serving']} of them.")
            text.append(f"{player1} played {player1_comprehensive['deuce_points_returning']} deuce points while returning and won {player1_comprehensive['deuce_points_won_returning']} of them.")
            text.append("")
        
        if player2_comprehensive:
            text.append(f"{player2.upper()} KEY POINTS AUTHORITATIVE TOTALS:")
            text.append(f"{player2} faced {player2_comprehensive['total_break_points_faced']} break points total.")
            text.append(f"{player2} faced {player2_comprehensive['total_game_points_faced']} game points total.")
            text.append(f"{player2} faced {player2_comprehensive['break_points_faced_serving']} break points while serving and won {player2_comprehensive['break_points_won_serving']} of them.")
            text.append(f"{player2} faced {player2_comprehensive['break_points_faced_returning']} break points while returning and won {player2_comprehensive['break_points_won_returning']} of them.")
            text.append(f"{player2} faced {player2_comprehensive['game_points_faced_serving']} game points while serving and won {player2_comprehensive['game_points_won_serving']} of them.")
            text.append(f"{player2} faced {player2_comprehensive['game_points_faced_returning']} game points while returning and won {player2_comprehensive['game_points_won_returning']} of them.")
            text.append(f"{player2} played {player2_comprehensive['deuce_points_serving']} deuce points while serving and won {player2_comprehensive['deuce_points_won_serving']} of them.")
            text.append(f"{player2} played {player2_comprehensive['deuce_points_returning']} deuce points while returning and won {player2_comprehensive['deuce_points_won_returning']} of them.")
            text.append("")
        
        text.append("DETAILED KEY POINTS BREAKDOWN (these are contextual details, not for recalculating totals):")
        text.append("")
        
        # Process detailed breakdowns (TIER 2)
        if table1_data:
            text.append("KEY POINTS STATISTICS (SERVES):")
            text.append("-" * 32)
            # Include authoritative totals at the beginning of serves section
            text.append("AUTHORITATIVE TOTALS FOR KEY POINTS:")
            text.append("-" * 35)
            if player1_comprehensive:
                text.append(f"{player1.upper()} KEY POINTS AUTHORITATIVE TOTALS:")
                text.append(f"{player1} faced {player1_comprehensive['total_break_points_faced']} break points total.")
                text.append(f"{player1} faced {player1_comprehensive['total_game_points_faced']} game points total.")
                text.append(f"{player1} faced {player1_comprehensive['break_points_faced_serving']} break points while serving and won {player1_comprehensive['break_points_won_serving']} of them.")
                text.append(f"{player1} faced {player1_comprehensive['break_points_faced_returning']} break points while returning and won {player1_comprehensive['break_points_won_returning']} of them.")
                text.append(f"{player1} faced {player1_comprehensive['game_points_faced_serving']} game points while serving and won {player1_comprehensive['game_points_won_serving']} of them.")
                text.append(f"{player1} faced {player1_comprehensive['game_points_faced_returning']} game points while returning and won {player1_comprehensive['game_points_won_returning']} of them.")
                text.append(f"{player1} played {player1_comprehensive['deuce_points_serving']} deuce points while serving and won {player1_comprehensive['deuce_points_won_serving']} of them.")
                text.append(f"{player1} played {player1_comprehensive['deuce_points_returning']} deuce points while returning and won {player1_comprehensive['deuce_points_won_returning']} of them.")
                text.append("")
            if player2_comprehensive:
                text.append(f"{player2.upper()} KEY POINTS AUTHORITATIVE TOTALS:")
                text.append(f"{player2} faced {player2_comprehensive['total_break_points_faced']} break points total.")
                text.append(f"{player2} faced {player2_comprehensive['total_game_points_faced']} game points total.")
                text.append(f"{player2} faced {player2_comprehensive['break_points_faced_serving']} break points while serving and won {player2_comprehensive['break_points_won_serving']} of them.")
                text.append(f"{player2} faced {player2_comprehensive['break_points_faced_returning']} break points while returning and won {player2_comprehensive['break_points_won_returning']} of them.")
                text.append(f"{player2} faced {player2_comprehensive['game_points_faced_serving']} game points while serving and won {player2_comprehensive['game_points_won_serving']} of them.")
                text.append(f"{player2} faced {player2_comprehensive['game_points_faced_returning']} game points while returning and won {player2_comprehensive['game_points_won_returning']} of them.")
                text.append(f"{player2} played {player2_comprehensive['deuce_points_serving']} deuce points while serving and won {player2_comprehensive['deuce_points_won_serving']} of them.")
                text.append(f"{player2} played {player2_comprehensive['deuce_points_returning']} deuce points while returning and won {player2_comprehensive['deuce_points_won_returning']} of them.")
                text.append("")
            text.append("DETAILED KEY POINTS BREAKDOWN (these are contextual details, not for recalculating totals):")
            text.append("")
            text.extend(self._convert_flat_keypoints_table_to_text(table1_data, "serves"))
            text.append("")
        
        if table2_data:
            text.append("KEY POINTS STATISTICS (RETURNS):")
            text.append("-" * 33)
            # Include authoritative totals at the beginning of returns section
            text.append("AUTHORITATIVE TOTALS FOR KEY POINTS:")
            text.append("-" * 35)
            if player1_comprehensive:
                text.append(f"{player1.upper()} KEY POINTS AUTHORITATIVE TOTALS:")
                text.append(f"{player1} faced {player1_comprehensive['total_break_points_faced']} break points total.")
                text.append(f"{player1} faced {player1_comprehensive['total_game_points_faced']} game points total.")
                text.append(f"{player1} faced {player1_comprehensive['break_points_faced_serving']} break points while serving and won {player1_comprehensive['break_points_won_serving']} of them.")
                text.append(f"{player1} faced {player1_comprehensive['break_points_faced_returning']} break points while returning and won {player1_comprehensive['break_points_won_returning']} of them.")
                text.append(f"{player1} faced {player1_comprehensive['game_points_faced_serving']} game points while serving and won {player1_comprehensive['game_points_won_serving']} of them.")
                text.append(f"{player1} faced {player1_comprehensive['game_points_faced_returning']} game points while returning and won {player1_comprehensive['game_points_won_returning']} of them.")
                text.append(f"{player1} played {player1_comprehensive['deuce_points_serving']} deuce points while serving and won {player1_comprehensive['deuce_points_won_serving']} of them.")
                text.append(f"{player1} played {player1_comprehensive['deuce_points_returning']} deuce points while returning and won {player1_comprehensive['deuce_points_won_returning']} of them.")
                text.append("")
            if player2_comprehensive:
                text.append(f"{player2.upper()} KEY POINTS AUTHORITATIVE TOTALS:")
                text.append(f"{player2} faced {player2_comprehensive['total_break_points_faced']} break points total.")
                text.append(f"{player2} faced {player2_comprehensive['total_game_points_faced']} game points total.")
                text.append(f"{player2} faced {player2_comprehensive['break_points_faced_serving']} break points while serving and won {player2_comprehensive['break_points_won_serving']} of them.")
                text.append(f"{player2} faced {player2_comprehensive['break_points_faced_returning']} break points while returning and won {player2_comprehensive['break_points_won_returning']} of them.")
                text.append(f"{player2} faced {player2_comprehensive['game_points_faced_serving']} game points while serving and won {player2_comprehensive['game_points_won_serving']} of them.")
                text.append(f"{player2} faced {player2_comprehensive['game_points_faced_returning']} game points while returning and won {player2_comprehensive['game_points_won_returning']} of them.")
                text.append(f"{player2} played {player2_comprehensive['deuce_points_serving']} deuce points while serving and won {player2_comprehensive['deuce_points_won_serving']} of them.")
                text.append(f"{player2} played {player2_comprehensive['deuce_points_returning']} deuce points while returning and won {player2_comprehensive['deuce_points_won_returning']} of them.")
                text.append("")
            text.append("DETAILED KEY POINTS BREAKDOWN (these are contextual details, not for recalculating totals):")
            text.append("")
            text.extend(self._convert_flat_keypoints_table_to_text(table2_data, "returns"))
            text.append("")
        
        return text

    def _generate_player_initials(self, player_name: str) -> str:
        """Generate player initials from full name"""
        if not player_name:
            return ""
        words = player_name.split()
        if len(words) >= 2:
            return words[0][0].upper() + words[1][0].upper()
        elif len(words) == 1:
            return words[0][:2].upper()
        return ""

    def _extract_keypoints_totals(self, keypoints_data: Dict[str, Any], player: str) -> Dict[str, str]:
        """Extract authoritative totals from key points statistics"""
        totals = {}
        
        # Generate player initials dynamically
        player_initials = self._generate_player_initials(player)
        
        # Find the header row
        header_key = None
        for key in keypoints_data.keys():
            if 'KEY POINTS:' in key:
                header_key = key
                break
        
        if header_key:
            headers = [h.strip() for h in keypoints_data[header_key].split(' | ')]
            
            # Process each data row to find player-specific totals
            for key, value in keypoints_data.items():
                if key != header_key and 'KEY POINTS:' not in key:
                    # Extract the row label
                    row_label = key.split(' - ', 1)[1] if ' - ' in key else key
                    
                    # Check if this row belongs to the target player using dynamic initials
                    if (player_initials in row_label) or (player in row_label):
                        
                        values = [v.strip() for v in value.split(' | ')]
                        
                        # Extract totals based on row type
                        if 'BP Faced' in row_label or 'Break Points' in row_label:
                            if len(values) >= 1:
                                totals['break_points_faced'] = values[0]
                            if len(values) >= 2:
                                totals['break_points_converted'] = values[1]
                        elif 'Game Pts' in row_label or 'Game Points' in row_label:
                            if len(values) >= 1:
                                totals['game_points'] = values[0]
                        elif 'Set Points' in row_label:
                            if len(values) >= 1:
                                totals['set_points'] = values[0]
                        elif 'Match Points' in row_label:
                            if len(values) >= 1:
                                totals['match_points'] = values[0]
        
        return totals
    
    def _extract_comprehensive_keypoints_totals(self, serves_data: Dict[str, Any], returns_data: Dict[str, Any], player: str) -> Dict[str, str]:
        """Extract comprehensive key points totals from both serves and returns tables"""
        comprehensive = {
            'total_break_points_faced': '0',
            'total_game_points_faced': '0',
            'break_points_faced_serving': '0',
            'break_points_won_serving': '0',
            'break_points_faced_returning': '0',
            'break_points_won_returning': '0',
            'game_points_faced_serving': '0',
            'game_points_won_serving': '0',
            'game_points_faced_returning': '0',
            'game_points_won_returning': '0',
            'deuce_points_serving': '0',
            'deuce_points_won_serving': '0',
            'deuce_points_returning': '0',
            'deuce_points_won_returning': '0'
        }
        
        # Extract from serves table (when player is serving)
        if serves_data:
            serves_totals = self._extract_keypoints_from_table(serves_data, player, "serves")
            comprehensive.update(serves_totals)
        
        # Extract from returns table (when player is returning)
        if returns_data:
            returns_totals = self._extract_keypoints_from_table(returns_data, player, "returns")
            comprehensive.update(returns_totals)
        
        # Calculate totals
        try:
            bp_serving_faced = int(comprehensive['break_points_faced_serving'])
            bp_returning_faced = int(comprehensive['break_points_faced_returning'])
            comprehensive['total_break_points_faced'] = str(bp_serving_faced + bp_returning_faced)
            
            gp_serving_faced = int(comprehensive['game_points_faced_serving'])
            gp_returning_faced = int(comprehensive['game_points_faced_returning'])
            comprehensive['total_game_points_faced'] = str(gp_serving_faced + gp_returning_faced)
            
            # Deuce points should be extracted from the data above
        except (ValueError, TypeError):
            pass
        
        return comprehensive
    
    def _extract_keypoints_from_table(self, table_data: Dict[str, Any], player: str, table_type: str) -> Dict[str, str]:
        """Extract key points data from a specific table (serves or returns)"""
        totals = {}
        
        # Generate player initials dynamically
        player_initials = self._generate_player_initials(player)
        
        # Find the header row
        header_key = None
        for key in table_data.keys():
            if 'KEY POINTS:' in key:
                header_key = key
                break
        
        if not header_key:
            return totals
        
        headers = [h.strip() for h in table_data[header_key].split(' | ')]
        
        # Process each data row to find player-specific data
        for key, value in table_data.items():
            if key != header_key and 'KEY POINTS:' not in key:
                # Extract the row label
                row_label = key.split(' - ', 1)[1] if ' - ' in key else key
                
                # Check if this row belongs to the target player using dynamic initials
                if player_initials in row_label:
                    
                    values = [v.strip() for v in value.split(' | ')]
                    
                    # Extract data based on row type and table type
                    if 'BP Faced' in row_label or 'BP Opps' in row_label:
                        if len(values) >= 1:
                            if table_type == "serves":
                                totals['break_points_faced_serving'] = values[0]
                            else:  # returns
                                totals['break_points_faced_returning'] = values[0]
                        if len(values) >= 2:
                            if table_type == "serves":
                                totals['break_points_won_serving'] = values[1].split('(')[0].strip()
                            else:  # returns
                                totals['break_points_won_returning'] = values[1].split('(')[0].strip()
                    
                    elif 'Game Pts' in row_label or 'GP Faced' in row_label:
                        if len(values) >= 1:
                            if table_type == "serves":
                                totals['game_points_faced_serving'] = values[0]
                            else:  # returns
                                totals['game_points_faced_returning'] = values[0]
                        if len(values) >= 2:
                            if table_type == "serves":
                                totals['game_points_won_serving'] = values[1].split('(')[0].strip()
                            else:  # returns
                                totals['game_points_won_returning'] = values[1].split('(')[0].strip()
                    
                    elif 'Svg Deuce' in row_label or 'Ret Deuce' in row_label:
                        if len(values) >= 1:
                            if table_type == "serves":
                                totals['deuce_points_serving'] = values[0]
                            else:  # returns
                                totals['deuce_points_returning'] = values[0]
                        if len(values) >= 2:
                            if table_type == "serves":
                                totals['deuce_points_won_serving'] = values[1].split('(')[0].strip()
                            else:  # returns
                                totals['deuce_points_won_returning'] = values[1].split('(')[0].strip()
        
        return totals

    def _convert_flat_keypoints_table_to_text(self, keypoints_data: Dict[str, Any], table_type: str) -> List[str]:
        """Convert flat key points table data to natural language text"""
        text = []
        
        # Find the header row
        header_key = None
        for key in keypoints_data.keys():
            if 'KEY POINTS:' in key:
                header_key = key
                break
        
        if header_key:
            headers = keypoints_data[header_key].split(' | ')
            
            # Process each data row
            for key, value in keypoints_data.items():
                if key != header_key and 'KEY POINTS:' not in key:
                    # Extract the row label (remove the prefix like "keypoints - ")
                    row_label = key.split(' - ', 1)[1].split('_table')[0]
                    
                    # Split the value by | to get individual values
                    values = [v.strip() for v in value.split(' | ')]
                    
                    # Convert to sentences using the existing method
                    sentences = self._convert_keypoints_row_to_sentences(row_label, values, headers, table_type)
                    text.extend(sentences)
        
        return text

    def _convert_keypoints_row_to_sentences(self, row_label: str, values: List[str], headers: List[str], table_type: str) -> List[str]:
        """Convert key points row to natural language sentences"""
        sentences = []
        
        # Determine player from row label dynamically
        player = "Unknown Player"
        if self.player1 and self.player2:
            player1_initials = ''.join([word[0] for word in self.player1.split()]).upper()
            player2_initials = ''.join([word[0] for word in self.player2.split()]).upper()
            if player1_initials in row_label:
                player = self.player1
            elif player2_initials in row_label:
                player = self.player2
        
        # Determine key point type from row label and table type
        if table_type == "serves":
            # When table_type is "serves", the player is serving
            if 'BP Faced' in row_label:
                key_point_type = "break points faced when serving"
            elif 'BP Opps' in row_label:
                key_point_type = "break point opportunities when serving"
            elif 'Game Pts' in row_label:
                key_point_type = "game points when serving"
            elif 'GP Faced' in row_label:
                key_point_type = "game points faced when serving"
            elif 'Svg Deuce' in row_label:
                key_point_type = "deuce points when serving"
            elif 'Ret Deuce' in row_label:
                key_point_type = "deuce points when returning serves"
            elif 'Total' in row_label:
                key_point_type = f"total key points ({table_type})"
            else:
                key_point_type = "key points"
        else:
            # When table_type is "returns", the player is returning
            if 'BP Faced' in row_label:
                key_point_type = "break points faced when returning serves"
            elif 'BP Opps' in row_label:
                key_point_type = "break point opportunities when returning serves"
            elif 'Game Pts' in row_label:
                key_point_type = "game points when returning serves"
            elif 'GP Faced' in row_label:
                key_point_type = "game points faced when returning serves"
            elif 'Svg Deuce' in row_label:
                key_point_type = "deuce points when serving"
            elif 'Ret Deuce' in row_label:
                key_point_type = "deuce points when returning serves"
            elif 'Total' in row_label:
                key_point_type = f"total key points ({table_type})"
            else:
                key_point_type = "key points"
        
        # Convert each value to a sentence
        for i, value in enumerate(values):
            if i < len(headers) and value and value != "0":
                header = headers[i]
                
                if header == "Pts":
                    sentences.append(f"{player} played {value} {key_point_type}.")
                elif header == "PtsW----%":
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} won {number} {key_point_type}, or {percentage}% of {key_point_type} for {player}.")
                    else:
                        sentences.append(f"{player} won {value} {key_point_type}.")
                elif header == "1stIn---%":
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} made {number} first serves in on {key_point_type}, or {percentage}% of {key_point_type} for {player}.")
                    else:
                        sentences.append(f"{player} made {value} first serves in on {key_point_type}.")
                elif header == "A-------%":
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} hit {number} aces on {key_point_type}, or {percentage}% of {key_point_type} for {player}.")
                    else:
                        sentences.append(f"{player} hit {value} aces on {key_point_type}.")
                elif header == "SvWnr---%":
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} hit {number} serve winners on {key_point_type}, or {percentage}% of {key_point_type} for {player}.")
                    else:
                        sentences.append(f"{player} hit {value} serve winners on {key_point_type}.")
                elif header == "RlyWnr--%":
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} hit {number} rally winners on {key_point_type}, or {percentage}% of {key_point_type} for {player}.")
                    else:
                        sentences.append(f"{player} hit {value} rally winners on {key_point_type}.")
                elif header == "RlyFcd--%":
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} forced {number} errors on {key_point_type}, or {percentage}% of {key_point_type} for {player}.")
                    else:
                        sentences.append(f"{player} forced {value} errors on {key_point_type}.")
                elif header == "UFE-----%":
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} made {number} unforced errors on {key_point_type}, or {percentage}% of {key_point_type} for {player}.")
                    else:
                        sentences.append(f"{player} made {value} unforced errors on {key_point_type}.")
                elif header == "DF------%":
                    if "(" in value and ")" in value:
                        number = value.split("(")[0].strip()
                        percentage = value.split("(")[1].split(")")[0].replace("%", "")
                        sentences.append(f"{player} made {number} double faults on {key_point_type}, or {percentage}% of {key_point_type} for {player}.")
                    else:
                        sentences.append(f"{player} made {value} double faults on {key_point_type}.")
        
        return sentences

    def _convert_flat_overview_to_text(self, overview_data: Dict[str, Any], player1: str, player2: str) -> List[str]:
        """Convert flat overview data to natural language text with hierarchy"""
        text = []
        
        # TIER 1 (AUTHORITATIVE): Extract key totals from Overview as single source of truth
        player1_serve_stats = {}
        player2_serve_stats = {}
        
        # Generate player initials dynamically
        player1_initials = self._generate_player_initials(player1)
        player2_initials = self._generate_player_initials(player2)
        
        # Find the header row
        header_key = None
        for key in overview_data.keys():
            if 'STATS OVERVIEW' in key:
                header_key = key
                break
        
        if header_key:
            headers = [h.strip() for h in overview_data[header_key].split(' | ')]
            
            # Process each player's data to extract authoritative totals
            for key, value in overview_data.items():
                if key != header_key and 'STATS OVERVIEW' not in key:
                    # Extract the player name
                    player = key.split(' - ', 1)[1] if ' - ' in key else key
                    
                    # Split the value by | to get individual values
                    values = [v.strip() for v in value.split(' | ')]
                    
                    # Store authoritative totals using dynamic player detection
                    if player1 in player or player1_initials in player:
                        player1_serve_stats = self._extract_overview_totals(values, headers)
                    elif player2 in player or player2_initials in player:
                        player2_serve_stats = self._extract_overview_totals(values, headers)
        
        # Add authoritative summary (TIER 1)
        text.append("AUTHORITATIVE TOTALS FROM OVERVIEW STATISTICS:")
        text.append("-" * 45)
        
        if player1_serve_stats:
            text.append(f"{player1.upper()} AUTHORITATIVE TOTALS:")
            text.append(f"First serve percentage: {player1_serve_stats.get('first_serve_pct', 'N/A')}")
            text.append(f"Second serve won percentage: {player1_serve_stats.get('second_serve_won_pct', 'N/A')}")
            text.append(f"Ace percentage: {player1_serve_stats.get('ace_pct', 'N/A')}")
            text.append(f"Double fault percentage: {player1_serve_stats.get('df_pct', 'N/A')}")
            text.append(f"Break points saved: {player1_serve_stats.get('bp_saved', 'N/A')}")
            text.append(f"Return points won percentage: {player1_serve_stats.get('return_pct', 'N/A')}")
            text.append(f"Total winners: {player1_serve_stats.get('winners', 'N/A')}")
            text.append(f"Total unforced errors: {player1_serve_stats.get('ufe', 'N/A')}")
            text.append("")
        
        if player2_serve_stats:
            text.append(f"{player2.upper()} AUTHORITATIVE TOTALS:")
            text.append(f"First serve percentage: {player2_serve_stats.get('first_serve_pct', 'N/A')}")
            text.append(f"Second serve won percentage: {player2_serve_stats.get('second_serve_won_pct', 'N/A')}")
            text.append(f"Ace percentage: {player2_serve_stats.get('ace_pct', 'N/A')}")
            text.append(f"Double fault percentage: {player2_serve_stats.get('df_pct', 'N/A')}")
            text.append(f"Break points saved: {player2_serve_stats.get('bp_saved', 'N/A')}")
            text.append(f"Return points won percentage: {player2_serve_stats.get('return_pct', 'N/A')}")
            text.append(f"Total winners: {player2_serve_stats.get('winners', 'N/A')}")
            text.append(f"Total unforced errors: {player2_serve_stats.get('ufe', 'N/A')}")
            text.append("")
        
        text.append("DETAILED BREAKDOWN (these are contextual details, not for recalculating totals):")
        text.append("")
        
        # Process detailed breakdowns (TIER 2)
        if header_key:
            headers = [h.strip() for h in overview_data[header_key].split(' | ')]
            
            for key, value in overview_data.items():
                if key != header_key and 'STATS OVERVIEW' not in key:
                    # Extract the player name
                    player = key.split(' - ', 1)[1] if ' - ' in key else key
                    
                    # Split the value by | to get individual values
                    values = [v.strip() for v in value.split(' | ')]
                    
                    # Convert to sentences
                    sentences = self._convert_overview_row_to_sentences(player, values, headers)
                    text.extend(sentences)
        
        return text

    def _extract_overview_totals(self, values: List[str], headers: List[str]) -> Dict[str, str]:
        """Extract authoritative totals from overview statistics"""
        totals = {}
        
        for i, value in enumerate(values):
            if i < len(headers) and value and value != "0":
                header = headers[i]
                
                if header == "1stIn":
                    totals['first_serve_pct'] = value
                elif header == "2nd%":
                    totals['second_serve_won_pct'] = value
                elif header == "A%":
                    totals['ace_pct'] = value
                elif header == "DF%":
                    totals['df_pct'] = value
                elif header == "BPSaved":
                    totals['bp_saved'] = value
                elif header == "RPW%":
                    totals['return_pct'] = value
                elif header == "Winners (FH/BH)":
                    totals['winners'] = value
                elif header == "UFE (FH/BH)":
                    totals['ufe'] = value
        
        return totals

    def _convert_overview_row_to_sentences(self, player: str, values: List[str], headers: List[str]) -> List[str]:
        """Convert overview statistics row to natural language sentences"""
        sentences = []
        
        # Convert each value to a sentence
        for i, value in enumerate(values):
            if i < len(headers) and value and value != "0":
                header = headers[i]
                
                if header == "A%":
                    sentences.append(f"{player} had an ace percentage of {value}.")
                elif header == "DF%":
                    sentences.append(f"{player} had a double fault percentage of {value}.")
                elif header == "1stIn":
                    sentences.append(f"{player} had a first serve percentage of {value}.")
                elif header == "1st%":
                    sentences.append(f"{player} won {value} of first serves.")
                elif header == "2nd%":
                    sentences.append(f"{player} won {value} of second serves.")
                elif header == "BPSaved":
                    sentences.append(f"{player} saved {value} break points.")
                elif header == "RPW%":
                    sentences.append(f"{player} won {value} of return points.")
                elif header == "Winners (FH/BH)":
                    sentences.append(f"{player} hit {value} winners (forehand/backhand).")
                elif header == "UFE (FH/BH)":
                    sentences.append(f"{player} made {value} unforced errors (forehand/backhand).")
                else:
                    sentences.append(f"{player} had {header}: {value}.")
        
        return sentences

    def _convert_point_log_to_text(self, point_log: List[Dict[str, Any]], player1: str, player2: str) -> List[str]:
        """Convert point-by-point data to natural language text with shot attribution and point winner"""
        text = []
        text.append("POINT-BY-POINT NARRATIVE:")
        text.append("-" * 30)
        text.append("")
        
        for i, point in enumerate(point_log, 1):
            # Extract point information
            point_num = point.get('point_number') or point.get('point') or i
            server = point.get('server', '').strip()
            sets = point.get('sets', '')
            games = point.get('games', '')
            points_score = point.get('points', '')
            description = point.get('description', '')
            
            if not description:
                continue
            
            # Determine the returner dynamically
            returner = self._determine_returner(server, player1, player2)
            
            # Parse rally and add shot attribution
            rally_shots = self._parse_rally_sequence(description, server, returner)
            
            # Determine point winner
            point_winner = self._determine_point_winner(rally_shots, server, returner)
            
            # Build formatted point text with attribution
            header = f"Point {point_num} [Server: {server} | Returner: {returner} | Score: {sets} {games} {points_score}]:"
            
            # Format rally with player attribution after each shot
            rally_parts = []
            for shot in rally_shots:
                shot_desc = shot.get('description', '')
                shot_player = shot.get('player', '')
                if shot_desc:
                    rally_parts.append(f"{shot_desc} [{shot_player}]")
            
            rally_text = "; ".join(rally_parts) + "." if rally_parts else description
            
            # Add point winner
            winner_text = f" [Point won by: {point_winner}]" if point_winner else ""
            
            text.append(f"{header}")
            text.append(f"{rally_text}{winner_text}")
            text.append("")
        
        return text
    
    def _determine_returner(self, server: str, player1: str, player2: str) -> str:
        """Determine the returner based on server and player names"""
        if not server:
            return player2
        
        server_lower = server.lower()
        p1_lower = player1.lower()
        p2_lower = player2.lower()
        
        # Exact match
        if server_lower == p1_lower:
            return player2
        elif server_lower == p2_lower:
            return player1
        
        # Partial matching (first name, last name, etc.)
        if any(part in server_lower for part in p1_lower.split()) or any(part in p1_lower for part in server_lower.split()):
            return player2
        elif any(part in server_lower for part in p2_lower.split()) or any(part in p2_lower for part in server_lower.split()):
            return player1
        
        return player2  # Default fallback
    
    def _determine_point_winner(self, rally_shots: List[Dict], server: str, returner: str, 
                                  return_details: bool = False) -> str:
        """
        UNIFIED point winner determination - use this everywhere.
        
        Args:
            rally_shots: List of parsed shot dictionaries
            server: Server name
            returner: Returner name
            return_details: If True, returns (winner, shot_type, error_player) tuple
            
        Returns:
            If return_details=False: winner name (str) or None
            If return_details=True: (winner, shot_type, error_player) tuple
        """
        if not rally_shots:
            return (None, None, None) if return_details else None
        
        winner = None
        shot_type = None
        error_player = None
        
        # Check for double fault first
        for shot in rally_shots:
            outcome = shot.get('outcome', '')
            desc_lower = shot.get('description', '').lower()
            
            # Check for double fault (generic)
            if 'double fault' in desc_lower or (outcome and 'DOUBLE' in outcome.upper()):
                winner = returner
                shot_type = 'double_fault'
                error_player = server
                return (winner, shot_type, error_player) if return_details else winner
            if '2nd serve' in desc_lower and 'fault' in desc_lower and 'fault (' not in desc_lower:
                winner = returner
                shot_type = 'double_fault'
                error_player = server
                return (winner, shot_type, error_player) if return_details else winner
        
        # Find the last shot with a decisive outcome - GENERIC using OUTCOME_CONFIG
        for shot in reversed(rally_shots):
            outcome = shot.get('outcome', '')
            shot_player = shot.get('player', '')
            desc_lower = shot.get('description', '').lower()
            
            if outcome == 'FAULT':
                continue  # Skip serve faults, look for actual outcome
            
            # GENERIC outcome handling using OUTCOME_CONFIG
            outcome_config = self._get_outcome_config(outcome)
            if outcome_config:
                winning_shot_type = outcome_config.get('winning_shot_type', '')
                player_attribution = outcome_config.get('player_attribution', '')
                is_positive = outcome_config.get('is_positive', True)
                
                if winning_shot_type:
                    shot_type = winning_shot_type
                    
                    if player_attribution == 'server':
                        winner = server if is_positive else returner
                        error_player = server if not is_positive else None
                    elif player_attribution == 'winner':
                        winner = shot_player
                        error_player = None
                    elif player_attribution == 'error':
                        # Error player loses - opponent wins
                        winner = returner if shot_player == server else server
                        error_player = shot_player
                    else:
                        winner = shot_player
                        error_player = None
                    
                    return (winner, shot_type, error_player) if return_details else winner
            
            # FALLBACK: Check description for winner/error keywords
            if 'ace' in desc_lower:
                winner = shot_player
                shot_type = 'ace'
                return (winner, shot_type, None) if return_details else winner
            elif 'winner' in desc_lower:
                winner = shot_player
                shot_type = 'winner'
                return (winner, shot_type, None) if return_details else winner
            elif 'forced error' in desc_lower:
                winner = returner if shot_player == server else server
                shot_type = 'forced_error'
                error_player = shot_player
                return (winner, shot_type, error_player) if return_details else winner
            elif 'unforced error' in desc_lower or 'error' in desc_lower:
                winner = returner if shot_player == server else server
                shot_type = 'unforced_error'
                error_player = shot_player
                return (winner, shot_type, error_player) if return_details else winner
        
        return (None, None, None) if return_details else None

    def _convert_other_data_table(self, rows: List[Dict[str, Any]]) -> List[str]:
        """Convert other data table to natural language text"""
        text = []
        text.append("OTHER DATA STATISTICS:")
        text.append("-" * 20)
        
        for row in rows:
            label = row.get('label', '')
            values = row.get('values', [])
            
            if label == 'Match Result' and values:
                text.append(f"Match result: {values[0]}")
        
        return text

    def _convert_serve_table(self, table_name: str, rows: List[Dict[str, Any]]) -> List[str]:
        """Convert serve table to natural language text"""
        text = []
        
        # Determine player
        if 'serve1' in table_name.lower():
            player = self.player1 if self.player1 else "Player 1"
            text.append("SERVE1 STATISTICS:")
        elif 'serve2' in table_name.lower():
            player = self.player2 if self.player2 else "Player 2"
            text.append("SERVE2 STATISTICS:")
        else:
            player = "Unknown Player"
            text.append(f"{table_name.upper()} STATISTICS:")
        
        text.append("-" * len(text[-1]))
        
        # Find header row
        headers = []
        data_rows = []
        
        for row in rows:
            label = row.get('label', '')
            if 'BREAKDOWN' in label:
                headers = row.get('values', [])
            else:
                data_rows.append(row)
        
        # Convert data rows
        for row in data_rows:
            label = row.get('label', '')
            values = row.get('values', [])
            
            if label and values:
                # Determine serve location and type from the row label
                serve_location = label.lower()
                
                # Convert serve location to proper description
                if 'deuce court' in serve_location:
                    location_desc = "to the Deuce court"
                elif 'ad court' in serve_location:
                    location_desc = "to the Ad court"
                elif 'wide serves' in serve_location:
                    location_desc = "wide"
                elif 'body serves' in serve_location:
                    location_desc = "into the body"
                elif 't serves' in serve_location:
                    location_desc = "down the T"
                else:
                    location_desc = serve_location
                
                # Extract all available stats
                total_pts = values[0] if len(values) > 0 else "0"
                won_pts = values[1] if len(values) > 1 else "0"
                aces = values[2] if len(values) > 2 else "0"
                unreturned = values[3] if len(values) > 3 else "0"
                forced_errors = values[4] if len(values) > 4 else "0"
                won_3_or_less = values[5] if len(values) > 5 else "0"
                first_serves_in = values[6] if len(values) > 6 else "0"
                double_faults = values[7] if len(values) > 7 else "0"
                
                # Create detailed descriptions for each serve location
                if total_pts and total_pts != "0":
                    # Total serves
                    text.append(f"{player} served {location_desc} {total_pts} times.")
                    
                    # Points won
                    if won_pts and won_pts != "0":
                        if "(" in won_pts and ")" in won_pts:
                            percentage = won_pts.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} served {location_desc} and won {won_pts.split('(')[0].strip()} points, or {percentage}% of total points served {location_desc} by {player}.")
                        else:
                            text.append(f"{player} served {location_desc} and won {won_pts} points, or {won_pts}% of total points served {location_desc} by {player}.")
                    
                    # Aces
                    if aces and aces != "0":
                        if "(" in aces and ")" in aces:
                            percentage = aces.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} hit {aces.split('(')[0].strip()} aces served {location_desc}, or {percentage}% of total points served {location_desc} by {player}.")
                        else:
                            text.append(f"{player} hit {aces} aces served {location_desc}, or {aces}% of total points served {location_desc} by {player}.")
                    
                    # Unreturned serves
                    if unreturned and unreturned != "0":
                        if "(" in unreturned and ")" in unreturned:
                            percentage = unreturned.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} had {unreturned.split('(')[0].strip()} unreturned serves served {location_desc}, or {percentage}% of total points served {location_desc} by {player}.")
                        else:
                            text.append(f"{player} had {unreturned} unreturned serves served {location_desc}, or {unreturned}% of total points served {location_desc} by {player}.")
                    
                    # Forced errors
                    if forced_errors and forced_errors != "0":
                        if "(" in forced_errors and ")" in forced_errors:
                            percentage = forced_errors.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} forced {forced_errors.split('(')[0].strip()} errors from her opponent on serves {location_desc}, or {percentage}% of total points served {location_desc} by {player}.")
                        else:
                            text.append(f"{player} forced {forced_errors} errors from her opponent on serves {location_desc}, or {forced_errors}% of total points served {location_desc} by {player}.")
                    
                    # Points won in 3 shots or less
                    if won_3_or_less and won_3_or_less != "0":
                        if "(" in won_3_or_less and ")" in won_3_or_less:
                            percentage = won_3_or_less.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} won {won_3_or_less.split('(')[0].strip()} points in 3 shots or less on serves {location_desc}, or {percentage}% of total points served {location_desc} by {player}.")
                        else:
                            text.append(f"{player} won {won_3_or_less} points in 3 shots or less on serves {location_desc}, or {won_3_or_less}% of total points served {location_desc} by {player}.")
                    
                    # First serves in
                    if first_serves_in and first_serves_in != "0":
                        if "(" in first_serves_in and ")" in first_serves_in:
                            percentage = first_serves_in.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} hit in {first_serves_in.split('(')[0].strip()} first serves served {location_desc}, or {percentage}% of first serves served {location_desc} by {player}.")
                        else:
                            text.append(f"{player} hit in {first_serves_in} first serves served {location_desc}, or {first_serves_in}% of first serves served {location_desc} by {player}.")
                    
                    # Double faults
                    if double_faults and double_faults != "0":
                        if "(" in double_faults and ")" in double_faults:
                            percentage = double_faults.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} served {location_desc} and had {double_faults.split('(')[0].strip()} double faults, or {percentage}% of serves {location_desc} by {player}.")
                        else:
                            text.append(f"{player} served {location_desc} and had {double_faults} double faults, or {double_faults}% of serves {location_desc} by {player}.")
        
        return text

    def _convert_return_table(self, table_name: str, rows: List[Dict[str, Any]]) -> List[str]:
        """Convert return table to natural language text"""
        text = []
        
        # Determine player
        if 'return1' in table_name.lower():
            player = self.player1 if self.player1 else "Player 1"
            text.append("RETURN1 STATISTICS:")
        elif 'return2' in table_name.lower():
            player = self.player2 if self.player2 else "Player 2"
            text.append("RETURN2 STATISTICS:")
        else:
            player = "Unknown Player"
            text.append(f"{table_name.upper()} STATISTICS:")
        
        text.append("-" * len(text[-1]))
        
        # Find header row
        headers = []
        data_rows = []
        
        for row in rows:
            label = row.get('label', '')
            if 'BREAKDOWN' in label:
                headers = row.get('values', [])
            else:
                data_rows.append(row)
        
        # Convert data rows
        for row in data_rows:
            label = row.get('label', '')
            values = row.get('values', [])
            
            if label and values:
                # Determine return type
                return_type = label.lower()
                if '1st serve return' in return_type:
                    return_desc = "first serves"
                elif '2nd serve return' in return_type:
                    return_desc = "second serves"
                else:
                    return_desc = return_type
                
                # Extract all available stats
                total_pts = values[0] if len(values) > 0 else "0"
                won_pts = values[1] if len(values) > 1 else "0"
                in_play = values[2] if len(values) > 2 else "0"
                in_play_won = values[3] if len(values) > 3 else "0"
                winners = values[4] if len(values) > 4 else "0"
                forced_errors = values[5] if len(values) > 5 else "0"
                unforced_errors = values[6] if len(values) > 6 else "0"
                avg_rally = values[7] if len(values) > 7 else "0"
                
                # Create detailed descriptions for each return type
                if total_pts and total_pts != "0":
                    # Total returns
                    # Remove "total" from the description when return_desc is "total"
                    if return_desc.lower() == "total":
                        text.append(f"{player} returned {total_pts} times.")
                    else:
                        text.append(f"{player} returned {return_desc} {total_pts} times.")
                    
                    # Points won
                    if won_pts and won_pts != "0":
                        if "(" in won_pts and ")" in won_pts:
                            percentage = won_pts.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} returned {return_desc} and won {won_pts.split('(')[0].strip()} points, or {percentage}% of returns for {return_desc}.")
                        else:
                            text.append(f"{player} returned {return_desc} and won {won_pts} points, or {won_pts}% of returns for {return_desc}.")
                    
                    # Returns in play
                    if in_play and in_play != "0":
                        if "(" in in_play and ")" in in_play:
                            percentage = in_play.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} got {in_play.split('(')[0].strip()} returns in play, or {percentage}% of returns when {player} was returning.")
                        else:
                            text.append(f"{player} got {in_play} returns in play, or {in_play}% of returns when {player} was returning.")
                    
                    # Points won on returns in play
                    if in_play_won and in_play_won != "0":
                        if "(" in in_play_won and ")" in in_play_won:
                            percentage = in_play_won.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} won {in_play_won.split('(')[0].strip()} points on returns in play, or {percentage}% of returns in play when {player} was returning.")
                        else:
                            text.append(f"{player} won {in_play_won} points on returns in play, or {in_play_won}% of returns in play when {player} was returning.")
                    
                    # Winners
                    if winners and winners != "0":
                        if "(" in winners and ")" in winners:
                            percentage = winners.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} hit {winners.split('(')[0].strip()} winners on returns, or {percentage}% of returns when {player} was returning.")
                        else:
                            text.append(f"{player} hit {winners} winners on returns, or {winners}% of returns when {player} was returning.")
                    
                    # Forced errors
                    if forced_errors and forced_errors != "0":
                        if "(" in forced_errors and ")" in forced_errors:
                            percentage = forced_errors.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} forced {forced_errors.split('(')[0].strip()} errors on returns, or {percentage}% of returns when {player} was returning.")
                        else:
                            text.append(f"{player} forced {forced_errors} errors on returns, or {forced_errors}% of returns when {player} was returning.")
                    
                    # Unforced errors
                    if unforced_errors and unforced_errors != "0":
                        if "(" in unforced_errors and ")" in unforced_errors:
                            percentage = unforced_errors.split("(")[1].split(")")[0].replace("%", "")
                            text.append(f"{player} made {unforced_errors.split('(')[0].strip()} unforced errors on returns, or {percentage}% of returns when {player} was returning.")
                        else:
                            text.append(f"{player} made {unforced_errors} unforced errors on returns, or {unforced_errors}% of returns when {player} was returning.")
                    
                    # Average rally length
                    if avg_rally and avg_rally != "0":
                        text.append(f"{player} had an average rally length of {avg_rally} shots when returning {return_desc}.")
        
        return text

    def _convert_keypoints_table(self, rows: List[Dict[str, Any]]) -> List[str]:
        """Convert key points table to natural language text"""
        text = []
        text.append("KEY POINTS STATISTICS:")
        text.append("-" * 22)
        
        # Find header row
        headers = []
        data_rows = []
        
        for row in rows:
            label = row.get('label', '')
            if 'KEY POINTS:' in label:
                headers = row.get('values', [])
            else:
                data_rows.append(row)
        
        # Convert data rows
        for row in data_rows:
            label = row.get('label', '')
            values = row.get('values', [])
            
            if label and values:
                # Determine player dynamically from initials
                player = "Unknown Player"
                if self.player1 and self.player2:
                    player1_initials = ''.join([word[0] for word in self.player1.split()]).upper()
                    player2_initials = ''.join([word[0] for word in self.player2.split()]).upper()
                    if player1_initials in label:
                        player = self.player1
                    elif player2_initials in label:
                        player = self.player2
                
                # Extract key stats
                total_pts = values[0] if len(values) > 0 else "0"
                won_pct = values[1] if len(values) > 1 else "0%"
                
                text.append(f"{player} played {total_pts} key points and won {won_pct} of them.")
        
        return text

    def _convert_serveneut_table(self, rows: List[Dict[str, Any]]) -> List[str]:
        """Convert serve neutral table to natural language text"""
        text = []
        text.append("SERVENEUT STATISTICS:")
        text.append("-" * 20)
        
        # Find header row
        headers = []
        data_rows = []
        
        for row in rows:
            label = row.get('label', '')
            if 'SERVE INFLUENCE' in label:
                headers = row.get('values', [])
            else:
                data_rows.append(row)
        
        # Convert data rows
        for row in data_rows:
            label = row.get('label', '')
            values = row.get('values', [])
            
            if label and values:
                # Determine player dynamically from initials
                player = "Unknown Player"
                if self.player1 and self.player2:
                    player1_initials = ''.join([word[0] for word in self.player1.split()]).upper()
                    player2_initials = ''.join([word[0] for word in self.player2.split()]).upper()
                    if player1_initials in label:
                        player = self.player1
                    elif player2_initials in label:
                        player = self.player2
                
                # Determine serve type
                if '1st Serve' in label:
                    serve_type = "first serves"
                elif '2nd Serve' in label:
                    serve_type = "second serves"
                else:
                    serve_type = "serves"
                
                # Extract key stats
                total_pts = values[0] if len(values) > 0 else "0"
                overall_pct = values[1] if len(values) > 1 else "0%"
                
                text.append(f"{player} served {total_pts} {serve_type} and won {overall_pct} of points overall.")
        
        return text

    def _convert_rallyoutcomes_table(self, rows: List[Dict[str, Any]], player1: str, player2: str) -> List[str]:
        """Convert rally outcomes table to natural language text"""
        text = []
        text.append("RALLY OUTCOMES STATISTICS:")
        text.append("-" * 26)
        
        # Generate player initials dynamically
        player1_initials = self._generate_player_initials(player1)
        player2_initials = self._generate_player_initials(player2)
        
        # Find header row
        headers = []
        data_rows = []
        
        for row in rows:
            label = row.get('label', '')
            if 'OUTCOMES' in label:
                headers = row.get('values', [])
            else:
                data_rows.append(row)
        
        # Convert data rows
        for row in data_rows:
            label = row.get('label', '')
            values = row.get('values', [])
            
            if label and values and len(values) >= 9:
                # Determine rally type and player context
                rally_type = label
                if 'Total' in label:
                    rally_type = "total rallies"
                elif 'All: 1-3' in label:
                    rally_type = "1-3 shot rallies"
                elif 'All: 4-6' in label:
                    rally_type = "4-6 shot rallies"
                elif 'All: 7-9' in label:
                    rally_type = "7-9 shot rallies"
                elif 'All: 10+' in label:
                    rally_type = "10+ shot rallies"
                elif f'{player1_initials} Sv:' in label:
                    rally_type = f"1-3 shot rallies on {player1} serves" if "1-3" in label else \
                               f"4-6 shot rallies on {player1} serves" if "4-6" in label else \
                               f"7-9 shot rallies on {player1} serves" if "7-9" in label else \
                               f"10+ shot rallies on {player1} serves" if "10+" in label else \
                               f"rallies on {player1} serves"
                elif f'{player2_initials} Sv:' in label:
                    rally_type = f"1-3 shot rallies on {player2} serves" if "1-3" in label else \
                               f"4-6 shot rallies on {player2} serves" if "4-6" in label else \
                               f"7-9 shot rallies on {player2} serves" if "7-9" in label else \
                               f"10+ shot rallies on {player2} serves" if "10+" in label else \
                               f"rallies on {player2} serves"
                
                # Extract stats for both players
                total_pts = values[0] if len(values) > 0 else "0"
                
                # Player 1 stats (columns 1-4) - strip percentages
                player1_wins = values[1].split('(')[0].strip() if len(values) > 1 and values[1] else "0"
                player1_winners = values[2].split('(')[0].strip() if len(values) > 2 and values[2] else "0"
                player1_forced_errors = values[3].split('(')[0].strip() if len(values) > 3 and values[3] else "0"
                player1_unforced_errors = values[4].split('(')[0].strip() if len(values) > 4 and values[4] else "0"
                
                # Player 2 stats (columns 5-8) - strip percentages
                player2_wins = values[5].split('(')[0].strip() if len(values) > 5 and values[5] else "0"
                player2_winners = values[6].split('(')[0].strip() if len(values) > 6 and values[6] else "0"
                player2_forced_errors = values[7].split('(')[0].strip() if len(values) > 7 and values[7] else "0"
                player2_unforced_errors = values[8].split('(')[0].strip() if len(values) > 8 and values[8] else "0"
                
                # Create sentences
                text.append(f"There were {total_pts} {rally_type} in the match.")
                
                # Add player-specific statistics
                if f'{player1_initials} Sv:' in label or f'{player2_initials} Sv:' in label:
                    # For player-specific rows, focus on that player's stats
                    if f'{player1_initials} Sv:' in label:
                        text.append(f"{player1} won {player1_wins} points and hit {player1_winners} winners on {rally_type}.")
                        text.append(f"{player1} had {player1_forced_errors} forced errors and made {player1_unforced_errors} unforced errors on {rally_type}.")
                    else:  # Player 2 Sv
                        text.append(f"{player2} won {player2_wins} points and hit {player2_winners} winners on {rally_type}.")
                        text.append(f"{player2} had {player2_forced_errors} forced errors and made {player2_unforced_errors} unforced errors on {rally_type}.")
                else:
                    # For total/all rows, show both players' stats
                    text.append(f"{player1} won {player1_wins} points and hit {player1_winners} winners on {rally_type}.")
                    text.append(f"{player1} had {player1_forced_errors} forced errors and made {player1_unforced_errors} unforced errors on {rally_type}.")
                    text.append(f"{player2} won {player2_wins} points and hit {player2_winners} winners on {rally_type}.")
                    text.append(f"{player2} had {player2_forced_errors} forced errors and made {player2_unforced_errors} unforced errors on {rally_type}.")
                
                text.append("")  # Add spacing between sections
        
        return text

    def _convert_overview_table(self, rows: List[Dict[str, Any]], player1: str, player2: str) -> List[str]:
        """Convert overview table to natural language text"""
        text = []
        text.append("OVERVIEW STATISTICS:")
        text.append("-" * 20)
        
        # Find header row
        headers = []
        data_rows = []
        
        for row in rows:
            label = row.get('label', '')
            if 'STATS OVERVIEW' in label:
                headers = row.get('values', [])
            else:
                data_rows.append(row)
        
        # Convert data rows
        for row in data_rows:
            label = row.get('label', '')
            values = row.get('values', [])
            
            if label and values:
                # Determine player
                if self.player1 and self.player1 in label:
                    player = self.player1
                elif self.player2 and self.player2 in label:
                    player = self.player2
                else:
                    # Try dynamic initials extraction as fallback
                    player = "Unknown Player"
                    if self.player1 and self.player2:
                        player1_initials = ''.join([word[0] for word in self.player1.split()]).upper()
                        player2_initials = ''.join([word[0] for word in self.player2.split()]).upper()
                        if player1_initials in label:
                            player = self.player1
                        elif player2_initials in label:
                            player = self.player2
                
                # Extract key stats
                ace_pct = values[0] if len(values) > 0 else "0%"
                df_pct = values[1] if len(values) > 1 else "0%"
                first_serve_pct = values[2] if len(values) > 2 else "0%"
                first_serve_won_pct = values[3] if len(values) > 3 else "0%"
                second_serve_won_pct = values[4] if len(values) > 4 else "0%"
                break_points_saved = values[5] if len(values) > 5 else "0"
                return_points_won_pct = values[6] if len(values) > 6 else "0%"
                winners = values[7] if len(values) > 7 else "0"
                unforced_errors = values[8] if len(values) > 8 else "0"
                
                text.append(f"{player} had {ace_pct} aces.")
                text.append(f"{player} had {df_pct} double faults.")
                text.append(f"{player} made {first_serve_pct} of first serves.")
                text.append(f"{player} won {first_serve_won_pct} of first serve points.")
                text.append(f"{player} won {second_serve_won_pct} of second serve points.")
                text.append(f"{player} saved {break_points_saved} break points.")
                text.append(f"{player} won {return_points_won_pct} of return points.")
                # Parse the winners and unforced errors to extract forehand/backhand breakdowns
                winners_total = winners.split(" (")[0] if " (" in winners else winners
                winners_fh_bh = winners.split("(")[1].split(")")[0] if "(" in winners else "0/0"
                winners_fh, winners_bh = winners_fh_bh.split("/") if "/" in winners_fh_bh else ("0", "0")
                
                ufe_total = unforced_errors.split(" (")[0] if " (" in unforced_errors else unforced_errors
                ufe_fh_bh = unforced_errors.split("(")[1].split(")")[0] if "(" in unforced_errors else "0/0"
                ufe_fh, ufe_bh = ufe_fh_bh.split("/") if "/" in ufe_fh_bh else ("0", "0")
                
                text.append(f"{player} hit {winners_total} winners, {winners_fh} forehand and {winners_bh} backhand.")
                text.append(f"{player} made {ufe_total} unforced errors, including {ufe_fh} on the forehand and {ufe_bh} on the backhand.")
        
        return text



    def _convert_generic_table(self, table_name: str, rows: List[Dict[str, Any]]) -> List[str]:
        """Convert generic table to natural language text"""
        text = []
        text.append(f"{table_name.upper()} STATISTICS:")
        text.append("-" * len(table_name + " STATISTICS"))
        
        for row in rows:
            label = row.get('label', '')
            values = row.get('values', [])
            
            if label and values:
                text.append(f"{label}: {', '.join(values)}")
        
        return text


